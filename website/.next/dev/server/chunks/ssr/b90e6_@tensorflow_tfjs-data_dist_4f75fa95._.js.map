{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 4, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-data@4.22.0_@tensorflow+tfjs-core@4.22.0_seedrandom@3.0.5/node_modules/@tensorflow/tfjs-data/dist/util/deep_map.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-data/src/util/deep_map.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs-core';\n\n// tslint:disable:no-any\n\n/**\n * A return value for a mapping function that can be applied via deepMap.\n *\n * If recurse is true, the value should be empty, and iteration will continue\n * into the object or array.\n */\nexport type DeepMapResult = {\n  value: any,\n  recurse: boolean\n};\n\n/**\n * Apply a mapping function to a nested structure in a recursive manner.\n *\n * The result of the mapping is an object with the same nested structure (i.e.,\n * of arrays and dicts) as the input, except that some subtrees are replaced,\n * according to the results of the mapping function.\n *\n * Mappings are memoized.  Thus, if the nested structure contains the same\n * object in multiple positions, the output will contain the same mapped object\n * in those positions.  Cycles are not supported, however.\n *\n * @param input: The object to which to apply the mapping function.\n * @param mapFn: A function that expects a single node of the object tree, and\n *   returns a `DeepMapResult`.  The `DeepMapResult` either provides a\n *   replacement value for that node (i.e., replacing the subtree), or indicates\n *   that the node should be processed recursively.\n */\nexport function deepMap(input: any, mapFn: (x: any) => DeepMapResult): any|\n    any[] {\n  return deepMapInternal(input, mapFn);\n}\n\n/**\n * @param seen: A Map of known object mappings (i.e., memoized results of\n *   `mapFn()`)\n * @param containedIn: An set containing objects on the reference path currently\n *   being processed (used to detect cycles).\n */\nfunction deepMapInternal(\n    input: any, mapFn: (x: any) => DeepMapResult,\n    seen: Map<any, any> = new Map(), containedIn: Set<{}> = new Set()): any|\n    any[] {\n  if (input == null) {\n    return null;\n  }\n  if (typeof Blob === 'function' && input instanceof Blob) {\n    return input.slice();\n  }\n\n  if (containedIn.has(input)) {\n    throw new Error('Circular references are not supported.');\n  }\n  if (seen.has(input)) {\n    return seen.get(input);\n  }\n  const result = mapFn(input);\n\n  if (result.recurse && result.value !== null) {\n    throw new Error(\n        'A deep map function may not return both a value and recurse=true.');\n  }\n\n  if (!result.recurse) {\n    seen.set(input, result.value);\n    return result.value;\n  } else if (isIterable(input)) {\n    // tslint:disable-next-line:no-any\n    const mappedIterable: any|any[] = Array.isArray(input) ? [] : {};\n    containedIn.add(input);\n    for (const k in input) {\n      const child = input[k];\n      const childResult = deepMapInternal(child, mapFn, seen, containedIn);\n      mappedIterable[k] = childResult;\n    }\n    containedIn.delete(input);\n    if (input.__proto__) {\n      mappedIterable.__proto__ = input.__proto__;\n    }\n    return mappedIterable;\n  } else {\n    throw new Error(`Can't recurse into non-iterable type: ${input}`);\n  }\n}\n\n// TODO(soergel, kangyizhang) Reconsider naming of deepZip() to avoid confusion\n// with zip()\n\n/**\n * Zip nested structures together in a recursive manner.\n *\n * This has the effect of transposing or pivoting data, e.g. converting it from\n * a row-major representation to a column-major representation.\n *\n * For example, `deepZip([{a: 1, b: 2}, {a: 3, b: 4}])` returns\n * `{a: [1, 3], b: [2, 4]}`.\n *\n * The inputs should all have the same nested structure (i.e., of arrays and\n * dicts).  The result is a single object with the same nested structure, where\n * the leaves are arrays collecting the values of the inputs at that location\n * (or, optionally, the result of a custom function applied to those arrays).\n *\n * @param inputs: An array of the objects to zip together.\n * @param zipFn: (optional) A function that expects an array of elements at a\n *   single node of the object tree, and returns a `DeepMapResult`.  The\n *   `DeepMapResult` either provides a result value for that node (i.e.,\n *   representing the subtree), or indicates that the node should be processed\n *   recursively.  The default zipFn recurses as far as possible and places\n *   arrays at the leaves.\n */\nexport function deepZip(\n    inputs: any[], zipFn: (xs: any[]) => DeepMapResult = zipToList): any|any[] {\n  return deepZipInternal(inputs, zipFn);\n}\n\n/**\n * @param containedIn: An set containing objects on the reference path currently\n *   being processed (used to detect cycles).\n */\nfunction deepZipInternal(\n    inputs: any[], zipFn: (xs: any[]) => DeepMapResult,\n    containedIn: Set<{}> = new Set()): any|any[] {\n  // The recursion follows the structure of input 0; it's assumed that all the\n  // other inputs have the same structure.\n  const input = inputs[0];\n  if (containedIn.has(input)) {\n    throw new Error('Circular references are not supported.');\n  }\n  const result = zipFn(inputs);\n\n  if (result.recurse && result.value !== null) {\n    throw new Error(\n        'A deep zip function may not return both a value and recurse=true.');\n  }\n\n  if (!result.recurse) {\n    return result.value;\n  } else if (isIterable(input)) {\n    // tslint:disable-next-line:no-any\n    const mappedIterable: any|any[] = Array.isArray(input) ? [] : {};\n    containedIn.add(input);\n    for (const k in input) {\n      const children = inputs.map(x => x[k]);\n      const childResult = deepZipInternal(children, zipFn, containedIn);\n      mappedIterable[k] = childResult;\n    }\n    containedIn.delete(input);\n    return mappedIterable;\n  } else {\n    throw new Error(`Can't recurse into non-iterable type: ${input}`);\n  }\n}\n\n// tslint:disable-next-line:no-any\nexport function zipToList(x: any[]): DeepMapResult {\n  if (x === null) {\n    return null;\n  }\n  // TODO(soergel): validate array type?\n\n  if (isIterable(x[0])) {\n    return {value: null, recurse: true};\n  } else {\n    return {value: x, recurse: false};\n  }\n}\n\n/**\n * A return value for an async map function for use with deepMapAndAwaitAll.\n *\n * If recurse is true, the value should be empty, and iteration will continue\n * into the object or array.\n */\nexport type DeepMapAsyncResult = {\n  value: Promise<any>,\n  recurse: boolean\n};\n\n/**\n * Apply an async mapping function to a nested structure in a recursive manner.\n *\n * This first creates a nested structure of Promises, and then awaits all of\n * those, resulting in a single Promise for a resolved nested structure.\n *\n * The result of the mapping is an object with the same nested structure (i.e.,\n * of arrays and dicts) as the input, except that some subtrees are replaced,\n * according to the results of the mapping function.\n *\n * Mappings are memoized.  Thus, if the nested structure contains the same\n * object in multiple positions, the output will contain the same mapped object\n * in those positions.  Cycles are not supported, however.\n *\n * @param input: The object to which to apply the mapping function.\n * @param mapFn: A function that expects a single node of the object tree, and\n *   returns a `DeepMapAsyncResult`.  The `DeepMapAsyncResult` either provides\n *   a `Promise` for a replacement value for that node (i.e., replacing the\n *   subtree), or indicates that the node should be processed recursively.  Note\n *   that the decision whether or not to recurse must be made immediately; only\n *   the mapped value may be promised.\n */\nexport async function deepMapAndAwaitAll(\n    input: any, mapFn: (x: any) => DeepMapAsyncResult): Promise<any|any[]> {\n  const seen: Map<any, any> = new Map();\n\n  // First do a normal deepMap, collecting Promises in 'seen' as a side effect.\n  deepMapInternal(input, mapFn, seen);\n\n  // Replace the Promises in 'seen' in place.\n  // Note TypeScript provides no async map iteration, and regular map iteration\n  // is broken too, so sadly we have to do Array.from() to make it work.\n  // (There's no advantage to Promise.all(), and that would be tricky anyway.)\n  for (const key of Array.from(seen.keys())) {\n    const value = seen.get(key);\n    if (tf.util.isPromise(value)) {\n      const mappedValue = await value;\n      seen.set(key, mappedValue);\n    }\n  }\n\n  // Normal deepMap again, this time filling in the resolved values.\n  // It's unfortunate that we have to do two passes.\n  // TODO(soergel): test performance and think harder about a fast solution.\n  const result = deepMapInternal(input, mapFn, seen);\n  return result;\n}\n\n/**\n * Determine whether the argument is iterable.\n *\n * @returns true if the argument is an array or any non-Tensor object.\n */\n// tslint:disable-next-line:no-any\nexport function isIterable(obj: any): boolean {\n  let isTextDecoder = false;\n  if (tf.env().get('IS_BROWSER')) {\n    isTextDecoder = obj instanceof TextDecoder;\n  } else {\n    // tslint:disable-next-line:no-require-imports\n    const {StringDecoder} = require('string_decoder');\n    isTextDecoder = obj instanceof StringDecoder;\n  }\n  return obj != null && (!ArrayBuffer.isView(obj)) &&\n      (Array.isArray(obj) ||\n       (typeof obj === 'object' && !(obj instanceof tf.Tensor) &&\n        !(obj instanceof Promise) && !isTextDecoder));\n}\n\n/**\n * Determine whether the argument can be converted to Tensor.\n *\n * Tensors, primitives, arrays, and TypedArrays all qualify; anything else does\n * not.\n *\n * @returns true if the argument can be converted to Tensor.\n */\n// tslint:disable-next-line:no-any\nexport function canTensorify(obj: any): boolean {\n  return obj == null || isPrimitive(obj) || Array.isArray(obj) ||\n      (typeof obj === 'object' && (obj instanceof tf.Tensor)) ||\n      tf.util.isTypedArray(obj);\n}\n\n/**\n * Returns true if the given `value` is a primitive type. Otherwise returns\n * false. This is equivalant to node util.isPrimitive\n */\nfunction isPrimitive(value: any): boolean {\n  return (\n      value === null ||\n      (typeof value !== 'object' && typeof value !== 'function'));\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;AAAA;;;;;;;;;;;;;;;;GAgBG;;;AAEH,OAAO,KAAK,EAAE,MAAM,uBAAuB,CAAC;;AAgCtC,SAAU,OAAO,CAAC,KAAU,EAAE,KAAgC;IAElE,OAAO,eAAe,CAAC,KAAK,EAAE,KAAK,CAAC,CAAC;AACvC,CAAC;AAED;;;;;GAKG,CACH,SAAS,eAAe,CACpB,KAAU,EAAE,KAAgC,EAC5C,OAAsB,IAAI,GAAG,EAAE,EAAE,cAAuB,IAAI,GAAG,EAAE;IAEnE,IAAI,KAAK,IAAI,IAAI,EAAE;QACjB,OAAO,IAAI,CAAC;KACb;IACD,IAAI,OAAO,IAAI,KAAK,UAAU,IAAI,KAAK,YAAY,IAAI,EAAE;QACvD,OAAO,KAAK,CAAC,KAAK,EAAE,CAAC;KACtB;IAED,IAAI,WAAW,CAAC,GAAG,CAAC,KAAK,CAAC,EAAE;QAC1B,MAAM,IAAI,KAAK,CAAC,wCAAwC,CAAC,CAAC;KAC3D;IACD,IAAI,IAAI,CAAC,GAAG,CAAC,KAAK,CAAC,EAAE;QACnB,OAAO,IAAI,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC;KACxB;IACD,MAAM,MAAM,GAAG,KAAK,CAAC,KAAK,CAAC,CAAC;IAE5B,IAAI,MAAM,CAAC,OAAO,IAAI,MAAM,CAAC,KAAK,KAAK,IAAI,EAAE;QAC3C,MAAM,IAAI,KAAK,CACX,mEAAmE,CAAC,CAAC;KAC1E;IAED,IAAI,CAAC,MAAM,CAAC,OAAO,EAAE;QACnB,IAAI,CAAC,GAAG,CAAC,KAAK,EAAE,MAAM,CAAC,KAAK,CAAC,CAAC;QAC9B,OAAO,MAAM,CAAC,KAAK,CAAC;KACrB,MAAM,IAAI,UAAU,CAAC,KAAK,CAAC,EAAE;QAC5B,kCAAkC;QAClC,MAAM,cAAc,GAAc,KAAK,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAA,CAAE,CAAC;QACjE,WAAW,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC;QACvB,IAAK,MAAM,CAAC,IAAI,KAAK,CAAE;YACrB,MAAM,KAAK,GAAG,KAAK,CAAC,CAAC,CAAC,CAAC;YACvB,MAAM,WAAW,GAAG,eAAe,CAAC,KAAK,EAAE,KAAK,EAAE,IAAI,EAAE,WAAW,CAAC,CAAC;YACrE,cAAc,CAAC,CAAC,CAAC,GAAG,WAAW,CAAC;SACjC;QACD,WAAW,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC;QAC1B,IAAI,KAAK,CAAC,SAAS,EAAE;YACnB,cAAc,CAAC,SAAS,GAAG,KAAK,CAAC,SAAS,CAAC;SAC5C;QACD,OAAO,cAAc,CAAC;KACvB,MAAM;QACL,MAAM,IAAI,KAAK,CAAC,CAAA,sCAAA,EAAyC,KAAK,EAAE,CAAC,CAAC;KACnE;AACH,CAAC;AA2BK,SAAU,OAAO,CACnB,MAAa,EAAE,QAAsC,SAAS;IAChE,OAAO,eAAe,CAAC,MAAM,EAAE,KAAK,CAAC,CAAC;AACxC,CAAC;AAED;;;GAGG,CACH,SAAS,eAAe,CACpB,MAAa,EAAE,KAAmC,EAClD,cAAuB,IAAI,GAAG,EAAE;IAClC,4EAA4E;IAC5E,wCAAwC;IACxC,MAAM,KAAK,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;IACxB,IAAI,WAAW,CAAC,GAAG,CAAC,KAAK,CAAC,EAAE;QAC1B,MAAM,IAAI,KAAK,CAAC,wCAAwC,CAAC,CAAC;KAC3D;IACD,MAAM,MAAM,GAAG,KAAK,CAAC,MAAM,CAAC,CAAC;IAE7B,IAAI,MAAM,CAAC,OAAO,IAAI,MAAM,CAAC,KAAK,KAAK,IAAI,EAAE;QAC3C,MAAM,IAAI,KAAK,CACX,mEAAmE,CAAC,CAAC;KAC1E;IAED,IAAI,CAAC,MAAM,CAAC,OAAO,EAAE;QACnB,OAAO,MAAM,CAAC,KAAK,CAAC;KACrB,MAAM,IAAI,UAAU,CAAC,KAAK,CAAC,EAAE;QAC5B,kCAAkC;QAClC,MAAM,cAAc,GAAc,KAAK,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAA,CAAE,CAAC;QACjE,WAAW,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC;QACvB,IAAK,MAAM,CAAC,IAAI,KAAK,CAAE;YACrB,MAAM,QAAQ,GAAG,MAAM,CAAC,GAAG,EAAC,CAAC,CAAC,EAAE,AAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;YACvC,MAAM,WAAW,GAAG,eAAe,CAAC,QAAQ,EAAE,KAAK,EAAE,WAAW,CAAC,CAAC;YAClE,cAAc,CAAC,CAAC,CAAC,GAAG,WAAW,CAAC;SACjC;QACD,WAAW,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC;QAC1B,OAAO,cAAc,CAAC;KACvB,MAAM;QACL,MAAM,IAAI,KAAK,CAAC,CAAA,sCAAA,EAAyC,KAAK,EAAE,CAAC,CAAC;KACnE;AACH,CAAC;AAGK,SAAU,SAAS,CAAC,CAAQ;IAChC,IAAI,CAAC,KAAK,IAAI,EAAE;QACd,OAAO,IAAI,CAAC;KACb;IACD,sCAAsC;IAEtC,IAAI,UAAU,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE;QACpB,OAAO;YAAC,KAAK,EAAE,IAAI;YAAE,OAAO,EAAE,IAAI;QAAA,CAAC,CAAC;KACrC,MAAM;QACL,OAAO;YAAC,KAAK,EAAE,CAAC;YAAE,OAAO,EAAE,KAAK;QAAA,CAAC,CAAC;KACnC;AACH,CAAC;AAmCM,KAAK,UAAU,kBAAkB,CACpC,KAAU,EAAE,KAAqC;IACnD,MAAM,IAAI,GAAkB,IAAI,GAAG,EAAE,CAAC;IAEtC,6EAA6E;IAC7E,eAAe,CAAC,KAAK,EAAE,KAAK,EAAE,IAAI,CAAC,CAAC;IAEpC,2CAA2C;IAC3C,6EAA6E;IAC7E,sEAAsE;IACtE,4EAA4E;IAC5E,KAAK,MAAM,GAAG,IAAI,KAAK,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,EAAE,CAAC,CAAE;QACzC,MAAM,KAAK,GAAG,IAAI,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC;QAC5B,IAAI,EAAE,CAAC,2QAAI,CAAC,SAAS,CAAC,KAAK,CAAC,EAAE;YAC5B,MAAM,WAAW,GAAG,MAAM,KAAK,CAAC;YAChC,IAAI,CAAC,GAAG,CAAC,GAAG,EAAE,WAAW,CAAC,CAAC;SAC5B;KACF;IAED,kEAAkE;IAClE,kDAAkD;IAClD,0EAA0E;IAC1E,MAAM,MAAM,GAAG,eAAe,CAAC,KAAK,EAAE,KAAK,EAAE,IAAI,CAAC,CAAC;IACnD,OAAO,MAAM,CAAC;AAChB,CAAC;AAQK,SAAU,UAAU,CAAC,GAAQ;IACjC,IAAI,aAAa,GAAG,KAAK,CAAC;IAC1B,IAAI,EAAE,CAAC,iPAAG,EAAE,CAAC,GAAG,CAAC,YAAY,CAAC,EAAE;QAC9B,aAAa,GAAG,GAAG,YAAY,WAAW,CAAC;KAC5C,MAAM;QACL,8CAA8C;QAC9C,MAAM,EAAC,aAAa,EAAC,GAAG,OAAO,CAAC,gBAAgB,CAAC,CAAC;QAClD,aAAa,GAAG,GAAG,YAAY,aAAa,CAAC;KAC9C;IACD,OAAO,GAAG,IAAI,IAAI,IAAI,AAAC,CAAC,WAAW,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,GAC5C,CAAC,KAAK,CAAC,OAAO,CAAC,GAAG,CAAC,IACjB,OAAO,GAAG,KAAK,QAAQ,IAAI,CAAC,CAAC,GAAG,YAAY,EAAE,CAAC,+OAAM,CAAC,IACtD,CAAC,CAAC,GAAG,YAAY,OAAO,CAAC,IAAI,CAAC,aAAa,AAAC,CAAC,CAAC;AACtD,CAAC;AAWK,SAAU,YAAY,CAAC,GAAQ;IACnC,OAAO,GAAG,IAAI,IAAI,IAAI,WAAW,CAAC,GAAG,CAAC,IAAI,KAAK,CAAC,OAAO,CAAC,GAAG,CAAC,IACvD,OAAO,GAAG,KAAK,QAAQ,IAAI,AAAC,GAAG,YAAY,EAAE,CAAC,+OAAM,CAAC,CAAC,EACvD,EAAE,CAAC,2QAAI,CAAC,YAAY,CAAC,GAAG,CAAC,CAAC;AAChC,CAAC;AAED;;;GAGG,CACH,SAAS,WAAW,CAAC,KAAU;IAC7B,OAAO,AACH,KAAK,KAAK,IAAI,IACb,OAAO,KAAK,KAAK,QAAQ,IAAI,OAAO,KAAK,KAAK,UAAU,CAAC,CAAC,CAAC;AAClE,CAAC"}},
    {"offset": {"line": 181, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-data@4.22.0_@tensorflow+tfjs-core@4.22.0_seedrandom@3.0.5/node_modules/@tensorflow/tfjs-data/dist/util/deep_clone.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-data/src/util/deep_clone.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs-core';\nimport {deepMap, DeepMapResult, isIterable} from './deep_map';\n\nexport function deepClone<T>(container: T): T {\n  return deepMap(container, cloneIfTensor);\n}\n\n// tslint:disable-next-line: no-any\nfunction cloneIfTensor(item: any): DeepMapResult {\n  if (item instanceof tf.Tensor) {\n    return ({value: item.clone(), recurse: false});\n  } else if (isIterable(item)) {\n    return {value: null, recurse: true};\n  } else {\n    return {value: item, recurse: false};\n  }\n}\n"],"names":[],"mappings":";;;;AAAA;;;;;;;;;;;;;;;;GAgBG;AAEH,OAAO,KAAK,EAAE,MAAM,uBAAuB,CAAC;AAC5C,OAAO,EAAC,OAAO,EAAiB,UAAU,EAAC,MAAM,YAAY,CAAC;;;AAExD,SAAU,SAAS,CAAI,SAAY;IACvC,WAAO,sUAAO,EAAC,SAAS,EAAE,aAAa,CAAC,CAAC;AAC3C,CAAC;AAED,mCAAmC;AACnC,SAAS,aAAa,CAAC,IAAS;IAC9B,IAAI,IAAI,YAAY,EAAE,CAAC,+OAAM,EAAE;QAC7B,OAAO,AAAC;YAAC,KAAK,EAAE,IAAI,CAAC,KAAK,EAAE;YAAE,OAAO,EAAE,KAAK;QAAA,CAAC,CAAC,CAAC;KAChD,MAAM,QAAI,yUAAU,EAAC,IAAI,CAAC,EAAE;QAC3B,OAAO;YAAC,KAAK,EAAE,IAAI;YAAE,OAAO,EAAE,IAAI;QAAA,CAAC,CAAC;KACrC,MAAM;QACL,OAAO;YAAC,KAAK,EAAE,IAAI;YAAE,OAAO,EAAE,KAAK;QAAA,CAAC,CAAC;KACtC;AACH,CAAC"}},
    {"offset": {"line": 232, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-data@4.22.0_@tensorflow+tfjs-core@4.22.0_seedrandom@3.0.5/node_modules/@tensorflow/tfjs-data/dist/util/ring_buffer.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-data/src/util/ring_buffer.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\n\n/**\n * A ring buffer, providing O(1) FIFO, LIFO, and related operations.\n */\nexport class RingBuffer<T> {\n  // Note we store the indices in the range 0 <= index < 2*capacity.\n  // This allows us to distinguish the full from the empty case.\n  // See https://www.snellman.net/blog/archive/2016-12-13-ring-buffers/\n  protected begin = 0;  // inclusive\n  protected end = 0;    // exclusive\n  protected doubledCapacity: number;\n\n  protected data: T[];\n\n  /**\n   * Constructs a `RingBuffer`.\n   * @param capacity The number of items that the buffer can accomodate.\n   */\n  constructor(public capacity: number) {\n    if (capacity == null) {\n      throw new RangeError('Can\\'t create a ring buffer of unknown capacity.');\n    }\n    if (capacity < 1) {\n      throw new RangeError('Can\\'t create ring buffer of capacity < 1.');\n    }\n    this.data = new Array<T>(capacity);\n    this.doubledCapacity = 2 * capacity;\n  }\n\n  /**\n   * Map any index into the range 0 <= index < 2*capacity.\n   */\n  protected wrap(index: number) {\n    // don't trust % on negative numbers\n    while (index < 0) {\n      index += this.doubledCapacity;\n    }\n    return index % this.doubledCapacity;\n  }\n\n  protected get(index: number) {\n    if (index < 0) {\n      throw new RangeError('Can\\'t get item at a negative index.');\n    }\n    return this.data[index % this.capacity];\n  }\n\n  protected set(index: number, value: T) {\n    if (index < 0) {\n      throw new RangeError('Can\\'t set item at a negative index.');\n    }\n    this.data[index % this.capacity] = value;\n  }\n\n  /**\n   * Returns the current number of items in the buffer.\n   */\n  length(): number {\n    let length = this.end - this.begin;\n    if (length < 0) {\n      length = this.doubledCapacity + length;\n    }\n    return length;\n  }\n\n  /**\n   * Reports whether the buffer is full.\n   * @returns true if the number of items in the buffer equals its capacity, and\n   *   false otherwise.\n   */\n  isFull() {\n    return this.length() === this.capacity;\n  }\n\n  /**\n   * Reports whether the buffer is empty.\n   * @returns true if the number of items in the buffer equals zero, and\n   *   false otherwise.\n   */\n  isEmpty() {\n    return this.length() === 0;\n  }\n\n  /**\n   * Adds an item to the end of the buffer.\n   */\n  push(value: T) {\n    if (this.isFull()) {\n      throw new RangeError('Ring buffer is full.');\n    }\n    this.set(this.end, value);\n    this.end = this.wrap(this.end + 1);\n  }\n\n  /**\n   * Adds many items to the end of the buffer, in order.\n   */\n  pushAll(values: T[]) {\n    for (const value of values) {\n      this.push(value);\n    }\n  }\n\n  /**\n   * Removes and returns the last item in the buffer.\n   */\n  pop(): T {\n    if (this.isEmpty()) {\n      throw new RangeError('Ring buffer is empty.');\n    }\n    this.end = this.wrap(this.end - 1);\n    const result = this.get(this.end);\n    this.set(this.end, undefined);\n    return result;\n  }\n\n  /**\n   * Adds an item to the beginning of the buffer.\n   */\n  unshift(value: T) {\n    if (this.isFull()) {\n      throw new RangeError('Ring buffer is full.');\n    }\n    this.begin = this.wrap(this.begin - 1);\n    this.set(this.begin, value);\n  }\n\n  /**\n   * Removes and returns the first item in the buffer.\n   */\n  shift(): T {\n    if (this.isEmpty()) {\n      throw new RangeError('Ring buffer is empty.');\n    }\n    const result = this.get(this.begin);\n    this.set(this.begin, undefined);\n    this.begin = this.wrap(this.begin + 1);\n    return result;\n  }\n\n  /**\n   * Removes and returns a specific item in the buffer, and moves the last item\n   * to the vacated slot.  This is useful for implementing a shuffling stream.\n   * Note that this operation necessarily scrambles the original order.\n   *\n   * @param relativeIndex: the index of the item to remove, relative to the\n   *   first item in the buffer (e.g., hiding the ring nature of the underlying\n   *   storage).\n   */\n  shuffleExcise(relativeIndex: number): T {\n    if (this.isEmpty()) {\n      throw new RangeError('Ring buffer is empty.');\n    }\n    const index = this.wrap(this.begin + relativeIndex);\n    const result = this.get(index);\n    this.set(index, this.pop());\n    return result;\n  }\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;;GAgBG,CAEH;;GAEG;;;;AACG,MAAO,UAAU;IAUrB;;;OAGG,CACH,YAAmB,QAAgB,CAAA;QAAhB,IAAA,CAAA,QAAQ,GAAR,QAAQ,CAAQ;QAbnC,kEAAkE;QAClE,8DAA8D;QAC9D,qEAAqE;QAC3D,IAAA,CAAA,KAAK,GAAG,CAAC,CAAC,CAAE,YAAY;QACxB,IAAA,CAAA,GAAG,GAAG,CAAC,CAAC,CAAI,YAAY;QAUhC,IAAI,QAAQ,IAAI,IAAI,EAAE;YACpB,MAAM,IAAI,UAAU,CAAC,kDAAkD,CAAC,CAAC;SAC1E;QACD,IAAI,QAAQ,GAAG,CAAC,EAAE;YAChB,MAAM,IAAI,UAAU,CAAC,4CAA4C,CAAC,CAAC;SACpE;QACD,IAAI,CAAC,IAAI,GAAG,IAAI,KAAK,CAAI,QAAQ,CAAC,CAAC;QACnC,IAAI,CAAC,eAAe,GAAG,CAAC,GAAG,QAAQ,CAAC;IACtC,CAAC;IAED;;OAEG,CACO,IAAI,CAAC,KAAa,EAAA;QAC1B,oCAAoC;QACpC,MAAO,KAAK,GAAG,CAAC,CAAE;YAChB,KAAK,IAAI,IAAI,CAAC,eAAe,CAAC;SAC/B;QACD,OAAO,KAAK,GAAG,IAAI,CAAC,eAAe,CAAC;IACtC,CAAC;IAES,GAAG,CAAC,KAAa,EAAA;QACzB,IAAI,KAAK,GAAG,CAAC,EAAE;YACb,MAAM,IAAI,UAAU,CAAC,sCAAsC,CAAC,CAAC;SAC9D;QACD,OAAO,IAAI,CAAC,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC,QAAQ,CAAC,CAAC;IAC1C,CAAC;IAES,GAAG,CAAC,KAAa,EAAE,KAAQ,EAAA;QACnC,IAAI,KAAK,GAAG,CAAC,EAAE;YACb,MAAM,IAAI,UAAU,CAAC,sCAAsC,CAAC,CAAC;SAC9D;QACD,IAAI,CAAC,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC,QAAQ,CAAC,GAAG,KAAK,CAAC;IAC3C,CAAC;IAED;;OAEG,CACH,MAAM,GAAA;QACJ,IAAI,MAAM,GAAG,IAAI,CAAC,GAAG,GAAG,IAAI,CAAC,KAAK,CAAC;QACnC,IAAI,MAAM,GAAG,CAAC,EAAE;YACd,MAAM,GAAG,IAAI,CAAC,eAAe,GAAG,MAAM,CAAC;SACxC;QACD,OAAO,MAAM,CAAC;IAChB,CAAC;IAED;;;;OAIG,CACH,MAAM,GAAA;QACJ,OAAO,IAAI,CAAC,MAAM,EAAE,KAAK,IAAI,CAAC,QAAQ,CAAC;IACzC,CAAC;IAED;;;;OAIG,CACH,OAAO,GAAA;QACL,OAAO,IAAI,CAAC,MAAM,EAAE,KAAK,CAAC,CAAC;IAC7B,CAAC;IAED;;OAEG,CACH,IAAI,CAAC,KAAQ,EAAA;QACX,IAAI,IAAI,CAAC,MAAM,EAAE,EAAE;YACjB,MAAM,IAAI,UAAU,CAAC,sBAAsB,CAAC,CAAC;SAC9C;QACD,IAAI,CAAC,GAAG,CAAC,IAAI,CAAC,GAAG,EAAE,KAAK,CAAC,CAAC;QAC1B,IAAI,CAAC,GAAG,GAAG,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,GAAG,GAAG,CAAC,CAAC,CAAC;IACrC,CAAC;IAED;;OAEG,CACH,OAAO,CAAC,MAAW,EAAA;QACjB,KAAK,MAAM,KAAK,IAAI,MAAM,CAAE;YAC1B,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;SAClB;IACH,CAAC;IAED;;OAEG,CACH,GAAG,GAAA;QACD,IAAI,IAAI,CAAC,OAAO,EAAE,EAAE;YAClB,MAAM,IAAI,UAAU,CAAC,uBAAuB,CAAC,CAAC;SAC/C;QACD,IAAI,CAAC,GAAG,GAAG,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,GAAG,GAAG,CAAC,CAAC,CAAC;QACnC,MAAM,MAAM,GAAG,IAAI,CAAC,GAAG,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC;QAClC,IAAI,CAAC,GAAG,CAAC,IAAI,CAAC,GAAG,EAAE,SAAS,CAAC,CAAC;QAC9B,OAAO,MAAM,CAAC;IAChB,CAAC;IAED;;OAEG,CACH,OAAO,CAAC,KAAQ,EAAA;QACd,IAAI,IAAI,CAAC,MAAM,EAAE,EAAE;YACjB,MAAM,IAAI,UAAU,CAAC,sBAAsB,CAAC,CAAC;SAC9C;QACD,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,KAAK,GAAG,CAAC,CAAC,CAAC;QACvC,IAAI,CAAC,GAAG,CAAC,IAAI,CAAC,KAAK,EAAE,KAAK,CAAC,CAAC;IAC9B,CAAC;IAED;;OAEG,CACH,KAAK,GAAA;QACH,IAAI,IAAI,CAAC,OAAO,EAAE,EAAE;YAClB,MAAM,IAAI,UAAU,CAAC,uBAAuB,CAAC,CAAC;SAC/C;QACD,MAAM,MAAM,GAAG,IAAI,CAAC,GAAG,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;QACpC,IAAI,CAAC,GAAG,CAAC,IAAI,CAAC,KAAK,EAAE,SAAS,CAAC,CAAC;QAChC,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,KAAK,GAAG,CAAC,CAAC,CAAC;QACvC,OAAO,MAAM,CAAC;IAChB,CAAC;IAED;;;;;;;;OAQG,CACH,aAAa,CAAC,aAAqB,EAAA;QACjC,IAAI,IAAI,CAAC,OAAO,EAAE,EAAE;YAClB,MAAM,IAAI,UAAU,CAAC,uBAAuB,CAAC,CAAC;SAC/C;QACD,MAAM,KAAK,GAAG,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,KAAK,GAAG,aAAa,CAAC,CAAC;QACpD,MAAM,MAAM,GAAG,IAAI,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC;QAC/B,IAAI,CAAC,GAAG,CAAC,KAAK,EAAE,IAAI,CAAC,GAAG,EAAE,CAAC,CAAC;QAC5B,OAAO,MAAM,CAAC;IAChB,CAAC;CACF"}},
    {"offset": {"line": 387, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-data@4.22.0_@tensorflow+tfjs-core@4.22.0_seedrandom@3.0.5/node_modules/@tensorflow/tfjs-data/dist/util/growing_ring_buffer.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-data/src/util/growing_ring_buffer.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\n\nimport {RingBuffer} from './ring_buffer';\n\nexport class GrowingRingBuffer<T> extends RingBuffer<T> {\n  private static INITIAL_CAPACITY = 32;\n\n  /**\n   * Constructs a `GrowingRingBuffer`.\n   */\n  constructor() {\n    super(GrowingRingBuffer.INITIAL_CAPACITY);\n  }\n\n  override isFull() {\n    return false;\n  }\n\n  override push(value: T) {\n    if (super.isFull()) {\n      this.expand();\n    }\n    super.push(value);\n  }\n\n  override unshift(value: T) {\n    if (super.isFull()) {\n      this.expand();\n    }\n    super.unshift(value);\n  }\n\n  /**\n   * Doubles the capacity of the buffer.\n   */\n  private expand() {\n    const newCapacity = this.capacity * 2;\n    const newData = new Array<T>(newCapacity);\n    const len = this.length();\n\n    // Rotate the buffer to start at index 0 again, since we can't just\n    // allocate more space at the end.\n    for (let i = 0; i < len; i++) {\n      newData[i] = this.get(this.wrap(this.begin + i));\n    }\n\n    this.data = newData;\n    this.capacity = newCapacity;\n    this.doubledCapacity = 2 * this.capacity;\n    this.begin = 0;\n    this.end = len;\n  }\n}\n"],"names":[],"mappings":";;;;AAAA;;;;;;;;;;;;;;;;GAgBG,CAEH,OAAO,EAAC,UAAU,EAAC,MAAM,eAAe,CAAC;;AAEzC,MAAa,iBAAqB,SAAQ,4UAAa;IAGrD;;OAEG,CACH,aAAA;QACE,KAAK,CAAC,iBAAiB,CAAC,gBAAgB,CAAC,CAAC;IAC5C,CAAC;IAEQ,MAAM,GAAA;QACb,OAAO,KAAK,CAAC;IACf,CAAC;IAEQ,IAAI,CAAC,KAAQ,EAAA;QACpB,IAAI,KAAK,CAAC,MAAM,EAAE,EAAE;YAClB,IAAI,CAAC,MAAM,EAAE,CAAC;SACf;QACD,KAAK,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;IACpB,CAAC;IAEQ,OAAO,CAAC,KAAQ,EAAA;QACvB,IAAI,KAAK,CAAC,MAAM,EAAE,EAAE;YAClB,IAAI,CAAC,MAAM,EAAE,CAAC;SACf;QACD,KAAK,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC;IACvB,CAAC;IAED;;OAEG,CACK,MAAM,GAAA;QACZ,MAAM,WAAW,GAAG,IAAI,CAAC,QAAQ,GAAG,CAAC,CAAC;QACtC,MAAM,OAAO,GAAG,IAAI,KAAK,CAAI,WAAW,CAAC,CAAC;QAC1C,MAAM,GAAG,GAAG,IAAI,CAAC,MAAM,EAAE,CAAC;QAE1B,mEAAmE;QACnE,kCAAkC;QAClC,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,GAAG,EAAE,CAAC,EAAE,CAAE;YAC5B,OAAO,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,KAAK,GAAG,CAAC,CAAC,CAAC,CAAC;SAClD;QAED,IAAI,CAAC,IAAI,GAAG,OAAO,CAAC;QACpB,IAAI,CAAC,QAAQ,GAAG,WAAW,CAAC;QAC5B,IAAI,CAAC,eAAe,GAAG,CAAC,GAAG,IAAI,CAAC,QAAQ,CAAC;QACzC,IAAI,CAAC,KAAK,GAAG,CAAC,CAAC;QACf,IAAI,CAAC,GAAG,GAAG,GAAG,CAAC;IACjB,CAAC;;AA9Cc,kBAAA,gBAAgB,GAAG,EAAE,CAAC"}},
    {"offset": {"line": 455, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-data@4.22.0_@tensorflow+tfjs-core@4.22.0_seedrandom@3.0.5/node_modules/@tensorflow/tfjs-data/dist/iterators/lazy_iterator.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-data/src/iterators/lazy_iterator.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs-core';\nimport * as seedrandom from 'seedrandom';\n\nimport {Container} from '../types';\nimport {deepClone} from '../util/deep_clone';\nimport {deepMapAndAwaitAll, DeepMapAsyncResult, DeepMapResult, deepZip, zipToList} from '../util/deep_map';\nimport {GrowingRingBuffer} from '../util/growing_ring_buffer';\nimport {RingBuffer} from '../util/ring_buffer';\n\n/**\n * A nested structure of LazyIterators, used as the input to zip().\n */\nexport type IteratorContainer = Container<LazyIterator<tf.TensorContainer>>;\n\n// Here we implement a simple asynchronous iterator.\n// This lets us avoid using either third-party stream libraries or\n// recent TypeScript language support requiring polyfills.\n\n/**\n * Create a `LazyIterator` from an array of items.\n */\nexport function iteratorFromItems<T>(items: T[]): LazyIterator<T> {\n  return new ArrayIterator(items);\n}\n\n/**\n * Create a `LazyIterator` of incrementing integers.\n */\nexport function iteratorFromIncrementing(start: number): LazyIterator<number> {\n  let i = start;\n  return iteratorFromFunction(() => ({value: i++, done: false}));\n}\n\n/**\n * Create a `LazyIterator` from a function.\n *\n * ```js\n * let i = -1;\n * const func = () =>\n *    ++i < 5 ? {value: i, done: false} : {value: null, done: true};\n * const iter = tf.data.iteratorFromFunction(func);\n * await iter.forEachAsync(e => console.log(e));\n * ```\n *\n * @param func A function that produces data on each call.\n */\nexport function iteratorFromFunction<T>(\n    func: () =>\n        IteratorResult<T>| Promise<IteratorResult<T>>): LazyIterator<T> {\n  return new FunctionCallIterator(func);\n}\n\n/**\n * Create a `LazyIterator` by concatenating underlying streams, which are\n * themselves provided as a stream.\n *\n * This can also be thought of as a \"stream flatten\" operation.\n *\n * @param baseIterators A stream of streams to be concatenated.\n * @param baseErrorHandler An optional function that can intercept `Error`s\n *   raised during a `next()` call on the base stream.  This function can decide\n *   whether the error should be propagated, whether the error should be\n *   ignored, or whether the base stream should be terminated.\n */\nexport function iteratorFromConcatenated<T>(\n    baseIterators: LazyIterator<LazyIterator<T>>,\n    baseErrorHandler?: (e: Error) => boolean): LazyIterator<T> {\n  return new ChainedIterator(baseIterators, baseErrorHandler);\n}\n\n/**\n * Create a `LazyIterator` by concatenating streams produced by calling a\n * stream-generating function a given number of times.\n *\n * Since a `LazyIterator` is read-once, it cannot be repeated, but this\n * function can be used to achieve a similar effect:\n *\n *   LazyIterator.ofConcatenatedFunction(() => new MyIterator(), 6);\n *\n * @param iteratorFunc: A function that produces a new stream on each call.\n * @param count: The number of times to call the function.\n * @param baseErrorHandler An optional function that can intercept `Error`s\n *   raised during a `next()` call on the base stream.  This function can decide\n *   whether the error should be propagated, whether the error should be\n *   ignored, or whether the base stream should be terminated.\n */\nexport function iteratorFromConcatenatedFunction<T>(\n    iteratorFunc: () => IteratorResult<LazyIterator<T>>, count: number,\n    baseErrorHandler?: (e: Error) => boolean): LazyIterator<T> {\n  return iteratorFromConcatenated(\n      iteratorFromFunction(iteratorFunc).take(count), baseErrorHandler);\n}\n\n/**\n * Create a `LazyIterator` by zipping together an array, dict, or nested\n * structure of `LazyIterator`s (and perhaps additional constants).\n *\n * The underlying streams must provide elements in a consistent order such\n * that they correspond.\n *\n * Typically, the underlying streams should have the same number of\n * elements. If they do not, the behavior is determined by the\n * `mismatchMode` argument.\n *\n * The nested structure of the `iterators` argument determines the\n * structure of elements in the resulting iterator.\n *\n * @param iterators: An array or object containing LazyIterators at the\n * leaves.\n * @param mismatchMode: Determines what to do when one underlying iterator\n * is exhausted before the others.  `ZipMismatchMode.FAIL` (the default)\n * causes an error to be thrown in this case.  `ZipMismatchMode.SHORTEST`\n * causes the zipped iterator to terminate with the furst underlying\n * streams, so elements remaining on the longer streams are ignored.\n * `ZipMismatchMode.LONGEST` causes the zipped stream to continue, filling\n * in nulls for the exhausted streams, until all streams are exhausted.\n */\nexport function iteratorFromZipped<O extends tf.TensorContainer>(\n    iterators: IteratorContainer,\n    mismatchMode: ZipMismatchMode = ZipMismatchMode.FAIL): LazyIterator<O> {\n  return new ZipIterator<O>(iterators, mismatchMode);\n}\n\n/**\n * An asynchronous iterator, providing lazy access to a potentially\n * unbounded stream of elements.\n *\n * Iterator can be obtained from a dataset:\n * `const iter = await dataset.iterator();`\n */\nexport abstract class LazyIterator<T> {\n  // This class implements AsyncIterator<T>, but we have not yet set the\n  // TypeScript --downlevelIteration flag to enable that.\n\n  abstract summary(): string;\n\n  /**\n   * Returns a `Promise` for the next element in the stream.\n   *\n   * When an item can be provided successfully, the return value is\n   * `{value:T, done:false}`.\n   *\n   * Calling next() on a closed stream returns `{value:null, done:true}`.\n   */\n  abstract next(): Promise<IteratorResult<T>>;\n\n  /**\n   * Collect all remaining elements of a bounded stream into an array.\n   * Obviously this will succeed only for small streams that fit in memory.\n   * Useful for testing.\n   *\n   * @returns A Promise for an array of stream elements, which will resolve\n   *   when the stream is exhausted.\n   */\n  async toArray(): Promise<T[]> {\n    const result: T[] = [];\n    let x = await this.next();\n    while (!x.done) {\n      result.push(x.value);\n      x = await this.next();\n    }\n    return result;\n  }\n\n  /**\n   * Collect all elements of this dataset into an array with prefetching 100\n   * elements. This is useful for testing, because the prefetch changes the\n   * order in which the Promises are resolved along the processing pipeline.\n   * This may help expose bugs where results are dependent on the order of\n   * Promise resolution rather than on the logical order of the stream (i.e.,\n   * due to hidden mutable state).\n   *\n   * @returns A Promise for an array of stream elements, which will resolve\n   *   when the stream is exhausted.\n   */\n  async toArrayForTest(): Promise<T[]> {\n    const stream = this.prefetch(100);\n    const result: T[] = [];\n    let x = await stream.next();\n    while (!x.done) {\n      result.push(x.value);\n      x = await stream.next();\n    }\n    return result;\n  }\n\n  /**\n   * Draw items from the stream until it is exhausted.\n   *\n   * This can be useful when the stream has side effects but no output.  In\n   * that case, calling this function guarantees that the stream will be\n   * fully processed.\n   */\n  async resolveFully(): Promise<void> {\n    let x = await this.next();\n    while (!x.done) {\n      x = await this.next();\n    }\n  }\n\n  /**\n   * Draw items from the stream until it is exhausted, or a predicate fails.\n   *\n   * This can be useful when the stream has side effects but no output.  In\n   * that case, calling this function guarantees that the stream will be\n   * fully processed.\n   */\n  async resolveWhile(predicate: (r: T) => boolean): Promise<void> {\n    let x = await this.next();\n    let shouldContinue = predicate(x.value);\n    while ((!x.done) && shouldContinue) {\n      x = await this.next();\n      shouldContinue = predicate(x.value);\n    }\n  }\n\n  /**\n   * Handles errors thrown on this stream using a provided handler function.\n   *\n   * @param handler A function that handles any `Error` thrown during a `next()`\n   *   call and returns true if the stream should continue (dropping the failed\n   *   call) or false if the stream should quietly terminate.  If the handler\n   *   itself throws (or rethrows) an `Error`, that will be propagated.\n   *\n   * @returns A `LazyIterator` of elements passed through from upstream,\n   *   possibly filtering or terminating on upstream `next()` calls that\n   *   throw an `Error`.\n   */\n  handleErrors(handler: (error: Error) => boolean): LazyIterator<T> {\n    return new ErrorHandlingLazyIterator(this, handler);\n  }\n\n  // TODO(soergel): Implement reduce() etc.\n\n  /**\n   * Filters this stream according to `predicate`.\n   *\n   * @param predicate A function mapping a stream element to a boolean or a\n   * `Promise` for one.\n   *\n   * @returns A `LazyIterator` of elements for which the predicate was true.\n   */\n  filter(predicate: (value: T) => boolean): LazyIterator<T> {\n    return new FilterIterator(this, predicate);\n  }\n\n  /**\n   * Maps this stream through a 1-to-1 transform.\n   *\n   * @param transform A function mapping a stream element to a transformed\n   *   element.\n   *\n   * @returns A `LazyIterator` of transformed elements.\n   */\n  map<O>(transform: (value: T) => O): LazyIterator<O> {\n    return new MapIterator(this, transform);\n  }\n\n  /**\n   * Maps this stream through an async 1-to-1 transform.\n   *\n   * @param transform A function mapping a stream element to a `Promise` for a\n   *   transformed stream element.\n   *\n   * @returns A `LazyIterator` of transformed elements.\n   */\n  mapAsync<O>(transform: (value: T) => Promise<O>): LazyIterator<O> {\n    return new AsyncMapIterator(this, transform);\n  }\n\n  /**\n   * Maps this stream through a 1-to-1 transform, forcing serial execution.\n   *\n   * @param transform A function mapping a stream element to a transformed\n   *   element.\n   *\n   * @returns A `LazyIterator` of transformed elements.\n   */\n  serialMapAsync<O>(transform: (value: T) => Promise<O>): LazyIterator<O> {\n    return new AsyncMapIterator(this, transform).serial();\n  }\n\n  /**\n   * Maps this stream through a 1-to-many transform.\n   *\n   * @param transform A function mapping a stream element to an array of\n   *   transformed elements.\n   *\n   * @returns A `DataStream` of transformed elements.\n   */\n  flatmap<O>(transform: (value: T) => O[]): LazyIterator<O> {\n    return new FlatmapIterator(this, transform);\n  }\n\n  /**\n   * Apply a function to every element of the stream.\n   *\n   * @param f A function to apply to each stream element.\n   */\n  async forEachAsync(f: (value: T) => void): Promise<void> {\n    return this.map(f).resolveFully();\n  }\n\n  /**\n   * Apply a function to every element of the stream, forcing serial execution.\n   *\n   * @param f A function to apply to each stream element.  Should return 'true'\n   *   to indicate that the stream should continue, or 'false' to cause it to\n   *   terminate.\n   */\n  async serialForEach(f: (value: T) => Promise<boolean>): Promise<void> {\n    return this.serialMapAsync(f).resolveWhile(x => (x === true));\n  }\n\n  /**\n   * Groups elements into batches, represented as arrays of elements.\n   *\n   * We can think of the elements of this iterator as 'rows' (even if they are\n   * nested structures).  By the same token, consecutive values for a given\n   * key within the elements form a 'column'.  This matches the usual sense of\n   * 'row' and 'column' when processing tabular data (e.g., parsing a CSV).\n   *\n   * Thus, \"Row-major\" means that the resulting batch is simply a collection of\n   * rows: `[row1, row2, row3, ...]`.  This is contrast to the column-major\n   * form, which is needed for vectorized computation.\n   *\n   * @param batchSize The number of elements desired per batch.\n   * @param smallLastBatch Whether to emit the final batch when it has fewer\n   *   than batchSize elements. Default true.\n   * @returns A `LazyIterator` of batches of elements, represented as arrays\n   *   of the original element type.\n   */\n  rowMajorBatch(batchSize: number, smallLastBatch = true): LazyIterator<T[]> {\n    return new RowMajorBatchIterator(this, batchSize, smallLastBatch);\n  }\n\n  /**\n   * Groups elements into batches, represented in column-major form.\n   *\n   * We can think of the elements of this iterator as 'rows' (even if they are\n   * nested structures).  By the same token, consecutive values for a given\n   * key within the elements form a 'column'.  This matches the usual sense of\n   * 'row' and 'column' when processing tabular data (e.g., parsing a CSV).\n   *\n   * Thus, \"column-major\" means that the resulting batch is a (potentially\n   * nested) structure representing the columns.  Each column entry, then,\n   * contains a collection of the values found in that column for a range of\n   * input elements.  This representation allows for vectorized computation, in\n   * contrast to the row-major form.\n   *\n   * The inputs should all have the same nested structure (i.e., of arrays and\n   * dicts).  The result is a single object with the same nested structure,\n   * where the leaves are arrays collecting the values of the inputs at that\n   * location (or, optionally, the result of a custom function applied to those\n   * arrays).\n   *\n   * @param batchSize The number of elements desired per batch.\n   * @param smallLastBatch Whether to emit the final batch when it has fewer\n   *   than batchSize elements. Default true.\n   * @param zipFn: (optional) A function that expects an array of elements at a\n   *   single node of the object tree, and returns a `DeepMapResult`.  The\n   *   `DeepMapResult` either provides a result value for that node (i.e.,\n   *   representing the subtree), or indicates that the node should be processed\n   *   recursively.  The default zipFn recurses as far as possible and places\n   *   arrays at the leaves.\n   * @returns A `LazyIterator` of batches of elements, represented as an object\n   *   with collections at the leaves.\n   */\n  columnMajorBatch(\n      batchSize: number, smallLastBatch = true,\n      // tslint:disable-next-line:no-any\n      zipFn: (xs: any[]) => DeepMapResult = zipToList):\n      LazyIterator<tf.TensorContainer> {\n    // First collect the desired number of input elements as a row-major batch.\n    const rowBatches = this.rowMajorBatch(batchSize, smallLastBatch);\n    // Now 'rotate' or 'pivot' the data, collecting all values from each column\n    // in the batch (i.e., for each key within the elements) into an array.\n    return rowBatches.map(x => deepZip(x, zipFn));\n  }\n\n  /**\n   * Concatenate this `LazyIterator` with another.\n   *\n   * @param iterator A `LazyIterator` to be concatenated onto this one.\n   * @param baseErrorHandler An optional function that can intercept `Error`s\n   *   raised during a `next()` call on the base stream.  This function can\n   *   decide whether the error should be propagated, whether the error should\n   *   be ignored, or whether the base stream should be terminated.\n   * @returns A `LazyIterator`.\n   */\n  concatenate(\n      iterator: LazyIterator<T>,\n      baseErrorHandler?: (e: Error) => boolean): LazyIterator<T> {\n    return new ChainedIterator(\n        iteratorFromItems([this, iterator]), baseErrorHandler);\n  }\n\n  /**\n   * Limits this stream to return at most `count` items.\n   *\n   * @param count The maximum number of items to provide from the stream. If\n   * a negative or undefined value is given, the entire stream is returned\n   *   unaltered.\n   */\n  take(count: number): LazyIterator<T> {\n    if (count < 0 || count == null) {\n      return this;\n    }\n    return new TakeIterator(this, count);\n  }\n\n  /**\n   * Skips the first `count` items in this stream.\n   *\n   * @param count The number of items to skip.  If a negative or undefined\n   * value is given, the entire stream is returned unaltered.\n   */\n  skip(count: number): LazyIterator<T> {\n    if (count < 0 || count == null) {\n      return this;\n    }\n    return new SkipIterator(this, count);\n  }\n\n  /**\n   * Prefetch the first `bufferSize` items in this stream.\n   *\n   * Note this prefetches Promises, but makes no guarantees about when those\n   * Promises resolve.\n   *\n   * @param bufferSize: An integer specifying the number of elements to be\n   *   prefetched.\n   */\n  prefetch(bufferSize: number): LazyIterator<T> {\n    return new PrefetchIterator(this, bufferSize);\n  }\n\n  // TODO(soergel): deep sharded shuffle, where supported\n\n  /**\n   * Randomly shuffles the elements of this stream.\n   *\n   * @param bufferSize: An integer specifying the number of elements from\n   * this stream from which the new stream will sample.\n   * @param seed: (Optional.) An integer specifying the random seed that\n   * will be used to create the distribution.\n   */\n  shuffle(windowSize: number, seed?: string): LazyIterator<T> {\n    return new ShuffleIterator(this, windowSize, seed);\n  }\n\n  /**\n   * Force an iterator to execute serially: each next() call will await the\n   * prior one, so that they cannot execute concurrently.\n   */\n  serial(): LazyIterator<T> {\n    return new SerialIterator(this);\n  }\n}\n\n// ============================================================================\n// The following private classes serve to implement the chainable methods\n// on LazyIterator.  Unfortunately they can't be placed in separate files,\n// due to resulting trouble with circular imports.\n// ============================================================================\n\n// Iterators that just extend LazyIterator directly\n// ============================================================================\n\nclass ArrayIterator<T> extends LazyIterator<T> {\n  private trav = 0;\n  constructor(protected items: T[]) {\n    super();\n  }\n\n  summary() {\n    return `Array of ${this.items.length} items`;\n  }\n\n  async next(): Promise<IteratorResult<T>> {\n    if (this.trav >= this.items.length) {\n      return {value: null, done: true};\n    }\n    const item = this.items[this.trav];\n    this.trav++;\n    return {value: deepClone(item), done: false};\n  }\n}\n\nclass FunctionCallIterator<T> extends LazyIterator<T> {\n  constructor(\n      protected nextFn: () => IteratorResult<T>| Promise<IteratorResult<T>>) {\n    super();\n  }\n\n  summary() {\n    return `Function call`;\n  }\n\n  async next(): Promise<IteratorResult<T>> {\n    try {\n      return this.nextFn();\n    } catch (e) {\n      // Modify the error message but leave the stack trace intact\n      e.message =\n          `Error thrown while iterating through a dataset: ${e.message}`;\n      throw e;\n    }\n  }\n}\n\nclass SerialIterator<T> extends LazyIterator<T> {\n  // Strict Promise execution order:\n  // a next() call may not even begin until the previous one completes.\n  private lastRead: Promise<IteratorResult<T>>;\n\n  constructor(protected upstream: LazyIterator<T>) {\n    super();\n    this.lastRead = Promise.resolve({value: null, done: false});\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Serial`;\n  }\n\n  async next(): Promise<IteratorResult<T>> {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n\n  private async serialNext(): Promise<IteratorResult<T>> {\n    return this.upstream.next();\n  }\n}\n\nclass SkipIterator<T> extends LazyIterator<T> {\n  // Strict Promise execution order:\n  // a next() call may not even begin until the previous one completes.\n  private lastRead: Promise<IteratorResult<T>>;\n\n  // Local state that should not be clobbered by out-of-order execution.\n  count = 0;\n\n  constructor(protected upstream: LazyIterator<T>, protected maxCount: number) {\n    super();\n    this.lastRead = Promise.resolve({value: null, done: false});\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Skip`;\n  }\n\n  async next(): Promise<IteratorResult<T>> {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n\n  private async serialNext(): Promise<IteratorResult<T>> {\n    // TODO(soergel): consider tradeoffs of reading in parallel, eg.\n    // collecting next() promises in an Array and then waiting for\n    // Promise.all() of those. Benefit: pseudo-parallel execution.  Drawback:\n    // maybe delayed GC.\n    while (this.count++ < this.maxCount) {\n      const skipped = await this.upstream.next();\n      // short-circuit if upstream is already empty\n      if (skipped.done) {\n        return skipped;\n      }\n      tf.dispose(skipped.value as {});\n    }\n    return this.upstream.next();\n  }\n}\n\nclass TakeIterator<T> extends LazyIterator<T> {\n  count = 0;\n  constructor(protected upstream: LazyIterator<T>, protected maxCount: number) {\n    super();\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Take`;\n  }\n\n  async next(): Promise<IteratorResult<T>> {\n    if (this.count++ >= this.maxCount) {\n      return {value: null, done: true};\n    }\n    return this.upstream.next();\n  }\n}\n\n// Note this batch just groups items into row-wise element arrays.\n// Rotating these to a column-wise representation happens only at the dataset\n// level.\nclass RowMajorBatchIterator<T> extends LazyIterator<T[]> {\n  // Strict Promise execution order:\n  // a next() call may not even begin until the previous one completes.\n  private lastRead: Promise<IteratorResult<T[]>>;\n\n  constructor(\n      protected upstream: LazyIterator<T>, protected batchSize: number,\n      protected enableSmallLastBatch = true) {\n    super();\n    this.lastRead = Promise.resolve({value: null, done: false});\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> RowMajorBatch`;\n  }\n\n  async next(): Promise<IteratorResult<T[]>> {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n\n  private async serialNext(): Promise<IteratorResult<T[]>> {\n    const batch: T[] = [];\n    while (batch.length < this.batchSize) {\n      const item = await this.upstream.next();\n      if (item.done) {\n        if (this.enableSmallLastBatch && batch.length > 0) {\n          return {value: batch, done: false};\n        }\n        return {value: null, done: true};\n      }\n      batch.push(item.value);\n    }\n    return {value: batch, done: false};\n  }\n}\n\nclass FilterIterator<T> extends LazyIterator<T> {\n  // Strict Promise execution order:\n  // a next() call may not even begin until the previous one completes.\n  private lastRead: Promise<IteratorResult<T>>;\n\n  constructor(\n      protected upstream: LazyIterator<T>,\n      protected predicate: (value: T) => boolean) {\n    super();\n    this.lastRead = Promise.resolve({value: null, done: false});\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Filter`;\n  }\n\n  async next(): Promise<IteratorResult<T>> {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n\n  private async serialNext(): Promise<IteratorResult<T>> {\n    while (true) {\n      const item = await this.upstream.next();\n      if (item.done || this.predicate(item.value)) {\n        return item;\n      }\n      tf.dispose(item.value as {});\n    }\n  }\n}\n\nclass MapIterator<I, O> extends LazyIterator<O> {\n  constructor(\n      protected upstream: LazyIterator<I>,\n      protected transform: (value: I) => O) {\n    super();\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Map`;\n  }\n\n  async next(): Promise<IteratorResult<O>> {\n    const item = await this.upstream.next();\n    if (item.done) {\n      return {value: null, done: true};\n    }\n    const inputTensors = tf.tensor_util.getTensorsInContainer(item.value as {});\n    // Careful: the transform may mutate the item in place.\n    // That's why we have to remember the input Tensors above, and then\n    // below dispose only those that were not passed through to the output.\n    // Note too that the transform function is responsible for tidying\n    // any intermediate Tensors.  Here we are concerned only about the\n    // inputs.\n    const mapped = this.transform(item.value);\n    const outputTensors = tf.tensor_util.getTensorsInContainer(mapped as {});\n\n    // TODO(soergel) faster intersection\n    // TODO(soergel) move to tf.disposeExcept(in, out)?\n    for (const t of inputTensors) {\n      if (!tf.tensor_util.isTensorInList(t, outputTensors)) {\n        t.dispose();\n      }\n    }\n    return {value: mapped, done: false};\n  }\n}\n\nclass ErrorHandlingLazyIterator<T> extends LazyIterator<T> {\n  count = 0;\n  constructor(\n      protected upstream: LazyIterator<T>,\n      protected handler: (error: Error) => boolean) {\n    super();\n    this.lastRead = Promise.resolve({value: null, done: false});\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> handleErrors`;\n  }\n\n  // Strict Promise execution order:\n  // a next() call may not even begin until the previous one completes.\n  private lastRead: Promise<IteratorResult<T>>;\n\n  async next(): Promise<IteratorResult<T>> {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n\n  async serialNext(): Promise<IteratorResult<T>> {\n    while (true) {\n      try {\n        return await this.upstream.next();\n      } catch (e) {\n        if (!this.handler(e)) {\n          return {value: null, done: true};\n        }\n        // If the handler returns true, loop and fetch the next upstream item.\n\n        // If the upstream iterator throws an endless stream of errors, and if\n        // the handler says to ignore them, then we loop forever here.  That is\n        // the correct behavior-- it's up to the handler to decide when to stop.\n      }\n    }\n  }\n}\n\nclass AsyncMapIterator<I, O> extends LazyIterator<O> {\n  constructor(\n      protected upstream: LazyIterator<I>,\n      protected transform: (value: I) => Promise<O>) {\n    super();\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> AsyncMap`;\n  }\n\n  async next(): Promise<IteratorResult<O>> {\n    const item = await this.upstream.next();\n    if (item.done) {\n      return {value: null, done: true};\n    }\n    const inputTensors = tf.tensor_util.getTensorsInContainer(item.value as {});\n    // Careful: the transform may mutate the item in place.\n    // That's why we have to remember the input Tensors above, and then\n    // below dispose only those that were not passed through to the output.\n    // Note too that the transform function is responsible for tidying\n    // any intermediate Tensors.  Here we are concerned only about the\n    // inputs.\n    const mapped = await this.transform(item.value);\n    const outputTensors = tf.tensor_util.getTensorsInContainer(mapped as {});\n\n    // TODO(soergel) faster intersection\n    // TODO(soergel) move to tf.disposeExcept(in, out)?\n    for (const t of inputTensors) {\n      if (!tf.tensor_util.isTensorInList(t, outputTensors)) {\n        t.dispose();\n      }\n    }\n    return {value: mapped, done: false};\n  }\n}\n\n// Iterators that maintain a queue of pending items\n// ============================================================================\n\n/**\n * A base class for transforming streams that operate by maintaining an\n * output queue of elements that are ready to return via next().  This is\n * commonly required when the transformation is 1-to-many:  A call to next()\n * may trigger a call to the underlying stream, which will produce many\n * mapped elements of this stream-- of which we need to return only one, so\n * we have to queue the rest.\n */\nexport abstract class OneToManyIterator<T> extends LazyIterator<T> {\n  // Strict Promise execution order:\n  // a next() call may not even begin until the previous one completes.\n  private lastRead: Promise<IteratorResult<T>>;\n\n  // Local state that should not be clobbered by out-of-order execution.\n  protected outputQueue: RingBuffer<T>;\n\n  constructor() {\n    super();\n    this.outputQueue = new GrowingRingBuffer<T>();\n    this.lastRead = Promise.resolve({value: null, done: false});\n  }\n\n  async next(): Promise<IteratorResult<T>> {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n\n  /**\n   * Read one or more chunks from upstream and process them, possibly\n   * reading or writing a carryover, and adding processed items to the\n   * output queue.  Note it's possible that no items are added to the queue\n   * on a given pump() call, even if the upstream stream is not closed\n   * (e.g., because items are filtered).\n   *\n   * @return `true` if any action was taken, i.e. fetching items from the\n   *   upstream source OR adding items to the output queue.  `false` if the\n   *   upstream source is exhausted AND nothing was added to the queue\n   * (i.e., any remaining carryover).\n   */\n  protected abstract pump(): Promise<boolean>;\n\n  async serialNext(): Promise<IteratorResult<T>> {\n    // Fetch so that the queue contains at least one item if possible.\n    // If the upstream source is exhausted, AND there are no items left in\n    // the output queue, then this stream is also exhausted.\n    while (this.outputQueue.length() === 0) {\n      // TODO(soergel): consider parallel reads.\n      if (!await this.pump()) {\n        return {value: null, done: true};\n      }\n    }\n    return {value: this.outputQueue.shift(), done: false};\n  }\n}\nclass FlatmapIterator<I, O> extends OneToManyIterator<O> {\n  constructor(\n      protected upstream: LazyIterator<I>,\n      protected transform: (value: I) => O[]) {\n    super();\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Flatmap`;\n  }\n\n  async pump(): Promise<boolean> {\n    const item = await this.upstream.next();\n    if (item.done) {\n      return false;\n    }\n    const inputTensors = tf.tensor_util.getTensorsInContainer(item.value as {});\n    // Careful: the transform may mutate the item in place.\n    // that's why we have to remember the input Tensors above, and then\n    // below dispose only those that were not passed through to the output.\n    // Note too that the transform function is responsible for tidying any\n    // intermediate Tensors.  Here we are concerned only about the inputs.\n    const mappedArray = this.transform(item.value);\n    const outputTensors =\n        tf.tensor_util.getTensorsInContainer(mappedArray as {});\n    this.outputQueue.pushAll(mappedArray);\n\n    // TODO(soergel) faster intersection, and deduplicate outputTensors\n    // TODO(soergel) move to tf.disposeExcept(in, out)?\n    for (const t of inputTensors) {\n      if (!tf.tensor_util.isTensorInList(t, outputTensors)) {\n        t.dispose();\n      }\n    }\n\n    return true;\n  }\n}\n\n/**\n * Provides a `LazyIterator` that concatenates a stream of underlying\n * streams.\n *\n * Doing this in a concurrency-safe way requires some trickery.  In\n * particular, we want this stream to return the elements from the\n * underlying streams in the correct order according to when next() was\n * called, even if the resulting Promises resolve in a different order.\n */\nexport class ChainedIterator<T> extends LazyIterator<T> {\n  // Strict Promise execution order:\n  // a next() call may not even begin until the previous one completes.\n  private lastRead: Promise<IteratorResult<T>> = null;\n\n  // Local state that should not be clobbered by out-of-order execution.\n  private iterator: LazyIterator<T> = null;\n  private moreIterators: LazyIterator<LazyIterator<T>>;\n\n  constructor(\n      iterators: LazyIterator<LazyIterator<T>>,\n      private readonly baseErrorHandler?: (e: Error) => boolean) {\n    super();\n    this.moreIterators = iterators;\n  }\n\n  summary() {\n    const upstreamSummaries = 'TODO: fill in upstream of chained summaries';\n    return `${upstreamSummaries} -> Chained`;\n  }\n\n  async next(): Promise<IteratorResult<T>> {\n    this.lastRead = this.readFromChain(this.lastRead);\n    return this.lastRead;\n  }\n\n  private async readFromChain(lastRead: Promise<IteratorResult<T>>):\n      Promise<IteratorResult<T>> {\n    // Must await on the previous read since the previous read may have advanced\n    // the stream of streams, from which we need to read.\n    // This is unfortunate since we can't parallelize reads. Which means\n    // prefetching of chained streams is a no-op.\n    // One solution is to prefetch immediately upstream of this.\n    await lastRead;\n    if (this.iterator == null) {\n      const iteratorResult = await this.moreIterators.next();\n      if (iteratorResult.done) {\n        // No more streams to stream from.\n        return {value: null, done: true};\n      }\n      this.iterator = iteratorResult.value;\n      if (this.baseErrorHandler != null) {\n        this.iterator = this.iterator.handleErrors(this.baseErrorHandler);\n      }\n    }\n    const itemResult = await this.iterator.next();\n    if (itemResult.done) {\n      this.iterator = null;\n      return this.readFromChain(lastRead);\n    }\n    return itemResult;\n  }\n}\n\nexport enum ZipMismatchMode {\n  FAIL,      // require zipped streams to have the same length\n  SHORTEST,  // terminate zip when the first stream is exhausted\n  LONGEST    // use nulls for exhausted streams; use up the longest stream.\n}\n\n/**\n * Provides a `LazyIterator` that zips together an array, dict, or nested\n * structure of `LazyIterator`s (and perhaps additional constants).\n *\n * The underlying streams must provide elements in a consistent order such\n * that they correspond.\n *\n * Typically, the underlying streams should have the same number of\n * elements. If they do not, the behavior is determined by the\n * `mismatchMode` argument.\n *\n * The nested structure of the `iterators` argument determines the\n * structure of elements in the resulting iterator.\n *\n * Doing this in a concurrency-safe way requires some trickery.  In\n * particular, we want this stream to return the elements from the\n * underlying streams in the correct order according to when next() was\n * called, even if the resulting Promises resolve in a different order.\n *\n * @param iterators: An array or object containing LazyIterators at the\n * leaves.\n * @param mismatchMode: Determines what to do when one underlying iterator\n * is exhausted before the others.  `ZipMismatchMode.FAIL` (the default)\n * causes an error to be thrown in this case.  `ZipMismatchMode.SHORTEST`\n * causes the zipped iterator to terminate with the furst underlying\n * streams, so elements remaining on the longer streams are ignored.\n * `ZipMismatchMode.LONGEST` causes the zipped stream to continue, filling\n * in nulls for the exhausted streams, until all streams are exhausted.\n */\nclass ZipIterator<O extends tf.TensorContainer> extends LazyIterator<O> {\n  private count = 0;\n  private currentPromise: Promise<IteratorResult<O>> = null;\n\n  constructor(\n      protected readonly iterators: IteratorContainer,\n      protected readonly mismatchMode: ZipMismatchMode = ZipMismatchMode.FAIL) {\n    super();\n  }\n\n  summary() {\n    const upstreamSummaries = 'TODO: fill in upstream of zip summaries';\n    return `{${upstreamSummaries}} -> Zip`;\n  }\n\n  private async nextState(afterState: Promise<IteratorResult<O>>):\n      Promise<IteratorResult<O>> {\n    // This chaining ensures that the underlying next() are not even called\n    // before the previous ones have resolved.\n    await afterState;\n\n    // Collect underlying iterator \"done\" signals as a side effect in\n    // getNext()\n    let numIterators = 0;\n    let iteratorsDone = 0;\n\n    function getNext(container: IteratorContainer): DeepMapAsyncResult {\n      if (container instanceof LazyIterator) {\n        const result = container.next();\n        return {\n          value: result.then(x => {\n            numIterators++;\n            if (x.done) {\n              iteratorsDone++;\n            }\n            return x.value;\n          }),\n          recurse: false\n        };\n      } else {\n        return {value: null, recurse: true};\n      }\n    }\n\n    const mapped: O = await deepMapAndAwaitAll(this.iterators, getNext);\n\n    if (numIterators === iteratorsDone) {\n      // The streams have all ended.\n      return {value: null, done: true};\n    }\n    if (iteratorsDone > 0) {\n      switch (this.mismatchMode) {\n        case ZipMismatchMode.FAIL:\n          throw new Error(\n              'Zipped streams should have the same length. ' +\n              `Mismatched at element ${this.count}.`);\n        case ZipMismatchMode.SHORTEST:\n          return {value: null, done: true};\n        case ZipMismatchMode.LONGEST:\n        default:\n          // Continue.  The exhausted streams already produced value: null.\n      }\n    }\n\n    this.count++;\n    return {value: mapped, done: false};\n  }\n\n  async next(): Promise<IteratorResult<O>> {\n    this.currentPromise = this.nextState(this.currentPromise);\n    return this.currentPromise;\n  }\n}\n\n// Iterators that maintain a ring buffer of pending promises\n// ============================================================================\n\n/**\n * A stream that prefetches a given number of items from an upstream source,\n * returning them in FIFO order.\n *\n * Note this prefetches Promises, but makes no guarantees about when those\n * Promises resolve.\n */\nexport class PrefetchIterator<T> extends LazyIterator<T> {\n  protected buffer: RingBuffer<Promise<IteratorResult<T>>>;\n\n  constructor(\n      protected upstream: LazyIterator<T>, protected bufferSize: number) {\n    super();\n    this.buffer = new RingBuffer<Promise<IteratorResult<T>>>(bufferSize);\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Prefetch`;\n  }\n\n  /**\n   * Refill the prefetch buffer.  Returns only after the buffer is full, or\n   * the upstream source is exhausted.\n   */\n  protected refill() {\n    while (!this.buffer.isFull()) {\n      const v = this.upstream.next();\n      this.buffer.push(v);\n    }\n  }\n\n  next(): Promise<IteratorResult<T>> {\n    this.refill();\n    // This shift will never throw an error because the buffer is always\n    // full after a refill. If the stream is exhausted, the buffer will be\n    // full of Promises that will resolve to the end-of-stream signal.\n    return this.buffer.shift();\n  }\n}\n\n/**\n * A stream that performs a sliding-window random shuffle on an upstream\n * source. This is like a `PrefetchIterator` except that the items are\n * returned in randomized order.  Mixing naturally improves as the buffer\n * size increases.\n */\nexport class ShuffleIterator<T> extends PrefetchIterator<T> {\n  private readonly random: seedrandom.prng;\n\n  // Strict Promise execution order:\n  // a next() call may not even begin until the previous one completes.\n  private lastRead: Promise<IteratorResult<T>>;\n\n  // Local state that should not be clobbered by out-of-order execution.\n  private upstreamExhausted = false;\n\n  constructor(\n    protected override upstream: LazyIterator<T>, protected windowSize: number,\n      seed?: string) {\n    super(upstream, windowSize);\n    this.random = seedrandom.alea(seed || tf.util.now().toString());\n    this.lastRead = Promise.resolve({value: null, done: false});\n  }\n\n  override async next(): Promise<IteratorResult<T>> {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n\n  private randomInt(max: number) {\n    return Math.floor(this.random() * max);\n  }\n\n  protected chooseIndex(): number {\n    return this.randomInt(this.buffer.length());\n  }\n\n  async serialNext(): Promise<IteratorResult<T>> {\n    // TODO(soergel): consider performance\n    if (!this.upstreamExhausted) {\n      this.refill();\n    }\n    while (!this.buffer.isEmpty()) {\n      const chosenIndex = this.chooseIndex();\n      const result = await this.buffer.shuffleExcise(chosenIndex);\n      if (result.done) {\n        this.upstreamExhausted = true;\n      } else {\n        this.refill();\n        return result;\n      }\n    }\n    return {value: null, done: true};\n  }\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;;;;;;;;;;;;;;;;GAgBG;;;AAEH,OAAO,KAAK,EAAE,MAAM,uBAAuB,CAAC;AAC5C,OAAO,KAAK,UAAU,MAAM,YAAY,CAAC;AAGzC,OAAO,EAAC,SAAS,EAAC,MAAM,oBAAoB,CAAC;AAC7C,OAAO,EAAC,kBAAkB,EAAqC,OAAO,EAAE,SAAS,EAAC,MAAM,kBAAkB,CAAC;AAC3G,OAAO,EAAC,iBAAiB,EAAC,MAAM,6BAA6B,CAAC;AAC9D,OAAO,EAAC,UAAU,EAAC,MAAM,qBAAqB,CAAC;;;;;;;AAczC,SAAU,iBAAiB,CAAI,KAAU;IAC7C,OAAO,IAAI,aAAa,CAAC,KAAK,CAAC,CAAC;AAClC,CAAC;AAKK,SAAU,wBAAwB,CAAC,KAAa;IACpD,IAAI,CAAC,GAAG,KAAK,CAAC;IACd,OAAO,oBAAoB,CAAC,GAAG,CAAG,CAAD,AAAE;YAAC,KAAK,EAAE,CAAC,EAAE;YAAE,IAAI,EAAE,KAAK;QAAA,CAAC,CAAC,CAAC,CAAC;AACjE,CAAC;AAeK,SAAU,oBAAoB,CAChC,IACiD;IACnD,OAAO,IAAI,oBAAoB,CAAC,IAAI,CAAC,CAAC;AACxC,CAAC;AAcK,SAAU,wBAAwB,CACpC,aAA4C,EAC5C,gBAAwC;IAC1C,OAAO,IAAI,eAAe,CAAC,aAAa,EAAE,gBAAgB,CAAC,CAAC;AAC9D,CAAC;AAkBK,SAAU,gCAAgC,CAC5C,YAAmD,EAAE,KAAa,EAClE,gBAAwC;IAC1C,OAAO,wBAAwB,CAC3B,oBAAoB,CAAC,YAAY,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,EAAE,gBAAgB,CAAC,CAAC;AACxE,CAAC;AA0BK,SAAU,kBAAkB,CAC9B,SAA4B,EAC5B,eAAgC,eAAe,CAAC,IAAI;IACtD,OAAO,IAAI,WAAW,CAAI,SAAS,EAAE,YAAY,CAAC,CAAC;AACrD,CAAC;AASK,MAAgB,YAAY;IAgBhC;;;;;;;OAOG,CACH,KAAK,CAAC,OAAO,GAAA;QACX,MAAM,MAAM,GAAQ,EAAE,CAAC;QACvB,IAAI,CAAC,GAAG,MAAM,IAAI,CAAC,IAAI,EAAE,CAAC;QAC1B,MAAO,CAAC,CAAC,CAAC,IAAI,CAAE;YACd,MAAM,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC;YACrB,CAAC,GAAG,MAAM,IAAI,CAAC,IAAI,EAAE,CAAC;SACvB;QACD,OAAO,MAAM,CAAC;IAChB,CAAC;IAED;;;;;;;;;;OAUG,CACH,KAAK,CAAC,cAAc,GAAA;QAClB,MAAM,MAAM,GAAG,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC;QAClC,MAAM,MAAM,GAAQ,EAAE,CAAC;QACvB,IAAI,CAAC,GAAG,MAAM,MAAM,CAAC,IAAI,EAAE,CAAC;QAC5B,MAAO,CAAC,CAAC,CAAC,IAAI,CAAE;YACd,MAAM,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC;YACrB,CAAC,GAAG,MAAM,MAAM,CAAC,IAAI,EAAE,CAAC;SACzB;QACD,OAAO,MAAM,CAAC;IAChB,CAAC;IAED;;;;;;OAMG,CACH,KAAK,CAAC,YAAY,GAAA;QAChB,IAAI,CAAC,GAAG,MAAM,IAAI,CAAC,IAAI,EAAE,CAAC;QAC1B,MAAO,CAAC,CAAC,CAAC,IAAI,CAAE;YACd,CAAC,GAAG,MAAM,IAAI,CAAC,IAAI,EAAE,CAAC;SACvB;IACH,CAAC;IAED;;;;;;OAMG,CACH,KAAK,CAAC,YAAY,CAAC,SAA4B,EAAA;QAC7C,IAAI,CAAC,GAAG,MAAM,IAAI,CAAC,IAAI,EAAE,CAAC;QAC1B,IAAI,cAAc,GAAG,SAAS,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC;QACxC,MAAO,AAAC,CAAC,CAAC,CAAC,IAAI,CAAC,GAAI,cAAc,CAAE;YAClC,CAAC,GAAG,MAAM,IAAI,CAAC,IAAI,EAAE,CAAC;YACtB,cAAc,GAAG,SAAS,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC;SACrC;IACH,CAAC;IAED;;;;;;;;;;;OAWG,CACH,YAAY,CAAC,OAAkC,EAAA;QAC7C,OAAO,IAAI,yBAAyB,CAAC,IAAI,EAAE,OAAO,CAAC,CAAC;IACtD,CAAC;IAED,yCAAyC;IAEzC;;;;;;;OAOG,CACH,MAAM,CAAC,SAAgC,EAAA;QACrC,OAAO,IAAI,cAAc,CAAC,IAAI,EAAE,SAAS,CAAC,CAAC;IAC7C,CAAC;IAED;;;;;;;OAOG,CACH,GAAG,CAAI,SAA0B,EAAA;QAC/B,OAAO,IAAI,WAAW,CAAC,IAAI,EAAE,SAAS,CAAC,CAAC;IAC1C,CAAC;IAED;;;;;;;OAOG,CACH,QAAQ,CAAI,SAAmC,EAAA;QAC7C,OAAO,IAAI,gBAAgB,CAAC,IAAI,EAAE,SAAS,CAAC,CAAC;IAC/C,CAAC;IAED;;;;;;;OAOG,CACH,cAAc,CAAI,SAAmC,EAAA;QACnD,OAAO,IAAI,gBAAgB,CAAC,IAAI,EAAE,SAAS,CAAC,CAAC,MAAM,EAAE,CAAC;IACxD,CAAC;IAED;;;;;;;OAOG,CACH,OAAO,CAAI,SAA4B,EAAA;QACrC,OAAO,IAAI,eAAe,CAAC,IAAI,EAAE,SAAS,CAAC,CAAC;IAC9C,CAAC;IAED;;;;OAIG,CACH,KAAK,CAAC,YAAY,CAAC,CAAqB,EAAA;QACtC,OAAO,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,YAAY,EAAE,CAAC;IACpC,CAAC;IAED;;;;;;OAMG,CACH,KAAK,CAAC,aAAa,CAAC,CAAiC,EAAA;QACnD,OAAO,IAAI,CAAC,cAAc,CAAC,CAAC,CAAC,CAAC,YAAY,EAAC,CAAC,CAAC,EAAE,AAAE,CAAD,AAAE,KAAK,IAAI,CAAC,CAAC,CAAC;IAChE,CAAC;IAED;;;;;;;;;;;;;;;;;OAiBG,CACH,aAAa,CAAC,SAAiB,EAAE,cAAc,GAAG,IAAI,EAAA;QACpD,OAAO,IAAI,qBAAqB,CAAC,IAAI,EAAE,SAAS,EAAE,cAAc,CAAC,CAAC;IACpE,CAAC;IAED;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;OA+BG,CACH,gBAAgB,CACZ,SAAiB,EAAE,cAAc,GAAG,IAAI,EACxC,kCAAkC;IAClC,QAAsC,wUAAS,EAAA;QAEjD,2EAA2E;QAC3E,MAAM,UAAU,GAAG,IAAI,CAAC,aAAa,CAAC,SAAS,EAAE,cAAc,CAAC,CAAC;QACjE,2EAA2E;QAC3E,uEAAuE;QACvE,OAAO,UAAU,CAAC,GAAG,EAAC,CAAC,CAAC,EAAE,IAAC,sUAAO,EAAC,CAAC,EAAE,KAAK,CAAC,CAAC,CAAC;IAChD,CAAC;IAED;;;;;;;;;OASG,CACH,WAAW,CACP,QAAyB,EACzB,gBAAwC,EAAA;QAC1C,OAAO,IAAI,eAAe,CACtB,iBAAiB,CAAC;YAAC,IAAI;YAAE,QAAQ;SAAC,CAAC,EAAE,gBAAgB,CAAC,CAAC;IAC7D,CAAC;IAED;;;;;;OAMG,CACH,IAAI,CAAC,KAAa,EAAA;QAChB,IAAI,KAAK,GAAG,CAAC,IAAI,KAAK,IAAI,IAAI,EAAE;YAC9B,OAAO,IAAI,CAAC;SACb;QACD,OAAO,IAAI,YAAY,CAAC,IAAI,EAAE,KAAK,CAAC,CAAC;IACvC,CAAC;IAED;;;;;OAKG,CACH,IAAI,CAAC,KAAa,EAAA;QAChB,IAAI,KAAK,GAAG,CAAC,IAAI,KAAK,IAAI,IAAI,EAAE;YAC9B,OAAO,IAAI,CAAC;SACb;QACD,OAAO,IAAI,YAAY,CAAC,IAAI,EAAE,KAAK,CAAC,CAAC;IACvC,CAAC;IAED;;;;;;;;OAQG,CACH,QAAQ,CAAC,UAAkB,EAAA;QACzB,OAAO,IAAI,gBAAgB,CAAC,IAAI,EAAE,UAAU,CAAC,CAAC;IAChD,CAAC;IAED,uDAAuD;IAEvD;;;;;;;OAOG,CACH,OAAO,CAAC,UAAkB,EAAE,IAAa,EAAA;QACvC,OAAO,IAAI,eAAe,CAAC,IAAI,EAAE,UAAU,EAAE,IAAI,CAAC,CAAC;IACrD,CAAC;IAED;;;OAGG,CACH,MAAM,GAAA;QACJ,OAAO,IAAI,cAAc,CAAC,IAAI,CAAC,CAAC;IAClC,CAAC;CACF;AAED,+EAA+E;AAC/E,yEAAyE;AACzE,0EAA0E;AAC1E,kDAAkD;AAClD,+EAA+E;AAE/E,mDAAmD;AACnD,+EAA+E;AAE/E,MAAM,aAAiB,SAAQ,YAAe;IAE5C,YAAsB,KAAU,CAAA;QAC9B,KAAK,EAAE,CAAC;QADY,IAAA,CAAA,KAAK,GAAL,KAAK,CAAK;QADxB,IAAA,CAAA,IAAI,GAAG,CAAC,CAAC;IAGjB,CAAC;IAED,OAAO,GAAA;QACL,OAAO,CAAA,SAAA,EAAY,IAAI,CAAC,KAAK,CAAC,MAAM,CAAA,MAAA,CAAQ,CAAC;IAC/C,CAAC;IAED,KAAK,CAAC,IAAI,GAAA;QACR,IAAI,IAAI,CAAC,IAAI,IAAI,IAAI,CAAC,KAAK,CAAC,MAAM,EAAE;YAClC,OAAO;gBAAC,KAAK,EAAE,IAAI;gBAAE,IAAI,EAAE,IAAI;YAAA,CAAC,CAAC;SAClC;QACD,MAAM,IAAI,GAAG,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;QACnC,IAAI,CAAC,IAAI,EAAE,CAAC;QACZ,OAAO;YAAC,KAAK,MAAE,0UAAS,EAAC,IAAI,CAAC;YAAE,IAAI,EAAE,KAAK;QAAA,CAAC,CAAC;IAC/C,CAAC;CACF;AAED,MAAM,oBAAwB,SAAQ,YAAe;IACnD,YACc,MAA2D,CAAA;QACvE,KAAK,EAAE,CAAC;QADI,IAAA,CAAA,MAAM,GAAN,MAAM,CAAqD;IAEzE,CAAC;IAED,OAAO,GAAA;QACL,OAAO,CAAA,aAAA,CAAe,CAAC;IACzB,CAAC;IAED,KAAK,CAAC,IAAI,GAAA;QACR,IAAI;YACF,OAAO,IAAI,CAAC,MAAM,EAAE,CAAC;SACtB,CAAC,OAAO,CAAC,EAAE;YACV,4DAA4D;YAC5D,CAAC,CAAC,OAAO,GACL,CAAA,gDAAA,EAAmD,CAAC,CAAC,OAAO,EAAE,CAAC;YACnE,MAAM,CAAC,CAAC;SACT;IACH,CAAC;CACF;AAED,MAAM,cAAkB,SAAQ,YAAe;IAK7C,YAAsB,QAAyB,CAAA;QAC7C,KAAK,EAAE,CAAC;QADY,IAAA,CAAA,QAAQ,GAAR,QAAQ,CAAiB;QAE7C,IAAI,CAAC,QAAQ,GAAG,OAAO,CAAC,OAAO,CAAC;YAAC,KAAK,EAAE,IAAI;YAAE,IAAI,EAAE,KAAK;QAAA,CAAC,CAAC,CAAC;IAC9D,CAAC;IAED,OAAO,GAAA;QACL,OAAO,GAAG,IAAI,CAAC,QAAQ,CAAC,OAAO,EAAE,CAAA,UAAA,CAAY,CAAC;IAChD,CAAC;IAED,KAAK,CAAC,IAAI,GAAA;QACR,qEAAqE;QACrE,yEAAyE;QACzE,uEAAuE;QACvE,oBAAoB;QACpB,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAC,GAAG,CAAG,CAAD,GAAK,CAAC,UAAU,EAAE,CAAC,CAAC;QAC5D,OAAO,IAAI,CAAC,QAAQ,CAAC;IACvB,CAAC;IAEO,KAAK,CAAC,UAAU,GAAA;QACtB,OAAO,IAAI,CAAC,QAAQ,CAAC,IAAI,EAAE,CAAC;IAC9B,CAAC;CACF;AAED,MAAM,YAAgB,SAAQ,YAAe;IAQ3C,YAAsB,QAAyB,EAAY,QAAgB,CAAA;QACzE,KAAK,EAAE,CAAC;QADY,IAAA,CAAA,QAAQ,GAAR,QAAQ,CAAiB;QAAY,IAAA,CAAA,QAAQ,GAAR,QAAQ,CAAQ;QAH3E,sEAAsE;QACtE,IAAA,CAAA,KAAK,GAAG,CAAC,CAAC;QAIR,IAAI,CAAC,QAAQ,GAAG,OAAO,CAAC,OAAO,CAAC;YAAC,KAAK,EAAE,IAAI;YAAE,IAAI,EAAE,KAAK;QAAA,CAAC,CAAC,CAAC;IAC9D,CAAC;IAED,OAAO,GAAA;QACL,OAAO,GAAG,IAAI,CAAC,QAAQ,CAAC,OAAO,EAAE,CAAA,QAAA,CAAU,CAAC;IAC9C,CAAC;IAED,KAAK,CAAC,IAAI,GAAA;QACR,qEAAqE;QACrE,yEAAyE;QACzE,uEAAuE;QACvE,oBAAoB;QACpB,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAC,GAAG,CAAG,CAAD,GAAK,CAAC,UAAU,EAAE,CAAC,CAAC;QAC5D,OAAO,IAAI,CAAC,QAAQ,CAAC;IACvB,CAAC;IAEO,KAAK,CAAC,UAAU,GAAA;QACtB,gEAAgE;QAChE,8DAA8D;QAC9D,yEAAyE;QACzE,oBAAoB;QACpB,MAAO,IAAI,CAAC,KAAK,EAAE,GAAG,IAAI,CAAC,QAAQ,CAAE;YACnC,MAAM,OAAO,GAAG,MAAM,IAAI,CAAC,QAAQ,CAAC,IAAI,EAAE,CAAC;YAC3C,6CAA6C;YAC7C,IAAI,OAAO,CAAC,IAAI,EAAE;gBAChB,OAAO,OAAO,CAAC;aAChB;YACD,EAAE,CAAC,iPAAO,CAAC,OAAO,CAAC,KAAW,CAAC,CAAC;SACjC;QACD,OAAO,IAAI,CAAC,QAAQ,CAAC,IAAI,EAAE,CAAC;IAC9B,CAAC;CACF;AAED,MAAM,YAAgB,SAAQ,YAAe;IAE3C,YAAsB,QAAyB,EAAY,QAAgB,CAAA;QACzE,KAAK,EAAE,CAAC;QADY,IAAA,CAAA,QAAQ,GAAR,QAAQ,CAAiB;QAAY,IAAA,CAAA,QAAQ,GAAR,QAAQ,CAAQ;QAD3E,IAAA,CAAA,KAAK,GAAG,CAAC,CAAC;IAGV,CAAC;IAED,OAAO,GAAA;QACL,OAAO,GAAG,IAAI,CAAC,QAAQ,CAAC,OAAO,EAAE,CAAA,QAAA,CAAU,CAAC;IAC9C,CAAC;IAED,KAAK,CAAC,IAAI,GAAA;QACR,IAAI,IAAI,CAAC,KAAK,EAAE,IAAI,IAAI,CAAC,QAAQ,EAAE;YACjC,OAAO;gBAAC,KAAK,EAAE,IAAI;gBAAE,IAAI,EAAE,IAAI;YAAA,CAAC,CAAC;SAClC;QACD,OAAO,IAAI,CAAC,QAAQ,CAAC,IAAI,EAAE,CAAC;IAC9B,CAAC;CACF;AAED,kEAAkE;AAClE,6EAA6E;AAC7E,SAAS;AACT,MAAM,qBAAyB,SAAQ,YAAiB;IAKtD,YACc,QAAyB,EAAY,SAAiB,EACtD,uBAAuB,IAAI,CAAA;QACvC,KAAK,EAAE,CAAC;QAFI,IAAA,CAAA,QAAQ,GAAR,QAAQ,CAAiB;QAAY,IAAA,CAAA,SAAS,GAAT,SAAS,CAAQ;QACtD,IAAA,CAAA,oBAAoB,GAApB,oBAAoB,CAAO;QAEvC,IAAI,CAAC,QAAQ,GAAG,OAAO,CAAC,OAAO,CAAC;YAAC,KAAK,EAAE,IAAI;YAAE,IAAI,EAAE,KAAK;QAAA,CAAC,CAAC,CAAC;IAC9D,CAAC;IAED,OAAO,GAAA;QACL,OAAO,GAAG,IAAI,CAAC,QAAQ,CAAC,OAAO,EAAE,CAAA,iBAAA,CAAmB,CAAC;IACvD,CAAC;IAED,KAAK,CAAC,IAAI,GAAA;QACR,qEAAqE;QACrE,yEAAyE;QACzE,uEAAuE;QACvE,oBAAoB;QACpB,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAC,GAAG,CAAG,CAAD,GAAK,CAAC,UAAU,EAAE,CAAC,CAAC;QAC5D,OAAO,IAAI,CAAC,QAAQ,CAAC;IACvB,CAAC;IAEO,KAAK,CAAC,UAAU,GAAA;QACtB,MAAM,KAAK,GAAQ,EAAE,CAAC;QACtB,MAAO,KAAK,CAAC,MAAM,GAAG,IAAI,CAAC,SAAS,CAAE;YACpC,MAAM,IAAI,GAAG,MAAM,IAAI,CAAC,QAAQ,CAAC,IAAI,EAAE,CAAC;YACxC,IAAI,IAAI,CAAC,IAAI,EAAE;gBACb,IAAI,IAAI,CAAC,oBAAoB,IAAI,KAAK,CAAC,MAAM,GAAG,CAAC,EAAE;oBACjD,OAAO;wBAAC,KAAK,EAAE,KAAK;wBAAE,IAAI,EAAE,KAAK;oBAAA,CAAC,CAAC;iBACpC;gBACD,OAAO;oBAAC,KAAK,EAAE,IAAI;oBAAE,IAAI,EAAE,IAAI;gBAAA,CAAC,CAAC;aAClC;YACD,KAAK,CAAC,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;SACxB;QACD,OAAO;YAAC,KAAK,EAAE,KAAK;YAAE,IAAI,EAAE,KAAK;QAAA,CAAC,CAAC;IACrC,CAAC;CACF;AAED,MAAM,cAAkB,SAAQ,YAAe;IAK7C,YACc,QAAyB,EACzB,SAAgC,CAAA;QAC5C,KAAK,EAAE,CAAC;QAFI,IAAA,CAAA,QAAQ,GAAR,QAAQ,CAAiB;QACzB,IAAA,CAAA,SAAS,GAAT,SAAS,CAAuB;QAE5C,IAAI,CAAC,QAAQ,GAAG,OAAO,CAAC,OAAO,CAAC;YAAC,KAAK,EAAE,IAAI;YAAE,IAAI,EAAE,KAAK;QAAA,CAAC,CAAC,CAAC;IAC9D,CAAC;IAED,OAAO,GAAA;QACL,OAAO,GAAG,IAAI,CAAC,QAAQ,CAAC,OAAO,EAAE,CAAA,UAAA,CAAY,CAAC;IAChD,CAAC;IAED,KAAK,CAAC,IAAI,GAAA;QACR,qEAAqE;QACrE,yEAAyE;QACzE,uEAAuE;QACvE,oBAAoB;QACpB,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAC,GAAG,CAAG,CAAD,GAAK,CAAC,UAAU,EAAE,CAAC,CAAC;QAC5D,OAAO,IAAI,CAAC,QAAQ,CAAC;IACvB,CAAC;IAEO,KAAK,CAAC,UAAU,GAAA;QACtB,MAAO,IAAI,CAAE;YACX,MAAM,IAAI,GAAG,MAAM,IAAI,CAAC,QAAQ,CAAC,IAAI,EAAE,CAAC;YACxC,IAAI,IAAI,CAAC,IAAI,IAAI,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,KAAK,CAAC,EAAE;gBAC3C,OAAO,IAAI,CAAC;aACb;YACD,EAAE,CAAC,iPAAO,CAAC,IAAI,CAAC,KAAW,CAAC,CAAC;SAC9B;IACH,CAAC;CACF;AAED,MAAM,WAAkB,SAAQ,YAAe;IAC7C,YACc,QAAyB,EACzB,SAA0B,CAAA;QACtC,KAAK,EAAE,CAAC;QAFI,IAAA,CAAA,QAAQ,GAAR,QAAQ,CAAiB;QACzB,IAAA,CAAA,SAAS,GAAT,SAAS,CAAiB;IAExC,CAAC;IAED,OAAO,GAAA;QACL,OAAO,GAAG,IAAI,CAAC,QAAQ,CAAC,OAAO,EAAE,CAAA,OAAA,CAAS,CAAC;IAC7C,CAAC;IAED,KAAK,CAAC,IAAI,GAAA;QACR,MAAM,IAAI,GAAG,MAAM,IAAI,CAAC,QAAQ,CAAC,IAAI,EAAE,CAAC;QACxC,IAAI,IAAI,CAAC,IAAI,EAAE;YACb,OAAO;gBAAC,KAAK,EAAE,IAAI;gBAAE,IAAI,EAAE,IAAI;YAAA,CAAC,CAAC;SAClC;QACD,MAAM,YAAY,GAAG,EAAE,CAAC,gSAAW,CAAC,qBAAqB,CAAC,IAAI,CAAC,KAAW,CAAC,CAAC;QAC5E,uDAAuD;QACvD,mEAAmE;QACnE,uEAAuE;QACvE,kEAAkE;QAClE,kEAAkE;QAClE,UAAU;QACV,MAAM,MAAM,GAAG,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;QAC1C,MAAM,aAAa,GAAG,EAAE,CAAC,gSAAW,CAAC,qBAAqB,CAAC,MAAY,CAAC,CAAC;QAEzE,oCAAoC;QACpC,mDAAmD;QACnD,KAAK,MAAM,CAAC,IAAI,YAAY,CAAE;YAC5B,IAAI,CAAC,EAAE,CAAC,gSAAW,CAAC,cAAc,CAAC,CAAC,EAAE,aAAa,CAAC,EAAE;gBACpD,CAAC,CAAC,OAAO,EAAE,CAAC;aACb;SACF;QACD,OAAO;YAAC,KAAK,EAAE,MAAM;YAAE,IAAI,EAAE,KAAK;QAAA,CAAC,CAAC;IACtC,CAAC;CACF;AAED,MAAM,yBAA6B,SAAQ,YAAe;IAExD,YACc,QAAyB,EACzB,OAAkC,CAAA;QAC9C,KAAK,EAAE,CAAC;QAFI,IAAA,CAAA,QAAQ,GAAR,QAAQ,CAAiB;QACzB,IAAA,CAAA,OAAO,GAAP,OAAO,CAA2B;QAHhD,IAAA,CAAA,KAAK,GAAG,CAAC,CAAC;QAKR,IAAI,CAAC,QAAQ,GAAG,OAAO,CAAC,OAAO,CAAC;YAAC,KAAK,EAAE,IAAI;YAAE,IAAI,EAAE,KAAK;QAAA,CAAC,CAAC,CAAC;IAC9D,CAAC;IAED,OAAO,GAAA;QACL,OAAO,GAAG,IAAI,CAAC,QAAQ,CAAC,OAAO,EAAE,CAAA,gBAAA,CAAkB,CAAC;IACtD,CAAC;IAMD,KAAK,CAAC,IAAI,GAAA;QACR,qEAAqE;QACrE,yEAAyE;QACzE,uEAAuE;QACvE,oBAAoB;QACpB,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAC,GAAG,CAAG,CAAD,GAAK,CAAC,UAAU,EAAE,CAAC,CAAC;QAC5D,OAAO,IAAI,CAAC,QAAQ,CAAC;IACvB,CAAC;IAED,KAAK,CAAC,UAAU,GAAA;QACd,MAAO,IAAI,CAAE;YACX,IAAI;gBACF,OAAO,MAAM,IAAI,CAAC,QAAQ,CAAC,IAAI,EAAE,CAAC;aACnC,CAAC,OAAO,CAAC,EAAE;gBACV,IAAI,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE;oBACpB,OAAO;wBAAC,KAAK,EAAE,IAAI;wBAAE,IAAI,EAAE,IAAI;oBAAA,CAAC,CAAC;iBAClC;YACD,sEAAsE;YAEtE,sEAAsE;YACtE,uEAAuE;YACvE,wEAAwE;aACzE;SACF;IACH,CAAC;CACF;AAED,MAAM,gBAAuB,SAAQ,YAAe;IAClD,YACc,QAAyB,EACzB,SAAmC,CAAA;QAC/C,KAAK,EAAE,CAAC;QAFI,IAAA,CAAA,QAAQ,GAAR,QAAQ,CAAiB;QACzB,IAAA,CAAA,SAAS,GAAT,SAAS,CAA0B;IAEjD,CAAC;IAED,OAAO,GAAA;QACL,OAAO,GAAG,IAAI,CAAC,QAAQ,CAAC,OAAO,EAAE,CAAA,YAAA,CAAc,CAAC;IAClD,CAAC;IAED,KAAK,CAAC,IAAI,GAAA;QACR,MAAM,IAAI,GAAG,MAAM,IAAI,CAAC,QAAQ,CAAC,IAAI,EAAE,CAAC;QACxC,IAAI,IAAI,CAAC,IAAI,EAAE;YACb,OAAO;gBAAC,KAAK,EAAE,IAAI;gBAAE,IAAI,EAAE,IAAI;YAAA,CAAC,CAAC;SAClC;QACD,MAAM,YAAY,GAAG,EAAE,CAAC,gSAAW,CAAC,qBAAqB,CAAC,IAAI,CAAC,KAAW,CAAC,CAAC;QAC5E,uDAAuD;QACvD,mEAAmE;QACnE,uEAAuE;QACvE,kEAAkE;QAClE,kEAAkE;QAClE,UAAU;QACV,MAAM,MAAM,GAAG,MAAM,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;QAChD,MAAM,aAAa,GAAG,EAAE,CAAC,gSAAW,CAAC,qBAAqB,CAAC,MAAY,CAAC,CAAC;QAEzE,oCAAoC;QACpC,mDAAmD;QACnD,KAAK,MAAM,CAAC,IAAI,YAAY,CAAE;YAC5B,IAAI,CAAC,EAAE,CAAC,gSAAW,CAAC,cAAc,CAAC,CAAC,EAAE,aAAa,CAAC,EAAE;gBACpD,CAAC,CAAC,OAAO,EAAE,CAAC;aACb;SACF;QACD,OAAO;YAAC,KAAK,EAAE,MAAM;YAAE,IAAI,EAAE,KAAK;QAAA,CAAC,CAAC;IACtC,CAAC;CACF;AAaK,MAAgB,iBAAqB,SAAQ,YAAe;IAQhE,aAAA;QACE,KAAK,EAAE,CAAC;QACR,IAAI,CAAC,WAAW,GAAG,IAAI,2VAAiB,EAAK,CAAC;QAC9C,IAAI,CAAC,QAAQ,GAAG,OAAO,CAAC,OAAO,CAAC;YAAC,KAAK,EAAE,IAAI;YAAE,IAAI,EAAE,KAAK;QAAA,CAAC,CAAC,CAAC;IAC9D,CAAC;IAED,KAAK,CAAC,IAAI,GAAA;QACR,qEAAqE;QACrE,yEAAyE;QACzE,uEAAuE;QACvE,oBAAoB;QACpB,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAC,GAAG,CAAG,CAAD,GAAK,CAAC,UAAU,EAAE,CAAC,CAAC;QAC5D,OAAO,IAAI,CAAC,QAAQ,CAAC;IACvB,CAAC;IAgBD,KAAK,CAAC,UAAU,GAAA;QACd,kEAAkE;QAClE,sEAAsE;QACtE,wDAAwD;QACxD,MAAO,IAAI,CAAC,WAAW,CAAC,MAAM,EAAE,KAAK,CAAC,CAAE;YACtC,0CAA0C;YAC1C,IAAI,CAAC,MAAM,IAAI,CAAC,IAAI,EAAE,EAAE;gBACtB,OAAO;oBAAC,KAAK,EAAE,IAAI;oBAAE,IAAI,EAAE,IAAI;gBAAA,CAAC,CAAC;aAClC;SACF;QACD,OAAO;YAAC,KAAK,EAAE,IAAI,CAAC,WAAW,CAAC,KAAK,EAAE;YAAE,IAAI,EAAE,KAAK;QAAA,CAAC,CAAC;IACxD,CAAC;CACF;AACD,MAAM,eAAsB,SAAQ,iBAAoB;IACtD,YACc,QAAyB,EACzB,SAA4B,CAAA;QACxC,KAAK,EAAE,CAAC;QAFI,IAAA,CAAA,QAAQ,GAAR,QAAQ,CAAiB;QACzB,IAAA,CAAA,SAAS,GAAT,SAAS,CAAmB;IAE1C,CAAC;IAED,OAAO,GAAA;QACL,OAAO,GAAG,IAAI,CAAC,QAAQ,CAAC,OAAO,EAAE,CAAA,WAAA,CAAa,CAAC;IACjD,CAAC;IAED,KAAK,CAAC,IAAI,GAAA;QACR,MAAM,IAAI,GAAG,MAAM,IAAI,CAAC,QAAQ,CAAC,IAAI,EAAE,CAAC;QACxC,IAAI,IAAI,CAAC,IAAI,EAAE;YACb,OAAO,KAAK,CAAC;SACd;QACD,MAAM,YAAY,GAAG,EAAE,CAAC,gSAAW,CAAC,qBAAqB,CAAC,IAAI,CAAC,KAAW,CAAC,CAAC;QAC5E,uDAAuD;QACvD,mEAAmE;QACnE,uEAAuE;QACvE,sEAAsE;QACtE,sEAAsE;QACtE,MAAM,WAAW,GAAG,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;QAC/C,MAAM,aAAa,GACf,EAAE,CAAC,gSAAW,CAAC,qBAAqB,CAAC,WAAiB,CAAC,CAAC;QAC5D,IAAI,CAAC,WAAW,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC;QAEtC,mEAAmE;QACnE,mDAAmD;QACnD,KAAK,MAAM,CAAC,IAAI,YAAY,CAAE;YAC5B,IAAI,CAAC,EAAE,CAAC,gSAAW,CAAC,cAAc,CAAC,CAAC,EAAE,aAAa,CAAC,EAAE;gBACpD,CAAC,CAAC,OAAO,EAAE,CAAC;aACb;SACF;QAED,OAAO,IAAI,CAAC;IACd,CAAC;CACF;AAWK,MAAO,eAAmB,SAAQ,YAAe;IASrD,YACI,SAAwC,EACvB,gBAAwC,CAAA;QAC3D,KAAK,EAAE,CAAC;QADW,IAAA,CAAA,gBAAgB,GAAhB,gBAAgB,CAAwB;QAV7D,kCAAkC;QAClC,qEAAqE;QAC7D,IAAA,CAAA,QAAQ,GAA+B,IAAI,CAAC;QAEpD,sEAAsE;QAC9D,IAAA,CAAA,QAAQ,GAAoB,IAAI,CAAC;QAOvC,IAAI,CAAC,aAAa,GAAG,SAAS,CAAC;IACjC,CAAC;IAED,OAAO,GAAA;QACL,MAAM,iBAAiB,GAAG,6CAA6C,CAAC;QACxE,OAAO,GAAG,iBAAiB,CAAA,WAAA,CAAa,CAAC;IAC3C,CAAC;IAED,KAAK,CAAC,IAAI,GAAA;QACR,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC;QAClD,OAAO,IAAI,CAAC,QAAQ,CAAC;IACvB,CAAC;IAEO,KAAK,CAAC,aAAa,CAAC,QAAoC,EAAA;QAE9D,4EAA4E;QAC5E,qDAAqD;QACrD,oEAAoE;QACpE,6CAA6C;QAC7C,4DAA4D;QAC5D,MAAM,QAAQ,CAAC;QACf,IAAI,IAAI,CAAC,QAAQ,IAAI,IAAI,EAAE;YACzB,MAAM,cAAc,GAAG,MAAM,IAAI,CAAC,aAAa,CAAC,IAAI,EAAE,CAAC;YACvD,IAAI,cAAc,CAAC,IAAI,EAAE;gBACvB,kCAAkC;gBAClC,OAAO;oBAAC,KAAK,EAAE,IAAI;oBAAE,IAAI,EAAE,IAAI;gBAAA,CAAC,CAAC;aAClC;YACD,IAAI,CAAC,QAAQ,GAAG,cAAc,CAAC,KAAK,CAAC;YACrC,IAAI,IAAI,CAAC,gBAAgB,IAAI,IAAI,EAAE;gBACjC,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC,QAAQ,CAAC,YAAY,CAAC,IAAI,CAAC,gBAAgB,CAAC,CAAC;aACnE;SACF;QACD,MAAM,UAAU,GAAG,MAAM,IAAI,CAAC,QAAQ,CAAC,IAAI,EAAE,CAAC;QAC9C,IAAI,UAAU,CAAC,IAAI,EAAE;YACnB,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC;YACrB,OAAO,IAAI,CAAC,aAAa,CAAC,QAAQ,CAAC,CAAC;SACrC;QACD,OAAO,UAAU,CAAC;IACpB,CAAC;CACF;AAED,IAAY,eAIX;AAJD,CAAA,SAAY,eAAe;IACzB,eAAA,CAAA,eAAA,CAAA,OAAA,GAAA,EAAA,GAAA,MAAI,CAAA;IACJ,eAAA,CAAA,eAAA,CAAA,WAAA,GAAA,EAAA,GAAA,UAAQ,CAAA;IACR,eAAA,CAAA,eAAA,CAAA,UAAA,GAAA,EAAA,GAAA,SAAO,CAAA,CAAI,8DAA8D;AAC3E,CAAC,EAJW,eAAe,IAAA,CAAf,eAAe,GAAA,CAAA,CAAA,GAI1B;AAED;;;;;;;;;;;;;;;;;;;;;;;;;;;;GA4BG,CACH,MAAM,WAA0C,SAAQ,YAAe;IAIrE,YACuB,SAA4B,EAC5B,eAAgC,eAAe,CAAC,IAAI,CAAA;QACzE,KAAK,EAAE,CAAC;QAFa,IAAA,CAAA,SAAS,GAAT,SAAS,CAAmB;QAC5B,IAAA,CAAA,YAAY,GAAZ,YAAY,CAAwC;QALnE,IAAA,CAAA,KAAK,GAAG,CAAC,CAAC;QACV,IAAA,CAAA,cAAc,GAA+B,IAAI,CAAC;IAM1D,CAAC;IAED,OAAO,GAAA;QACL,MAAM,iBAAiB,GAAG,yCAAyC,CAAC;QACpE,OAAO,CAAA,CAAA,EAAI,iBAAiB,CAAA,QAAA,CAAU,CAAC;IACzC,CAAC;IAEO,KAAK,CAAC,SAAS,CAAC,UAAsC,EAAA;QAE5D,uEAAuE;QACvE,0CAA0C;QAC1C,MAAM,UAAU,CAAC;QAEjB,iEAAiE;QACjE,YAAY;QACZ,IAAI,YAAY,GAAG,CAAC,CAAC;QACrB,IAAI,aAAa,GAAG,CAAC,CAAC;QAEtB,SAAS,OAAO,CAAC,SAA4B;YAC3C,IAAI,SAAS,YAAY,YAAY,EAAE;gBACrC,MAAM,MAAM,GAAG,SAAS,CAAC,IAAI,EAAE,CAAC;gBAChC,OAAO;oBACL,KAAK,EAAE,MAAM,CAAC,IAAI,EAAC,CAAC,CAAC,EAAE;wBACrB,YAAY,EAAE,CAAC;wBACf,IAAI,CAAC,CAAC,IAAI,EAAE;4BACV,aAAa,EAAE,CAAC;yBACjB;wBACD,OAAO,CAAC,CAAC,KAAK,CAAC;oBACjB,CAAC,CAAC;oBACF,OAAO,EAAE,KAAK;iBACf,CAAC;aACH,MAAM;gBACL,OAAO;oBAAC,KAAK,EAAE,IAAI;oBAAE,OAAO,EAAE,IAAI;gBAAA,CAAC,CAAC;aACrC;QACH,CAAC;QAED,MAAM,MAAM,GAAM,UAAM,iVAAkB,EAAC,IAAI,CAAC,SAAS,EAAE,OAAO,CAAC,CAAC;QAEpE,IAAI,YAAY,KAAK,aAAa,EAAE;YAClC,8BAA8B;YAC9B,OAAO;gBAAC,KAAK,EAAE,IAAI;gBAAE,IAAI,EAAE,IAAI;YAAA,CAAC,CAAC;SAClC;QACD,IAAI,aAAa,GAAG,CAAC,EAAE;YACrB,OAAQ,IAAI,CAAC,YAAY,EAAE;gBACzB,KAAK,eAAe,CAAC,IAAI;oBACvB,MAAM,IAAI,KAAK,CACX,8CAA8C,GAC9C,CAAA,sBAAA,EAAyB,IAAI,CAAC,KAAK,CAAA,CAAA,CAAG,CAAC,CAAC;gBAC9C,KAAK,eAAe,CAAC,QAAQ;oBAC3B,OAAO;wBAAC,KAAK,EAAE,IAAI;wBAAE,IAAI,EAAE,IAAI;oBAAA,CAAC,CAAC;gBACnC,KAAK,eAAe,CAAC,OAAO,CAAC;gBAC7B,QAAQ;aAET;SACF;QAED,IAAI,CAAC,KAAK,EAAE,CAAC;QACb,OAAO;YAAC,KAAK,EAAE,MAAM;YAAE,IAAI,EAAE,KAAK;QAAA,CAAC,CAAC;IACtC,CAAC;IAED,KAAK,CAAC,IAAI,GAAA;QACR,IAAI,CAAC,cAAc,GAAG,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,cAAc,CAAC,CAAC;QAC1D,OAAO,IAAI,CAAC,cAAc,CAAC;IAC7B,CAAC;CACF;AAYK,MAAO,gBAAoB,SAAQ,YAAe;IAGtD,YACc,QAAyB,EAAY,UAAkB,CAAA;QACnE,KAAK,EAAE,CAAC;QADI,IAAA,CAAA,QAAQ,GAAR,QAAQ,CAAiB;QAAY,IAAA,CAAA,UAAU,GAAV,UAAU,CAAQ;QAEnE,IAAI,CAAC,MAAM,GAAG,IAAI,4UAAU,CAA6B,UAAU,CAAC,CAAC;IACvE,CAAC;IAED,OAAO,GAAA;QACL,OAAO,GAAG,IAAI,CAAC,QAAQ,CAAC,OAAO,EAAE,CAAA,YAAA,CAAc,CAAC;IAClD,CAAC;IAED;;;OAGG,CACO,MAAM,GAAA;QACd,MAAO,CAAC,IAAI,CAAC,MAAM,CAAC,MAAM,EAAE,CAAE;YAC5B,MAAM,CAAC,GAAG,IAAI,CAAC,QAAQ,CAAC,IAAI,EAAE,CAAC;YAC/B,IAAI,CAAC,MAAM,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;SACrB;IACH,CAAC;IAED,IAAI,GAAA;QACF,IAAI,CAAC,MAAM,EAAE,CAAC;QACd,oEAAoE;QACpE,sEAAsE;QACtE,kEAAkE;QAClE,OAAO,IAAI,CAAC,MAAM,CAAC,KAAK,EAAE,CAAC;IAC7B,CAAC;CACF;AAQK,MAAO,eAAmB,SAAQ,gBAAmB;IAUzD,YACqB,QAAyB,EAAY,UAAkB,EACxE,IAAa,CAAA;QACf,KAAK,CAAC,QAAQ,EAAE,UAAU,CAAC,CAAC;QAFT,IAAA,CAAA,QAAQ,GAAR,QAAQ,CAAiB;QAAY,IAAA,CAAA,UAAU,GAAV,UAAU,CAAQ;QAJ5E,sEAAsE;QAC9D,IAAA,CAAA,iBAAiB,GAAG,KAAK,CAAC;QAMhC,IAAI,CAAC,MAAM,GAAG,UAAU,CAAC,uLAAI,CAAC,IAAI,IAAI,EAAE,CAAC,2QAAI,CAAC,GAAG,EAAE,CAAC,QAAQ,EAAE,CAAC,CAAC;QAChE,IAAI,CAAC,QAAQ,GAAG,OAAO,CAAC,OAAO,CAAC;YAAC,KAAK,EAAE,IAAI;YAAE,IAAI,EAAE,KAAK;QAAA,CAAC,CAAC,CAAC;IAC9D,CAAC;IAEQ,KAAK,CAAC,IAAI,GAAA;QACjB,qEAAqE;QACrE,yEAAyE;QACzE,uEAAuE;QACvE,oBAAoB;QACpB,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAC,GAAG,CAAG,CAAD,GAAK,CAAC,UAAU,EAAE,CAAC,CAAC;QAC5D,OAAO,IAAI,CAAC,QAAQ,CAAC;IACvB,CAAC;IAEO,SAAS,CAAC,GAAW,EAAA;QAC3B,OAAO,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,MAAM,EAAE,GAAG,GAAG,CAAC,CAAC;IACzC,CAAC;IAES,WAAW,GAAA;QACnB,OAAO,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,MAAM,CAAC,MAAM,EAAE,CAAC,CAAC;IAC9C,CAAC;IAED,KAAK,CAAC,UAAU,GAAA;QACd,sCAAsC;QACtC,IAAI,CAAC,IAAI,CAAC,iBAAiB,EAAE;YAC3B,IAAI,CAAC,MAAM,EAAE,CAAC;SACf;QACD,MAAO,CAAC,IAAI,CAAC,MAAM,CAAC,OAAO,EAAE,CAAE;YAC7B,MAAM,WAAW,GAAG,IAAI,CAAC,WAAW,EAAE,CAAC;YACvC,MAAM,MAAM,GAAG,MAAM,IAAI,CAAC,MAAM,CAAC,aAAa,CAAC,WAAW,CAAC,CAAC;YAC5D,IAAI,MAAM,CAAC,IAAI,EAAE;gBACf,IAAI,CAAC,iBAAiB,GAAG,IAAI,CAAC;aAC/B,MAAM;gBACL,IAAI,CAAC,MAAM,EAAE,CAAC;gBACd,OAAO,MAAM,CAAC;aACf;SACF;QACD,OAAO;YAAC,KAAK,EAAE,IAAI;YAAE,IAAI,EAAE,IAAI;QAAA,CAAC,CAAC;IACnC,CAAC;CACF"}},
    {"offset": {"line": 1437, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-data@4.22.0_@tensorflow+tfjs-core@4.22.0_seedrandom@3.0.5/node_modules/@tensorflow/tfjs-data/dist/dataset.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-data/src/dataset.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs-core';\nimport {TensorContainer, TensorLike} from '@tensorflow/tfjs-core';\nimport * as seedrandom from 'seedrandom';\n\nimport {iteratorFromConcatenated, iteratorFromFunction, iteratorFromItems, iteratorFromZipped, LazyIterator, ZipMismatchMode} from './iterators/lazy_iterator';\nimport {Container} from './types';\nimport {canTensorify, deepMapAndAwaitAll, DeepMapResult, isIterable} from './util/deep_map';\n\n/**\n * A nested structure of Datasets, used as the input to zip().\n */\nexport type DatasetContainer = Container<Dataset<TensorContainer>>;\n\n// TODO(soergel): consider vectorized operations within the pipeline.\n\n/**\n * Represents a potentially large list of independent data elements (typically\n * 'samples' or 'examples').\n *\n * A 'data example' may be a primitive, an array, a map from string keys to\n * values, or any nested structure of these.\n *\n * A `Dataset` represents an ordered collection of elements, together with a\n * chain of transformations to be performed on those elements. Each\n * transformation is a method of `Dataset` that returns another `Dataset`, so\n * these may be chained, e.g.\n * `const processedDataset = rawDataset.filter(...).map(...).batch(...)`.\n *\n * Data loading and transformation is done in a lazy, streaming fashion.  The\n * dataset may be iterated over multiple times; each iteration starts the data\n * loading anew and recapitulates the transformations.\n *\n * A `Dataset` is typically processed as a stream of unbatched examples -- i.e.,\n * its transformations are applied one example at a time. Batching produces a\n * new `Dataset` where each element is a batch. Batching should usually come\n * last in a pipeline, because data transformations are easier to express on a\n * per-example basis than on a per-batch basis.\n *\n * The following code examples are calling `await dataset.forEachAsync(...)` to\n * iterate once over the entire dataset in order to print out the data.\n *\n * @doc {heading: 'Data', subheading: 'Classes', namespace: 'data'}\n */\nexport abstract class Dataset<T extends tf.TensorContainer> {\n  /*\n   * Provide a new stream of elements.  Note this will also start new streams\n   * from any underlying `Dataset`s.\n   *\n   * CAUTION: Any Tensors contained within the elements returned from\n   * this stream *must* be manually disposed to avoid a GPU memory leak.\n   * The tf.tidy() approach cannot be used in an asynchronous context.\n   */\n  abstract iterator(): Promise<LazyIterator<T>>;\n\n  readonly size: number = null;\n\n  // TODO(soergel): Make Datasets report whether repeated iterator() calls\n  // produce the same result (e.g., reading from a file) or different results\n  // (e.g., from the webcam).  Currently we don't make this distinction but it\n  // could be important for the user to know.\n  // abstract isDeterministic(): boolean;\n\n  /**\n   * Groups elements into batches.\n   *\n   * It is assumed that each of the incoming dataset elements has the same\n   * structure -- i.e. the same set of keys at each location in an object\n   * hierarchy.  For each key, the resulting `Dataset` provides a batched\n   * element collecting all of the incoming values for that key.\n   *\n   *  * Incoming primitives are grouped into a 1-D Tensor.\n   *  * Incoming Tensors are grouped into a new Tensor where the 0th axis is\n   *    the batch dimension.\n   *  * Incoming arrays are converted to Tensor and then batched.\n   *  * A nested array is interpreted as an n-D Tensor, so the batched result\n   *    has n+1 dimensions.\n   *  * An array that cannot be converted to Tensor produces an error.\n   *\n   * If an array should not be batched as a unit, it should first be converted\n   * to an object with integer keys.\n   *\n   * Here are a few examples:\n   *\n   * Batch a dataset of numbers:\n   * ```js\n   * const a = tf.data.array([1, 2, 3, 4, 5, 6, 7, 8]).batch(4);\n   * await a.forEachAsync(e => e.print());\n   * ```\n   *\n   * Batch a dataset of arrays:\n   * ```js\n   * const b = tf.data.array([[1], [2], [3], [4], [5], [6], [7], [8]]).batch(4);\n   * await b.forEachAsync(e => e.print());\n   * ```\n   *\n   * Batch a dataset of objects:\n   * ```js\n   * const c = tf.data.array([{a: 1, b: 11}, {a: 2, b: 12}, {a: 3, b: 13},\n   *   {a: 4, b: 14}, {a: 5, b: 15}, {a: 6, b: 16}, {a: 7, b: 17},\n   *   {a: 8, b: 18}]).batch(4);\n   * await c.forEachAsync(e => {\n   *   console.log('{');\n   *   for(var key in e) {\n   *     console.log(key+':');\n   *     e[key].print();\n   *   }\n   *   console.log('}');\n   * })\n   * ```\n   *\n   * @param batchSize The number of elements desired per batch.\n   * @param smallLastBatch Whether to emit the final batch when it has fewer\n   *   than batchSize elements. Default true.\n   * @returns A `Dataset`, from which a stream of batches can be obtained.\n   *\n   * @doc {heading: 'Data', subheading: 'Classes'}\n   */\n  batch(batchSize: number, smallLastBatch = true): Dataset<tf.TensorContainer> {\n    const base = this;\n    tf.util.assert(\n        batchSize > 0, () => `batchSize needs to be positive, but it is\n      ${batchSize}`);\n    let size;\n    if (this.size === Infinity || this.size == null) {\n      // If the size of this dataset is infinity or null, the new size keeps the\n      // same.\n      size = this.size;\n    } else if (smallLastBatch) {\n      // If the size of this dataset is known and include small last batch, the\n      // new size is full batch count plus last batch.\n      size = Math.ceil(this.size / batchSize);\n    } else {\n      // If the size of this dataset is known and not include small last batch,\n      // the new size is full batch count.\n      size = Math.floor(this.size / batchSize);\n    }\n    return datasetFromIteratorFn(async () => {\n      return (await base.iterator())\n          .columnMajorBatch(batchSize, smallLastBatch, deepBatchConcat);\n    }, size);\n  }\n\n  /**\n   * Concatenates this `Dataset` with another.\n   *\n   * ```js\n   * const a = tf.data.array([1, 2, 3]);\n   * const b = tf.data.array([4, 5, 6]);\n   * const c = a.concatenate(b);\n   * await c.forEachAsync(e => console.log(e));\n   * ```\n   *\n   * @param dataset A `Dataset` to be concatenated onto this one.\n   * @returns A `Dataset`.\n   *\n   * @doc {heading: 'Data', subheading: 'Classes'}\n   */\n  concatenate(dataset: Dataset<T>): Dataset<T> {\n    const base = this;\n    let size;\n    if (this.size === Infinity || dataset.size === Infinity) {\n      // If the size of any of these two dataset is infinity, new size is\n      // infinity.\n      size = Infinity;\n    } else if (this.size != null && dataset.size != null) {\n      // If the size of both datasets are known and not infinity, new size is\n      // sum the size of these two datasets.\n      size = this.size + dataset.size;\n    } else {\n      // If neither of these two datasets has infinite size and any of these two\n      // datasets' size is null, the new size is null.\n      size = null;\n    }\n    return datasetFromIteratorFn(\n        async () =>\n            (await base.iterator()).concatenate(await dataset.iterator()),\n        size);\n  }\n\n  /**\n   * Filters this dataset according to `predicate`.\n   *\n   * ```js\n   * const a = tf.data.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n   *   .filter(x => x%2 === 0);\n   * await a.forEachAsync(e => console.log(e));\n   * ```\n   *\n   * @param predicate A function mapping a dataset element to a boolean or a\n   * `Promise` for one.\n   *\n   * @returns A `Dataset` of elements for which the predicate was true.\n   *\n   * @doc {heading: 'Data', subheading: 'Classes'}\n   */\n  filter(predicate: (value: T) => boolean): Dataset<T> {\n    const base = this;\n    let size;\n    if (this.size === Infinity) {\n      // If the size of this dataset is infinity, new size is infinity\n      size = Infinity;\n    } else {\n      // If this dataset has limited elements, new size is null because it might\n      // exhausted randomly.\n      size = null;\n    }\n    return datasetFromIteratorFn(async () => {\n      return (await base.iterator()).filter(x => tf.tidy(() => predicate(x)));\n    }, size);\n  }\n\n  /**\n   * Apply a function to every element of the dataset.\n   *\n   * After the function is applied to a dataset element, any Tensors contained\n   * within that element are disposed.\n   *\n   * ```js\n   * const a = tf.data.array([1, 2, 3]);\n   * await a.forEachAsync(e => console.log(e));\n   * ```\n   *\n   * @param f A function to apply to each dataset element.\n   * @returns A `Promise` that resolves after all elements have been processed.\n   *\n   * @doc {heading: 'Data', subheading: 'Classes'}\n   */\n  async forEachAsync(f: (input: T) => void): Promise<void> {\n    return (await this.iterator()).forEachAsync(f);\n  }\n\n  /**\n   * Maps this dataset through a 1-to-1 transform.\n   *\n   * ```js\n   * const a = tf.data.array([1, 2, 3]).map(x => x*x);\n   * await a.forEachAsync(e => console.log(e));\n   * ```\n   *\n   * @param transform A function mapping a dataset element to a transformed\n   *   dataset element.\n   *\n   * @returns A `Dataset` of transformed elements.\n   *\n   * @doc {heading: 'Data', subheading: 'Classes'}\n   */\n  map<O extends tf.TensorContainer>(transform: (value: T) => O): Dataset<O> {\n    const base = this;\n    return datasetFromIteratorFn(async () => {\n      return (await base.iterator()).map(x => tf.tidy(() => transform(x)));\n    }, this.size);\n  }\n\n  /**\n   * Maps this dataset through an async 1-to-1 transform.\n   *\n   * ```js\n   * const a =\n   *  tf.data.array([1, 2, 3]).mapAsync(x => new Promise(function(resolve){\n   *    setTimeout(() => {\n   *      resolve(x * x);\n   *    }, Math.random()*1000 + 500);\n   *  }));\n   * console.log(await a.toArray());\n   * ```\n   *\n   * @param transform A function mapping a dataset element to a `Promise` for a\n   *   transformed dataset element.  This transform is responsible for disposing\n   *   any intermediate `Tensor`s, i.e. by wrapping its computation in\n   *   `tf.tidy()`; that cannot be automated here (as it is in the synchronous\n   *   `map()` case).\n   *\n   * @returns A `Dataset` of transformed elements.\n   *\n   * @doc {heading: 'Data', subheading: 'Classes'}\n   */\n  mapAsync<O extends tf.TensorContainer>(transform: (value: T) => Promise<O>):\n      Dataset<O> {\n    const base = this;\n    return datasetFromIteratorFn(async () => {\n      return (await base.iterator()).mapAsync(transform);\n    }, this.size);\n  }\n\n  /**\n   *  Creates a `Dataset` that prefetches elements from this dataset.\n   *\n   * @param bufferSize: An integer specifying the number of elements to be\n   *   prefetched.\n   * @returns A `Dataset`.\n   *\n   * @doc {heading: 'Data', subheading: 'Classes'}\n   */\n  prefetch(bufferSize: number): Dataset<T> {\n    if (bufferSize == null) {\n      throw new RangeError(\n          '`Dataset.prefetch()` requires bufferSize to be specified.');\n    }\n\n    const base = this;\n    return datasetFromIteratorFn(\n        async () => (await base.iterator()).prefetch(bufferSize), this.size);\n  }\n\n  /**\n   * Repeats this dataset `count` times.\n   *\n   * NOTE: If this dataset is a function of global state (e.g. a random number\n   * generator), then different repetitions may produce different elements.\n   *\n   * ```js\n   * const a = tf.data.array([1, 2, 3]).repeat(3);\n   * await a.forEachAsync(e => console.log(e));\n   * ```\n   *\n   * @param count: (Optional) An integer, representing the number of times\n   *   the dataset should be repeated. The default behavior (if `count` is\n   *   `undefined` or negative) is for the dataset be repeated indefinitely.\n   * @returns A `Dataset`.\n   *\n   * @doc {heading: 'Data', subheading: 'Classes'}\n   */\n  repeat(count?: number): Dataset<T> {\n    const base = this;\n    let size;\n    if (this.size != null && count > 0) {\n      // If this dataset has size and count is positive, new size is current\n      // size multiply count. This also covers the case that current size is\n      // infinity.\n      size = this.size * count;\n    } else if (count === 0) {\n      // If count is 0, new size is 0.\n      size = 0;\n    } else if (this.size != null && (count === undefined || count < 0)) {\n      // If this dataset has size and count is undefined or negative, the\n      // dataset will be repeated indefinitely and new size is infinity.\n      size = Infinity;\n    } else {\n      // If the size of this dataset is null, the new dataset's size is null.\n      size = null;\n    }\n    return datasetFromIteratorFn(async () => {\n      const iteratorIterator = iteratorFromFunction(\n          async () => ({value: await base.iterator(), done: false}));\n      return iteratorFromConcatenated(iteratorIterator.take(count));\n    }, size);\n  }\n\n  /**\n   * Creates a `Dataset` that skips `count` initial elements from this dataset.\n   *\n   * ```js\n   * const a = tf.data.array([1, 2, 3, 4, 5, 6]).skip(3);\n   * await a.forEachAsync(e => console.log(e));\n   * ```\n   *\n   * @param count: The number of elements of this dataset that should be skipped\n   *   to form the new dataset.  If `count` is greater than the size of this\n   *   dataset, the new dataset will contain no elements.  If `count`\n   *   is `undefined` or negative, skips the entire dataset.\n   *\n   * @returns A `Dataset`.\n   *\n   * @doc {heading: 'Data', subheading: 'Classes'}\n   */\n  skip(count: number): Dataset<T> {\n    const base = this;\n    let size;\n    if (this.size != null && count >= 0 && this.size >= count) {\n      // If the size of this dataset is greater than count, the new dataset's\n      // size is current size minus skipped size.This also covers the case that\n      // current size is infinity.\n      size = this.size - count;\n    } else if (\n        this.size != null &&\n        (this.size < count || count === undefined || count < 0)) {\n      // If the size of this dataset is smaller than count, or count is\n      // undefined or negative, skips the entire dataset and the new size is 0.\n      size = 0;\n    } else {\n      // If the size of this dataset is null, the new dataset's size is null.\n      size = null;\n    }\n    return datasetFromIteratorFn(\n        async () => (await base.iterator()).skip(count), size);\n  }\n\n  // TODO(soergel): deep sharded shuffle, where supported\n\n  static readonly MAX_BUFFER_SIZE = 10000;\n\n  /**\n   * Pseudorandomly shuffles the elements of this dataset. This is done in a\n   * streaming manner, by sampling from a given number of prefetched elements.\n   *\n   * ```js\n   * const a = tf.data.array([1, 2, 3, 4, 5, 6]).shuffle(3);\n   * await a.forEachAsync(e => console.log(e));\n   * ```\n   *\n   * @param bufferSize: An integer specifying the number of elements from this\n   *   dataset from which the new dataset will sample.\n   * @param seed: (Optional) An integer specifying the random seed that will\n   *   be used to create the distribution.\n   * @param reshuffleEachIteration: (Optional) A boolean, which if true\n   *   indicates that the dataset should be pseudorandomly reshuffled each time\n   *   it is iterated over. If false, elements will be returned in the same\n   *   shuffled order on each iteration. (Defaults to `true`.)\n   * @returns A `Dataset`.\n   *\n   * @doc {heading: 'Data', subheading: 'Classes'}\n   */\n  shuffle(bufferSize: number, seed?: string, reshuffleEachIteration = true):\n      Dataset<T> {\n    if (bufferSize == null || bufferSize < 0) {\n      if (this.size == null) {\n        throw new RangeError(\n            '`Dataset.shuffle()` requires bufferSize to be specified.');\n      } else {\n        throw new RangeError(\n            '`Dataset.shuffle()` requires bufferSize to be specified.  ' +\n            'If your data fits in main memory (for regular JS objects), ' +\n            'and/or GPU memory (for `tf.Tensor`s), consider setting ' +\n            `bufferSize to the dataset size (${this.size} elements)`);\n      }\n    }\n    const base = this;\n    const random = seedrandom.alea(seed || tf.util.now().toString());\n    return datasetFromIteratorFn(async () => {\n      let seed2 = random.int32();\n      if (reshuffleEachIteration) {\n        seed2 += random.int32();\n      }\n      return (await base.iterator()).shuffle(bufferSize, seed2.toString());\n    }, this.size);\n  }\n\n  /**\n   * Creates a `Dataset` with at most `count` initial elements from this\n   * dataset.\n   *\n   * ```js\n   * const a = tf.data.array([1, 2, 3, 4, 5, 6]).take(3);\n   * await a.forEachAsync(e => console.log(e));\n   * ```\n   *\n   * @param count: The number of elements of this dataset that should be taken\n   *   to form the new dataset.  If `count` is `undefined` or negative, or if\n   *   `count` is greater than the size of this dataset, the new dataset will\n   *   contain all elements of this dataset.\n   * @returns A `Dataset`.\n   *\n   * @doc {heading: 'Data', subheading: 'Classes'}\n   */\n  take(count: number): Dataset<T> {\n    const base = this;\n    let size;\n    if (this.size != null && this.size > count) {\n      // If the size of this dataset is greater than count, the new dataset's\n      // size is count.\n      size = count;\n    } else if (this.size != null && this.size <= count) {\n      // If the size of this dataset is equal or smaller than count, the new\n      // dataset's size is the size of this dataset.\n      size = this.size;\n    } else {\n      // If the size of this dataset is null, the new dataset's size is null.\n      size = null;\n    }\n    return datasetFromIteratorFn(\n        async () => (await base.iterator()).take(count), size);\n  }\n\n  /**\n   * Collect all elements of this dataset into an array.\n   *\n   * Obviously this will succeed only for small datasets that fit in memory.\n   * Useful for testing and generally should be avoided if possible.\n   *\n   * ```js\n   * const a = tf.data.array([1, 2, 3, 4, 5, 6]);\n   * console.log(await a.toArray());\n   * ```\n   *\n   * @returns A Promise for an array of elements, which will resolve\n   *   when a new stream has been obtained and fully consumed.\n   *\n   * @doc {heading: 'Data', subheading: 'Classes'}\n   */\n  async toArray() {\n    if (this.size === Infinity) {\n      throw new Error('Can not convert infinite data stream to array.');\n    }\n    return (await this.iterator()).toArray();\n  }\n\n  /**\n   * Collect all elements of this dataset into an array with prefetching 100\n   * elements. This is useful for testing, because the prefetch changes the\n   * order in which the Promises are resolved along the processing pipeline.\n   * This may help expose bugs where results are dependent on the order of\n   * Promise resolution rather than on the logical order of the stream (i.e.,\n   * due to hidden mutable state).\n   *\n   * @returns A Promise for an array of elements, which will resolve\n   *   when a new stream has been obtained and fully consumed.\n   */\n  async toArrayForTest() {\n    if (this.size === Infinity) {\n      throw new Error('Can not convert infinite data stream to array.');\n    }\n    return (await this.iterator()).toArrayForTest();\n  }\n}\n\n/**\n * Create a `Dataset` defined by a provided iterator() function.\n *\n * ```js\n * let i = -1;\n * const func = () =>\n *    ++i < 5 ? {value: i, done: false} : {value: null, done: true};\n * const iter = tf.data.iteratorFromFunction(func);\n * const ds = tf.data.datasetFromIteratorFn(iter);\n * await ds.forEachAsync(e => console.log(e));\n * ```\n */\nexport function datasetFromIteratorFn<T extends tf.TensorContainer>(\n    iteratorFn: () => Promise<LazyIterator<T>>,\n    size: number = null): Dataset<T> {\n  return new class extends Dataset<T> {\n    override size = size;\n\n    /*\n     * Provide a new stream of elements.  Note this will also start new streams\n     * from any underlying `Dataset`s.\n     */\n    async iterator(): Promise<LazyIterator<T>> {\n      return iteratorFn();\n    }\n  }\n  ();\n}\n\n/**\n * Create a `Dataset` from an array of elements.\n *\n * Create a Dataset from an array of objects:\n * ```js\n * const a = tf.data.array([{'item': 1}, {'item': 2}, {'item': 3}]);\n * await a.forEachAsync(e => console.log(e));\n * ```\n *\n * Create a Dataset from an array of numbers:\n * ```js\n * const a = tf.data.array([4, 5, 6]);\n * await a.forEachAsync(e => console.log(e));\n * ```\n * @param items An array of elements that will be parsed as items in a dataset.\n *\n * @doc {heading: 'Data', subheading: 'Creation', namespace: 'data'}\n */\nexport function array<T extends tf.TensorContainer>(items: T[]): Dataset<T> {\n  return datasetFromIteratorFn(\n      async () => iteratorFromItems(items), items.length);\n}\n\n/**\n * Create a `Dataset` by zipping together an array, dict, or nested\n * structure of `Dataset`s (and perhaps additional constants).\n * The underlying datasets must provide elements in a consistent order such that\n * they correspond.\n *\n * The number of elements in the resulting dataset is the same as the size of\n * the smallest dataset in datasets.\n *\n * The nested structure of the `datasets` argument determines the\n * structure of elements in the resulting iterator.\n *\n * Note this means that, given an array of two datasets that produce dict\n * elements, the result is a dataset that produces elements that are arrays\n * of two dicts:\n *\n * Zip an array of datasets:\n * ```js\n * console.log('Zip two datasets of objects:');\n * const ds1 = tf.data.array([{a: 1}, {a: 2}, {a: 3}]);\n * const ds2 = tf.data.array([{b: 4}, {b: 5}, {b: 6}]);\n * const ds3 = tf.data.zip([ds1, ds2]);\n * await ds3.forEachAsync(e => console.log(JSON.stringify(e)));\n *\n * // If the goal is to merge the dicts in order to produce elements like\n * // {a: ..., b: ...}, this requires a second step such as:\n * console.log('Merge the objects:');\n * const ds4 = ds3.map(x => {return {a: x[0].a, b: x[1].b}});\n * await ds4.forEachAsync(e => console.log(e));\n * ```\n *\n * Zip a dict of datasets:\n * ```js\n * const a = tf.data.array([{a: 1}, {a: 2}, {a: 3}]);\n * const b = tf.data.array([{b: 4}, {b: 5}, {b: 6}]);\n * const c = tf.data.zip({c: a, d: b});\n * await c.forEachAsync(e => console.log(JSON.stringify(e)));\n * ```\n *\n * @doc {heading: 'Data', subheading: 'Operations', namespace: 'data'}\n */\nexport function zip<O extends tf.TensorContainer>(datasets: DatasetContainer):\n    Dataset<O> {\n  // manually type-check the argument for JS users\n  if (!isIterable(datasets)) {\n    throw new Error('The argument to zip() must be an object or array.');\n  }\n  let size;\n  if (Array.isArray(datasets)) {\n    for (let i = 0; i < datasets.length; i++) {\n      size = size == null ? (datasets[i] as Dataset<O>).size :\n                            Math.min(size, (datasets[i] as Dataset<O>).size);\n    }\n  } else if (datasets instanceof Object) {\n    for (const ds in datasets) {\n      size = size == null ? (datasets[ds] as Dataset<O>).size :\n                            Math.min(size, (datasets[ds] as Dataset<O>).size);\n    }\n  }\n  return datasetFromIteratorFn<O>(async () => {\n    const streams = await deepMapAndAwaitAll(datasets, d => {\n      if (d instanceof Dataset) {\n        return {value: d.iterator(), recurse: false};\n      } else if (isIterable(d)) {\n        return {value: null, recurse: true};\n      } else {\n        throw new Error(\n            'Leaves of the structure passed to zip() must be Datasets, ' +\n            'not primitives.');\n      }\n    });\n    return iteratorFromZipped<O>(streams, ZipMismatchMode.SHORTEST);\n  }, size);\n}\n\n/**\n * A zip function for use with deepZip, passed via the columnMajorBatch call.\n *\n * Accepts an array of identically-structured nested elements and either batches\n * them (if they are primitives, numeric arrays, or Tensors) or requests\n * recursion (if not).\n */\n// tslint:disable-next-line:no-any\nfunction deepBatchConcat(rows: any[]): DeepMapResult {\n  if (rows === null) {\n    return null;\n  }\n\n  // use the first item to decide whether to recurse or batch here.\n  const exampleRow = rows[0];\n\n  if (canTensorify(exampleRow)) {\n    // rows is an array of primitives, Tensors, or arrays.  Batch them.\n    const value = batchConcat(rows);\n    return {value, recurse: false};\n  }\n\n  // the example row is an object, so recurse into it.\n  return {value: null, recurse: true};\n}\n\n/**\n * Assembles a list of same-shaped numbers, number arrays, or Tensors\n * into a single new Tensor where axis 0 is the batch dimension.\n */\nfunction batchConcat<T extends(TensorLike | tf.Tensor)>(arrays: T[]):\n    tf.Tensor {\n  if (arrays.length === 0) {\n    // We can't return an empty Tensor because we don't know the element shape.\n    throw new Error('Can\\'t make a batch of zero elements.');\n  }\n\n  if (arrays[0] instanceof tf.Tensor) {\n    // Input is an array of Tensors\n    return tf.stack(arrays as tf.Tensor[]);\n  } else {\n    // Input is a possibly-nested array of numbers.\n    return tf.tensor(arrays as TensorLike);\n  }\n}\n"],"names":[],"mappings":";;;;;;;;;;AAAA;;;;;;;;;;;;;;;;GAgBG;;;;;AAEH,OAAO,KAAK,EAAE,MAAM,uBAAuB,CAAC;AAE5C,OAAO,KAAK,UAAU,MAAM,YAAY,CAAC;AAEzC,OAAO,EAAC,wBAAwB,EAAE,oBAAoB,EAAE,iBAAiB,EAAE,kBAAkB,EAAgB,eAAe,EAAC,MAAM,2BAA2B,CAAC;AAE/J,OAAO,EAAC,YAAY,EAAE,kBAAkB,EAAiB,UAAU,EAAC,MAAM,iBAAiB,CAAC;;;;;AAO5F,qEAAqE;AAErE;;;;;;;;;;;;;;;;;;;;;;;;;;;GA2BG,CACH,MAAsB,OAAO;IAA7B,aAAA;QAWW,IAAA,CAAA,IAAI,GAAW,IAAI,CAAC;IA2c/B,CAAC;IAzcC,wEAAwE;IACxE,2EAA2E;IAC3E,4EAA4E;IAC5E,2CAA2C;IAC3C,uCAAuC;IAEvC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;OAsDG,CACH,KAAK,CAAC,SAAiB,EAAE,cAAc,GAAG,IAAI,EAAA;QAC5C,MAAM,IAAI,GAAG,IAAI,CAAC;QAClB,EAAE,CAAC,2QAAI,CAAC,MAAM,CACV,SAAS,GAAG,CAAC,EAAE,GAAG,CAAG,CAAD,AAAC;QACrB,SAAS,EAAE,CAAC,CAAC;QACjB,IAAI,IAAI,CAAC;QACT,IAAI,IAAI,CAAC,IAAI,KAAK,QAAQ,IAAI,IAAI,CAAC,IAAI,IAAI,IAAI,EAAE;YAC/C,0EAA0E;YAC1E,QAAQ;YACR,IAAI,GAAG,IAAI,CAAC,IAAI,CAAC;SAClB,MAAM,IAAI,cAAc,EAAE;YACzB,yEAAyE;YACzE,gDAAgD;YAChD,IAAI,GAAG,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,GAAG,SAAS,CAAC,CAAC;SACzC,MAAM;YACL,yEAAyE;YACzE,oCAAoC;YACpC,IAAI,GAAG,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,IAAI,GAAG,SAAS,CAAC,CAAC;SAC1C;QACD,OAAO,qBAAqB,CAAC,KAAK,IAAI,EAAE;YACtC,OAAO,CAAC,MAAM,IAAI,CAAC,QAAQ,EAAE,CAAC,CACzB,gBAAgB,CAAC,SAAS,EAAE,cAAc,EAAE,eAAe,CAAC,CAAC;QACpE,CAAC,EAAE,IAAI,CAAC,CAAC;IACX,CAAC;IAED;;;;;;;;;;;;;;OAcG,CACH,WAAW,CAAC,OAAmB,EAAA;QAC7B,MAAM,IAAI,GAAG,IAAI,CAAC;QAClB,IAAI,IAAI,CAAC;QACT,IAAI,IAAI,CAAC,IAAI,KAAK,QAAQ,IAAI,OAAO,CAAC,IAAI,KAAK,QAAQ,EAAE;YACvD,mEAAmE;YACnE,YAAY;YACZ,IAAI,GAAG,QAAQ,CAAC;SACjB,MAAM,IAAI,IAAI,CAAC,IAAI,IAAI,IAAI,IAAI,OAAO,CAAC,IAAI,IAAI,IAAI,EAAE;YACpD,uEAAuE;YACvE,sCAAsC;YACtC,IAAI,GAAG,IAAI,CAAC,IAAI,GAAG,OAAO,CAAC,IAAI,CAAC;SACjC,MAAM;YACL,0EAA0E;YAC1E,gDAAgD;YAChD,IAAI,GAAG,IAAI,CAAC;SACb;QACD,OAAO,qBAAqB,CACxB,KAAK,IAAI,CACL,CADO,AACN,MAAM,IAAI,CAAC,QAAQ,EAAE,CAAC,CAAC,WAAW,CAAC,MAAM,OAAO,CAAC,QAAQ,EAAE,CAAC,EACjE,IAAI,CAAC,CAAC;IACZ,CAAC;IAED;;;;;;;;;;;;;;;OAeG,CACH,MAAM,CAAC,SAAgC,EAAA;QACrC,MAAM,IAAI,GAAG,IAAI,CAAC;QAClB,IAAI,IAAI,CAAC;QACT,IAAI,IAAI,CAAC,IAAI,KAAK,QAAQ,EAAE;YAC1B,gEAAgE;YAChE,IAAI,GAAG,QAAQ,CAAC;SACjB,MAAM;YACL,0EAA0E;YAC1E,sBAAsB;YACtB,IAAI,GAAG,IAAI,CAAC;SACb;QACD,OAAO,qBAAqB,CAAC,KAAK,IAAI,EAAE;YACtC,OAAO,CAAC,MAAM,IAAI,CAAC,QAAQ,EAAE,CAAC,CAAC,MAAM,EAAC,CAAC,CAAC,EAAE,AAAC,EAAE,CAAC,8OAAI,CAAC,GAAG,CAAG,CAAD,QAAU,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAC1E,CAAC,EAAE,IAAI,CAAC,CAAC;IACX,CAAC;IAED;;;;;;;;;;;;;;;OAeG,CACH,KAAK,CAAC,YAAY,CAAC,CAAqB,EAAA;QACtC,OAAO,CAAC,MAAM,IAAI,CAAC,QAAQ,EAAE,CAAC,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC;IACjD,CAAC;IAED;;;;;;;;;;;;;;OAcG,CACH,GAAG,CAA+B,SAA0B,EAAA;QAC1D,MAAM,IAAI,GAAG,IAAI,CAAC;QAClB,OAAO,qBAAqB,CAAC,KAAK,IAAI,EAAE;YACtC,OAAO,CAAC,MAAM,IAAI,CAAC,QAAQ,EAAE,CAAC,CAAC,GAAG,EAAC,CAAC,CAAC,EAAE,AAAC,EAAE,CAAC,8OAAI,CAAC,GAAG,CAAG,CAAD,QAAU,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QACvE,CAAC,EAAE,IAAI,CAAC,IAAI,CAAC,CAAC;IAChB,CAAC;IAED;;;;;;;;;;;;;;;;;;;;;;OAsBG,CACH,QAAQ,CAA+B,SAAmC,EAAA;QAExE,MAAM,IAAI,GAAG,IAAI,CAAC;QAClB,OAAO,qBAAqB,CAAC,KAAK,IAAI,EAAE;YACtC,OAAO,CAAC,MAAM,IAAI,CAAC,QAAQ,EAAE,CAAC,CAAC,QAAQ,CAAC,SAAS,CAAC,CAAC;QACrD,CAAC,EAAE,IAAI,CAAC,IAAI,CAAC,CAAC;IAChB,CAAC;IAED;;;;;;;;OAQG,CACH,QAAQ,CAAC,UAAkB,EAAA;QACzB,IAAI,UAAU,IAAI,IAAI,EAAE;YACtB,MAAM,IAAI,UAAU,CAChB,2DAA2D,CAAC,CAAC;SAClE;QAED,MAAM,IAAI,GAAG,IAAI,CAAC;QAClB,OAAO,qBAAqB,CACxB,KAAK,IAAI,CAAG,CAAD,AAAE,MAAM,IAAI,CAAC,QAAQ,EAAE,CAAC,CAAC,QAAQ,CAAC,UAAU,CAAC,EAAE,IAAI,CAAC,IAAI,CAAC,CAAC;IAC3E,CAAC;IAED;;;;;;;;;;;;;;;;;OAiBG,CACH,MAAM,CAAC,KAAc,EAAA;QACnB,MAAM,IAAI,GAAG,IAAI,CAAC;QAClB,IAAI,IAAI,CAAC;QACT,IAAI,IAAI,CAAC,IAAI,IAAI,IAAI,IAAI,KAAK,GAAG,CAAC,EAAE;YAClC,sEAAsE;YACtE,sEAAsE;YACtE,YAAY;YACZ,IAAI,GAAG,IAAI,CAAC,IAAI,GAAG,KAAK,CAAC;SAC1B,MAAM,IAAI,KAAK,KAAK,CAAC,EAAE;YACtB,gCAAgC;YAChC,IAAI,GAAG,CAAC,CAAC;SACV,MAAM,IAAI,IAAI,CAAC,IAAI,IAAI,IAAI,IAAI,CAAC,KAAK,KAAK,SAAS,IAAI,KAAK,GAAG,CAAC,CAAC,EAAE;YAClE,mEAAmE;YACnE,kEAAkE;YAClE,IAAI,GAAG,QAAQ,CAAC;SACjB,MAAM;YACL,uEAAuE;YACvE,IAAI,GAAG,IAAI,CAAC;SACb;QACD,OAAO,qBAAqB,CAAC,KAAK,IAAI,EAAE;YACtC,MAAM,gBAAgB,OAAG,6VAAoB,EACzC,KAAK,IAAI,CAAG,CAAD,AAAE;oBAAC,KAAK,EAAE,MAAM,IAAI,CAAC,QAAQ,EAAE;oBAAE,IAAI,EAAE,KAAK;gBAAA,CAAC,CAAC,CAAC,CAAC;YAC/D,WAAO,iWAAwB,EAAC,gBAAgB,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC,CAAC;QAChE,CAAC,EAAE,IAAI,CAAC,CAAC;IACX,CAAC;IAED;;;;;;;;;;;;;;;;OAgBG,CACH,IAAI,CAAC,KAAa,EAAA;QAChB,MAAM,IAAI,GAAG,IAAI,CAAC;QAClB,IAAI,IAAI,CAAC;QACT,IAAI,IAAI,CAAC,IAAI,IAAI,IAAI,IAAI,KAAK,IAAI,CAAC,IAAI,IAAI,CAAC,IAAI,IAAI,KAAK,EAAE;YACzD,uEAAuE;YACvE,yEAAyE;YACzE,4BAA4B;YAC5B,IAAI,GAAG,IAAI,CAAC,IAAI,GAAG,KAAK,CAAC;SAC1B,MAAM,IACH,IAAI,CAAC,IAAI,IAAI,IAAI,IACjB,CAAC,IAAI,CAAC,IAAI,GAAG,KAAK,IAAI,KAAK,KAAK,SAAS,IAAI,KAAK,GAAG,CAAC,CAAC,EAAE;YAC3D,iEAAiE;YACjE,yEAAyE;YACzE,IAAI,GAAG,CAAC,CAAC;SACV,MAAM;YACL,uEAAuE;YACvE,IAAI,GAAG,IAAI,CAAC;SACb;QACD,OAAO,qBAAqB,CACxB,KAAK,IAAI,CAAG,CAAC,AAAF,MAAQ,IAAI,CAAC,QAAQ,EAAE,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,EAAE,IAAI,CAAC,CAAC;IAC7D,CAAC;IAMD;;;;;;;;;;;;;;;;;;;;OAoBG,CACH,OAAO,CAAC,UAAkB,EAAE,IAAa,EAAE,sBAAsB,GAAG,IAAI,EAAA;QAEtE,IAAI,UAAU,IAAI,IAAI,IAAI,UAAU,GAAG,CAAC,EAAE;YACxC,IAAI,IAAI,CAAC,IAAI,IAAI,IAAI,EAAE;gBACrB,MAAM,IAAI,UAAU,CAChB,0DAA0D,CAAC,CAAC;aACjE,MAAM;gBACL,MAAM,IAAI,UAAU,CAChB,4DAA4D,GAC5D,6DAA6D,GAC7D,yDAAyD,GACzD,CAAA,gCAAA,EAAmC,IAAI,CAAC,IAAI,CAAA,UAAA,CAAY,CAAC,CAAC;aAC/D;SACF;QACD,MAAM,IAAI,GAAG,IAAI,CAAC;QAClB,MAAM,MAAM,GAAG,UAAU,CAAC,uLAAI,CAAC,IAAI,IAAI,EAAE,CAAC,2QAAI,CAAC,GAAG,EAAE,CAAC,QAAQ,EAAE,CAAC,CAAC;QACjE,OAAO,qBAAqB,CAAC,KAAK,IAAI,EAAE;YACtC,IAAI,KAAK,GAAG,MAAM,CAAC,KAAK,EAAE,CAAC;YAC3B,IAAI,sBAAsB,EAAE;gBAC1B,KAAK,IAAI,MAAM,CAAC,KAAK,EAAE,CAAC;aACzB;YACD,OAAO,CAAC,MAAM,IAAI,CAAC,QAAQ,EAAE,CAAC,CAAC,OAAO,CAAC,UAAU,EAAE,KAAK,CAAC,QAAQ,EAAE,CAAC,CAAC;QACvE,CAAC,EAAE,IAAI,CAAC,IAAI,CAAC,CAAC;IAChB,CAAC;IAED;;;;;;;;;;;;;;;;OAgBG,CACH,IAAI,CAAC,KAAa,EAAA;QAChB,MAAM,IAAI,GAAG,IAAI,CAAC;QAClB,IAAI,IAAI,CAAC;QACT,IAAI,IAAI,CAAC,IAAI,IAAI,IAAI,IAAI,IAAI,CAAC,IAAI,GAAG,KAAK,EAAE;YAC1C,uEAAuE;YACvE,iBAAiB;YACjB,IAAI,GAAG,KAAK,CAAC;SACd,MAAM,IAAI,IAAI,CAAC,IAAI,IAAI,IAAI,IAAI,IAAI,CAAC,IAAI,IAAI,KAAK,EAAE;YAClD,sEAAsE;YACtE,8CAA8C;YAC9C,IAAI,GAAG,IAAI,CAAC,IAAI,CAAC;SAClB,MAAM;YACL,uEAAuE;YACvE,IAAI,GAAG,IAAI,CAAC;SACb;QACD,OAAO,qBAAqB,CACxB,KAAK,IAAI,CAAG,CAAD,AAAE,MAAM,IAAI,CAAC,QAAQ,EAAE,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,EAAE,IAAI,CAAC,CAAC;IAC7D,CAAC;IAED;;;;;;;;;;;;;;;OAeG,CACH,KAAK,CAAC,OAAO,GAAA;QACX,IAAI,IAAI,CAAC,IAAI,KAAK,QAAQ,EAAE;YAC1B,MAAM,IAAI,KAAK,CAAC,gDAAgD,CAAC,CAAC;SACnE;QACD,OAAO,CAAC,MAAM,IAAI,CAAC,QAAQ,EAAE,CAAC,CAAC,OAAO,EAAE,CAAC;IAC3C,CAAC;IAED;;;;;;;;;;OAUG,CACH,KAAK,CAAC,cAAc,GAAA;QAClB,IAAI,IAAI,CAAC,IAAI,KAAK,QAAQ,EAAE;YAC1B,MAAM,IAAI,KAAK,CAAC,gDAAgD,CAAC,CAAC;SACnE;QACD,OAAO,CAAC,MAAM,IAAI,CAAC,QAAQ,EAAE,CAAC,CAAC,cAAc,EAAE,CAAC;IAClD,CAAC;;AA7HD,uDAAuD;AAEvC,QAAA,eAAe,GAAG,KAAK,AAAR,CAAS;;AA0IpC,SAAU,qBAAqB,CACjC,UAA0C,EAC1C,OAAe,IAAI;IACrB,OAAO,IAAI,KAAM,SAAQ,OAAU;QAAxB,aAAA;;YACA,IAAA,CAAA,IAAI,GAAG,IAAI,CAAC;QASvB,CAAC;QAPC;;;WAGG,CACH,KAAK,CAAC,QAAQ,GAAA;YACZ,OAAO,UAAU,EAAE,CAAC;QACtB,CAAC;KACF,EACC,CAAC;AACL,CAAC;AAoBK,SAAU,KAAK,CAA+B,KAAU;IAC5D,OAAO,qBAAqB,CACxB,KAAK,IAAI,EAAE,GAAC,0VAAiB,EAAC,KAAK,CAAC,EAAE,KAAK,CAAC,MAAM,CAAC,CAAC;AAC1D,CAAC;AA2CK,SAAU,GAAG,CAA+B,QAA0B;IAE1E,gDAAgD;IAChD,IAAI,KAAC,yUAAU,EAAC,QAAQ,CAAC,EAAE;QACzB,MAAM,IAAI,KAAK,CAAC,mDAAmD,CAAC,CAAC;KACtE;IACD,IAAI,IAAI,CAAC;IACT,IAAI,KAAK,CAAC,OAAO,CAAC,QAAQ,CAAC,EAAE;QAC3B,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,QAAQ,CAAC,MAAM,EAAE,CAAC,EAAE,CAAE;YACxC,IAAI,GAAG,IAAI,IAAI,IAAI,CAAC,CAAC,CAAE,QAAQ,CAAC,CAAC,CAAgB,CAAC,IAAI,CAAC,CAAC,CAClC,IAAI,CAAC,GAAG,CAAC,IAAI,EAAG,QAAQ,CAAC,CAAC,CAAgB,CAAC,IAAI,CAAC,CAAC;SACxE;KACF,MAAM,IAAI,QAAQ,YAAY,MAAM,EAAE;QACrC,IAAK,MAAM,EAAE,IAAI,QAAQ,CAAE;YACzB,IAAI,GAAG,IAAI,IAAI,IAAI,CAAC,CAAC,CAAE,QAAQ,CAAC,EAAE,CAAgB,CAAC,IAAI,CAAC,CAAC,CACnC,IAAI,CAAC,GAAG,CAAC,IAAI,EAAG,QAAQ,CAAC,EAAE,CAAgB,CAAC,IAAI,CAAC,CAAC;SACzE;KACF;IACD,OAAO,qBAAqB,CAAI,KAAK,IAAI,EAAE;QACzC,MAAM,OAAO,GAAG,UAAM,iVAAkB,EAAC,QAAQ,GAAE,CAAC,CAAC,EAAE;YACrD,IAAI,CAAC,YAAY,OAAO,EAAE;gBACxB,OAAO;oBAAC,KAAK,EAAE,CAAC,CAAC,QAAQ,EAAE;oBAAE,OAAO,EAAE,KAAK;gBAAA,CAAC,CAAC;aAC9C,MAAM,QAAI,yUAAU,EAAC,CAAC,CAAC,EAAE;gBACxB,OAAO;oBAAC,KAAK,EAAE,IAAI;oBAAE,OAAO,EAAE,IAAI;gBAAA,CAAC,CAAC;aACrC,MAAM;gBACL,MAAM,IAAI,KAAK,CACX,4DAA4D,GAC5D,iBAAiB,CAAC,CAAC;aACxB;QACH,CAAC,CAAC,CAAC;QACH,WAAO,2VAAkB,EAAI,OAAO,EAAE,wVAAe,CAAC,QAAQ,CAAC,CAAC;IAClE,CAAC,EAAE,IAAI,CAAC,CAAC;AACX,CAAC;AAED;;;;;;GAMG,CACH,kCAAkC;AAClC,SAAS,eAAe,CAAC,IAAW;IAClC,IAAI,IAAI,KAAK,IAAI,EAAE;QACjB,OAAO,IAAI,CAAC;KACb;IAED,iEAAiE;IACjE,MAAM,UAAU,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC;IAE3B,QAAI,2UAAY,EAAC,UAAU,CAAC,EAAE;QAC5B,mEAAmE;QACnE,MAAM,KAAK,GAAG,WAAW,CAAC,IAAI,CAAC,CAAC;QAChC,OAAO;YAAC,KAAK;YAAE,OAAO,EAAE,KAAK;QAAA,CAAC,CAAC;KAChC;IAED,oDAAoD;IACpD,OAAO;QAAC,KAAK,EAAE,IAAI;QAAE,OAAO,EAAE,IAAI;IAAA,CAAC,CAAC;AACtC,CAAC;AAED;;;GAGG,CACH,SAAS,WAAW,CAAoC,MAAW;IAEjE,IAAI,MAAM,CAAC,MAAM,KAAK,CAAC,EAAE;QACvB,2EAA2E;QAC3E,MAAM,IAAI,KAAK,CAAC,uCAAuC,CAAC,CAAC;KAC1D;IAED,IAAI,MAAM,CAAC,CAAC,CAAC,YAAY,EAAE,CAAC,+OAAM,EAAE;QAClC,+BAA+B;QAC/B,OAAO,EAAE,CAAC,oPAAK,CAAC,MAAqB,CAAC,CAAC;KACxC,MAAM;QACL,+CAA+C;QAC/C,OAAO,EAAE,CAAC,sPAAM,CAAC,MAAoB,CAAC,CAAC;KACxC;AACH,CAAC"}},
    {"offset": {"line": 2020, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-data@4.22.0_@tensorflow+tfjs-core@4.22.0_seedrandom@3.0.5/node_modules/@tensorflow/tfjs-data/dist/datasets/text_line_dataset.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-data/src/datasets/text_line_dataset.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\n\nimport {Dataset} from '../dataset';\nimport {DataSource} from '../datasource';\nimport {LazyIterator} from '../iterators/lazy_iterator';\n\n/**\n * Represents a potentially large collection of text lines.\n *\n * The results are not batched.\n */\nexport class TextLineDataset extends Dataset<string> {\n  /**\n   * Create a `TextLineDataset`.\n   *\n   * @param input A `DataSource` providing a chunked, UTF8-encoded byte stream.\n   */\n  constructor(protected readonly input: DataSource) {\n    super();\n  }\n\n  async iterator(): Promise<LazyIterator<string>> {\n    const inputIterator = await this.input.iterator();\n    const utf8Iterator = inputIterator.decodeUTF8();\n    const lineIterator = utf8Iterator.split('\\n').map(line => {\n      // Windows/DOS format text file has extra line breaker at the end of line.\n      if (line.endsWith('\\r')) {\n        line = line.slice(0, -1);\n      }\n      return line;\n    });\n    return lineIterator;\n  }\n}\n"],"names":[],"mappings":";;;;AAAA;;;;;;;;;;;;;;;;GAgBG,CAEH,OAAO,EAAC,OAAO,EAAC,MAAM,YAAY,CAAC;;AAS7B,MAAO,eAAgB,SAAQ,6TAAe;IAClD;;;;OAIG,CACH,YAA+B,KAAiB,CAAA;QAC9C,KAAK,EAAE,CAAC;QADqB,IAAA,CAAA,KAAK,GAAL,KAAK,CAAY;IAEhD,CAAC;IAED,KAAK,CAAC,QAAQ,GAAA;QACZ,MAAM,aAAa,GAAG,MAAM,IAAI,CAAC,KAAK,CAAC,QAAQ,EAAE,CAAC;QAClD,MAAM,YAAY,GAAG,aAAa,CAAC,UAAU,EAAE,CAAC;QAChD,MAAM,YAAY,GAAG,YAAY,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC,GAAG,EAAC,IAAI,CAAC,EAAE;YACvD,0EAA0E;YAC1E,IAAI,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAC,EAAE;gBACvB,IAAI,GAAG,IAAI,CAAC,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;aAC1B;YACD,OAAO,IAAI,CAAC;QACd,CAAC,CAAC,CAAC;QACH,OAAO,YAAY,CAAC;IACtB,CAAC;CACF"}},
    {"offset": {"line": 2068, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-data@4.22.0_@tensorflow+tfjs-core@4.22.0_seedrandom@3.0.5/node_modules/@tensorflow/tfjs-data/dist/datasets/csv_dataset.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-data/src/datasets/csv_dataset.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\n\nimport {TensorContainer, util} from '@tensorflow/tfjs-core';\nimport {Dataset} from '../dataset';\nimport {DataSource} from '../datasource';\nimport {LazyIterator} from '../iterators/lazy_iterator';\nimport {ColumnConfig, CSVConfig} from '../types';\nimport {TextLineDataset} from './text_line_dataset';\n\nconst CODE_QUOTE = '\"';\nconst STATE_OUT = Symbol('out');\nconst STATE_FIELD = Symbol('field');\nconst STATE_QUOTE = Symbol('quote');\nconst STATE_QUOTE_AFTER_QUOTE = Symbol('quoteafterquote');\nconst STATE_WITHIN_QUOTE_IN_QUOTE = Symbol('quoteinquote');\n\n/**\n * Represents a potentially large collection of delimited text records.\n *\n * The produced `TensorContainer`s each contain one key-value pair for\n * every column of the table.  When a field is empty in the incoming data, the\n * resulting value is `undefined`, or throw error if it is required.  Values\n * that can be parsed as numbers are emitted as type `number`, other values\n * are parsed as `string`.\n *\n * The results are not batched.\n *\n * @doc {heading: 'Data', subheading: 'Classes', namespace: 'data'}\n */\nexport class CSVDataset extends Dataset<TensorContainer> {\n  base: TextLineDataset;\n  private hasHeader = true;\n  private fullColumnNames: string[] = null;\n  private columnNamesValidated = false;\n  private columnConfigs: {[key: string]: ColumnConfig} = null;\n  private configuredColumnsOnly = false;\n  private delimiter = ',';\n  private delimWhitespace = false;\n\n  /**\n   * Returns column names of the csv dataset. If `configuredColumnsOnly` is\n   * true, return column names in `columnConfigs`. If `configuredColumnsOnly` is\n   * false and `columnNames` is provided, `columnNames`. If\n   * `configuredColumnsOnly` is false and `columnNames` is not provided, return\n   * all column names parsed from the csv file. For example usage please go to\n   * `tf.data.csv`.\n   *\n   * @doc {heading: 'Data', subheading: 'Classes'}\n   */\n  async columnNames() {\n    if (!this.columnNamesValidated) {\n      await this.setColumnNames();\n    }\n    return this.configuredColumnsOnly ? Object.keys(this.columnConfigs) :\n                                        this.fullColumnNames;\n  }\n\n  /* 1) If `columnNames` is provided as string[], use this string[] as output\n   * keys in corresponding order. The length must match the number of inferred\n   * columns if `hasHeader` is true .\n   * 2) If `columnNames` is not provided, parse header line as `columnNames` if\n   * hasHeader is true. If `hasHeader` is false, throw an error.\n   * 3) If `columnConfigs` is provided, all the keys in `columnConfigs` must\n   * exist in parsed `columnNames`.\n   */\n  private async setColumnNames() {\n    const columnNamesFromFile = await this.maybeReadHeaderLine();\n    if (!this.fullColumnNames && !columnNamesFromFile) {\n      // Throw an error if columnNames is not provided and no header line.\n      throw new Error(\n          'Column names must be provided if there is no header line.');\n    } else if (this.fullColumnNames && columnNamesFromFile) {\n      // Check provided columnNames match header line.\n      util.assert(\n          columnNamesFromFile.length === this.fullColumnNames.length,\n          () => 'The length of provided columnNames (' +\n              this.fullColumnNames.length.toString() +\n              ') does not match the length of the header line read from ' +\n              'file (' + columnNamesFromFile.length.toString() + ').');\n    }\n    if (!this.fullColumnNames) {\n      this.fullColumnNames = columnNamesFromFile;\n    }\n    // Check if there are duplicate column names.\n    const counts: {[key: string]: number} = this.fullColumnNames.reduce(\n        (countAcc: {[key: string]: number}, name) => {\n          countAcc[name] = (countAcc[name] + 1) || 1;\n          return countAcc;\n        },\n        {});\n    const duplicateNames =\n        Object.keys(counts).filter((name) => (counts[name] > 1));\n    util.assert(\n        duplicateNames.length === 0,\n        () => 'Duplicate column names found: ' + duplicateNames.toString());\n    // Check if keys in columnConfigs match columnNames.\n    if (this.columnConfigs) {\n      for (const key of Object.keys(this.columnConfigs)) {\n        const index = this.fullColumnNames.indexOf(key);\n        if (index === -1) {\n          throw new Error(\n              'The key \"' + key +\n              '\" provided in columnConfigs does not match any of the column ' +\n              'names (' + this.fullColumnNames.toString() + ').');\n        }\n      }\n    }\n    this.columnNamesValidated = true;\n  }\n\n  private async maybeReadHeaderLine() {\n    if (this.hasHeader) {\n      const iter = await this.base.iterator();\n      const firstElement = await iter.next();\n      if (firstElement.done) {\n        throw new Error('No data was found for CSV parsing.');\n      }\n      const firstLine: string = firstElement.value;\n      const headers = this.parseRow(firstLine, false);\n      return headers;\n    } else {\n      return null;\n    }\n  }\n\n  /**\n   * Create a `CSVDataset`.\n   *\n   * @param input A `DataSource` providing a chunked, UTF8-encoded byte stream.\n   * @param csvConfig (Optional) A CSVConfig object that contains configurations\n   *     of reading and decoding from CSV file(s).\n   *\n   *     hasHeader: (Optional) A boolean value that indicates whether the first\n   *     row of provided CSV file is a header line with column names, and should\n   *     not be included in the data. Defaults to `true`.\n   *\n   *     columnNames: (Optional) A list of strings that corresponds to\n   *     the CSV column names, in order. If provided, it ignores the column\n   *     names inferred from the header row. If not provided, infers the column\n   *     names from the first row of the records. If hasHeader is false and\n   *     columnNames is not provided, this method throws an error.\n   *\n   *     columnConfigs: (Optional) A dictionary whose key is column names, value\n   *     is an object stating if this column is required, column's data type,\n   *     default value, and if this column is label. If provided, keys must\n   *     correspond to names provided in columnNames or inferred from the file\n   *     header lines. If isLabel is true any column, returns an array of two\n   *     items: the first item is a dict of features key/value pairs, the second\n   *     item is a dict of labels key/value pairs. If no feature is marked as\n   *     label, returns a dict of features only.\n   *\n   *     configuredColumnsOnly (Optional) If true, only columns provided in\n   *     columnConfigs will be parsed and provided during iteration.\n   *\n   *     delimiter (Optional) The string used to parse each line of the input\n   *     file. Defaults to `,`.\n   */\n  constructor(protected readonly input: DataSource, csvConfig?: CSVConfig) {\n    super();\n    this.base = new TextLineDataset(input);\n    if (!csvConfig) {\n      csvConfig = {};\n    }\n    this.hasHeader = csvConfig.hasHeader === false ? false : true;\n    this.fullColumnNames = csvConfig.columnNames;\n    this.columnConfigs = csvConfig.columnConfigs;\n    this.configuredColumnsOnly = csvConfig.configuredColumnsOnly;\n    if (csvConfig.delimWhitespace) {\n      util.assert(\n          csvConfig.delimiter == null,\n          () =>\n              'Delimiter should not be provided when delimWhitespace is true.');\n      this.delimWhitespace = true;\n      this.delimiter = ' ';\n    } else {\n      this.delimiter = csvConfig.delimiter ? csvConfig.delimiter : ',';\n    }\n  }\n\n  async iterator(): Promise<LazyIterator<TensorContainer>> {\n    if (!this.columnNamesValidated) {\n      await this.setColumnNames();\n    }\n    let lines = await this.base.iterator();\n    if (this.hasHeader) {\n      // We previously read the first line to get the columnNames.\n      // Now that we're providing data, skip it.\n      lines = lines.skip(1);\n    }\n    return lines.map(x => this.makeDataElement(x));\n  }\n\n  makeDataElement(line: string): TensorContainer {\n    const values = this.parseRow(line);\n    const features: {[key: string]: TensorContainer} = {};\n    const labels: {[key: string]: TensorContainer} = {};\n\n    for (let i = 0; i < this.fullColumnNames.length; i++) {\n      const key = this.fullColumnNames[i];\n      const config = this.columnConfigs ? this.columnConfigs[key] : null;\n      if (this.configuredColumnsOnly && !config) {\n        // This column is not selected.\n        continue;\n      } else {\n        const value = values[i];\n        let parsedValue = null;\n        if (value === '') {\n          // If default value is provided, use it. If default value is not\n          // provided, set as undefined.\n          if (config && config.default !== undefined) {\n            parsedValue = config.default;\n          } else if (config && (config.required || config.isLabel)) {\n            throw new Error(\n                `Required column ${key} is empty in this line: ${line}`);\n          } else {\n            parsedValue = undefined;\n          }\n        } else {\n          // A value is present, so parse it based on type\n          const valueAsNum = Number(value);\n          if (isNaN(valueAsNum)) {\n            // The value is a string and this column is declared as boolean\n            // in config, parse it as boolean.\n            if (config && config.dtype === 'bool') {\n              parsedValue = this.getBoolean(value);\n            } else {\n              // Set value as string\n              parsedValue = value;\n            }\n          } else if (!config || !config.dtype) {\n            // If this value is a number and no type config is provided, return\n            // it as number.\n            parsedValue = valueAsNum;\n          } else {\n            // If this value is a number and data type is provided, parse it\n            // according to provided data type.\n            switch (config.dtype) {\n              case 'float32':\n                parsedValue = valueAsNum;\n                break;\n              case 'int32':\n                parsedValue = Math.floor(valueAsNum);\n                break;\n              case 'bool':\n                parsedValue = this.getBoolean(value);\n                break;\n              default:\n                parsedValue = valueAsNum;\n            }\n          }\n        }\n        // Check if this column is label.\n        (config && config.isLabel) ? labels[key] = parsedValue :\n                                     features[key] = parsedValue;\n      }\n    }\n    // If label exists, return an object of features and labels as {xs:features,\n    // ys:labels}, otherwise return features only.\n    if (Object.keys(labels).length === 0) {\n      return features;\n\n    } else {\n      return {xs: features, ys: labels};\n    }\n  }\n\n  private getBoolean(value: string): number {\n    if (value === '1' || value.toLowerCase() === 'true') {\n      return 1;\n    } else {\n      return 0;\n    }\n  }\n\n  // adapted from https://beta.observablehq.com/@mbostock/streaming-csv\n  private parseRow(line: string, validateElementCount = true): string[] {\n    const result: string[] = [];\n    let readOffset = 0;\n    const readLength = line.length;\n    let currentState = STATE_OUT;\n    // Goes through the line to parse quote.\n    for (let i = 0; i < readLength; i++) {\n      switch (currentState) {\n        // Before enter a new field\n        case STATE_OUT:\n          switch (line.charAt(i)) {\n            // Enter a quoted field\n            case CODE_QUOTE:\n              readOffset = i + 1;\n              currentState = STATE_QUOTE;\n              break;\n            // Read an empty field\n            case this.delimiter:\n              readOffset = i + 1;\n              // If delimiter is white space and configured to collapse\n              // multiple white spaces, ignore this white space.\n              if (this.delimiter === ' ' && this.delimWhitespace) {\n                break;\n              }\n              result.push('');\n              currentState = STATE_OUT;\n              break;\n            // Enter an unquoted field\n            default:\n              currentState = STATE_FIELD;\n              readOffset = i;\n              break;\n          }\n          break;\n        // In an unquoted field\n        case STATE_FIELD:\n          switch (line.charAt(i)) {\n            // Exit an unquoted field, add it to result\n            case this.delimiter:\n              result.push(line.substring(readOffset, i));\n              currentState = STATE_OUT;\n              readOffset = i + 1;\n              break;\n            default:\n          }\n          break;\n        // In a quoted field\n        case STATE_QUOTE:\n          switch (line.charAt(i)) {\n            // Read a quote after a quote\n            case CODE_QUOTE:\n              currentState = STATE_QUOTE_AFTER_QUOTE;\n              break;\n            default:\n          }\n          break;\n        // This state means it's right after a second quote in a field\n        case STATE_QUOTE_AFTER_QUOTE:\n          switch (line.charAt(i)) {\n            // Finished a quoted field\n            case this.delimiter:\n              result.push(line.substring(readOffset, i - 1));\n              currentState = STATE_OUT;\n              readOffset = i + 1;\n              break;\n            // Finished a quoted part in a quoted field\n            case CODE_QUOTE:\n              currentState = STATE_QUOTE;\n              break;\n            // In a quoted part in a quoted field\n            default:\n              currentState = STATE_WITHIN_QUOTE_IN_QUOTE;\n              break;\n          }\n          break;\n        case STATE_WITHIN_QUOTE_IN_QUOTE:\n          switch (line.charAt(i)) {\n            // Exit a quoted part in a quoted field\n            case CODE_QUOTE:\n              currentState = STATE_QUOTE;\n              break;\n            default:\n          }\n          break;\n        default:\n      }\n    }\n    // Adds last item based on if it is quoted.\n    if (currentState === STATE_QUOTE_AFTER_QUOTE) {\n      result.push(line.substring(readOffset, readLength - 1));\n    } else {\n      result.push(line.substring(readOffset));\n    }\n    // Check if each row has the same number of elements as column names.\n    if (validateElementCount && result.length !== this.fullColumnNames.length) {\n      throw new Error(`Invalid row in csv file. Should have ${\n          this.fullColumnNames.length} elements in a row, but got ${result}`);\n    }\n    return result;\n  }\n}\n\n// TODO(soergel): add more basic datasets for parity with tf.data\n// tf.data.FixedLengthRecordDataset()\n// tf.data.TFRecordDataset()\n"],"names":[],"mappings":";;;;AAAA;;;;;;;;;;;;;;;;GAgBG;AAEH,OAAO,EAAkB,IAAI,EAAC,MAAM,uBAAuB,CAAC;AAC5D,OAAO,EAAC,OAAO,EAAC,MAAM,YAAY,CAAC;AAInC,OAAO,EAAC,eAAe,EAAC,MAAM,qBAAqB,CAAC;;;;AAEpD,MAAM,UAAU,GAAG,GAAG,CAAC;AACvB,MAAM,SAAS,GAAG,MAAM,CAAC,KAAK,CAAC,CAAC;AAChC,MAAM,WAAW,GAAG,MAAM,CAAC,OAAO,CAAC,CAAC;AACpC,MAAM,WAAW,GAAG,MAAM,CAAC,OAAO,CAAC,CAAC;AACpC,MAAM,uBAAuB,GAAG,MAAM,CAAC,iBAAiB,CAAC,CAAC;AAC1D,MAAM,2BAA2B,GAAG,MAAM,CAAC,cAAc,CAAC,CAAC;AAerD,MAAO,UAAW,SAAQ,6TAAwB;IAUtD;;;;;;;;;OASG,CACH,KAAK,CAAC,WAAW,GAAA;QACf,IAAI,CAAC,IAAI,CAAC,oBAAoB,EAAE;YAC9B,MAAM,IAAI,CAAC,cAAc,EAAE,CAAC;SAC7B;QACD,OAAO,IAAI,CAAC,qBAAqB,CAAC,CAAC,CAAC,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC,CACjC,IAAI,CAAC,eAAe,CAAC;IAC3D,CAAC;IAED;;;;;;;OAOG,CACK,KAAK,CAAC,cAAc,GAAA;QAC1B,MAAM,mBAAmB,GAAG,MAAM,IAAI,CAAC,mBAAmB,EAAE,CAAC;QAC7D,IAAI,CAAC,IAAI,CAAC,eAAe,IAAI,CAAC,mBAAmB,EAAE;YACjD,oEAAoE;YACpE,MAAM,IAAI,KAAK,CACX,2DAA2D,CAAC,CAAC;SAClE,MAAM,IAAI,IAAI,CAAC,eAAe,IAAI,mBAAmB,EAAE;YACtD,gDAAgD;YAChD,8QAAI,CAAC,MAAM,CACP,mBAAmB,CAAC,MAAM,KAAK,IAAI,CAAC,eAAe,CAAC,MAAM,EAC1D,GAAG,CAAG,CAAD,qCAAuC,GACxC,IAAI,CAAC,eAAe,CAAC,MAAM,CAAC,QAAQ,EAAE,GACtC,2DAA2D,GAC3D,QAAQ,GAAG,mBAAmB,CAAC,MAAM,CAAC,QAAQ,EAAE,GAAG,IAAI,CAAC,CAAC;SAClE;QACD,IAAI,CAAC,IAAI,CAAC,eAAe,EAAE;YACzB,IAAI,CAAC,eAAe,GAAG,mBAAmB,CAAC;SAC5C;QACD,6CAA6C;QAC7C,MAAM,MAAM,GAA4B,IAAI,CAAC,eAAe,CAAC,MAAM,CAC/D,CAAC,QAAiC,EAAE,IAAI,EAAE,EAAE;YAC1C,QAAQ,CAAC,IAAI,CAAC,GAAG,AAAC,QAAQ,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,GAAI,CAAC,CAAC;YAC3C,OAAO,QAAQ,CAAC;QAClB,CAAC,EACD,CAAA,CAAE,CAAC,CAAC;QACR,MAAM,cAAc,GAChB,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,MAAM,CAAC,CAAC,IAAI,EAAE,CAAI,CAAF,CAAC,IAAO,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;QAC7D,8QAAI,CAAC,MAAM,CACP,cAAc,CAAC,MAAM,KAAK,CAAC,EAC3B,GAAG,CAAG,CAAD,+BAAiC,GAAG,cAAc,CAAC,QAAQ,EAAE,CAAC,CAAC;QACxE,oDAAoD;QACpD,IAAI,IAAI,CAAC,aAAa,EAAE;YACtB,KAAK,MAAM,GAAG,IAAI,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC,aAAa,CAAC,CAAE;gBACjD,MAAM,KAAK,GAAG,IAAI,CAAC,eAAe,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC;gBAChD,IAAI,KAAK,KAAK,CAAC,CAAC,EAAE;oBAChB,MAAM,IAAI,KAAK,CACX,WAAW,GAAG,GAAG,GACjB,+DAA+D,GAC/D,SAAS,GAAG,IAAI,CAAC,eAAe,CAAC,QAAQ,EAAE,GAAG,IAAI,CAAC,CAAC;iBACzD;aACF;SACF;QACD,IAAI,CAAC,oBAAoB,GAAG,IAAI,CAAC;IACnC,CAAC;IAEO,KAAK,CAAC,mBAAmB,GAAA;QAC/B,IAAI,IAAI,CAAC,SAAS,EAAE;YAClB,MAAM,IAAI,GAAG,MAAM,IAAI,CAAC,IAAI,CAAC,QAAQ,EAAE,CAAC;YACxC,MAAM,YAAY,GAAG,MAAM,IAAI,CAAC,IAAI,EAAE,CAAC;YACvC,IAAI,YAAY,CAAC,IAAI,EAAE;gBACrB,MAAM,IAAI,KAAK,CAAC,oCAAoC,CAAC,CAAC;aACvD;YACD,MAAM,SAAS,GAAW,YAAY,CAAC,KAAK,CAAC;YAC7C,MAAM,OAAO,GAAG,IAAI,CAAC,QAAQ,CAAC,SAAS,EAAE,KAAK,CAAC,CAAC;YAChD,OAAO,OAAO,CAAC;SAChB,MAAM;YACL,OAAO,IAAI,CAAC;SACb;IACH,CAAC;IAED;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;OA+BG,CACH,YAA+B,KAAiB,EAAE,SAAqB,CAAA;QACrE,KAAK,EAAE,CAAC;QADqB,IAAA,CAAA,KAAK,GAAL,KAAK,CAAY;QA9HxC,IAAA,CAAA,SAAS,GAAG,IAAI,CAAC;QACjB,IAAA,CAAA,eAAe,GAAa,IAAI,CAAC;QACjC,IAAA,CAAA,oBAAoB,GAAG,KAAK,CAAC;QAC7B,IAAA,CAAA,aAAa,GAAkC,IAAI,CAAC;QACpD,IAAA,CAAA,qBAAqB,GAAG,KAAK,CAAC;QAC9B,IAAA,CAAA,SAAS,GAAG,GAAG,CAAC;QAChB,IAAA,CAAA,eAAe,GAAG,KAAK,CAAC;QA0H9B,IAAI,CAAC,IAAI,GAAG,IAAI,2VAAe,CAAC,KAAK,CAAC,CAAC;QACvC,IAAI,CAAC,SAAS,EAAE;YACd,SAAS,GAAG,CAAA,CAAE,CAAC;SAChB;QACD,IAAI,CAAC,SAAS,GAAG,SAAS,CAAC,SAAS,KAAK,KAAK,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,IAAI,CAAC;QAC9D,IAAI,CAAC,eAAe,GAAG,SAAS,CAAC,WAAW,CAAC;QAC7C,IAAI,CAAC,aAAa,GAAG,SAAS,CAAC,aAAa,CAAC;QAC7C,IAAI,CAAC,qBAAqB,GAAG,SAAS,CAAC,qBAAqB,CAAC;QAC7D,IAAI,SAAS,CAAC,eAAe,EAAE;YAC7B,8QAAI,CAAC,MAAM,CACP,SAAS,CAAC,SAAS,IAAI,IAAI,EAC3B,GAAG,CACC,CADC,+DAC+D,CAAC,CAAC;YAC1E,IAAI,CAAC,eAAe,GAAG,IAAI,CAAC;YAC5B,IAAI,CAAC,SAAS,GAAG,GAAG,CAAC;SACtB,MAAM;YACL,IAAI,CAAC,SAAS,GAAG,SAAS,CAAC,SAAS,CAAC,CAAC,CAAC,SAAS,CAAC,SAAS,CAAC,CAAC,CAAC,GAAG,CAAC;SAClE;IACH,CAAC;IAED,KAAK,CAAC,QAAQ,GAAA;QACZ,IAAI,CAAC,IAAI,CAAC,oBAAoB,EAAE;YAC9B,MAAM,IAAI,CAAC,cAAc,EAAE,CAAC;SAC7B;QACD,IAAI,KAAK,GAAG,MAAM,IAAI,CAAC,IAAI,CAAC,QAAQ,EAAE,CAAC;QACvC,IAAI,IAAI,CAAC,SAAS,EAAE;YAClB,4DAA4D;YAC5D,0CAA0C;YAC1C,KAAK,GAAG,KAAK,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;SACvB;QACD,OAAO,KAAK,CAAC,GAAG,EAAC,CAAC,CAAC,EAAE,AAAC,IAAI,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC,CAAC;IACjD,CAAC;IAED,eAAe,CAAC,IAAY,EAAA;QAC1B,MAAM,MAAM,GAAG,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAC,CAAC;QACnC,MAAM,QAAQ,GAAqC,CAAA,CAAE,CAAC;QACtD,MAAM,MAAM,GAAqC,CAAA,CAAE,CAAC;QAEpD,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,eAAe,CAAC,MAAM,EAAE,CAAC,EAAE,CAAE;YACpD,MAAM,GAAG,GAAG,IAAI,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC;YACpC,MAAM,MAAM,GAAG,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC,IAAI,CAAC,aAAa,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC;YACnE,IAAI,IAAI,CAAC,qBAAqB,IAAI,CAAC,MAAM,EAAE;gBAEzC,SAAS;aACV,MAAM;gBACL,MAAM,KAAK,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;gBACxB,IAAI,WAAW,GAAG,IAAI,CAAC;gBACvB,IAAI,KAAK,KAAK,EAAE,EAAE;oBAChB,gEAAgE;oBAChE,8BAA8B;oBAC9B,IAAI,MAAM,IAAI,MAAM,CAAC,OAAO,KAAK,SAAS,EAAE;wBAC1C,WAAW,GAAG,MAAM,CAAC,OAAO,CAAC;qBAC9B,MAAM,IAAI,MAAM,IAAI,CAAC,MAAM,CAAC,QAAQ,IAAI,MAAM,CAAC,OAAO,CAAC,EAAE;wBACxD,MAAM,IAAI,KAAK,CACX,CAAA,gBAAA,EAAmB,GAAG,CAAA,wBAAA,EAA2B,IAAI,EAAE,CAAC,CAAC;qBAC9D,MAAM;wBACL,WAAW,GAAG,SAAS,CAAC;qBACzB;iBACF,MAAM;oBACL,gDAAgD;oBAChD,MAAM,UAAU,GAAG,MAAM,CAAC,KAAK,CAAC,CAAC;oBACjC,IAAI,KAAK,CAAC,UAAU,CAAC,EAAE;wBACrB,+DAA+D;wBAC/D,kCAAkC;wBAClC,IAAI,MAAM,IAAI,MAAM,CAAC,KAAK,KAAK,MAAM,EAAE;4BACrC,WAAW,GAAG,IAAI,CAAC,UAAU,CAAC,KAAK,CAAC,CAAC;yBACtC,MAAM;4BACL,sBAAsB;4BACtB,WAAW,GAAG,KAAK,CAAC;yBACrB;qBACF,MAAM,IAAI,CAAC,MAAM,IAAI,CAAC,MAAM,CAAC,KAAK,EAAE;wBACnC,mEAAmE;wBACnE,gBAAgB;wBAChB,WAAW,GAAG,UAAU,CAAC;qBAC1B,MAAM;wBACL,gEAAgE;wBAChE,mCAAmC;wBACnC,OAAQ,MAAM,CAAC,KAAK,EAAE;4BACpB,KAAK,SAAS;gCACZ,WAAW,GAAG,UAAU,CAAC;gCACzB,MAAM;4BACR,KAAK,OAAO;gCACV,WAAW,GAAG,IAAI,CAAC,KAAK,CAAC,UAAU,CAAC,CAAC;gCACrC,MAAM;4BACR,KAAK,MAAM;gCACT,WAAW,GAAG,IAAI,CAAC,UAAU,CAAC,KAAK,CAAC,CAAC;gCACrC,MAAM;4BACR;gCACE,WAAW,GAAG,UAAU,CAAC;yBAC5B;qBACF;iBACF;gBACD,iCAAiC;gBAChC,MAAM,IAAI,MAAM,CAAC,OAAO,CAAC,CAAC,CAAC,AAAC,MAAM,CAAC,GAAG,CAAC,GAAG,WAAW,CAAC,CAAC,CAC3B,QAAQ,CAAC,GAAG,CAAC,GAAG,WAAW,CAAC;aAC1D;SACF;QACD,4EAA4E;QAC5E,8CAA8C;QAC9C,IAAI,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,MAAM,KAAK,CAAC,EAAE;YACpC,OAAO,QAAQ,CAAC;SAEjB,MAAM;YACL,OAAO;gBAAC,EAAE,EAAE,QAAQ;gBAAE,EAAE,EAAE,MAAM;YAAA,CAAC,CAAC;SACnC;IACH,CAAC;IAEO,UAAU,CAAC,KAAa,EAAA;QAC9B,IAAI,KAAK,KAAK,GAAG,IAAI,KAAK,CAAC,WAAW,EAAE,KAAK,MAAM,EAAE;YACnD,OAAO,CAAC,CAAC;SACV,MAAM;YACL,OAAO,CAAC,CAAC;SACV;IACH,CAAC;IAED,qEAAqE;IAC7D,QAAQ,CAAC,IAAY,EAAE,oBAAoB,GAAG,IAAI,EAAA;QACxD,MAAM,MAAM,GAAa,EAAE,CAAC;QAC5B,IAAI,UAAU,GAAG,CAAC,CAAC;QACnB,MAAM,UAAU,GAAG,IAAI,CAAC,MAAM,CAAC;QAC/B,IAAI,YAAY,GAAG,SAAS,CAAC;QAC7B,wCAAwC;QACxC,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,UAAU,EAAE,CAAC,EAAE,CAAE;YACnC,OAAQ,YAAY,EAAE;gBACpB,2BAA2B;gBAC3B,KAAK,SAAS;oBACZ,OAAQ,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC,EAAE;wBACtB,uBAAuB;wBACvB,KAAK,UAAU;4BACb,UAAU,GAAG,CAAC,GAAG,CAAC,CAAC;4BACnB,YAAY,GAAG,WAAW,CAAC;4BAC3B,MAAM;wBACR,sBAAsB;wBACtB,KAAK,IAAI,CAAC,SAAS;4BACjB,UAAU,GAAG,CAAC,GAAG,CAAC,CAAC;4BACnB,yDAAyD;4BACzD,kDAAkD;4BAClD,IAAI,IAAI,CAAC,SAAS,KAAK,GAAG,IAAI,IAAI,CAAC,eAAe,EAAE;gCAClD,MAAM;6BACP;4BACD,MAAM,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC;4BAChB,YAAY,GAAG,SAAS,CAAC;4BACzB,MAAM;wBACR,0BAA0B;wBAC1B;4BACE,YAAY,GAAG,WAAW,CAAC;4BAC3B,UAAU,GAAG,CAAC,CAAC;4BACf,MAAM;qBACT;oBACD,MAAM;gBACR,uBAAuB;gBACvB,KAAK,WAAW;oBACd,OAAQ,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC,EAAE;wBACtB,2CAA2C;wBAC3C,KAAK,IAAI,CAAC,SAAS;4BACjB,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,UAAU,EAAE,CAAC,CAAC,CAAC,CAAC;4BAC3C,YAAY,GAAG,SAAS,CAAC;4BACzB,UAAU,GAAG,CAAC,GAAG,CAAC,CAAC;4BACnB,MAAM;wBACR,QAAQ;qBACT;oBACD,MAAM;gBACR,oBAAoB;gBACpB,KAAK,WAAW;oBACd,OAAQ,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC,EAAE;wBACtB,6BAA6B;wBAC7B,KAAK,UAAU;4BACb,YAAY,GAAG,uBAAuB,CAAC;4BACvC,MAAM;wBACR,QAAQ;qBACT;oBACD,MAAM;gBACR,8DAA8D;gBAC9D,KAAK,uBAAuB;oBAC1B,OAAQ,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC,EAAE;wBACtB,0BAA0B;wBAC1B,KAAK,IAAI,CAAC,SAAS;4BACjB,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,UAAU,EAAE,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;4BAC/C,YAAY,GAAG,SAAS,CAAC;4BACzB,UAAU,GAAG,CAAC,GAAG,CAAC,CAAC;4BACnB,MAAM;wBACR,2CAA2C;wBAC3C,KAAK,UAAU;4BACb,YAAY,GAAG,WAAW,CAAC;4BAC3B,MAAM;wBACR,qCAAqC;wBACrC;4BACE,YAAY,GAAG,2BAA2B,CAAC;4BAC3C,MAAM;qBACT;oBACD,MAAM;gBACR,KAAK,2BAA2B;oBAC9B,OAAQ,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC,EAAE;wBACtB,uCAAuC;wBACvC,KAAK,UAAU;4BACb,YAAY,GAAG,WAAW,CAAC;4BAC3B,MAAM;wBACR,QAAQ;qBACT;oBACD,MAAM;gBACR,QAAQ;aACT;SACF;QACD,2CAA2C;QAC3C,IAAI,YAAY,KAAK,uBAAuB,EAAE;YAC5C,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,UAAU,EAAE,UAAU,GAAG,CAAC,CAAC,CAAC,CAAC;SACzD,MAAM;YACL,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,UAAU,CAAC,CAAC,CAAC;SACzC;QACD,qEAAqE;QACrE,IAAI,oBAAoB,IAAI,MAAM,CAAC,MAAM,KAAK,IAAI,CAAC,eAAe,CAAC,MAAM,EAAE;YACzE,MAAM,IAAI,KAAK,CAAC,CAAA,qCAAA,EACZ,IAAI,CAAC,eAAe,CAAC,MAAM,CAAA,4BAAA,EAA+B,MAAM,EAAE,CAAC,CAAC;SACzE;QACD,OAAO,MAAM,CAAC;IAChB,CAAC;CACF,CAED,iEAAiE;CACjE,qCAAqC;CACrC,4BAA4B"}},
    {"offset": {"line": 2423, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-data@4.22.0_@tensorflow+tfjs-core@4.22.0_seedrandom@3.0.5/node_modules/@tensorflow/tfjs-data/dist/iterators/microphone_iterator.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-data/src/iterators/microphone_iterator.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\n\nimport {env, Tensor, tensor, Tensor2D, Tensor3D, TensorContainer, util} from '@tensorflow/tfjs-core';\nimport {MicrophoneConfig} from '../types';\nimport {LazyIterator} from './lazy_iterator';\n\n/**\n * Provide a stream of tensors from microphone audio stream. The tensors are\n * representing audio data as frequency-domain spectrogram generated with\n * browser's native FFT. Tensors representing time-domain waveform is available\n * based on configuration. Only works in browser environment.\n */\nexport class MicrophoneIterator extends LazyIterator<TensorContainer> {\n  private isClosed = false;\n  private stream: MediaStream;\n  private readonly fftSize: number;\n  private readonly columnTruncateLength: number;\n  private freqData: Float32Array;\n  private timeData: Float32Array;\n  private readonly numFrames: number;\n  private analyser: AnalyserNode;\n  private audioContext: AudioContext;\n  private sampleRateHz: number;\n  private readonly audioTrackConstraints: MediaTrackConstraints;\n  private readonly smoothingTimeConstant: number;\n  private readonly includeSpectrogram: boolean;\n  private readonly includeWaveform: boolean;\n\n  private constructor(protected readonly microphoneConfig: MicrophoneConfig) {\n    super();\n    this.fftSize = microphoneConfig.fftSize || 1024;\n    const fftSizeLog2 = Math.log2(this.fftSize);\n    if (this.fftSize < 0 || fftSizeLog2 < 4 || fftSizeLog2 > 14 ||\n        !Number.isInteger(fftSizeLog2)) {\n      throw new Error(\n          `Invalid fftSize: it must be a power of 2 between ` +\n          `2 to 4 and 2 to 14, but got ${this.fftSize}`);\n    }\n\n    this.numFrames = microphoneConfig.numFramesPerSpectrogram || 43;\n    this.sampleRateHz = microphoneConfig.sampleRateHz;\n    this.columnTruncateLength =\n        microphoneConfig.columnTruncateLength || this.fftSize;\n    this.audioTrackConstraints = microphoneConfig.audioTrackConstraints;\n    this.smoothingTimeConstant = microphoneConfig.smoothingTimeConstant || 0;\n\n    this.includeSpectrogram =\n        microphoneConfig.includeSpectrogram === false ? false : true;\n    this.includeWaveform =\n        microphoneConfig.includeWaveform === true ? true : false;\n    if (!this.includeSpectrogram && !this.includeWaveform) {\n      throw new Error(\n          'Both includeSpectrogram and includeWaveform are false. ' +\n          'At least one type of data should be returned.');\n    }\n  }\n\n  summary() {\n    return `microphone`;\n  }\n\n  // Construct a MicrophoneIterator and start the audio stream.\n  static async create(microphoneConfig: MicrophoneConfig = {}) {\n    if (!env().get('IS_BROWSER')) {\n      throw new Error(\n          'microphone API is only supported in browser environment.');\n    }\n\n    const microphoneIterator = new MicrophoneIterator(microphoneConfig);\n\n    // Call async function start() to initialize the audio stream.\n    await microphoneIterator.start();\n\n    return microphoneIterator;\n  }\n\n  // Start the audio stream and FFT.\n  async start(): Promise<void> {\n    try {\n      this.stream = await navigator.mediaDevices.getUserMedia({\n        audio: this.audioTrackConstraints == null ? true :\n                                                    this.audioTrackConstraints,\n        video: false\n      });\n    } catch (e) {\n      throw new Error(\n          `Error thrown while initializing video stream: ${e.message}`);\n    }\n\n    if (!this.stream) {\n      throw new Error('Could not obtain audio from microphone.');\n    }\n\n    const ctxConstructor =\n        // tslint:disable-next-line:no-any\n        (window as any).AudioContext || (window as any).webkitAudioContext;\n    this.audioContext = new ctxConstructor();\n\n    if (!this.sampleRateHz) {\n      // If sample rate is not provided, use the available sample rate on\n      // device.\n      this.sampleRateHz = this.audioContext.sampleRate;\n    } else if (this.audioContext.sampleRate !== this.sampleRateHz) {\n      throw new Error(\n          `Mismatch in sampling rate: ` +\n          `Expected: ${this.sampleRateHz}; ` +\n          `Actual: ${this.audioContext.sampleRate}`);\n    }\n\n    const streamSource = this.audioContext.createMediaStreamSource(this.stream);\n    this.analyser = this.audioContext.createAnalyser();\n    this.analyser.fftSize = this.fftSize * 2;\n    this.analyser.smoothingTimeConstant = this.smoothingTimeConstant;\n    streamSource.connect(this.analyser);\n    this.freqData = new Float32Array(this.fftSize);\n    this.timeData = new Float32Array(this.fftSize);\n    return;\n  }\n\n  async next(): Promise<IteratorResult<TensorContainer>> {\n    if (this.isClosed) {\n      return {value: null, done: true};\n    }\n\n    let spectrogramTensor: Tensor;\n    let waveformTensor: Tensor;\n\n    const audioDataQueue = await this.getAudioData();\n    if (this.includeSpectrogram) {\n      const freqData = this.flattenQueue(audioDataQueue.freqDataQueue);\n      spectrogramTensor = this.getTensorFromAudioDataArray(\n          freqData, [this.numFrames, this.columnTruncateLength, 1]);\n    }\n    if (this.includeWaveform) {\n      const timeData = this.flattenQueue(audioDataQueue.timeDataQueue);\n      waveformTensor = this.getTensorFromAudioDataArray(\n          timeData, [this.numFrames * this.fftSize, 1]);\n    }\n\n    return {\n      value: {'spectrogram': spectrogramTensor, 'waveform': waveformTensor},\n      done: false\n    };\n  }\n\n  // Capture one result from the audio stream, and extract the value from\n  // iterator.next() result.\n  async capture(): Promise<{spectrogram: Tensor3D, waveform: Tensor2D}> {\n    return (await this.next()).value as\n        {spectrogram: Tensor3D, waveform: Tensor2D};\n  }\n\n  private async getAudioData():\n      Promise<{freqDataQueue: Float32Array[], timeDataQueue: Float32Array[]}> {\n    const freqDataQueue: Float32Array[] = [];\n    const timeDataQueue: Float32Array[] = [];\n    let currentFrames = 0;\n    return new Promise(resolve => {\n      const intervalID = setInterval(() => {\n        if (this.includeSpectrogram) {\n          this.analyser.getFloatFrequencyData(this.freqData);\n          // If the audio stream is initializing, return empty queue.\n          if (this.freqData[0] === -Infinity) {\n            resolve({freqDataQueue, timeDataQueue});\n          }\n          freqDataQueue.push(this.freqData.slice(0, this.columnTruncateLength));\n        }\n        if (this.includeWaveform) {\n          this.analyser.getFloatTimeDomainData(this.timeData);\n          timeDataQueue.push(this.timeData.slice());\n        }\n\n        // Clean interval and return when all frames have been collected\n        if (++currentFrames === this.numFrames) {\n          clearInterval(intervalID);\n          resolve({freqDataQueue, timeDataQueue});\n        }\n      }, this.fftSize / this.sampleRateHz * 1e3);\n    });\n  }\n\n  // Stop the audio stream and pause the iterator.\n  stop(): void {\n    if (!this.isClosed) {\n      this.isClosed = true;\n      this.analyser.disconnect();\n      this.audioContext.close();\n      if (this.stream != null && this.stream.getTracks().length > 0) {\n        this.stream.getTracks()[0].stop();\n      }\n    }\n  }\n\n  // Override toArray() function to prevent collecting.\n  override toArray(): Promise<Tensor[]> {\n    throw new Error('Can not convert infinite audio stream to array.');\n  }\n\n  // Return audio sampling rate in Hz\n  getSampleRate(): number {\n    return this.sampleRateHz;\n  }\n\n  private flattenQueue(queue: Float32Array[]): Float32Array {\n    const frameSize = queue[0].length;\n    const freqData = new Float32Array(queue.length * frameSize);\n    queue.forEach((data, i) => freqData.set(data, i * frameSize));\n    return freqData;\n  }\n\n  private getTensorFromAudioDataArray(freqData: Float32Array, shape: number[]):\n      Tensor {\n    const vals = new Float32Array(util.sizeFromShape(shape));\n    // If the data is less than the output shape, the rest is padded with zeros.\n    vals.set(freqData, vals.length - freqData.length);\n    return tensor(vals, shape);\n  }\n}\n"],"names":[],"mappings":";;;;AAAA;;;;;;;;;;;;;;;;GAgBG;;;AAEH,OAAO,EAAC,GAAG,EAAU,MAAM,EAAuC,IAAI,EAAC,MAAM,uBAAuB,CAAC;AAErG,OAAO,EAAC,YAAY,EAAC,MAAM,iBAAiB,CAAC;;;AAQvC,MAAO,kBAAmB,SAAQ,qVAA6B;IAgBnE,YAAuC,gBAAkC,CAAA;QACvE,KAAK,EAAE,CAAC;QAD6B,IAAA,CAAA,gBAAgB,GAAhB,gBAAgB,CAAkB;QAfjE,IAAA,CAAA,QAAQ,GAAG,KAAK,CAAC;QAiBvB,IAAI,CAAC,OAAO,GAAG,gBAAgB,CAAC,OAAO,IAAI,IAAI,CAAC;QAChD,MAAM,WAAW,GAAG,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC;QAC5C,IAAI,IAAI,CAAC,OAAO,GAAG,CAAC,IAAI,WAAW,GAAG,CAAC,IAAI,WAAW,GAAG,EAAE,IACvD,CAAC,MAAM,CAAC,SAAS,CAAC,WAAW,CAAC,EAAE;YAClC,MAAM,IAAI,KAAK,CACX,CAAA,iDAAA,CAAmD,GACnD,CAAA,4BAAA,EAA+B,IAAI,CAAC,OAAO,EAAE,CAAC,CAAC;SACpD;QAED,IAAI,CAAC,SAAS,GAAG,gBAAgB,CAAC,uBAAuB,IAAI,EAAE,CAAC;QAChE,IAAI,CAAC,YAAY,GAAG,gBAAgB,CAAC,YAAY,CAAC;QAClD,IAAI,CAAC,oBAAoB,GACrB,gBAAgB,CAAC,oBAAoB,IAAI,IAAI,CAAC,OAAO,CAAC;QAC1D,IAAI,CAAC,qBAAqB,GAAG,gBAAgB,CAAC,qBAAqB,CAAC;QACpE,IAAI,CAAC,qBAAqB,GAAG,gBAAgB,CAAC,qBAAqB,IAAI,CAAC,CAAC;QAEzE,IAAI,CAAC,kBAAkB,GACnB,gBAAgB,CAAC,kBAAkB,KAAK,KAAK,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,IAAI,CAAC;QACjE,IAAI,CAAC,eAAe,GAChB,gBAAgB,CAAC,eAAe,KAAK,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,CAAC;QAC7D,IAAI,CAAC,IAAI,CAAC,kBAAkB,IAAI,CAAC,IAAI,CAAC,eAAe,EAAE;YACrD,MAAM,IAAI,KAAK,CACX,yDAAyD,GACzD,+CAA+C,CAAC,CAAC;SACtD;IACH,CAAC;IAED,OAAO,GAAA;QACL,OAAO,CAAA,UAAA,CAAY,CAAC;IACtB,CAAC;IAED,6DAA6D;IAC7D,MAAM,CAAC,KAAK,CAAC,MAAM,CAAC,mBAAqC,CAAA,CAAE,EAAA;QACzD,IAAI,KAAC,oPAAG,EAAE,EAAC,GAAG,CAAC,YAAY,CAAC,EAAE;YAC5B,MAAM,IAAI,KAAK,CACX,0DAA0D,CAAC,CAAC;SACjE;QAED,MAAM,kBAAkB,GAAG,IAAI,kBAAkB,CAAC,gBAAgB,CAAC,CAAC;QAEpE,8DAA8D;QAC9D,MAAM,kBAAkB,CAAC,KAAK,EAAE,CAAC;QAEjC,OAAO,kBAAkB,CAAC;IAC5B,CAAC;IAED,kCAAkC;IAClC,KAAK,CAAC,KAAK,GAAA;QACT,IAAI;YACF,IAAI,CAAC,MAAM,GAAG,MAAM,SAAS,CAAC,YAAY,CAAC,YAAY,CAAC;gBACtD,KAAK,EAAE,IAAI,CAAC,qBAAqB,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CACN,IAAI,CAAC,qBAAqB;gBACtE,KAAK,EAAE,KAAK;aACb,CAAC,CAAC;SACJ,CAAC,OAAO,CAAC,EAAE;YACV,MAAM,IAAI,KAAK,CACX,CAAA,8CAAA,EAAiD,CAAC,CAAC,OAAO,EAAE,CAAC,CAAC;SACnE;QAED,IAAI,CAAC,IAAI,CAAC,MAAM,EAAE;YAChB,MAAM,IAAI,KAAK,CAAC,yCAAyC,CAAC,CAAC;SAC5D;QAED,MAAM,cAAc,GAChB,kCAAkC;QACjC,MAAc,CAAC,YAAY,IAAK,MAAc,CAAC,kBAAkB,CAAC;QACvE,IAAI,CAAC,YAAY,GAAG,IAAI,cAAc,EAAE,CAAC;QAEzC,IAAI,CAAC,IAAI,CAAC,YAAY,EAAE;YACtB,mEAAmE;YACnE,UAAU;YACV,IAAI,CAAC,YAAY,GAAG,IAAI,CAAC,YAAY,CAAC,UAAU,CAAC;SAClD,MAAM,IAAI,IAAI,CAAC,YAAY,CAAC,UAAU,KAAK,IAAI,CAAC,YAAY,EAAE;YAC7D,MAAM,IAAI,KAAK,CACX,CAAA,2BAAA,CAA6B,GAC7B,CAAA,UAAA,EAAa,IAAI,CAAC,YAAY,CAAA,EAAA,CAAI,GAClC,CAAA,QAAA,EAAW,IAAI,CAAC,YAAY,CAAC,UAAU,EAAE,CAAC,CAAC;SAChD;QAED,MAAM,YAAY,GAAG,IAAI,CAAC,YAAY,CAAC,uBAAuB,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;QAC5E,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC,YAAY,CAAC,cAAc,EAAE,CAAC;QACnD,IAAI,CAAC,QAAQ,CAAC,OAAO,GAAG,IAAI,CAAC,OAAO,GAAG,CAAC,CAAC;QACzC,IAAI,CAAC,QAAQ,CAAC,qBAAqB,GAAG,IAAI,CAAC,qBAAqB,CAAC;QACjE,YAAY,CAAC,OAAO,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC;QACpC,IAAI,CAAC,QAAQ,GAAG,IAAI,YAAY,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC;QAC/C,IAAI,CAAC,QAAQ,GAAG,IAAI,YAAY,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC;QAC/C,OAAO;IACT,CAAC;IAED,KAAK,CAAC,IAAI,GAAA;QACR,IAAI,IAAI,CAAC,QAAQ,EAAE;YACjB,OAAO;gBAAC,KAAK,EAAE,IAAI;gBAAE,IAAI,EAAE,IAAI;YAAA,CAAC,CAAC;SAClC;QAED,IAAI,iBAAyB,CAAC;QAC9B,IAAI,cAAsB,CAAC;QAE3B,MAAM,cAAc,GAAG,MAAM,IAAI,CAAC,YAAY,EAAE,CAAC;QACjD,IAAI,IAAI,CAAC,kBAAkB,EAAE;YAC3B,MAAM,QAAQ,GAAG,IAAI,CAAC,YAAY,CAAC,cAAc,CAAC,aAAa,CAAC,CAAC;YACjE,iBAAiB,GAAG,IAAI,CAAC,2BAA2B,CAChD,QAAQ,EAAE;gBAAC,IAAI,CAAC,SAAS;gBAAE,IAAI,CAAC,oBAAoB;gBAAE,CAAC;aAAC,CAAC,CAAC;SAC/D;QACD,IAAI,IAAI,CAAC,eAAe,EAAE;YACxB,MAAM,QAAQ,GAAG,IAAI,CAAC,YAAY,CAAC,cAAc,CAAC,aAAa,CAAC,CAAC;YACjE,cAAc,GAAG,IAAI,CAAC,2BAA2B,CAC7C,QAAQ,EAAE;gBAAC,IAAI,CAAC,SAAS,GAAG,IAAI,CAAC,OAAO;gBAAE,CAAC;aAAC,CAAC,CAAC;SACnD;QAED,OAAO;YACL,KAAK,EAAE;gBAAC,aAAa,EAAE,iBAAiB;gBAAE,UAAU,EAAE,cAAc;YAAA,CAAC;YACrE,IAAI,EAAE,KAAK;SACZ,CAAC;IACJ,CAAC;IAED,uEAAuE;IACvE,0BAA0B;IAC1B,KAAK,CAAC,OAAO,GAAA;QACX,OAAO,CAAC,MAAM,IAAI,CAAC,IAAI,EAAE,CAAC,CAAC,KACoB,CAAC;IAClD,CAAC;IAEO,KAAK,CAAC,YAAY,GAAA;QAExB,MAAM,aAAa,GAAmB,EAAE,CAAC;QACzC,MAAM,aAAa,GAAmB,EAAE,CAAC;QACzC,IAAI,aAAa,GAAG,CAAC,CAAC;QACtB,OAAO,IAAI,OAAO,EAAC,OAAO,CAAC,EAAE;YAC3B,MAAM,UAAU,GAAG,WAAW,CAAC,GAAG,EAAE;gBAClC,IAAI,IAAI,CAAC,kBAAkB,EAAE;oBAC3B,IAAI,CAAC,QAAQ,CAAC,qBAAqB,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC;oBACnD,2DAA2D;oBAC3D,IAAI,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,KAAK,CAAC,QAAQ,EAAE;wBAClC,OAAO,CAAC;4BAAC,aAAa;4BAAE,aAAa;wBAAA,CAAC,CAAC,CAAC;qBACzC;oBACD,aAAa,CAAC,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,KAAK,CAAC,CAAC,EAAE,IAAI,CAAC,oBAAoB,CAAC,CAAC,CAAC;iBACvE;gBACD,IAAI,IAAI,CAAC,eAAe,EAAE;oBACxB,IAAI,CAAC,QAAQ,CAAC,sBAAsB,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC;oBACpD,aAAa,CAAC,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,KAAK,EAAE,CAAC,CAAC;iBAC3C;gBAED,gEAAgE;gBAChE,IAAI,EAAE,aAAa,KAAK,IAAI,CAAC,SAAS,EAAE;oBACtC,aAAa,CAAC,UAAU,CAAC,CAAC;oBAC1B,OAAO,CAAC;wBAAC,aAAa;wBAAE,aAAa;oBAAA,CAAC,CAAC,CAAC;iBACzC;YACH,CAAC,EAAE,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC,YAAY,GAAG,GAAG,CAAC,CAAC;QAC7C,CAAC,CAAC,CAAC;IACL,CAAC;IAED,gDAAgD;IAChD,IAAI,GAAA;QACF,IAAI,CAAC,IAAI,CAAC,QAAQ,EAAE;YAClB,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC;YACrB,IAAI,CAAC,QAAQ,CAAC,UAAU,EAAE,CAAC;YAC3B,IAAI,CAAC,YAAY,CAAC,KAAK,EAAE,CAAC;YAC1B,IAAI,IAAI,CAAC,MAAM,IAAI,IAAI,IAAI,IAAI,CAAC,MAAM,CAAC,SAAS,EAAE,CAAC,MAAM,GAAG,CAAC,EAAE;gBAC7D,IAAI,CAAC,MAAM,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC,CAAC,IAAI,EAAE,CAAC;aACnC;SACF;IACH,CAAC;IAED,qDAAqD;IAC5C,OAAO,GAAA;QACd,MAAM,IAAI,KAAK,CAAC,iDAAiD,CAAC,CAAC;IACrE,CAAC;IAED,mCAAmC;IACnC,aAAa,GAAA;QACX,OAAO,IAAI,CAAC,YAAY,CAAC;IAC3B,CAAC;IAEO,YAAY,CAAC,KAAqB,EAAA;QACxC,MAAM,SAAS,GAAG,KAAK,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC;QAClC,MAAM,QAAQ,GAAG,IAAI,YAAY,CAAC,KAAK,CAAC,MAAM,GAAG,SAAS,CAAC,CAAC;QAC5D,KAAK,CAAC,OAAO,CAAC,CAAC,IAAI,EAAE,CAAC,EAAE,CAAG,CAAD,OAAS,CAAC,GAAG,CAAC,IAAI,EAAE,CAAC,GAAG,SAAS,CAAC,CAAC,CAAC;QAC9D,OAAO,QAAQ,CAAC;IAClB,CAAC;IAEO,2BAA2B,CAAC,QAAsB,EAAE,KAAe,EAAA;QAEzE,MAAM,IAAI,GAAG,IAAI,YAAY,CAAC,8QAAI,CAAC,aAAa,CAAC,KAAK,CAAC,CAAC,CAAC;QACzD,4EAA4E;QAC5E,IAAI,CAAC,GAAG,CAAC,QAAQ,EAAE,IAAI,CAAC,MAAM,GAAG,QAAQ,CAAC,MAAM,CAAC,CAAC;QAClD,WAAO,yPAAM,EAAC,IAAI,EAAE,KAAK,CAAC,CAAC;IAC7B,CAAC;CACF"}},
    {"offset": {"line": 2622, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-data@4.22.0_@tensorflow+tfjs-core@4.22.0_seedrandom@3.0.5/node_modules/@tensorflow/tfjs-data/dist/iterators/webcam_iterator.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-data/src/iterators/webcam_iterator.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\n\nimport {browser, cast, env, expandDims, image, reshape, tensor1d, Tensor1D, tensor2d, Tensor2D, Tensor3D, Tensor4D, tidy, util} from '@tensorflow/tfjs-core';\nimport {WebcamConfig} from '../types';\nimport {LazyIterator} from './lazy_iterator';\n\n/**\n * Provide a stream of image tensors from webcam video stream. Only works in\n * browser environment.\n */\nexport class WebcamIterator extends LazyIterator<Tensor3D> {\n  private isClosed = true;\n  private stream: MediaStream;\n  private resize = false;\n  private cropSize: [number, number];\n  private cropBox: Tensor2D;\n  private cropBoxInd: Tensor1D;\n\n  private constructor(\n      protected readonly webcamVideoElement: HTMLVideoElement,\n      protected readonly webcamConfig: WebcamConfig) {\n    super();\n    if (this.needToResize()) {\n      this.resize = true;\n      this.cropSize =\n          [this.webcamConfig.resizeHeight, this.webcamConfig.resizeWidth];\n      this.cropBoxInd = tensor1d([0], 'int32');\n      if (this.webcamConfig.centerCrop) {\n        // Calculate the box based on resizing shape.\n        const widthCroppingRatio =\n            this.webcamConfig.resizeWidth * 1.0 / this.webcamVideoElement.width;\n        const heightCroppingRatio = this.webcamConfig.resizeHeight * 1.0 /\n            this.webcamVideoElement.height;\n        const widthCropStart = (1 - widthCroppingRatio) / 2;\n        const heightCropStart = (1 - heightCroppingRatio) / 2;\n        const widthCropEnd = widthCropStart + widthCroppingRatio;\n        const heightCropEnd = heightCroppingRatio + heightCropStart;\n        this.cropBox = tensor2d(\n            [heightCropStart, widthCropStart, heightCropEnd, widthCropEnd],\n            [1, 4]);\n      } else {\n        this.cropBox = tensor2d([0, 0, 1, 1], [1, 4]);\n      }\n    }\n  }\n\n  summary() {\n    return `webcam`;\n  }\n\n  // Construct a WebcamIterator and start it's video stream.\n  static async create(\n      webcamVideoElement?: HTMLVideoElement, webcamConfig: WebcamConfig = {}) {\n    if (!env().get('IS_BROWSER')) {\n      throw new Error(\n          'tf.data.webcam is only supported in browser environment.');\n    }\n\n    if (!webcamVideoElement) {\n      // If webcam video element is not provided, create a hidden video element\n      // with provided width and height.\n      webcamVideoElement = document.createElement('video');\n      if (!webcamConfig.resizeWidth || !webcamConfig.resizeHeight) {\n        throw new Error(\n            'Please provide webcam video element, or resizeWidth and ' +\n            'resizeHeight to create a hidden video element.');\n      }\n      webcamVideoElement.width = webcamConfig.resizeWidth;\n      webcamVideoElement.height = webcamConfig.resizeHeight;\n    }\n    const webcamIterator = new WebcamIterator(webcamVideoElement, webcamConfig);\n\n    // Call async function to initialize the video stream.\n    await webcamIterator.start();\n\n    return webcamIterator;\n  }\n\n  // Async function to start video stream.\n  async start(): Promise<void> {\n    if (this.webcamConfig.facingMode) {\n      util.assert(\n          (this.webcamConfig.facingMode === 'user') ||\n              (this.webcamConfig.facingMode === 'environment'),\n          () =>\n              `Invalid webcam facing mode: ${this.webcamConfig.facingMode}. ` +\n              `Please provide 'user' or 'environment'`);\n    }\n\n    try {\n      this.stream = await navigator.mediaDevices.getUserMedia({\n        video: {\n          deviceId: this.webcamConfig.deviceId,\n          facingMode: this.webcamConfig.facingMode ?\n              this.webcamConfig.facingMode :\n              'user',\n          width: this.webcamVideoElement.width,\n          height: this.webcamVideoElement.height\n        }\n      });\n    } catch (e) {\n      // Modify the error message but leave the stack trace intact\n      e.message = `Error thrown while initializing video stream: ${e.message}`;\n      throw e;\n    }\n\n    if (!this.stream) {\n      throw new Error('Could not obtain video from webcam.');\n    }\n\n    // Older browsers may not have srcObject\n    try {\n      this.webcamVideoElement.srcObject = this.stream;\n    } catch (error) {\n      console.log(error);\n      this.webcamVideoElement.src = window.URL.createObjectURL(\n        this.stream as unknown as MediaSource);\n    }\n    // Start the webcam video stream\n    this.webcamVideoElement.play();\n\n    this.isClosed = false;\n\n    return new Promise<void>(resolve => {\n      // Add event listener to make sure the webcam has been fully initialized.\n      this.webcamVideoElement.onloadedmetadata = () => {\n        resolve();\n      };\n    });\n  }\n\n  async next(): Promise<IteratorResult<Tensor3D>> {\n    if (this.isClosed) {\n      return {value: null, done: true};\n    }\n\n    let img;\n    try {\n      img = browser.fromPixels(this.webcamVideoElement);\n    } catch (e) {\n      throw new Error(\n          `Error thrown converting video to pixels: ${JSON.stringify(e)}`);\n    }\n    if (this.resize) {\n      try {\n        return {value: this.cropAndResizeFrame(img), done: false};\n      } catch (e) {\n        throw new Error(`Error thrown cropping the video: ${e.message}`);\n      } finally {\n        img.dispose();\n      }\n    } else {\n      return {value: img, done: false};\n    }\n  }\n\n  private needToResize() {\n    // If resizeWidth and resizeHeight are provided, and different from the\n    // width and height of original HTMLVideoElement, then resizing and cropping\n    // is required.\n    if (this.webcamConfig.resizeWidth && this.webcamConfig.resizeHeight &&\n        (this.webcamVideoElement.width !== this.webcamConfig.resizeWidth ||\n         this.webcamVideoElement.height !== this.webcamConfig.resizeHeight)) {\n      return true;\n    }\n    return false;\n  }\n\n  // Cropping and resizing each frame based on config\n  cropAndResizeFrame(img: Tensor3D): Tensor3D {\n    return tidy(() => {\n      const expandedImage: Tensor4D = expandDims(cast(img, 'float32'), (0));\n      let resizedImage;\n      resizedImage = image.cropAndResize(\n          expandedImage, this.cropBox, this.cropBoxInd, this.cropSize,\n          'bilinear');\n      // Extract image from batch cropping.\n      const shape = resizedImage.shape;\n      return reshape(resizedImage, shape.slice(1) as [number, number, number]);\n    });\n  }\n\n  // Capture one frame from the video stream, and extract the value from\n  // iterator.next() result.\n  async capture(): Promise<Tensor3D> {\n    return (await this.next()).value;\n  }\n\n  // Stop the video stream and pause webcam iterator.\n  stop(): void {\n    const tracks = this.stream.getTracks();\n\n    tracks.forEach(track => track.stop());\n\n    try {\n      this.webcamVideoElement.srcObject = null;\n    } catch (error) {\n      console.log(error);\n      this.webcamVideoElement.src = null;\n    }\n    this.isClosed = true;\n  }\n\n  // Override toArray() function to prevent collecting.\n  override toArray(): Promise<Tensor3D[]> {\n    throw new Error('Can not convert infinite video stream to array.');\n  }\n}\n"],"names":[],"mappings":";;;;AAAA;;;;;;;;;;;;;;;;GAgBG;;;;;;;;;;AAEH,OAAO,EAAC,OAAO,EAAE,IAAI,EAAE,GAAG,EAAE,UAAU,EAAE,KAAK,EAAE,OAAO,EAAE,QAAQ,EAAY,QAAQ,EAAgC,IAAI,EAAE,IAAI,EAAC,MAAM,uBAAuB,CAAC;AAE7J,OAAO,EAAC,YAAY,EAAC,MAAM,iBAAiB,CAAC;;;AAMvC,MAAO,cAAe,SAAQ,qVAAsB;IAQxD,YACuB,kBAAoC,EACpC,YAA0B,CAAA;QAC/C,KAAK,EAAE,CAAC;QAFa,IAAA,CAAA,kBAAkB,GAAlB,kBAAkB,CAAkB;QACpC,IAAA,CAAA,YAAY,GAAZ,YAAY,CAAc;QATzC,IAAA,CAAA,QAAQ,GAAG,IAAI,CAAC;QAEhB,IAAA,CAAA,MAAM,GAAG,KAAK,CAAC;QASrB,IAAI,IAAI,CAAC,YAAY,EAAE,EAAE;YACvB,IAAI,CAAC,MAAM,GAAG,IAAI,CAAC;YACnB,IAAI,CAAC,QAAQ,GACT;gBAAC,IAAI,CAAC,YAAY,CAAC,YAAY;gBAAE,IAAI,CAAC,YAAY,CAAC,WAAW;aAAC,CAAC;YACpE,IAAI,CAAC,UAAU,OAAG,6PAAQ,EAAC;gBAAC,CAAC;aAAC,EAAE,OAAO,CAAC,CAAC;YACzC,IAAI,IAAI,CAAC,YAAY,CAAC,UAAU,EAAE;gBAChC,6CAA6C;gBAC7C,MAAM,kBAAkB,GACpB,IAAI,CAAC,YAAY,CAAC,WAAW,GAAG,GAAG,GAAG,IAAI,CAAC,kBAAkB,CAAC,KAAK,CAAC;gBACxE,MAAM,mBAAmB,GAAG,IAAI,CAAC,YAAY,CAAC,YAAY,GAAG,GAAG,GAC5D,IAAI,CAAC,kBAAkB,CAAC,MAAM,CAAC;gBACnC,MAAM,cAAc,GAAG,CAAC,CAAC,GAAG,kBAAkB,CAAC,GAAG,CAAC,CAAC;gBACpD,MAAM,eAAe,GAAG,CAAC,CAAC,GAAG,mBAAmB,CAAC,GAAG,CAAC,CAAC;gBACtD,MAAM,YAAY,GAAG,cAAc,GAAG,kBAAkB,CAAC;gBACzD,MAAM,aAAa,GAAG,mBAAmB,GAAG,eAAe,CAAC;gBAC5D,IAAI,CAAC,OAAO,OAAG,6PAAQ,EACnB;oBAAC,eAAe;oBAAE,cAAc;oBAAE,aAAa;oBAAE,YAAY;iBAAC,EAC9D;oBAAC,CAAC;oBAAE,CAAC;iBAAC,CAAC,CAAC;aACb,MAAM;gBACL,IAAI,CAAC,OAAO,OAAG,6PAAQ,EAAC;oBAAC,CAAC;oBAAE,CAAC;oBAAE,CAAC;oBAAE,CAAC;iBAAC,EAAE;oBAAC,CAAC;oBAAE,CAAC;iBAAC,CAAC,CAAC;aAC/C;SACF;IACH,CAAC;IAED,OAAO,GAAA;QACL,OAAO,CAAA,MAAA,CAAQ,CAAC;IAClB,CAAC;IAED,0DAA0D;IAC1D,MAAM,CAAC,KAAK,CAAC,MAAM,CACf,kBAAqC,EAAE,eAA6B,CAAA,CAAE,EAAA;QACxE,IAAI,KAAC,oPAAG,EAAE,EAAC,GAAG,CAAC,YAAY,CAAC,EAAE;YAC5B,MAAM,IAAI,KAAK,CACX,0DAA0D,CAAC,CAAC;SACjE;QAED,IAAI,CAAC,kBAAkB,EAAE;YACvB,yEAAyE;YACzE,kCAAkC;YAClC,kBAAkB,GAAG,QAAQ,CAAC,aAAa,CAAC,OAAO,CAAC,CAAC;YACrD,IAAI,CAAC,YAAY,CAAC,WAAW,IAAI,CAAC,YAAY,CAAC,YAAY,EAAE;gBAC3D,MAAM,IAAI,KAAK,CACX,0DAA0D,GAC1D,gDAAgD,CAAC,CAAC;aACvD;YACD,kBAAkB,CAAC,KAAK,GAAG,YAAY,CAAC,WAAW,CAAC;YACpD,kBAAkB,CAAC,MAAM,GAAG,YAAY,CAAC,YAAY,CAAC;SACvD;QACD,MAAM,cAAc,GAAG,IAAI,cAAc,CAAC,kBAAkB,EAAE,YAAY,CAAC,CAAC;QAE5E,sDAAsD;QACtD,MAAM,cAAc,CAAC,KAAK,EAAE,CAAC;QAE7B,OAAO,cAAc,CAAC;IACxB,CAAC;IAED,wCAAwC;IACxC,KAAK,CAAC,KAAK,GAAA;QACT,IAAI,IAAI,CAAC,YAAY,CAAC,UAAU,EAAE;YAChC,8QAAI,CAAC,MAAM,CACP,AAAC,IAAI,CAAC,YAAY,CAAC,UAAU,KAAK,MAAM,CAAC,GACpC,IAAI,CAAC,YAAY,CAAC,UAAU,KAAK,aAAa,CAAC,CACpD,GAAG,CACC,CADC,AACD,4BAAA,EAA+B,IAAI,CAAC,YAAY,CAAC,UAAU,CAAA,EAAA,CAAI,GAC/D,CAAA,sCAAA,CAAwC,CAAC,CAAC;SACnD;QAED,IAAI;YACF,IAAI,CAAC,MAAM,GAAG,MAAM,SAAS,CAAC,YAAY,CAAC,YAAY,CAAC;gBACtD,KAAK,EAAE;oBACL,QAAQ,EAAE,IAAI,CAAC,YAAY,CAAC,QAAQ;oBACpC,UAAU,EAAE,IAAI,CAAC,YAAY,CAAC,UAAU,CAAC,CAAC,CACtC,IAAI,CAAC,YAAY,CAAC,UAAU,CAAC,CAAC,CAC9B,MAAM;oBACV,KAAK,EAAE,IAAI,CAAC,kBAAkB,CAAC,KAAK;oBACpC,MAAM,EAAE,IAAI,CAAC,kBAAkB,CAAC,MAAM;iBACvC;aACF,CAAC,CAAC;SACJ,CAAC,OAAO,CAAC,EAAE;YACV,4DAA4D;YAC5D,CAAC,CAAC,OAAO,GAAG,CAAA,8CAAA,EAAiD,CAAC,CAAC,OAAO,EAAE,CAAC;YACzE,MAAM,CAAC,CAAC;SACT;QAED,IAAI,CAAC,IAAI,CAAC,MAAM,EAAE;YAChB,MAAM,IAAI,KAAK,CAAC,qCAAqC,CAAC,CAAC;SACxD;QAED,wCAAwC;QACxC,IAAI;YACF,IAAI,CAAC,kBAAkB,CAAC,SAAS,GAAG,IAAI,CAAC,MAAM,CAAC;SACjD,CAAC,OAAO,KAAK,EAAE;YACd,OAAO,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC;YACnB,IAAI,CAAC,kBAAkB,CAAC,GAAG,GAAG,MAAM,CAAC,GAAG,CAAC,eAAe,CACtD,IAAI,CAAC,MAAgC,CAAC,CAAC;SAC1C;QACD,gCAAgC;QAChC,IAAI,CAAC,kBAAkB,CAAC,IAAI,EAAE,CAAC;QAE/B,IAAI,CAAC,QAAQ,GAAG,KAAK,CAAC;QAEtB,OAAO,IAAI,OAAO,EAAO,OAAO,CAAC,EAAE;YACjC,yEAAyE;YACzE,IAAI,CAAC,kBAAkB,CAAC,gBAAgB,GAAG,GAAG,EAAE;gBAC9C,OAAO,EAAE,CAAC;YACZ,CAAC,CAAC;QACJ,CAAC,CAAC,CAAC;IACL,CAAC;IAED,KAAK,CAAC,IAAI,GAAA;QACR,IAAI,IAAI,CAAC,QAAQ,EAAE;YACjB,OAAO;gBAAC,KAAK,EAAE,IAAI;gBAAE,IAAI,EAAE,IAAI;YAAA,CAAC,CAAC;SAClC;QAED,IAAI,GAAG,CAAC;QACR,IAAI;YACF,GAAG,GAAG,8RAAO,CAAC,UAAU,CAAC,IAAI,CAAC,kBAAkB,CAAC,CAAC;SACnD,CAAC,OAAO,CAAC,EAAE;YACV,MAAM,IAAI,KAAK,CACX,CAAA,yCAAA,EAA4C,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC;SACtE;QACD,IAAI,IAAI,CAAC,MAAM,EAAE;YACf,IAAI;gBACF,OAAO;oBAAC,KAAK,EAAE,IAAI,CAAC,kBAAkB,CAAC,GAAG,CAAC;oBAAE,IAAI,EAAE,KAAK;gBAAA,CAAC,CAAC;aAC3D,CAAC,OAAO,CAAC,EAAE;gBACV,MAAM,IAAI,KAAK,CAAC,CAAA,iCAAA,EAAoC,CAAC,CAAC,OAAO,EAAE,CAAC,CAAC;aAClE,QAAS;gBACR,GAAG,CAAC,OAAO,EAAE,CAAC;aACf;SACF,MAAM;YACL,OAAO;gBAAC,KAAK,EAAE,GAAG;gBAAE,IAAI,EAAE,KAAK;YAAA,CAAC,CAAC;SAClC;IACH,CAAC;IAEO,YAAY,GAAA;QAClB,uEAAuE;QACvE,4EAA4E;QAC5E,eAAe;QACf,IAAI,IAAI,CAAC,YAAY,CAAC,WAAW,IAAI,IAAI,CAAC,YAAY,CAAC,YAAY,IAC/D,CAAC,IAAI,CAAC,kBAAkB,CAAC,KAAK,KAAK,IAAI,CAAC,YAAY,CAAC,WAAW,IAC/D,IAAI,CAAC,kBAAkB,CAAC,MAAM,KAAK,IAAI,CAAC,YAAY,CAAC,YAAY,CAAC,EAAE;YACvE,OAAO,IAAI,CAAC;SACb;QACD,OAAO,KAAK,CAAC;IACf,CAAC;IAED,mDAAmD;IACnD,kBAAkB,CAAC,GAAa,EAAA;QAC9B,WAAO,iPAAI,EAAC,GAAG,EAAE;YACf,MAAM,aAAa,OAAa,kQAAU,MAAC,qPAAI,EAAC,GAAG,EAAE,SAAS,CAAC,EAAE,AAAC,CAAC,CAAC,CAAC,CAAC;YACtE,IAAI,YAAY,CAAC;YACjB,YAAY,GAAG,qQAAK,CAAC,aAAa,CAC9B,aAAa,EAAE,IAAI,CAAC,OAAO,EAAE,IAAI,CAAC,UAAU,EAAE,IAAI,CAAC,QAAQ,EAC3D,UAAU,CAAC,CAAC;YAChB,qCAAqC;YACrC,MAAM,KAAK,GAAG,YAAY,CAAC,KAAK,CAAC;YACjC,WAAO,2PAAO,EAAC,YAAY,EAAE,KAAK,CAAC,KAAK,CAAC,CAAC,CAA6B,CAAC,CAAC;QAC3E,CAAC,CAAC,CAAC;IACL,CAAC;IAED,sEAAsE;IACtE,0BAA0B;IAC1B,KAAK,CAAC,OAAO,GAAA;QACX,OAAO,CAAC,MAAM,IAAI,CAAC,IAAI,EAAE,CAAC,CAAC,KAAK,CAAC;IACnC,CAAC;IAED,mDAAmD;IACnD,IAAI,GAAA;QACF,MAAM,MAAM,GAAG,IAAI,CAAC,MAAM,CAAC,SAAS,EAAE,CAAC;QAEvC,MAAM,CAAC,OAAO,EAAC,KAAK,CAAC,EAAG,AAAD,KAAM,CAAC,IAAI,EAAE,CAAC,CAAC;QAEtC,IAAI;YACF,IAAI,CAAC,kBAAkB,CAAC,SAAS,GAAG,IAAI,CAAC;SAC1C,CAAC,OAAO,KAAK,EAAE;YACd,OAAO,CAAC,GAAG,CAAC,KAAK,CAAC,CAAC;YACnB,IAAI,CAAC,kBAAkB,CAAC,GAAG,GAAG,IAAI,CAAC;SACpC;QACD,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC;IACvB,CAAC;IAED,qDAAqD;IAC5C,OAAO,GAAA;QACd,MAAM,IAAI,KAAK,CAAC,iDAAiD,CAAC,CAAC;IACrE,CAAC;CACF"}},
    {"offset": {"line": 2841, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-data@4.22.0_@tensorflow+tfjs-core@4.22.0_seedrandom@3.0.5/node_modules/@tensorflow/tfjs-data/dist/datasource.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-data/src/datasource.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\n\nimport {ByteChunkIterator} from './iterators/byte_chunk_iterator';\n\n/**\n * Represents a data source readable as a stream of binary data chunks.\n *\n * Because `Dataset`s can be read repeatedly (via `Dataset.iterator()`), this\n * provides a means to repeatedly create streams from the underlying data\n * sources.\n */\nexport abstract class DataSource {\n  /**\n   * Obtain a new stream of binary data chunks.\n   *\n   * Starts the new stream from the beginning of the data source, even if other\n   * streams have been obtained previously.\n   */\n  abstract iterator(): Promise<ByteChunkIterator>;\n\n  // TODO(soergel): consider chainable Dataset construction here\n}\n\n// TODO(soergel): consider convenience factory functions here\n// in combination with chainable source->dataset above, e.g.:\n// tf.data.url(...).asCsvDataset().shuffle().batch()\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;;GAgBG,CAIH;;;;;;GAMG;;;;AACG,MAAgB,UAAU;CAU/B,CAED,6DAA6D;CAC7D,6DAA6D;CAC7D,oDAAoD"}},
    {"offset": {"line": 2876, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-data@4.22.0_@tensorflow+tfjs-core@4.22.0_seedrandom@3.0.5/node_modules/@tensorflow/tfjs-data/dist/iterators/string_iterator.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-data/src/iterators/string_iterator.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\n\nimport {LazyIterator, OneToManyIterator} from './lazy_iterator';\n\nexport abstract class StringIterator extends LazyIterator<string> {\n  /**\n   * Splits a string stream on a given separator.\n   *\n   * It is assumed that the incoming chunk boundaries have no semantic meaning,\n   * so conceptually the incoming stream is treated simply as the concatenation\n   * of its elements.\n   *\n   * The outgoing stream provides chunks corresponding to the results of the\n   * standard string split() operation (even if such a chunk spanned incoming\n   * chunks).  The separators are not included.\n   *\n   * A typical usage is to split a text file (represented as a stream with\n   * arbitrary chunk boundaries) into lines.\n   *\n   * @param upstream A readable stream of strings that can be treated as\n   *   concatenated.\n   * @param separator A character to split on.\n   */\n  split(separator: string): StringIterator {\n    return new SplitIterator(this, separator);\n  }\n}\n\n// ============================================================================\n// The following private classes serve to implement the chainable methods\n// on StringIterator.  Unfortunately they can't be placed in separate files, due\n// to resulting trouble with circular imports.\n// ============================================================================\n\n// We wanted multiple inheritance, e.g.\n//   class SplitIterator extends QueueIterator<string>, StringIterator\n// but the TypeScript mixin approach is a bit hacky, so we take this adapter\n// approach instead.\n\nclass SplitIterator extends StringIterator {\n  private impl: SplitIteratorImpl;\n\n  constructor(protected upstream: LazyIterator<string>, separator: string) {\n    super();\n    this.impl = new SplitIteratorImpl(upstream, separator);\n  }\n\n  summary() {\n    return this.impl.summary();\n  }\n\n  async next() {\n    return this.impl.next();\n  }\n}\n\nclass SplitIteratorImpl extends OneToManyIterator<string> {\n  // A partial string at the end of an upstream chunk\n  carryover = '';\n\n  constructor(\n      protected upstream: LazyIterator<string>, protected separator: string) {\n    super();\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Split('${this.separator}')`;\n  }\n\n  async pump(): Promise<boolean> {\n    const chunkResult = await this.upstream.next();\n    if (chunkResult.done) {\n      if (this.carryover === '') {\n        return false;\n      }\n\n      // Pretend that the pump succeeded in order to emit the small last batch.\n      // The next pump() call will actually fail.\n      this.outputQueue.push(this.carryover);\n      this.carryover = '';\n      return true;\n    }\n    const lines = chunkResult.value.split(this.separator) as string[];\n    // Note the behavior: \" ab \".split(' ') === ['', 'ab', '']\n    // Thus the carryover may be '' if the separator falls on a chunk\n    // boundary; this produces the correct result.\n\n    lines[0] = this.carryover + lines[0];\n    for (const line of lines.slice(0, -1)) {\n      this.outputQueue.push(line);\n    }\n    this.carryover = lines[lines.length - 1];\n\n    return true;\n  }\n}\n"],"names":[],"mappings":";;;;AAAA;;;;;;;;;;;;;;;;GAgBG,CAEH,OAAO,EAAC,YAAY,EAAE,iBAAiB,EAAC,MAAM,iBAAiB,CAAC;;AAE1D,MAAgB,cAAe,SAAQ,qVAAoB;IAC/D;;;;;;;;;;;;;;;;;OAiBG,CACH,KAAK,CAAC,SAAiB,EAAA;QACrB,OAAO,IAAI,aAAa,CAAC,IAAI,EAAE,SAAS,CAAC,CAAC;IAC5C,CAAC;CACF;AAED,+EAA+E;AAC/E,yEAAyE;AACzE,gFAAgF;AAChF,8CAA8C;AAC9C,+EAA+E;AAE/E,uCAAuC;AACvC,sEAAsE;AACtE,4EAA4E;AAC5E,oBAAoB;AAEpB,MAAM,aAAc,SAAQ,cAAc;IAGxC,YAAsB,QAA8B,EAAE,SAAiB,CAAA;QACrE,KAAK,EAAE,CAAC;QADY,IAAA,CAAA,QAAQ,GAAR,QAAQ,CAAsB;QAElD,IAAI,CAAC,IAAI,GAAG,IAAI,iBAAiB,CAAC,QAAQ,EAAE,SAAS,CAAC,CAAC;IACzD,CAAC;IAED,OAAO,GAAA;QACL,OAAO,IAAI,CAAC,IAAI,CAAC,OAAO,EAAE,CAAC;IAC7B,CAAC;IAED,KAAK,CAAC,IAAI,GAAA;QACR,OAAO,IAAI,CAAC,IAAI,CAAC,IAAI,EAAE,CAAC;IAC1B,CAAC;CACF;AAED,MAAM,iBAAkB,SAAQ,0VAAyB;IAIvD,YACc,QAA8B,EAAY,SAAiB,CAAA;QACvE,KAAK,EAAE,CAAC;QADI,IAAA,CAAA,QAAQ,GAAR,QAAQ,CAAsB;QAAY,IAAA,CAAA,SAAS,GAAT,SAAS,CAAQ;QAJzE,mDAAmD;QACnD,IAAA,CAAA,SAAS,GAAG,EAAE,CAAC;IAKf,CAAC;IAED,OAAO,GAAA;QACL,OAAO,GAAG,IAAI,CAAC,QAAQ,CAAC,OAAO,EAAE,CAAA,WAAA,EAAc,IAAI,CAAC,SAAS,CAAA,EAAA,CAAI,CAAC;IACpE,CAAC;IAED,KAAK,CAAC,IAAI,GAAA;QACR,MAAM,WAAW,GAAG,MAAM,IAAI,CAAC,QAAQ,CAAC,IAAI,EAAE,CAAC;QAC/C,IAAI,WAAW,CAAC,IAAI,EAAE;YACpB,IAAI,IAAI,CAAC,SAAS,KAAK,EAAE,EAAE;gBACzB,OAAO,KAAK,CAAC;aACd;YAED,yEAAyE;YACzE,2CAA2C;YAC3C,IAAI,CAAC,WAAW,CAAC,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC;YACtC,IAAI,CAAC,SAAS,GAAG,EAAE,CAAC;YACpB,OAAO,IAAI,CAAC;SACb;QACD,MAAM,KAAK,GAAG,WAAW,CAAC,KAAK,CAAC,KAAK,CAAC,IAAI,CAAC,SAAS,CAAa,CAAC;QAClE,0DAA0D;QAC1D,iEAAiE;QACjE,8CAA8C;QAE9C,KAAK,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,SAAS,GAAG,KAAK,CAAC,CAAC,CAAC,CAAC;QACrC,KAAK,MAAM,IAAI,IAAI,KAAK,CAAC,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAE;YACrC,IAAI,CAAC,WAAW,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;SAC7B;QACD,IAAI,CAAC,SAAS,GAAG,KAAK,CAAC,KAAK,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;QAEzC,OAAO,IAAI,CAAC;IACd,CAAC;CACF"}},
    {"offset": {"line": 2981, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-data@4.22.0_@tensorflow+tfjs-core@4.22.0_seedrandom@3.0.5/node_modules/@tensorflow/tfjs-data/dist/iterators/byte_chunk_iterator.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-data/src/iterators/byte_chunk_iterator.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\n\nimport {env} from '@tensorflow/tfjs-core';\nimport {LazyIterator, OneToManyIterator} from './lazy_iterator';\nimport {StringIterator} from './string_iterator';\n\nexport abstract class ByteChunkIterator extends LazyIterator<Uint8Array> {\n  /**\n   * Decode a stream of UTF8-encoded byte arrays to a stream of strings.\n   *\n   * The byte arrays producetd from the ByteChunkIterator on which this is\n   * called will be interpreted as concatenated.  No assumptions are made about\n   * the boundaries of the incoming chunks, so a multi-byte UTF8 encoding of a\n   * character may span the boundary between chunks.  This naturally happens,\n   * for instance, when reading fixed-size byte arrays from a file.\n   */\n  decodeUTF8(): StringIterator {\n    return new Utf8Iterator(this);\n  }\n}\n\n// ============================================================================\n// The following private classes serve to implement the chainable methods\n// on ByteChunkIterator.  Unfortunately they can't be placed in separate files,\n// due to resulting trouble with circular imports.\n// ============================================================================\n\n// We wanted multiple inheritance, e.g.\n//   class Utf8Iterator extends QueueIterator<string>, StringIterator\n// but the TypeScript mixin approach is a bit hacky, so we take this adapter\n// approach instead.\n\nclass Utf8Iterator extends StringIterator {\n  private impl: Utf8IteratorImpl;\n\n  constructor(protected upstream: LazyIterator<Uint8Array>) {\n    super();\n    this.impl = new Utf8IteratorImpl(upstream);\n  }\n\n  summary() {\n    return this.impl.summary();\n  }\n\n  async next() {\n    return this.impl.next();\n  }\n}\n\n/**\n * Decode a stream of UTF8-encoded byte arrays to a stream of strings.\n *\n * This is tricky because the incoming byte array boundaries may disrupt a\n * multi-byte UTF8 character. Thus any incomplete character data at the end of\n * a chunk must be carried over and prepended to the next chunk before\n * decoding. Luckily with native decoder, TextDecoder in browser and\n * string_decoder in node, byte array boundaries are handled automatically.\n *\n * In the context of an input pipeline for machine learning, UTF8 decoding is\n * needed to parse text files containing training examples or prediction\n * requests (e.g., formatted as CSV or JSON). We cannot use the built-in\n * decoding provided by FileReader.readAsText() because here we are in a\n * streaming context, which FileReader does not support.\n *\n * @param upstream A `LazyIterator` of `Uint8Arrays` containing UTF8-encoded\n *   text, which should be interpreted as concatenated.  No assumptions are\n *   made about the boundaries of the incoming chunks, so a multi-byte UTF8\n *   encoding of a character may span the boundary between chunks.  This\n *   naturally happens, for instance, when reading fixed-size byte arrays from a\n *   file.\n */\nclass Utf8IteratorImpl extends OneToManyIterator<string> {\n  // `decoder` as `any` here to dynamically assign value based on the\n  // environment.\n  // tslint:disable-next-line:no-any\n  decoder: any;\n\n  constructor(protected readonly upstream: LazyIterator<Uint8Array>) {\n    super();\n    if (env().get('IS_BROWSER')) {\n      this.decoder = new TextDecoder('utf-8');\n    } else {\n      // tslint:disable-next-line:no-require-imports\n      const {StringDecoder} = require('string_decoder');\n      this.decoder = new StringDecoder('utf8');\n    }\n  }\n  summary() {\n    return `${this.upstream.summary()} -> Utf8`;\n  }\n\n  async pump(): Promise<boolean> {\n    const chunkResult = await this.upstream.next();\n    let chunk;\n    if (chunkResult.done) {\n      return false;\n    } else {\n      chunk = chunkResult.value;\n    }\n\n    let text: string;\n    if (env().get('IS_BROWSER')) {\n      text = this.decoder.decode(chunk, {stream: true});\n    } else {\n      text = this.decoder.write(Buffer.from(chunk.buffer));\n    }\n    this.outputQueue.push(text);\n    return true;\n  }\n}\n"],"names":[],"mappings":";;;;AAAA;;;;;;;;;;;;;;;;GAgBG;AAEH,OAAO,EAAC,GAAG,EAAC,MAAM,uBAAuB,CAAC;AAC1C,OAAO,EAAC,YAAY,EAAE,iBAAiB,EAAC,MAAM,iBAAiB,CAAC;AAChE,OAAO,EAAC,cAAc,EAAC,MAAM,mBAAmB,CAAC;;;;AAE3C,MAAgB,iBAAkB,SAAQ,qVAAwB;IACtE;;;;;;;;OAQG,CACH,UAAU,GAAA;QACR,OAAO,IAAI,YAAY,CAAC,IAAI,CAAC,CAAC;IAChC,CAAC;CACF;AAED,+EAA+E;AAC/E,yEAAyE;AACzE,+EAA+E;AAC/E,kDAAkD;AAClD,+EAA+E;AAE/E,uCAAuC;AACvC,qEAAqE;AACrE,4EAA4E;AAC5E,oBAAoB;AAEpB,MAAM,YAAa,SAAQ,yVAAc;IAGvC,YAAsB,QAAkC,CAAA;QACtD,KAAK,EAAE,CAAC;QADY,IAAA,CAAA,QAAQ,GAAR,QAAQ,CAA0B;QAEtD,IAAI,CAAC,IAAI,GAAG,IAAI,gBAAgB,CAAC,QAAQ,CAAC,CAAC;IAC7C,CAAC;IAED,OAAO,GAAA;QACL,OAAO,IAAI,CAAC,IAAI,CAAC,OAAO,EAAE,CAAC;IAC7B,CAAC;IAED,KAAK,CAAC,IAAI,GAAA;QACR,OAAO,IAAI,CAAC,IAAI,CAAC,IAAI,EAAE,CAAC;IAC1B,CAAC;CACF;AAED;;;;;;;;;;;;;;;;;;;;;GAqBG,CACH,MAAM,gBAAiB,SAAQ,0VAAyB;IAMtD,YAA+B,QAAkC,CAAA;QAC/D,KAAK,EAAE,CAAC;QADqB,IAAA,CAAA,QAAQ,GAAR,QAAQ,CAA0B;QAE/D,QAAI,oPAAG,EAAE,EAAC,GAAG,CAAC,YAAY,CAAC,EAAE;YAC3B,IAAI,CAAC,OAAO,GAAG,IAAI,WAAW,CAAC,OAAO,CAAC,CAAC;SACzC,MAAM;YACL,8CAA8C;YAC9C,MAAM,EAAC,aAAa,EAAC,GAAG,OAAO,CAAC,gBAAgB,CAAC,CAAC;YAClD,IAAI,CAAC,OAAO,GAAG,IAAI,aAAa,CAAC,MAAM,CAAC,CAAC;SAC1C;IACH,CAAC;IACD,OAAO,GAAA;QACL,OAAO,GAAG,IAAI,CAAC,QAAQ,CAAC,OAAO,EAAE,CAAA,QAAA,CAAU,CAAC;IAC9C,CAAC;IAED,KAAK,CAAC,IAAI,GAAA;QACR,MAAM,WAAW,GAAG,MAAM,IAAI,CAAC,QAAQ,CAAC,IAAI,EAAE,CAAC;QAC/C,IAAI,KAAK,CAAC;QACV,IAAI,WAAW,CAAC,IAAI,EAAE;YACpB,OAAO,KAAK,CAAC;SACd,MAAM;YACL,KAAK,GAAG,WAAW,CAAC,KAAK,CAAC;SAC3B;QAED,IAAI,IAAY,CAAC;QACjB,QAAI,oPAAG,EAAE,EAAC,GAAG,CAAC,YAAY,CAAC,EAAE;YAC3B,IAAI,GAAG,IAAI,CAAC,OAAO,CAAC,MAAM,CAAC,KAAK,EAAE;gBAAC,MAAM,EAAE,IAAI;YAAA,CAAC,CAAC,CAAC;SACnD,MAAM;YACL,IAAI,GAAG,IAAI,CAAC,OAAO,CAAC,KAAK,CAAC,MAAM,CAAC,IAAI,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC,CAAC;SACtD;QACD,IAAI,CAAC,WAAW,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;QAC5B,OAAO,IAAI,CAAC;IACd,CAAC;CACF"}},
    {"offset": {"line": 3103, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-data@4.22.0_@tensorflow+tfjs-core@4.22.0_seedrandom@3.0.5/node_modules/@tensorflow/tfjs-data/dist/iterators/file_chunk_iterator.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-data/src/iterators/file_chunk_iterator.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\n\n// inspired by https://github.com/maxogden/filereader-stream\nimport {env, util} from '@tensorflow/tfjs-core';\nimport {FileElement} from '../types';\nimport {ByteChunkIterator} from './byte_chunk_iterator';\n\nexport interface FileChunkIteratorOptions {\n  /** The byte offset at which to begin reading the File or Blob. Default 0. */\n  offset?: number;\n  /** The number of bytes to read at a time. Default 1MB. */\n  chunkSize?: number;\n}\n\n/**\n * Provide a stream of chunks from a File, Blob, or Uint8Array.\n * @param file The source File, Blob or Uint8Array.\n * @param options Optional settings controlling file reading.\n * @returns a lazy Iterator of Uint8Arrays containing sequential chunks of the\n *   input File, Blob or Uint8Array.\n */\nexport class FileChunkIterator extends ByteChunkIterator {\n  offset: number;\n  chunkSize: number;\n\n  constructor(\n      protected file: FileElement,\n      protected options: FileChunkIteratorOptions = {}) {\n    super();\n    util.assert(\n        (file instanceof Uint8Array) ||\n            (env().get('IS_BROWSER') ?\n                 (file instanceof File || file instanceof Blob) :\n                 false),\n        () => 'FileChunkIterator only supports File, Blob and Uint8Array ' +\n            'right now.');\n    this.offset = options.offset || 0;\n    // default 1MB chunk has tolerable perf on large files\n    this.chunkSize = options.chunkSize || 1024 * 1024;\n  }\n\n  summary() {\n    return `FileChunks ${this.file}`;\n  }\n\n  async next(): Promise<IteratorResult<Uint8Array>> {\n    if (this.offset >= ((this.file instanceof Uint8Array) ?\n                            this.file.byteLength :\n                            this.file.size)) {\n      return {value: null, done: true};\n    }\n    const chunk = new Promise<Uint8Array>((resolve, reject) => {\n      const end = this.offset + this.chunkSize;\n      if (this.file instanceof Uint8Array) {\n        // Note if end > this.uint8Array.byteLength, we just get a small last\n        // chunk.\n        resolve(new Uint8Array(this.file.slice(this.offset, end)));\n      } else {\n        // This branch assumes that this.file type is File or Blob, which\n        // means it is in the browser environment.\n\n        // TODO(soergel): is this a performance issue?\n        const fileReader = new FileReader();\n        fileReader.onload = (event) => {\n          let data: string|ArrayBuffer|Uint8Array = fileReader.result;\n          // Not sure we can trust the return type of\n          // FileReader.readAsArrayBuffer See e.g.\n          // https://github.com/node-file-api/FileReader/issues/2\n          if (data instanceof ArrayBuffer) {\n            data = new Uint8Array(data);\n          }\n          if (!(data instanceof Uint8Array)) {\n            return reject(new TypeError('FileReader returned unknown type.'));\n          }\n          resolve(data);\n        };\n        fileReader.onabort = (event) => {\n          return reject(new Error('Aborted'));\n        };\n        fileReader.onerror = (event) => {\n          return reject(new Error(event.type));\n        };\n        // TODO(soergel): better handle onabort, onerror\n        // Note if end > this.file.size, we just get a small last chunk.\n        const slice = this.file.slice(this.offset, end);\n        // We can't use readAsText here (even if we know the file is text)\n        // because the slice boundary may fall within a multi-byte character.\n        fileReader.readAsArrayBuffer(slice);\n      }\n      this.offset = end;\n    });\n    return {value: (await chunk), done: false};\n  }\n}\n"],"names":[],"mappings":";;;;AAAA;;;;;;;;;;;;;;;;GAgBG,CAEH,4DAA4D;;;AAC5D,OAAO,EAAC,GAAG,EAAE,IAAI,EAAC,MAAM,uBAAuB,CAAC;AAEhD,OAAO,EAAC,iBAAiB,EAAC,MAAM,uBAAuB,CAAC;;;AAgBlD,MAAO,iBAAkB,SAAQ,gWAAiB;IAItD,YACc,IAAiB,EACjB,UAAoC,CAAA,CAAE,CAAA;QAClD,KAAK,EAAE,CAAC;QAFI,IAAA,CAAA,IAAI,GAAJ,IAAI,CAAa;QACjB,IAAA,CAAA,OAAO,GAAP,OAAO,CAA+B;QAElD,8QAAI,CAAC,MAAM,CACP,AAAC,IAAI,YAAY,UAAU,CAAC,GACxB,KAAC,oPAAG,EAAE,EAAC,GAAG,CAAC,YAAY,CAAC,CAAC,CAAC,CACpB,IAAI,YAAY,IAAI,IAAI,IAAI,YAAY,IAAI,CAAC,CAAC,CAAC,AAChD,KAAK,CAAC,EACf,GAAG,CAAG,CAAD,2DAA6D,GAC9D,YAAY,CAAC,CAAC;QACtB,IAAI,CAAC,MAAM,GAAG,OAAO,CAAC,MAAM,IAAI,CAAC,CAAC;QAClC,sDAAsD;QACtD,IAAI,CAAC,SAAS,GAAG,OAAO,CAAC,SAAS,IAAI,IAAI,GAAG,IAAI,CAAC;IACpD,CAAC;IAED,OAAO,GAAA;QACL,OAAO,CAAA,WAAA,EAAc,IAAI,CAAC,IAAI,EAAE,CAAC;IACnC,CAAC;IAED,KAAK,CAAC,IAAI,GAAA;QACR,IAAI,IAAI,CAAC,MAAM,IAAI,CAAC,AAAC,IAAI,CAAC,IAAI,YAAY,UAAU,CAAC,CAAC,CAAC,AAC/B,IAAI,CAAC,IAAI,CAAC,UAAU,CAAC,CAAC,CACtB,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,EAAE;YACvC,OAAO;gBAAC,KAAK,EAAE,IAAI;gBAAE,IAAI,EAAE,IAAI;YAAA,CAAC,CAAC;SAClC;QACD,MAAM,KAAK,GAAG,IAAI,OAAO,CAAa,CAAC,OAAO,EAAE,MAAM,EAAE,EAAE;YACxD,MAAM,GAAG,GAAG,IAAI,CAAC,MAAM,GAAG,IAAI,CAAC,SAAS,CAAC;YACzC,IAAI,IAAI,CAAC,IAAI,YAAY,UAAU,EAAE;gBACnC,qEAAqE;gBACrE,SAAS;gBACT,OAAO,CAAC,IAAI,UAAU,CAAC,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,MAAM,EAAE,GAAG,CAAC,CAAC,CAAC,CAAC;aAC5D,MAAM;gBACL,iEAAiE;gBACjE,0CAA0C;gBAE1C,8CAA8C;gBAC9C,MAAM,UAAU,GAAG,IAAI,UAAU,EAAE,CAAC;gBACpC,UAAU,CAAC,MAAM,GAAG,CAAC,KAAK,EAAE,EAAE;oBAC5B,IAAI,IAAI,GAAkC,UAAU,CAAC,MAAM,CAAC;oBAC5D,2CAA2C;oBAC3C,wCAAwC;oBACxC,uDAAuD;oBACvD,IAAI,IAAI,YAAY,WAAW,EAAE;wBAC/B,IAAI,GAAG,IAAI,UAAU,CAAC,IAAI,CAAC,CAAC;qBAC7B;oBACD,IAAI,CAAC,CAAC,IAAI,YAAY,UAAU,CAAC,EAAE;wBACjC,OAAO,MAAM,CAAC,IAAI,SAAS,CAAC,mCAAmC,CAAC,CAAC,CAAC;qBACnE;oBACD,OAAO,CAAC,IAAI,CAAC,CAAC;gBAChB,CAAC,CAAC;gBACF,UAAU,CAAC,OAAO,GAAG,CAAC,KAAK,EAAE,EAAE;oBAC7B,OAAO,MAAM,CAAC,IAAI,KAAK,CAAC,SAAS,CAAC,CAAC,CAAC;gBACtC,CAAC,CAAC;gBACF,UAAU,CAAC,OAAO,GAAG,CAAC,KAAK,EAAE,EAAE;oBAC7B,OAAO,MAAM,CAAC,IAAI,KAAK,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC,CAAC;gBACvC,CAAC,CAAC;gBACF,gDAAgD;gBAChD,gEAAgE;gBAChE,MAAM,KAAK,GAAG,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,MAAM,EAAE,GAAG,CAAC,CAAC;gBAChD,kEAAkE;gBAClE,qEAAqE;gBACrE,UAAU,CAAC,iBAAiB,CAAC,KAAK,CAAC,CAAC;aACrC;YACD,IAAI,CAAC,MAAM,GAAG,GAAG,CAAC;QACpB,CAAC,CAAC,CAAC;QACH,OAAO;YAAC,KAAK,EAAE,AAAC,MAAM,KAAK,CAAC;YAAE,IAAI,EAAE,KAAK;QAAA,CAAC,CAAC;IAC7C,CAAC;CACF"}},
    {"offset": {"line": 3199, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-data@4.22.0_@tensorflow+tfjs-core@4.22.0_seedrandom@3.0.5/node_modules/@tensorflow/tfjs-data/dist/iterators/url_chunk_iterator.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-data/src/iterators/url_chunk_iterator.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\n\nimport {util} from '@tensorflow/tfjs-core';\nimport {FileChunkIterator, FileChunkIteratorOptions} from './file_chunk_iterator';\n\n/**\n * Provide a stream of chunks from a URL.\n *\n * Note this class first downloads the entire file into memory before providing\n * the first element from the stream.  This is because the Fetch API does not\n * yet reliably provide a reader stream for the response body.\n */\nexport async function urlChunkIterator(\n    url: RequestInfo, options: FileChunkIteratorOptions = {},\n    fetchFunc?: Function) {\n  let urlString;\n  let requestInit;\n  if ((typeof url) === 'string') {\n    urlString = url as string;\n  } else {\n    urlString = (url as Request).url;\n    requestInit = getRequestInitFromRequest(url as Request);\n  }\n  const response = await (fetchFunc || util.fetch)(urlString, requestInit);\n  if (response.ok) {\n    const uint8Array = new Uint8Array(await response.arrayBuffer());\n    return new FileChunkIterator(uint8Array, options);\n  } else {\n    throw new Error(response.statusText);\n  }\n}\n\n// Generate RequestInit from Request to match tf.util.fetch signature.\nconst getRequestInitFromRequest = (request: Request) => {\n  const init = {\n    method: request.method,\n    headers: request.headers,\n    body: request.body,\n    mode: request.mode,\n    credentials: request.credentials,\n    cache: request.cache,\n    redirect: request.redirect,\n    referrer: request.referrer,\n    integrity: request.integrity,\n  };\n  return init;\n};\n"],"names":[],"mappings":";;;;AAAA;;;;;;;;;;;;;;;;GAgBG;AAEH,OAAO,EAAC,IAAI,EAAC,MAAM,uBAAuB,CAAC;AAC3C,OAAO,EAAC,iBAAiB,EAA2B,MAAM,uBAAuB,CAAC;;;AAS3E,KAAK,UAAU,gBAAgB,CAClC,GAAgB,EAAE,UAAoC,CAAA,CAAE,EACxD,SAAoB;IACtB,IAAI,SAAS,CAAC;IACd,IAAI,WAAW,CAAC;IAChB,IAAI,AAAC,OAAO,GAAG,CAAC,IAAK,QAAQ,EAAE;QAC7B,SAAS,GAAG,GAAa,CAAC;KAC3B,MAAM;QACL,SAAS,GAAI,GAAe,CAAC,GAAG,CAAC;QACjC,WAAW,GAAG,yBAAyB,CAAC,GAAc,CAAC,CAAC;KACzD;IACD,MAAM,QAAQ,GAAG,MAAM,CAAC,SAAS,IAAI,8QAAI,CAAC,KAAK,CAAC,CAAC,SAAS,EAAE,WAAW,CAAC,CAAC;IACzE,IAAI,QAAQ,CAAC,EAAE,EAAE;QACf,MAAM,UAAU,GAAG,IAAI,UAAU,CAAC,MAAM,QAAQ,CAAC,WAAW,EAAE,CAAC,CAAC;QAChE,OAAO,IAAI,gWAAiB,CAAC,UAAU,EAAE,OAAO,CAAC,CAAC;KACnD,MAAM;QACL,MAAM,IAAI,KAAK,CAAC,QAAQ,CAAC,UAAU,CAAC,CAAC;KACtC;AACH,CAAC;AAED,sEAAsE;AACtE,MAAM,yBAAyB,GAAG,CAAC,OAAgB,EAAE,EAAE;IACrD,MAAM,IAAI,GAAG;QACX,MAAM,EAAE,OAAO,CAAC,MAAM;QACtB,OAAO,EAAE,OAAO,CAAC,OAAO;QACxB,IAAI,EAAE,OAAO,CAAC,IAAI;QAClB,IAAI,EAAE,OAAO,CAAC,IAAI;QAClB,WAAW,EAAE,OAAO,CAAC,WAAW;QAChC,KAAK,EAAE,OAAO,CAAC,KAAK;QACpB,QAAQ,EAAE,OAAO,CAAC,QAAQ;QAC1B,QAAQ,EAAE,OAAO,CAAC,QAAQ;QAC1B,SAAS,EAAE,OAAO,CAAC,SAAS;KAC7B,CAAC;IACF,OAAO,IAAI,CAAC;AACd,CAAC,CAAC"}},
    {"offset": {"line": 3260, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-data@4.22.0_@tensorflow+tfjs-core@4.22.0_seedrandom@3.0.5/node_modules/@tensorflow/tfjs-data/dist/util/source_util.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-data/src/util/source_util.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\n\n// Skip tslint any type check cause this method is aiming to check type of\n// input.\n// tslint:disable-next-line:no-any\nexport function isLocalPath(source: any): boolean {\n  return (typeof source === 'string') && source.slice(0, 7) === 'file://';\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;;GAgBG,CAEH,0EAA0E;AAC1E,SAAS;AACT,kCAAkC;;;;;AAC5B,SAAU,WAAW,CAAC,MAAW;IACrC,OAAO,AAAC,OAAO,MAAM,KAAK,QAAQ,CAAC,GAAI,MAAM,CAAC,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,KAAK,SAAS,CAAC;AAC1E,CAAC"}},
    {"offset": {"line": 3290, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-data@4.22.0_@tensorflow+tfjs-core@4.22.0_seedrandom@3.0.5/node_modules/@tensorflow/tfjs-data/dist/sources/file_data_source.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-data/src/sources/file_data_source.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\n\nimport {env} from '@tensorflow/tfjs-core';\nimport {DataSource} from '../datasource';\nimport {ByteChunkIterator} from '../iterators/byte_chunk_iterator';\nimport {FileChunkIterator, FileChunkIteratorOptions} from '../iterators/file_chunk_iterator';\nimport {FileElement} from '../types';\nimport {isLocalPath} from '../util/source_util';\n\n/**\n * Represents a file, blob, or Uint8Array readable as a stream of binary data\n * chunks.\n */\nexport class FileDataSource extends DataSource {\n  /**\n   * Create a `FileDataSource`.\n   *\n   * @param input Local file path, or `File`/`Blob`/`Uint8Array` object to\n   *     read. Local file only works in node environment.\n   * @param options Options passed to the underlying `FileChunkIterator`s,\n   *   such as {chunksize: 1024}.\n   */\n  constructor(\n      protected input: FileElement|string,\n      protected readonly options: FileChunkIteratorOptions = {}) {\n    super();\n  }\n\n  async iterator(): Promise<ByteChunkIterator> {\n    if (isLocalPath(this.input) && env().get('IS_NODE')) {\n      // tslint:disable-next-line:no-require-imports\n      const fs = require('fs');\n      this.input = fs.readFileSync((this.input as string).slice(7));\n    }\n    // TODO(kangyizhang): Add LocalFileChunkIterator to split local streaming\n    // with file in browser.\n    return new FileChunkIterator(this.input as FileElement, this.options);\n  }\n}\n"],"names":[],"mappings":";;;;AAAA;;;;;;;;;;;;;;;;GAgBG;AAEH,OAAO,EAAC,GAAG,EAAC,MAAM,uBAAuB,CAAC;AAC1C,OAAO,EAAC,UAAU,EAAC,MAAM,eAAe,CAAC;AAEzC,OAAO,EAAC,iBAAiB,EAA2B,MAAM,kCAAkC,CAAC;AAE7F,OAAO,EAAC,WAAW,EAAC,MAAM,qBAAqB,CAAC;;;;;AAM1C,MAAO,cAAe,SAAQ,mUAAU;IAC5C;;;;;;;OAOG,CACH,YACc,KAAyB,EAChB,UAAoC,CAAA,CAAE,CAAA;QAC3D,KAAK,EAAE,CAAC;QAFI,IAAA,CAAA,KAAK,GAAL,KAAK,CAAoB;QAChB,IAAA,CAAA,OAAO,GAAP,OAAO,CAA+B;IAE7D,CAAC;IAED,KAAK,CAAC,QAAQ,GAAA;QACZ,QAAI,6UAAW,EAAC,IAAI,CAAC,KAAK,CAAC,QAAI,oPAAG,EAAE,EAAC,GAAG,CAAC,SAAS,CAAC,EAAE;YACnD,8CAA8C;YAC9C,MAAM,EAAE,GAAG,OAAO,CAAC,IAAI,CAAC,CAAC;YACzB,IAAI,CAAC,KAAK,GAAG,EAAE,CAAC,YAAY,CAAE,IAAI,CAAC,KAAgB,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;SAC/D;QACD,yEAAyE;QACzE,wBAAwB;QACxB,OAAO,IAAI,gWAAiB,CAAC,IAAI,CAAC,KAAoB,EAAE,IAAI,CAAC,OAAO,CAAC,CAAC;IACxE,CAAC;CACF"}},
    {"offset": {"line": 3347, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-data@4.22.0_@tensorflow+tfjs-core@4.22.0_seedrandom@3.0.5/node_modules/@tensorflow/tfjs-data/dist/sources/url_data_source.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-data/src/sources/url_data_source.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\n\nimport {DataSource} from '../datasource';\nimport {ByteChunkIterator} from '../iterators/byte_chunk_iterator';\nimport {FileChunkIteratorOptions} from '../iterators/file_chunk_iterator';\nimport {urlChunkIterator} from '../iterators/url_chunk_iterator';\nimport {isLocalPath} from '../util/source_util';\nimport {FileDataSource} from './file_data_source';\n\n/*\n * Represents a URL readable as a stream of binary data chunks.\n */\nexport class URLDataSource extends DataSource {\n  /**\n   * Create a `URLDataSource`.\n   *\n   * @param url A source URL string, or a `Request` object.\n   * @param options Options passed to the underlying `FileChunkIterator`s,\n   *   such as {chunksize: 1024}.\n   */\n  constructor(\n      protected readonly url: RequestInfo,\n      protected readonly fileOptions: FileChunkIteratorOptions = {}) {\n    super();\n  }\n\n  // TODO(soergel): provide appropriate caching options.  Currently this\n  // will download the URL anew for each call to iterator().  Since we have\n  // to treat the downloaded file as a blob/buffer anyway, we may as well retain\n  // it-- but that raises GC issues.  Also we may want a persistent disk cache.\n  async iterator(): Promise<ByteChunkIterator> {\n    if (isLocalPath(this.url)) {\n      return (new FileDataSource(this.url as string, this.fileOptions))\n          .iterator();\n    } else {\n      return urlChunkIterator(this.url, this.fileOptions);\n    }\n  }\n}\n"],"names":[],"mappings":";;;;AAAA;;;;;;;;;;;;;;;;GAgBG,CAEH,OAAO,EAAC,UAAU,EAAC,MAAM,eAAe,CAAC;AAGzC,OAAO,EAAC,gBAAgB,EAAC,MAAM,iCAAiC,CAAC;AACjE,OAAO,EAAC,WAAW,EAAC,MAAM,qBAAqB,CAAC;AAChD,OAAO,EAAC,cAAc,EAAC,MAAM,oBAAoB,CAAC;;;;;AAK5C,MAAO,aAAc,SAAQ,mUAAU;IAC3C;;;;;;OAMG,CACH,YACuB,GAAgB,EAChB,cAAwC,CAAA,CAAE,CAAA;QAC/D,KAAK,EAAE,CAAC;QAFa,IAAA,CAAA,GAAG,GAAH,GAAG,CAAa;QAChB,IAAA,CAAA,WAAW,GAAX,WAAW,CAA+B;IAEjE,CAAC;IAED,sEAAsE;IACtE,yEAAyE;IACzE,8EAA8E;IAC9E,6EAA6E;IAC7E,KAAK,CAAC,QAAQ,GAAA;QACZ,QAAI,6UAAW,EAAC,IAAI,CAAC,GAAG,CAAC,EAAE;YACzB,OAAO,AAAC,IAAI,wVAAc,CAAC,IAAI,CAAC,GAAa,EAAE,IAAI,CAAC,WAAW,CAAC,CAAC,AAC5D,QAAQ,EAAE,CAAC;SACjB,MAAM;YACL,WAAO,8VAAgB,EAAC,IAAI,CAAC,GAAG,EAAE,IAAI,CAAC,WAAW,CAAC,CAAC;SACrD;IACH,CAAC;CACF"}},
    {"offset": {"line": 3403, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-data@4.22.0_@tensorflow+tfjs-core@4.22.0_seedrandom@3.0.5/node_modules/@tensorflow/tfjs-data/dist/readers.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-data/src/readers.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\n\nimport {TensorContainer} from '@tensorflow/tfjs-core';\nimport {Dataset, datasetFromIteratorFn} from './dataset';\nimport {CSVDataset} from './datasets/csv_dataset';\nimport {iteratorFromFunction} from './iterators/lazy_iterator';\nimport {MicrophoneIterator} from './iterators/microphone_iterator';\nimport {WebcamIterator} from './iterators/webcam_iterator';\nimport {URLDataSource} from './sources/url_data_source';\nimport {CSVConfig, MicrophoneConfig, WebcamConfig} from './types';\n\n/**\n * Create a `CSVDataset` by reading and decoding CSV file(s) from provided URL\n * or local path if it's in Node environment.\n *\n * Note: If isLabel in columnConfigs is `true` for at least one column, the\n * element in returned `CSVDataset` will be an object of\n * `{xs:features, ys:labels}`: xs is a dict of features key/value pairs, ys\n * is a dict of labels key/value pairs. If no column is marked as label,\n * returns a dict of features only.\n *\n * ```js\n * const csvUrl =\n * 'https://storage.googleapis.com/tfjs-examples/multivariate-linear-regression/data/boston-housing-train.csv';\n *\n * async function run() {\n *   // We want to predict the column \"medv\", which represents a median value of\n *   // a home (in $1000s), so we mark it as a label.\n *   const csvDataset = tf.data.csv(\n *     csvUrl, {\n *       columnConfigs: {\n *         medv: {\n *           isLabel: true\n *         }\n *       }\n *     });\n *\n *   // Number of features is the number of column names minus one for the label\n *   // column.\n *   const numOfFeatures = (await csvDataset.columnNames()).length - 1;\n *\n *   // Prepare the Dataset for training.\n *   const flattenedDataset =\n *     csvDataset\n *     .map(({xs, ys}) =>\n *       {\n *         // Convert xs(features) and ys(labels) from object form (keyed by\n *         // column name) to array form.\n *         return {xs:Object.values(xs), ys:Object.values(ys)};\n *       })\n *     .batch(10);\n *\n *   // Define the model.\n *   const model = tf.sequential();\n *   model.add(tf.layers.dense({\n *     inputShape: [numOfFeatures],\n *     units: 1\n *   }));\n *   model.compile({\n *     optimizer: tf.train.sgd(0.000001),\n *     loss: 'meanSquaredError'\n *   });\n *\n *   // Fit the model using the prepared Dataset\n *   return model.fitDataset(flattenedDataset, {\n *     epochs: 10,\n *     callbacks: {\n *       onEpochEnd: async (epoch, logs) => {\n *         console.log(epoch + ':' + logs.loss);\n *       }\n *     }\n *   });\n * }\n *\n * await run();\n * ```\n *\n * @param source URL or local path to get CSV file. If it's a local path, it\n * must have prefix `file://` and it only works in node environment.\n * @param csvConfig (Optional) A CSVConfig object that contains configurations\n *     of reading and decoding from CSV file(s).\n *\n * @doc {\n *   heading: 'Data',\n *   subheading: 'Creation',\n *   namespace: 'data',\n *   configParamIndices: [1]\n *  }\n */\nexport function csv(\n    source: RequestInfo, csvConfig: CSVConfig = {}): CSVDataset {\n  return new CSVDataset(new URLDataSource(source), csvConfig);\n}\n\n/**\n * Create a `Dataset` that produces each element by calling a provided function.\n *\n * Note that repeated iterations over this `Dataset` may produce different\n * results, because the function will be called anew for each element of each\n * iteration.\n *\n * Also, beware that the sequence of calls to this function may be out of order\n * in time with respect to the logical order of the Dataset. This is due to the\n * asynchronous lazy nature of stream processing, and depends on downstream\n * transformations (e.g. .shuffle()). If the provided function is pure, this is\n * no problem, but if it is a closure over a mutable state (e.g., a traversal\n * pointer), then the order of the produced elements may be scrambled.\n *\n * ```js\n * let i = -1;\n * const func = () =>\n *    ++i < 5 ? {value: i, done: false} : {value: null, done: true};\n * const ds = tf.data.func(func);\n * await ds.forEachAsync(e => console.log(e));\n * ```\n *\n * @param f A function that produces one data element on each call.\n */\nexport function func<T extends TensorContainer>(\n    f: () => IteratorResult<T>| Promise<IteratorResult<T>>): Dataset<T> {\n  const iter = iteratorFromFunction(f);\n  return datasetFromIteratorFn(async () => iter);\n}\n\n/**\n * Create a `Dataset` that produces each element from provided JavaScript\n * generator, which is a function that returns a (potentially async) iterator.\n *\n * For more information on iterators and generators, see\n * https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Iterators_and_Generators .\n * For the iterator protocol, see\n * https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Iteration_protocols .\n *\n * Example of creating a dataset from an iterator factory:\n * ```js\n * function makeIterator() {\n *   const numElements = 10;\n *   let index = 0;\n *\n *   const iterator = {\n *     next: () => {\n *       let result;\n *       if (index < numElements) {\n *         result = {value: index, done: false};\n *         index++;\n *         return result;\n *       }\n *       return {value: index, done: true};\n *     }\n *   };\n *   return iterator;\n * }\n * const ds = tf.data.generator(makeIterator);\n * await ds.forEachAsync(e => console.log(e));\n * ```\n *\n * Example of creating a dataset from a generator:\n * ```js\n * function* dataGenerator() {\n *   const numElements = 10;\n *   let index = 0;\n *   while (index < numElements) {\n *     const x = index;\n *     index++;\n *     yield x;\n *   }\n * }\n *\n * const ds = tf.data.generator(dataGenerator);\n * await ds.forEachAsync(e => console.log(e));\n * ```\n *\n * @param generator A JavaScript function that returns\n *     a (potentially async) JavaScript iterator.\n *\n * @doc {\n *   heading: 'Data',\n *   subheading: 'Creation',\n *   namespace: 'data',\n *   configParamIndices: [1]\n *  }\n */\nexport function generator<T extends TensorContainer>(\n  generator: () => Iterator<T> | Promise<Iterator<T>> | AsyncIterator<T>,\n): Dataset<T> {\n  return datasetFromIteratorFn(async () => {\n    const gen = await generator();\n    return iteratorFromFunction(() => gen.next());\n  });\n}\n\n/**\n * Create an iterator that generates `Tensor`s from webcam video stream. This\n * API only works in Browser environment when the device has webcam.\n *\n * Note: this code snippet only works when the device has a webcam. It will\n * request permission to open the webcam when running.\n * ```js\n * const videoElement = document.createElement('video');\n * videoElement.width = 100;\n * videoElement.height = 100;\n * const cam = await tf.data.webcam(videoElement);\n * const img = await cam.capture();\n * img.print();\n * cam.stop();\n * ```\n *\n * @param webcamVideoElement A `HTMLVideoElement` used to play video from\n *     webcam. If this element is not provided, a hidden `HTMLVideoElement` will\n *     be created. In that case, `resizeWidth` and `resizeHeight` must be\n *     provided to set the generated tensor shape.\n * @param webcamConfig A `WebcamConfig` object that contains configurations of\n *     reading and manipulating data from webcam video stream.\n *\n * @doc {\n *   heading: 'Data',\n *   subheading: 'Creation',\n *   namespace: 'data',\n *   ignoreCI: true\n *  }\n */\nexport async function webcam(\n    webcamVideoElement?: HTMLVideoElement,\n    webcamConfig?: WebcamConfig): Promise<WebcamIterator> {\n  return WebcamIterator.create(webcamVideoElement, webcamConfig);\n}\n\n/**\n * Create an iterator that generates frequency-domain spectrogram `Tensor`s from\n * microphone audio stream with browser's native FFT. This API only works in\n * browser environment when the device has microphone.\n *\n * Note: this code snippet only works when the device has a microphone. It will\n * request permission to open the microphone when running.\n * ```js\n * const mic = await tf.data.microphone({\n *   fftSize: 1024,\n *   columnTruncateLength: 232,\n *   numFramesPerSpectrogram: 43,\n *   sampleRateHz:44100,\n *   includeSpectrogram: true,\n *   includeWaveform: true\n * });\n * const audioData = await mic.capture();\n * const spectrogramTensor = audioData.spectrogram;\n * spectrogramTensor.print();\n * const waveformTensor = audioData.waveform;\n * waveformTensor.print();\n * mic.stop();\n * ```\n *\n * @param microphoneConfig A `MicrophoneConfig` object that contains\n *     configurations of reading audio data from microphone.\n *\n * @doc {\n *   heading: 'Data',\n *   subheading: 'Creation',\n *   namespace: 'data',\n *   ignoreCI: true\n *  }\n */\nexport async function microphone(microphoneConfig?: MicrophoneConfig):\n    Promise<MicrophoneIterator> {\n  return MicrophoneIterator.create(microphoneConfig);\n}\n"],"names":[],"mappings":";;;;;;;;;;;;AAAA;;;;;;;;;;;;;;;;GAgBG,CAGH,OAAO,EAAU,qBAAqB,EAAC,MAAM,WAAW,CAAC;AACzD,OAAO,EAAC,UAAU,EAAC,MAAM,wBAAwB,CAAC;AAClD,OAAO,EAAC,oBAAoB,EAAC,MAAM,2BAA2B,CAAC;AAC/D,OAAO,EAAC,kBAAkB,EAAC,MAAM,iCAAiC,CAAC;AACnE,OAAO,EAAC,cAAc,EAAC,MAAM,6BAA6B,CAAC;AAC3D,OAAO,EAAC,aAAa,EAAC,MAAM,2BAA2B,CAAC;;;;;;;AAiFlD,SAAU,GAAG,CACf,MAAmB,EAAE,YAAuB,CAAA,CAAE;IAChD,OAAO,IAAI,gVAAU,CAAC,IAAI,sVAAa,CAAC,MAAM,CAAC,EAAE,SAAS,CAAC,CAAC;AAC9D,CAAC;AA0BK,SAAU,IAAI,CAChB,CAAsD;IACxD,MAAM,IAAI,OAAG,6VAAoB,EAAC,CAAC,CAAC,CAAC;IACrC,WAAO,2UAAqB,EAAC,KAAK,IAAI,CAAG,CAAD,GAAK,CAAC,CAAC;AACjD,CAAC;AA4DK,SAAU,SAAS,CACvB,SAAsE;IAEtE,WAAO,2UAAqB,EAAC,KAAK,IAAI,EAAE;QACtC,MAAM,GAAG,GAAG,MAAM,SAAS,EAAE,CAAC;QAC9B,WAAO,6VAAoB,EAAC,GAAG,CAAG,CAAD,EAAI,CAAC,IAAI,EAAE,CAAC,CAAC;IAChD,CAAC,CAAC,CAAC;AACL,CAAC;AAgCM,KAAK,UAAU,MAAM,CACxB,kBAAqC,EACrC,YAA2B;IAC7B,OAAO,yVAAc,CAAC,MAAM,CAAC,kBAAkB,EAAE,YAAY,CAAC,CAAC;AACjE,CAAC;AAoCM,KAAK,UAAU,UAAU,CAAC,gBAAmC;IAElE,OAAO,iWAAkB,CAAC,MAAM,CAAC,gBAAgB,CAAC,CAAC;AACrD,CAAC"}},
    {"offset": {"line": 3466, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-data@4.22.0_@tensorflow+tfjs-core@4.22.0_seedrandom@3.0.5/node_modules/@tensorflow/tfjs-data/dist/version.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-data/src/version.ts"],"sourcesContent":["/** @license See the LICENSE file. */\n\n// This code is auto-generated, do not modify this file!\nconst version = '4.22.0';\nexport {version};\n"],"names":[],"mappings":";;;;AAAA,mCAAA,EAAqC,CAErC,wDAAwD;AACxD,MAAM,OAAO,GAAG,QAAQ,CAAC"}},
    {"offset": {"line": 3478, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-data@4.22.0_@tensorflow+tfjs-core@4.22.0_seedrandom@3.0.5/node_modules/@tensorflow/tfjs-data/dist/index.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-data/src/index.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport {array, Dataset, zip} from './dataset';\nexport {CSVDataset} from './datasets/csv_dataset';\nexport {TextLineDataset} from './datasets/text_line_dataset';\nexport {csv, func, generator, microphone, webcam} from './readers';\nexport {FileDataSource} from './sources/file_data_source';\nexport {URLDataSource} from './sources/url_data_source';\nexport {ColumnConfig, MicrophoneConfig, WebcamConfig} from './types';\nexport {version as version_data} from './version';\n"],"names":[],"mappings":";AAAA;;;;;;;;;;;;;;;GAeG,CAEH,OAAO,EAAC,KAAK,EAAE,OAAO,EAAE,GAAG,EAAC,MAAM,WAAW,CAAC;AAC9C,OAAO,EAAC,UAAU,EAAC,MAAM,wBAAwB,CAAC;AAClD,OAAO,EAAC,eAAe,EAAC,MAAM,8BAA8B,CAAC;AAC7D,OAAO,EAAC,GAAG,EAAE,IAAI,EAAE,SAAS,EAAE,UAAU,EAAE,MAAM,EAAC,MAAM,WAAW,CAAC;AACnE,OAAO,EAAC,cAAc,EAAC,MAAM,4BAA4B,CAAC;AAC1D,OAAO,EAAC,aAAa,EAAC,MAAM,2BAA2B,CAAC;AAExD,OAAO,EAAC,OAAO,IAAI,YAAY,EAAC,MAAM,WAAW,CAAC"}}]
}