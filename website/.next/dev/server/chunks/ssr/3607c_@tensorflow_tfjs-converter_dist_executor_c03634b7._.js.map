{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 4, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-converter@4.22.0_@tensorflow+tfjs-core@4.22.0/node_modules/@tensorflow/tfjs-converter/dist/executor/tensor_utils.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-converter/src/executor/tensor_utils.ts"],"sourcesContent":["\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n/**\n * This differs from util.assertShapesMatch in that it allows values of\n * negative one, an undefined size of a dimensinon, in a shape to match\n * anything.\n */\n\nimport {Tensor, util} from '@tensorflow/tfjs-core';\n\n/**\n * Used by TensorList and TensorArray to verify if elementShape matches, support\n * negative value as the dim shape.\n * @param shapeA\n * @param shapeB\n * @param errorMessagePrefix\n */\nexport function assertShapesMatchAllowUndefinedSize(\n    shapeA: number|number[], shapeB: number|number[],\n    errorMessagePrefix = ''): void {\n  // constant shape means unknown rank\n  if (typeof shapeA === 'number' || typeof shapeB === 'number') {\n    return;\n  }\n  util.assert(\n      shapeA.length === shapeB.length,\n      () => errorMessagePrefix + ` Shapes ${shapeA} and ${shapeB} must match`);\n  for (let i = 0; i < shapeA.length; i++) {\n    const dim0 = shapeA[i];\n    const dim1 = shapeB[i];\n    util.assert(\n        dim0 < 0 || dim1 < 0 || dim0 === dim1,\n        () =>\n            errorMessagePrefix + ` Shapes ${shapeA} and ${shapeB} must match`);\n  }\n}\n\nexport function fullDefinedShape(elementShape: number|number[]): boolean {\n  if (typeof elementShape === 'number' || elementShape.some(dim => dim < 0)) {\n    return false;\n  }\n  return true;\n}\n/**\n * Generate the output element shape from the list elementShape, list tensors\n * and input param.\n * @param listElementShape\n * @param tensors\n * @param elementShape\n */\nexport function inferElementShape(\n    listElementShape: number|number[], tensors: Tensor[],\n    elementShape: number|number[]): number[] {\n  let partialShape = mergeElementShape(listElementShape, elementShape);\n  const notfullDefinedShape = !fullDefinedShape(partialShape);\n  if (notfullDefinedShape && tensors.length === 0) {\n    throw new Error(\n        `Tried to calculate elements of an empty list` +\n        ` with non-fully-defined elementShape: ${partialShape}`);\n  }\n  if (notfullDefinedShape) {\n    tensors.forEach(tensor => {\n      partialShape = mergeElementShape(tensor.shape, partialShape);\n    });\n  }\n  if (!fullDefinedShape(partialShape)) {\n    throw new Error(`Non-fully-defined elementShape: ${partialShape}`);\n  }\n  return partialShape as number[];\n}\n\nexport function mergeElementShape(\n    elementShapeA: number|number[], elementShapeB: number|number[]): number|\n    number[] {\n  if (typeof elementShapeA === 'number') {\n    return elementShapeB;\n  }\n  if (typeof elementShapeB === 'number') {\n    return elementShapeA;\n  }\n\n  if (elementShapeA.length !== elementShapeB.length) {\n    throw new Error(`Incompatible ranks during merge: ${elementShapeA} vs. ${\n        elementShapeB}`);\n  }\n\n  const result: number[] = [];\n  for (let i = 0; i < elementShapeA.length; ++i) {\n    const dim0 = elementShapeA[i];\n    const dim1 = elementShapeB[i];\n    if (dim0 >= 0 && dim1 >= 0 && dim0 !== dim1) {\n      throw new Error(`Incompatible shape during merge: ${elementShapeA} vs. ${\n          elementShapeB}`);\n    }\n    result[i] = dim0 >= 0 ? dim0 : dim1;\n  }\n  return result;\n}\n"],"names":[],"mappings":";;;;;;;;;;AACA;;;;;;;;;;;;;;;GAeG,CACH;;;;GAIG;AAEH,OAAO,EAAS,IAAI,EAAC,MAAM,uBAAuB,CAAC;;AAS7C,SAAU,mCAAmC,CAC/C,MAAuB,EAAE,MAAuB,EAChD,kBAAkB,GAAG,EAAE;IACzB,oCAAoC;IACpC,IAAI,OAAO,MAAM,KAAK,QAAQ,IAAI,OAAO,MAAM,KAAK,QAAQ,EAAE;QAC5D,OAAO;KACR;IACD,8QAAI,CAAC,MAAM,CACP,MAAM,CAAC,MAAM,KAAK,MAAM,CAAC,MAAM,EAC/B,GAAG,CAAG,CAAD,iBAAmB,GAAG,CAAA,QAAA,EAAW,MAAM,CAAA,KAAA,EAAQ,MAAM,CAAA,WAAA,CAAa,CAAC,CAAC;IAC7E,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,CAAC,EAAE,CAAE;QACtC,MAAM,IAAI,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;QACvB,MAAM,IAAI,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;QACvB,8QAAI,CAAC,MAAM,CACP,IAAI,GAAG,CAAC,IAAI,IAAI,GAAG,CAAC,IAAI,IAAI,KAAK,IAAI,EACrC,GAAG,CACC,CADC,iBACiB,GAAG,CAAA,QAAA,EAAW,MAAM,CAAA,KAAA,EAAQ,MAAM,CAAA,WAAA,CAAa,CAAC,CAAC;KAC5E;AACH,CAAC;AAEK,SAAU,gBAAgB,CAAC,YAA6B;IAC5D,IAAI,OAAO,YAAY,KAAK,QAAQ,IAAI,YAAY,CAAC,IAAI,EAAC,GAAG,CAAC,EAAE,AAAC,GAAG,GAAG,CAAC,CAAC,EAAE;QACzE,OAAO,KAAK,CAAC;KACd;IACD,OAAO,IAAI,CAAC;AACd,CAAC;AAQK,SAAU,iBAAiB,CAC7B,gBAAiC,EAAE,OAAiB,EACpD,YAA6B;IAC/B,IAAI,YAAY,GAAG,iBAAiB,CAAC,gBAAgB,EAAE,YAAY,CAAC,CAAC;IACrE,MAAM,mBAAmB,GAAG,CAAC,gBAAgB,CAAC,YAAY,CAAC,CAAC;IAC5D,IAAI,mBAAmB,IAAI,OAAO,CAAC,MAAM,KAAK,CAAC,EAAE;QAC/C,MAAM,IAAI,KAAK,CACX,CAAA,4CAAA,CAA8C,GAC9C,CAAA,sCAAA,EAAyC,YAAY,EAAE,CAAC,CAAC;KAC9D;IACD,IAAI,mBAAmB,EAAE;QACvB,OAAO,CAAC,OAAO,EAAC,MAAM,CAAC,EAAE;YACvB,YAAY,GAAG,iBAAiB,CAAC,MAAM,CAAC,KAAK,EAAE,YAAY,CAAC,CAAC;QAC/D,CAAC,CAAC,CAAC;KACJ;IACD,IAAI,CAAC,gBAAgB,CAAC,YAAY,CAAC,EAAE;QACnC,MAAM,IAAI,KAAK,CAAC,CAAA,gCAAA,EAAmC,YAAY,EAAE,CAAC,CAAC;KACpE;IACD,OAAO,YAAwB,CAAC;AAClC,CAAC;AAEK,SAAU,iBAAiB,CAC7B,aAA8B,EAAE,aAA8B;IAEhE,IAAI,OAAO,aAAa,KAAK,QAAQ,EAAE;QACrC,OAAO,aAAa,CAAC;KACtB;IACD,IAAI,OAAO,aAAa,KAAK,QAAQ,EAAE;QACrC,OAAO,aAAa,CAAC;KACtB;IAED,IAAI,aAAa,CAAC,MAAM,KAAK,aAAa,CAAC,MAAM,EAAE;QACjD,MAAM,IAAI,KAAK,CAAC,CAAA,iCAAA,EAAoC,aAAa,CAAA,KAAA,EAC7D,aAAa,EAAE,CAAC,CAAC;KACtB;IAED,MAAM,MAAM,GAAa,EAAE,CAAC;IAC5B,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,aAAa,CAAC,MAAM,EAAE,EAAE,CAAC,CAAE;QAC7C,MAAM,IAAI,GAAG,aAAa,CAAC,CAAC,CAAC,CAAC;QAC9B,MAAM,IAAI,GAAG,aAAa,CAAC,CAAC,CAAC,CAAC;QAC9B,IAAI,IAAI,IAAI,CAAC,IAAI,IAAI,IAAI,CAAC,IAAI,IAAI,KAAK,IAAI,EAAE;YAC3C,MAAM,IAAI,KAAK,CAAC,CAAA,iCAAA,EAAoC,aAAa,CAAA,KAAA,EAC7D,aAAa,EAAE,CAAC,CAAC;SACtB;QACD,MAAM,CAAC,CAAC,CAAC,GAAG,IAAI,IAAI,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC;KACrC;IACD,OAAO,MAAM,CAAC;AAChB,CAAC"}},
    {"offset": {"line": 95, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-converter@4.22.0_@tensorflow+tfjs-core@4.22.0/node_modules/@tensorflow/tfjs-converter/dist/executor/tensor_array.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-converter/src/executor/tensor_array.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {concat, DataType, keep, reshape, scalar, slice, stack, Tensor, tensor, tidy, unstack} from '@tensorflow/tfjs-core';\n\nimport {assertShapesMatchAllowUndefinedSize} from './tensor_utils';\n\nexport interface TensorWithState {\n  tensor?: Tensor;\n  written?: boolean;\n  read?: boolean;\n  cleared?: boolean;\n}\n/**\n * The TensorArray object keeps an array of Tensors.  It\n * allows reading from the array and writing to the array.\n */\nexport class TensorArray {\n  private tensors: TensorWithState[] = [];\n  private closed_ = false;\n  readonly idTensor: Tensor;\n  constructor(\n      readonly name: string, readonly dtype: DataType, private maxSize: number,\n      private elementShape: number[], readonly identicalElementShapes: boolean,\n      readonly dynamicSize: boolean, readonly clearAfterRead: boolean) {\n    this.idTensor = scalar(0);\n    keep(this.idTensor);\n  }\n\n  get id() {\n    return this.idTensor.id;\n  }\n\n  get closed() {\n    return this.closed_;\n  }\n\n  /**\n   * Dispose the tensors and idTensor and mark the TensoryArray as closed.\n   */\n  clearAndClose(keepIds?: Set<number>) {\n    this.tensors.forEach(tensor => {\n      if (keepIds == null || !keepIds.has(tensor.tensor.id)) {\n        tensor.tensor.dispose();\n      }\n    });\n    this.tensors = [];\n    this.closed_ = true;\n    this.idTensor.dispose();\n  }\n\n  size(): number {\n    return this.tensors.length;\n  }\n\n  /**\n   * Read the value at location index in the TensorArray.\n   * @param index Number the index to read from.\n   */\n  read(index: number): Tensor {\n    if (this.closed_) {\n      throw new Error(`TensorArray ${this.name} has already been closed.`);\n    }\n\n    if (index < 0 || index >= this.size()) {\n      throw new Error(`Tried to read from index ${index}, but array size is: ${\n          this.size()}`);\n    }\n\n    const tensorWithState = this.tensors[index];\n    if (tensorWithState.cleared) {\n      throw new Error(\n          `TensorArray ${this.name}: Could not read index ${\n              index} twice because it was cleared after a previous read ` +\n          `(perhaps try setting clear_after_read = false?).`);\n    }\n\n    if (this.clearAfterRead) {\n      tensorWithState.cleared = true;\n    }\n\n    tensorWithState.read = true;\n    return tensorWithState.tensor;\n  }\n\n  /**\n   * Helper method to read multiple tensors from the specified indices.\n   */\n  readMany(indices: number[]): Tensor[] {\n    return indices.map(index => this.read(index));\n  }\n\n  /**\n   * Write value into the index of the TensorArray.\n   * @param index number the index to write to.\n   * @param tensor\n   */\n  write(index: number, tensor: Tensor) {\n    if (this.closed_) {\n      throw new Error(`TensorArray ${this.name} has already been closed.`);\n    }\n\n    if (index < 0 || !this.dynamicSize && index >= this.maxSize) {\n      throw new Error(`Tried to write to index ${\n          index}, but array is not resizeable and size is: ${this.maxSize}`);\n    }\n\n    const t = this.tensors[index] || {};\n\n    if (tensor.dtype !== this.dtype) {\n      throw new Error(`TensorArray ${\n          this.name}: Could not write to TensorArray index ${index},\n          because the value dtype is ${\n          tensor.dtype}, but TensorArray dtype is ${this.dtype}.`);\n    }\n\n    // Set the shape for the first time write to unknow shape tensor array\n    if (this.size() === 0 &&\n        (this.elementShape == null || this.elementShape.length === 0)) {\n      this.elementShape = tensor.shape;\n    }\n\n    assertShapesMatchAllowUndefinedSize(\n        this.elementShape, tensor.shape,\n        `TensorArray ${this.name}: Could not write to TensorArray index ${\n            index}.`);\n\n    if (t.read) {\n      throw new Error(\n          `TensorArray ${this.name}: Could not write to TensorArray index ${\n              index}, because it has already been read.`);\n    }\n\n    if (t.written) {\n      throw new Error(\n          `TensorArray ${this.name}: Could not write to TensorArray index ${\n              index}, because it has already been written.`);\n    }\n\n    t.tensor = tensor;\n    keep(tensor);\n    t.written = true;\n\n    this.tensors[index] = t;\n  }\n\n  /**\n   * Helper method to write multiple tensors to the specified indices.\n   */\n  writeMany(indices: number[], tensors: Tensor[]) {\n    if (indices.length !== tensors.length) {\n      throw new Error(\n          `TensorArray ${this.name}: could not write multiple tensors,` +\n          `because the index size: ${\n              indices.length} is not the same as tensors size: ${\n              tensors.length}.`);\n    }\n\n    indices.forEach((i, index) => this.write(i, tensors[index]));\n  }\n\n  /**\n   * Return selected values in the TensorArray as a packed Tensor. All of\n   * selected values must have been written and their shapes must all match.\n   * @param [indices] number[] Optional. Taking values in [0, max_value). If the\n   *    TensorArray is not dynamic, max_value=size(). If not specified returns\n   *    all tensors in the original order.\n   * @param [dtype]\n   */\n  gather(indices?: number[], dtype?: DataType): Tensor {\n    if (!!dtype && dtype !== this.dtype) {\n      throw new Error(`TensorArray dtype is ${\n          this.dtype} but gather requested dtype ${dtype}`);\n    }\n\n    if (!indices) {\n      indices = [];\n      for (let i = 0; i < this.size(); i++) {\n        indices.push(i);\n      }\n    } else {\n      indices = indices.slice(0, this.size());\n    }\n\n    if (indices.length === 0) {\n      return tensor([], [0].concat(this.elementShape));\n    }\n\n    // Read all the PersistentTensors into a vector to keep track of\n    // their memory.\n    const tensors = this.readMany(indices);\n\n    assertShapesMatchAllowUndefinedSize(\n        this.elementShape, tensors[0].shape, 'TensorArray shape mismatch: ');\n\n    return stack(tensors, 0);\n  }\n\n  /**\n   * Return the values in the TensorArray as a concatenated Tensor.\n   */\n  concat(dtype?: DataType): Tensor {\n    if (!!dtype && dtype !== this.dtype) {\n      throw new Error(`TensorArray dtype is ${\n          this.dtype} but concat requested dtype ${dtype}`);\n    }\n\n    if (this.size() === 0) {\n      return tensor([], [0].concat(this.elementShape));\n    }\n\n    const indices = [];\n    for (let i = 0; i < this.size(); i++) {\n      indices.push(i);\n    }\n    // Collect all the tensors from the tensors array.\n    const tensors = this.readMany(indices);\n\n    assertShapesMatchAllowUndefinedSize(\n        this.elementShape, tensors[0].shape,\n        `TensorArray shape mismatch: tensor array shape (${\n            this.elementShape}) vs first tensor shape (${tensors[0].shape})`);\n\n    return concat(tensors, 0);\n  }\n\n  /**\n   * Scatter the values of a Tensor in specific indices of a TensorArray.\n   * @param indices number[] values in [0, max_value). If the\n   *    TensorArray is not dynamic, max_value=size().\n   * @param tensor Tensor input tensor.\n   */\n  scatter(indices: number[], tensor: Tensor) {\n    if (tensor.dtype !== this.dtype) {\n      throw new Error(`TensorArray dtype is ${\n          this.dtype} but tensor has dtype ${tensor.dtype}`);\n    }\n\n    if (indices.length !== tensor.shape[0]) {\n      throw new Error(`Expected len(indices) == tensor.shape[0], but saw: ${\n          indices.length} vs. ${tensor.shape[0]}`);\n    }\n\n    const maxIndex = Math.max(...indices);\n\n    if (!this.dynamicSize && maxIndex >= this.maxSize) {\n      throw new Error(\n          `Max index must be < array size (${maxIndex}  vs. ${this.maxSize})`);\n    }\n\n    this.writeMany(indices, unstack(tensor, 0));\n  }\n\n  /**\n   * Split the values of a Tensor into the TensorArray.\n   * @param length number[] with the lengths to use when splitting value along\n   *    its first dimension.\n   * @param tensor Tensor, the tensor to split.\n   */\n  split(length: number[], tensor: Tensor) {\n    if (tensor.dtype !== this.dtype) {\n      throw new Error(`TensorArray dtype is ${\n          this.dtype} but tensor has dtype ${tensor.dtype}`);\n    }\n    let totalLength = 0;\n    const cumulativeLengths = length.map(len => {\n      totalLength += len;\n      return totalLength;\n    });\n\n    if (totalLength !== tensor.shape[0]) {\n      throw new Error(`Expected sum of lengths to be equal to\n          tensor.shape[0], but sum of lengths is\n        ${totalLength}, and tensor's shape is: ${tensor.shape}`);\n    }\n\n    if (!this.dynamicSize && length.length !== this.maxSize) {\n      throw new Error(\n          `TensorArray's size is not equal to the size of lengths (${\n              this.maxSize} vs. ${length.length}), ` +\n          'and the TensorArray is not marked as dynamically resizeable');\n    }\n\n    const elementPerRow = totalLength === 0 ? 0 : tensor.size / totalLength;\n    const tensors: Tensor[] = [];\n    tidy(() => {\n      tensor = reshape(tensor, [1, totalLength, elementPerRow]);\n      for (let i = 0; i < length.length; ++i) {\n        const previousLength = (i === 0) ? 0 : cumulativeLengths[i - 1];\n        const indices = [0, previousLength, 0];\n        const sizes = [1, length[i], elementPerRow];\n        tensors[i] = reshape(slice(tensor, indices, sizes), this.elementShape);\n      }\n      return tensors;\n    });\n    const indices = [];\n    for (let i = 0; i < length.length; i++) {\n      indices[i] = i;\n    }\n    this.writeMany(indices, tensors);\n  }\n}\n"],"names":[],"mappings":";;;;AAAA;;;;;;;;;;;;;;;GAeG;;;;;;;;AAEH,OAAO,EAAC,MAAM,EAAY,IAAI,EAAE,OAAO,EAAE,MAAM,EAAE,KAAK,EAAE,KAAK,EAAU,MAAM,EAAE,IAAI,EAAE,OAAO,EAAC,MAAM,uBAAuB,CAAC;AAE3H,OAAO,EAAC,mCAAmC,EAAC,MAAM,gBAAgB,CAAC;;;AAY7D,MAAO,WAAW;IAItB,YACa,IAAY,EAAW,KAAe,EAAU,OAAe,EAChE,YAAsB,EAAW,sBAA+B,EAC/D,WAAoB,EAAW,cAAuB,CAAA;QAFtD,IAAA,CAAA,IAAI,GAAJ,IAAI,CAAQ;QAAW,IAAA,CAAA,KAAK,GAAL,KAAK,CAAU;QAAU,IAAA,CAAA,OAAO,GAAP,OAAO,CAAQ;QAChE,IAAA,CAAA,YAAY,GAAZ,YAAY,CAAU;QAAW,IAAA,CAAA,sBAAsB,GAAtB,sBAAsB,CAAS;QAC/D,IAAA,CAAA,WAAW,GAAX,WAAW,CAAS;QAAW,IAAA,CAAA,cAAc,GAAd,cAAc,CAAS;QAN3D,IAAA,CAAA,OAAO,GAAsB,EAAE,CAAC;QAChC,IAAA,CAAA,OAAO,GAAG,KAAK,CAAC;QAMtB,IAAI,CAAC,QAAQ,OAAG,yPAAM,EAAC,CAAC,CAAC,CAAC;YAC1B,iPAAI,EAAC,IAAI,CAAC,QAAQ,CAAC,CAAC;IACtB,CAAC;IAED,IAAI,EAAE,GAAA;QACJ,OAAO,IAAI,CAAC,QAAQ,CAAC,EAAE,CAAC;IAC1B,CAAC;IAED,IAAI,MAAM,GAAA;QACR,OAAO,IAAI,CAAC,OAAO,CAAC;IACtB,CAAC;IAED;;OAEG,CACH,aAAa,CAAC,OAAqB,EAAA;QACjC,IAAI,CAAC,OAAO,CAAC,OAAO,EAAC,MAAM,CAAC,EAAE;YAC5B,IAAI,OAAO,IAAI,IAAI,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,MAAM,CAAC,MAAM,CAAC,EAAE,CAAC,EAAE;gBACrD,MAAM,CAAC,MAAM,CAAC,OAAO,EAAE,CAAC;aACzB;QACH,CAAC,CAAC,CAAC;QACH,IAAI,CAAC,OAAO,GAAG,EAAE,CAAC;QAClB,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC;QACpB,IAAI,CAAC,QAAQ,CAAC,OAAO,EAAE,CAAC;IAC1B,CAAC;IAED,IAAI,GAAA;QACF,OAAO,IAAI,CAAC,OAAO,CAAC,MAAM,CAAC;IAC7B,CAAC;IAED;;;OAGG,CACH,IAAI,CAAC,KAAa,EAAA;QAChB,IAAI,IAAI,CAAC,OAAO,EAAE;YAChB,MAAM,IAAI,KAAK,CAAC,CAAA,YAAA,EAAe,IAAI,CAAC,IAAI,CAAA,yBAAA,CAA2B,CAAC,CAAC;SACtE;QAED,IAAI,KAAK,GAAG,CAAC,IAAI,KAAK,IAAI,IAAI,CAAC,IAAI,EAAE,EAAE;YACrC,MAAM,IAAI,KAAK,CAAC,CAAA,yBAAA,EAA4B,KAAK,CAAA,qBAAA,EAC7C,IAAI,CAAC,IAAI,EAAE,EAAE,CAAC,CAAC;SACpB;QAED,MAAM,eAAe,GAAG,IAAI,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC;QAC5C,IAAI,eAAe,CAAC,OAAO,EAAE;YAC3B,MAAM,IAAI,KAAK,CACX,CAAA,YAAA,EAAe,IAAI,CAAC,IAAI,CAAA,uBAAA,EACpB,KAAK,CAAA,oDAAA,CAAsD,GAC/D,CAAA,gDAAA,CAAkD,CAAC,CAAC;SACzD;QAED,IAAI,IAAI,CAAC,cAAc,EAAE;YACvB,eAAe,CAAC,OAAO,GAAG,IAAI,CAAC;SAChC;QAED,eAAe,CAAC,IAAI,GAAG,IAAI,CAAC;QAC5B,OAAO,eAAe,CAAC,MAAM,CAAC;IAChC,CAAC;IAED;;OAEG,CACH,QAAQ,CAAC,OAAiB,EAAA;QACxB,OAAO,OAAO,CAAC,GAAG,EAAC,KAAK,CAAC,EAAE,AAAC,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC,CAAC;IAChD,CAAC;IAED;;;;OAIG,CACH,KAAK,CAAC,KAAa,EAAE,MAAc,EAAA;QACjC,IAAI,IAAI,CAAC,OAAO,EAAE;YAChB,MAAM,IAAI,KAAK,CAAC,CAAA,YAAA,EAAe,IAAI,CAAC,IAAI,CAAA,yBAAA,CAA2B,CAAC,CAAC;SACtE;QAED,IAAI,KAAK,GAAG,CAAC,IAAI,CAAC,IAAI,CAAC,WAAW,IAAI,KAAK,IAAI,IAAI,CAAC,OAAO,EAAE;YAC3D,MAAM,IAAI,KAAK,CAAC,CAAA,wBAAA,EACZ,KAAK,CAAA,2CAAA,EAA8C,IAAI,CAAC,OAAO,EAAE,CAAC,CAAC;SACxE;QAED,MAAM,CAAC,GAAG,IAAI,CAAC,OAAO,CAAC,KAAK,CAAC,IAAI,CAAA,CAAE,CAAC;QAEpC,IAAI,MAAM,CAAC,KAAK,KAAK,IAAI,CAAC,KAAK,EAAE;YAC/B,MAAM,IAAI,KAAK,CAAC,CAAA,YAAA,EACZ,IAAI,CAAC,IAAI,CAAA,uCAAA,EAA0C,KAAK,CAAA;uCAExD,MAAM,CAAC,KAAK,CAAA,2BAAA,EAA8B,IAAI,CAAC,KAAK,CAAA,CAAA,CAAG,CAAC,CAAC;SAC9D;QAED,sEAAsE;QACtE,IAAI,IAAI,CAAC,IAAI,EAAE,KAAK,CAAC,IACjB,CAAC,IAAI,CAAC,YAAY,IAAI,IAAI,IAAI,IAAI,CAAC,YAAY,CAAC,MAAM,KAAK,CAAC,CAAC,EAAE;YACjE,IAAI,CAAC,YAAY,GAAG,MAAM,CAAC,KAAK,CAAC;SAClC;YAED,0VAAmC,EAC/B,IAAI,CAAC,YAAY,EAAE,MAAM,CAAC,KAAK,EAC/B,CAAA,YAAA,EAAe,IAAI,CAAC,IAAI,CAAA,uCAAA,EACpB,KAAK,CAAA,CAAA,CAAG,CAAC,CAAC;QAElB,IAAI,CAAC,CAAC,IAAI,EAAE;YACV,MAAM,IAAI,KAAK,CACX,CAAA,YAAA,EAAe,IAAI,CAAC,IAAI,CAAA,uCAAA,EACpB,KAAK,CAAA,mCAAA,CAAqC,CAAC,CAAC;SACrD;QAED,IAAI,CAAC,CAAC,OAAO,EAAE;YACb,MAAM,IAAI,KAAK,CACX,CAAA,YAAA,EAAe,IAAI,CAAC,IAAI,CAAA,uCAAA,EACpB,KAAK,CAAA,sCAAA,CAAwC,CAAC,CAAC;SACxD;QAED,CAAC,CAAC,MAAM,GAAG,MAAM,CAAC;YAClB,iPAAI,EAAC,MAAM,CAAC,CAAC;QACb,CAAC,CAAC,OAAO,GAAG,IAAI,CAAC;QAEjB,IAAI,CAAC,OAAO,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC;IAC1B,CAAC;IAED;;OAEG,CACH,SAAS,CAAC,OAAiB,EAAE,OAAiB,EAAA;QAC5C,IAAI,OAAO,CAAC,MAAM,KAAK,OAAO,CAAC,MAAM,EAAE;YACrC,MAAM,IAAI,KAAK,CACX,CAAA,YAAA,EAAe,IAAI,CAAC,IAAI,CAAA,mCAAA,CAAqC,GAC7D,CAAA,wBAAA,EACI,OAAO,CAAC,MAAM,CAAA,kCAAA,EACd,OAAO,CAAC,MAAM,CAAA,CAAA,CAAG,CAAC,CAAC;SAC5B;QAED,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,KAAK,EAAE,CAAG,CAAD,GAAK,CAAC,KAAK,CAAC,CAAC,EAAE,OAAO,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;IAC/D,CAAC;IAED;;;;;;;OAOG,CACH,MAAM,CAAC,OAAkB,EAAE,KAAgB,EAAA;QACzC,IAAI,CAAC,CAAC,KAAK,IAAI,KAAK,KAAK,IAAI,CAAC,KAAK,EAAE;YACnC,MAAM,IAAI,KAAK,CAAC,CAAA,qBAAA,EACZ,IAAI,CAAC,KAAK,CAAA,4BAAA,EAA+B,KAAK,EAAE,CAAC,CAAC;SACvD;QAED,IAAI,CAAC,OAAO,EAAE;YACZ,OAAO,GAAG,EAAE,CAAC;YACb,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,IAAI,EAAE,EAAE,CAAC,EAAE,CAAE;gBACpC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;aACjB;SACF,MAAM;YACL,OAAO,GAAG,OAAO,CAAC,KAAK,CAAC,CAAC,EAAE,IAAI,CAAC,IAAI,EAAE,CAAC,CAAC;SACzC;QAED,IAAI,OAAO,CAAC,MAAM,KAAK,CAAC,EAAE;YACxB,WAAO,yPAAM,EAAC,EAAE,EAAE;gBAAC,CAAC;aAAC,CAAC,MAAM,CAAC,IAAI,CAAC,YAAY,CAAC,CAAC,CAAC;SAClD;QAED,gEAAgE;QAChE,gBAAgB;QAChB,MAAM,OAAO,GAAG,IAAI,CAAC,QAAQ,CAAC,OAAO,CAAC,CAAC;YAEvC,0VAAmC,EAC/B,IAAI,CAAC,YAAY,EAAE,OAAO,CAAC,CAAC,CAAC,CAAC,KAAK,EAAE,8BAA8B,CAAC,CAAC;QAEzE,WAAO,uPAAK,EAAC,OAAO,EAAE,CAAC,CAAC,CAAC;IAC3B,CAAC;IAED;;OAEG,CACH,MAAM,CAAC,KAAgB,EAAA;QACrB,IAAI,CAAC,CAAC,KAAK,IAAI,KAAK,KAAK,IAAI,CAAC,KAAK,EAAE;YACnC,MAAM,IAAI,KAAK,CAAC,CAAA,qBAAA,EACZ,IAAI,CAAC,KAAK,CAAA,4BAAA,EAA+B,KAAK,EAAE,CAAC,CAAC;SACvD;QAED,IAAI,IAAI,CAAC,IAAI,EAAE,KAAK,CAAC,EAAE;YACrB,WAAO,yPAAM,EAAC,EAAE,EAAE;gBAAC,CAAC;aAAC,CAAC,MAAM,CAAC,IAAI,CAAC,YAAY,CAAC,CAAC,CAAC;SAClD;QAED,MAAM,OAAO,GAAG,EAAE,CAAC;QACnB,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,IAAI,EAAE,EAAE,CAAC,EAAE,CAAE;YACpC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;SACjB;QACD,kDAAkD;QAClD,MAAM,OAAO,GAAG,IAAI,CAAC,QAAQ,CAAC,OAAO,CAAC,CAAC;YAEvC,0VAAmC,EAC/B,IAAI,CAAC,YAAY,EAAE,OAAO,CAAC,CAAC,CAAC,CAAC,KAAK,EACnC,CAAA,gDAAA,EACI,IAAI,CAAC,YAAY,CAAA,yBAAA,EAA4B,OAAO,CAAC,CAAC,CAAC,CAAC,KAAK,CAAA,CAAA,CAAG,CAAC,CAAC;QAE1E,WAAO,yPAAM,EAAC,OAAO,EAAE,CAAC,CAAC,CAAC;IAC5B,CAAC;IAED;;;;;OAKG,CACH,OAAO,CAAC,OAAiB,EAAE,MAAc,EAAA;QACvC,IAAI,MAAM,CAAC,KAAK,KAAK,IAAI,CAAC,KAAK,EAAE;YAC/B,MAAM,IAAI,KAAK,CAAC,CAAA,qBAAA,EACZ,IAAI,CAAC,KAAK,CAAA,sBAAA,EAAyB,MAAM,CAAC,KAAK,EAAE,CAAC,CAAC;SACxD;QAED,IAAI,OAAO,CAAC,MAAM,KAAK,MAAM,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE;YACtC,MAAM,IAAI,KAAK,CAAC,CAAA,mDAAA,EACZ,OAAO,CAAC,MAAM,CAAA,KAAA,EAAQ,MAAM,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC;SAC9C;QAED,MAAM,QAAQ,GAAG,IAAI,CAAC,GAAG,CAAC,GAAG,OAAO,CAAC,CAAC;QAEtC,IAAI,CAAC,IAAI,CAAC,WAAW,IAAI,QAAQ,IAAI,IAAI,CAAC,OAAO,EAAE;YACjD,MAAM,IAAI,KAAK,CACX,CAAA,gCAAA,EAAmC,QAAQ,CAAA,MAAA,EAAS,IAAI,CAAC,OAAO,CAAA,CAAA,CAAG,CAAC,CAAC;SAC1E;QAED,IAAI,CAAC,SAAS,CAAC,OAAO,MAAE,2PAAO,EAAC,MAAM,EAAE,CAAC,CAAC,CAAC,CAAC;IAC9C,CAAC;IAED;;;;;OAKG,CACH,KAAK,CAAC,MAAgB,EAAE,MAAc,EAAA;QACpC,IAAI,MAAM,CAAC,KAAK,KAAK,IAAI,CAAC,KAAK,EAAE;YAC/B,MAAM,IAAI,KAAK,CAAC,CAAA,qBAAA,EACZ,IAAI,CAAC,KAAK,CAAA,sBAAA,EAAyB,MAAM,CAAC,KAAK,EAAE,CAAC,CAAC;SACxD;QACD,IAAI,WAAW,GAAG,CAAC,CAAC;QACpB,MAAM,iBAAiB,GAAG,MAAM,CAAC,GAAG,EAAC,GAAG,CAAC,EAAE;YACzC,WAAW,IAAI,GAAG,CAAC;YACnB,OAAO,WAAW,CAAC;QACrB,CAAC,CAAC,CAAC;QAEH,IAAI,WAAW,KAAK,MAAM,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE;YACnC,MAAM,IAAI,KAAK,CAAC,CAAA;;UAEZ,WAAW,CAAA,yBAAA,EAA4B,MAAM,CAAC,KAAK,EAAE,CAAC,CAAC;SAC5D;QAED,IAAI,CAAC,IAAI,CAAC,WAAW,IAAI,MAAM,CAAC,MAAM,KAAK,IAAI,CAAC,OAAO,EAAE;YACvD,MAAM,IAAI,KAAK,CACX,CAAA,wDAAA,EACI,IAAI,CAAC,OAAO,CAAA,KAAA,EAAQ,MAAM,CAAC,MAAM,CAAA,GAAA,CAAK,GAC1C,6DAA6D,CAAC,CAAC;SACpE;QAED,MAAM,aAAa,GAAG,WAAW,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC,IAAI,GAAG,WAAW,CAAC;QACxE,MAAM,OAAO,GAAa,EAAE,CAAC;YAC7B,iPAAI,EAAC,GAAG,EAAE;YACR,MAAM,OAAG,2PAAO,EAAC,MAAM,EAAE;gBAAC,CAAC;gBAAE,WAAW;gBAAE,aAAa;aAAC,CAAC,CAAC;YAC1D,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,CAAE;gBACtC,MAAM,cAAc,GAAG,AAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,AAAC,CAAC,CAAC,CAAC,CAAC,iBAAiB,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC;gBAChE,MAAM,OAAO,GAAG;oBAAC,CAAC;oBAAE,cAAc;oBAAE,CAAC;iBAAC,CAAC;gBACvC,MAAM,KAAK,GAAG;oBAAC,CAAC;oBAAE,MAAM,CAAC,CAAC,CAAC;oBAAE,aAAa;iBAAC,CAAC;gBAC5C,OAAO,CAAC,CAAC,CAAC,OAAG,2PAAO,MAAC,uPAAK,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,CAAC,EAAE,IAAI,CAAC,YAAY,CAAC,CAAC;aACxE;YACD,OAAO,OAAO,CAAC;QACjB,CAAC,CAAC,CAAC;QACH,MAAM,OAAO,GAAG,EAAE,CAAC;QACnB,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,CAAC,EAAE,CAAE;YACtC,OAAO,CAAC,CAAC,CAAC,GAAG,CAAC,CAAC;SAChB;QACD,IAAI,CAAC,SAAS,CAAC,OAAO,EAAE,OAAO,CAAC,CAAC;IACnC,CAAC;CACF"}},
    {"offset": {"line": 351, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-converter@4.22.0_@tensorflow+tfjs-core@4.22.0/node_modules/@tensorflow/tfjs-converter/dist/executor/tensor_list.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-converter/src/executor/tensor_list.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {concat, DataType, keep, reshape, scalar, slice, stack, Tensor, tensor, tidy, unstack} from '@tensorflow/tfjs-core';\n\nimport {assertShapesMatchAllowUndefinedSize, inferElementShape, mergeElementShape} from './tensor_utils';\n\n/**\n * TensorList stores a container of `tf.Tensor` objects, which are accessible\n * via tensors field.\n *\n * In order to get a copy of the underlying list, use the copy method:\n * ```\n *    TensorList b = a.copy();\n *    b.tensors().pushBack(t);  // This does not modify a.tensors().\n * ```\n *\n * Note that this is not a deep copy: the memory locations of the underlying\n * tensors will still point to the same locations of the corresponding tensors\n * in the original.\n */\n\nexport class TensorList {\n  readonly idTensor: Tensor;\n  maxNumElements: number;\n\n  get id() {\n    return this.idTensor.id;\n  }\n  /**\n   *\n   * @param tensors list of tensors\n   * @param elementShape shape of each tensor, this can be a single number (any\n   * shape is allowed) or partial shape (dim = -1).\n   * @param elementDtype data type of each tensor\n   * @param maxNumElements The maximum allowed size of `tensors`. Defaults to -1\n   *   meaning that the size of `tensors` is unbounded.\n   */\n  constructor(\n      readonly tensors: Tensor[], readonly elementShape: number|number[],\n      readonly elementDtype: DataType, maxNumElements = -1) {\n    if (tensors != null) {\n      tensors.forEach(tensor => {\n        if (elementDtype !== tensor.dtype) {\n          throw new Error(`Invalid data types; op elements ${\n              elementDtype}, but list elements ${tensor.dtype}`);\n        }\n        assertShapesMatchAllowUndefinedSize(\n            elementShape, tensor.shape, 'TensorList shape mismatch: ');\n\n        keep(tensor);\n      });\n    }\n    this.idTensor = scalar(0);\n    this.maxNumElements = maxNumElements;\n    keep(this.idTensor);\n  }\n\n  /**\n   * Get a new TensorList containing a copy of the underlying tensor container.\n   */\n  copy(): TensorList {\n    return new TensorList(\n        [...this.tensors], this.elementShape, this.elementDtype);\n  }\n\n  /**\n   * Dispose the tensors and idTensor and clear the tensor list.\n   */\n  clearAndClose(keepIds?: Set<number>) {\n    this.tensors.forEach(tensor => {\n      if (keepIds == null || !keepIds.has(tensor.id)) {\n        tensor.dispose();\n      }\n    });\n    this.tensors.length = 0;\n    this.idTensor.dispose();\n  }\n  /**\n   * The size of the tensors in the tensor list.\n   */\n  size() {\n    return this.tensors.length;\n  }\n\n  /**\n   * Return a tensor that stacks a list of rank-R tf.Tensors into one rank-(R+1)\n   * tf.Tensor.\n   * @param elementShape shape of each tensor\n   * @param elementDtype data type of each tensor\n   * @param numElements the number of elements to stack\n   */\n  stack(elementShape: number[], elementDtype: DataType, numElements = -1):\n      Tensor {\n    if (elementDtype !== this.elementDtype) {\n      throw new Error(`Invalid data types; op elements ${\n          elementDtype}, but list elements ${this.elementDtype}`);\n    }\n    if (numElements !== -1 && this.tensors.length !== numElements) {\n      throw new Error(`Operation expected a list with ${\n          numElements} elements but got a list with ${\n          this.tensors.length} elements.`);\n    }\n    assertShapesMatchAllowUndefinedSize(\n        elementShape, this.elementShape, 'TensorList shape mismatch: ');\n    const outputElementShape =\n        inferElementShape(this.elementShape, this.tensors, elementShape);\n    return tidy(() => {\n      const reshapedTensors =\n          this.tensors.map(tensor => reshape(tensor, outputElementShape));\n      return stack(reshapedTensors, 0);\n    });\n  }\n\n  /**\n   * Pop a tensor from the end of the list.\n   * @param elementShape shape of the tensor\n   * @param elementDtype data type of the tensor\n   */\n  popBack(elementShape: number[], elementDtype: DataType): Tensor {\n    if (elementDtype !== this.elementDtype) {\n      throw new Error(`Invalid data types; op elements ${\n          elementDtype}, but list elements ${this.elementDtype}`);\n    }\n\n    if (this.size() === 0) {\n      throw new Error('Trying to pop from an empty list.');\n    }\n    const outputElementShape =\n        inferElementShape(this.elementShape, this.tensors, elementShape);\n    const tensor = this.tensors.pop();\n    tensor.kept = false;\n\n    assertShapesMatchAllowUndefinedSize(\n        tensor.shape, elementShape, 'TensorList shape mismatch: ');\n\n    return reshape(tensor, outputElementShape);\n  }\n\n  /**\n   * Push a tensor to the end of the list.\n   * @param tensor Tensor to be pushed.\n   */\n  pushBack(tensor: Tensor) {\n    if (tensor.dtype !== this.elementDtype) {\n      throw new Error(`Invalid data types; op elements ${\n          tensor.dtype}, but list elements ${this.elementDtype}`);\n    }\n\n    assertShapesMatchAllowUndefinedSize(\n        tensor.shape, this.elementShape, 'TensorList shape mismatch: ');\n\n    if (this.maxNumElements === this.size()) {\n      throw new Error(`Trying to push element into a full list.`);\n    }\n    keep(tensor);\n    this.tensors.push(tensor);\n  }\n\n  /**\n   * Update the size of the list.\n   * @param size the new size of the list.\n   */\n  resize(size: number) {\n    if (size < 0) {\n      throw new Error(\n          `TensorListResize expects size to be non-negative. Got: ${size}`);\n    }\n\n    if (this.maxNumElements !== -1 && size > this.maxNumElements) {\n      throw new Error(`TensorListResize input size ${\n          size} is greater maxNumElement ${this.maxNumElements}.`);\n    }\n\n    const destTensorList: TensorList = new TensorList(\n        [], this.elementShape, this.elementDtype, this.maxNumElements);\n    destTensorList.tensors.length = size;\n    for (let i = 0; i < Math.min(this.tensors.length, size); ++i) {\n      destTensorList.tensors[i] = this.tensors[i];\n    }\n    return destTensorList;\n  }\n\n  /**\n   * Retrieve the element at the provided index\n   * @param elementShape shape of the tensor\n   * @param elementDtype dtype of the tensor\n   * @param elementIndex index of the tensor\n   */\n  getItem(elementIndex: number, elementShape: number[], elementDtype: DataType):\n      Tensor {\n    if (elementDtype !== this.elementDtype) {\n      throw new Error(`Invalid data types; op elements ${\n          elementDtype}, but list elements ${this.elementDtype}`);\n    }\n    if (elementIndex < 0 || elementIndex > this.tensors.length) {\n      throw new Error(`Trying to access element ${\n          elementIndex} in a list with ${this.tensors.length} elements.`);\n    }\n\n    if (this.tensors[elementIndex] == null) {\n      throw new Error(`element at index ${elementIndex} is null.`);\n    }\n\n    assertShapesMatchAllowUndefinedSize(\n        this.tensors[elementIndex].shape, elementShape,\n        'TensorList shape mismatch: ');\n    const outputElementShape =\n        inferElementShape(this.elementShape, this.tensors, elementShape);\n    return reshape(this.tensors[elementIndex], outputElementShape);\n  }\n\n  /**\n   * Set the tensor at the index\n   * @param elementIndex index of the tensor\n   * @param tensor the tensor to be inserted into the list\n   */\n  setItem(elementIndex: number, tensor: Tensor) {\n    if (tensor.dtype !== this.elementDtype) {\n      throw new Error(`Invalid data types; op elements ${\n          tensor.dtype}, but list elements ${this.elementDtype}`);\n    }\n\n    if (elementIndex < 0 ||\n        this.maxNumElements !== -1 && elementIndex >= this.maxNumElements) {\n      throw new Error(`Trying to set element ${\n          elementIndex} in a list with max ${this.maxNumElements} elements.`);\n    }\n\n    assertShapesMatchAllowUndefinedSize(\n        this.elementShape, tensor.shape, 'TensorList shape mismatch: ');\n    keep(tensor);\n\n    // dispose the previous value if it is replacing.\n    if (this.tensors[elementIndex] != null) {\n      this.tensors[elementIndex].kept = false;\n    }\n\n    this.tensors[elementIndex] = tensor;\n  }\n\n  /**\n   * Return selected values in the TensorList as a stacked Tensor. All of\n   * selected values must have been written and their shapes must all match.\n   * @param indices indices of tensors to gather\n   * @param elementDtype output tensor dtype\n   * @param elementShape output tensor element shape\n   */\n  gather(indices: number[], elementDtype: DataType, elementShape: number[]):\n      Tensor {\n    if (elementDtype !== this.elementDtype) {\n      throw new Error(`Invalid data types; op elements ${\n          elementDtype}, but list elements ${this.elementDtype}`);\n    }\n\n    assertShapesMatchAllowUndefinedSize(\n        this.elementShape, elementShape, 'TensorList shape mismatch: ');\n\n    // When indices is greater than the size of the list, indices beyond the\n    // size of the list are ignored.\n    indices = indices.slice(0, this.size());\n    const outputElementShape =\n        inferElementShape(this.elementShape, this.tensors, elementShape);\n    if (indices.length === 0) {\n      return tensor([], [0].concat(outputElementShape));\n    }\n\n    return tidy(() => {\n      const tensors =\n          indices.map(i => reshape(this.tensors[i], outputElementShape));\n      return stack(tensors, 0);\n    });\n  }\n\n  /**\n   * Return the values in the TensorList as a concatenated Tensor.\n   * @param elementDtype output tensor dtype\n   * @param elementShape output tensor element shape\n   */\n  concat(elementDtype: DataType, elementShape: number[]): Tensor {\n    if (!!elementDtype && elementDtype !== this.elementDtype) {\n      throw new Error(`TensorList dtype is ${\n          this.elementDtype} but concat requested dtype ${elementDtype}`);\n    }\n\n    assertShapesMatchAllowUndefinedSize(\n        this.elementShape, elementShape, 'TensorList shape mismatch: ');\n    const outputElementShape =\n        inferElementShape(this.elementShape, this.tensors, elementShape);\n\n    if (this.size() === 0) {\n      return tensor([], [0].concat(outputElementShape));\n    }\n    return tidy(() => {\n      const tensors = this.tensors.map(t => reshape(t, outputElementShape));\n      return concat(tensors, 0);\n    });\n  }\n}\n\n/**\n * Creates a TensorList which, when stacked, has the value of tensor.\n * @param tensor from tensor\n * @param elementShape output tensor element shape\n */\nexport function fromTensor(\n    tensor: Tensor, elementShape: number[], elementDtype: DataType) {\n  const dtype = tensor.dtype;\n  if (tensor.shape.length < 1) {\n    throw new Error(\n        `Tensor must be at least a vector, but saw shape: ${tensor.shape}`);\n  }\n  if (tensor.dtype !== elementDtype) {\n    throw new Error(`Invalid data types; op elements ${\n        tensor.dtype}, but list elements ${elementDtype}`);\n  }\n  const tensorElementShape = tensor.shape.slice(1);\n  assertShapesMatchAllowUndefinedSize(\n      tensorElementShape, elementShape, 'TensorList shape mismatch: ');\n  const tensorList: Tensor[] = unstack(tensor);\n  return new TensorList(tensorList, elementShape, dtype);\n}\n\n/**\n * Return a TensorList of the given size with empty elements.\n * @param elementShape the shape of the future elements of the list\n * @param elementDtype the desired type of elements in the list\n * @param numElements the number of elements to reserve\n * @param maxNumElements the maximum number of elements in th list\n */\nexport function reserve(\n    elementShape: number[], elementDtype: DataType, numElements: number,\n    maxNumElements: number) {\n  return new TensorList([], elementShape, elementDtype, maxNumElements);\n}\n\n/**\n * Put tensors at specific indices of a stacked tensor into a TensorList.\n * @param indices list of indices on how to scatter the tensor.\n * @param tensor input tensor.\n * @param elementShape the shape of the future elements of the list\n * @param numElements the number of elements to scatter\n */\nexport function scatter(\n    tensor: Tensor, indices: number[], elementShape: number[],\n    numElements?: number): TensorList {\n  if (indices.length !== tensor.shape[0]) {\n    throw new Error(`Expected len(indices) == tensor.shape[0], but saw: ${\n        indices.length} vs. ${tensor.shape[0]}`);\n  }\n\n  const maxIndex = Math.max(...indices);\n\n  if (numElements != null && numElements !== -1 && maxIndex >= numElements) {\n    throw new Error(\n        `Max index must be < array size (${maxIndex}  vs. ${numElements})`);\n  }\n\n  const list = new TensorList([], elementShape, tensor.dtype, numElements);\n  const tensors = unstack(tensor, 0);\n  indices.forEach((value, index) => {\n    list.setItem(value, tensors[index]);\n  });\n  return list;\n}\n\n/**\n * Split the values of a Tensor into a TensorList.\n * @param length the lengths to use when splitting value along\n *    its first dimension.\n * @param tensor the tensor to split.\n * @param elementShape the shape of the future elements of the list\n */\nexport function split(\n    tensor: Tensor, length: number[], elementShape: number[]) {\n  let totalLength = 0;\n  const cumulativeLengths = length.map(len => {\n    totalLength += len;\n    return totalLength;\n  });\n\n  if (totalLength !== tensor.shape[0]) {\n    throw new Error(`Expected sum of lengths to be equal to\n          tensor.shape[0], but sum of lengths is\n        ${totalLength}, and tensor's shape is: ${tensor.shape}`);\n  }\n\n  const shapeWithoutFirstDim = tensor.shape.slice(1);\n  const outputElementShape =\n      mergeElementShape(shapeWithoutFirstDim, elementShape);\n  const elementPerRow = totalLength === 0 ? 0 : tensor.size / totalLength;\n  const tensors: Tensor[] = tidy(() => {\n    const tensors = [];\n    tensor = reshape(tensor, [1, totalLength, elementPerRow]);\n    for (let i = 0; i < length.length; ++i) {\n      const previousLength = (i === 0) ? 0 : cumulativeLengths[i - 1];\n      const indices = [0, previousLength, 0];\n      const sizes = [1, length[i], elementPerRow];\n      tensors[i] = reshape(\n          slice(tensor, indices, sizes), outputElementShape as number[]);\n    }\n    tensor.dispose();\n    return tensors;\n  });\n\n  const list = new TensorList([], elementShape, tensor.dtype, length.length);\n\n  for (let i = 0; i < tensors.length; i++) {\n    list.setItem(i, tensors[i]);\n  }\n  return list;\n}\n"],"names":[],"mappings":";;;;;;;;;;;;AAAA;;;;;;;;;;;;;;;GAeG;;;;;;;;AAEH,OAAO,EAAC,MAAM,EAAY,IAAI,EAAE,OAAO,EAAE,MAAM,EAAE,KAAK,EAAE,KAAK,EAAU,MAAM,EAAE,IAAI,EAAE,OAAO,EAAC,MAAM,uBAAuB,CAAC;AAE3H,OAAO,EAAC,mCAAmC,EAAE,iBAAiB,EAAE,iBAAiB,EAAC,MAAM,gBAAgB,CAAC;;;AAiBnG,MAAO,UAAU;IAIrB,IAAI,EAAE,GAAA;QACJ,OAAO,IAAI,CAAC,QAAQ,CAAC,EAAE,CAAC;IAC1B,CAAC;IACD;;;;;;;;OAQG,CACH,YACa,OAAiB,EAAW,YAA6B,EACzD,YAAsB,EAAE,cAAc,GAAG,CAAC,CAAC,CAAA;QAD3C,IAAA,CAAA,OAAO,GAAP,OAAO,CAAU;QAAW,IAAA,CAAA,YAAY,GAAZ,YAAY,CAAiB;QACzD,IAAA,CAAA,YAAY,GAAZ,YAAY,CAAU;QACjC,IAAI,OAAO,IAAI,IAAI,EAAE;YACnB,OAAO,CAAC,OAAO,EAAC,MAAM,CAAC,EAAE;gBACvB,IAAI,YAAY,KAAK,MAAM,CAAC,KAAK,EAAE;oBACjC,MAAM,IAAI,KAAK,CAAC,CAAA,gCAAA,EACZ,YAAY,CAAA,oBAAA,EAAuB,MAAM,CAAC,KAAK,EAAE,CAAC,CAAC;iBACxD;oBACD,0VAAmC,EAC/B,YAAY,EAAE,MAAM,CAAC,KAAK,EAAE,6BAA6B,CAAC,CAAC;oBAE/D,iPAAI,EAAC,MAAM,CAAC,CAAC;YACf,CAAC,CAAC,CAAC;SACJ;QACD,IAAI,CAAC,QAAQ,OAAG,yPAAM,EAAC,CAAC,CAAC,CAAC;QAC1B,IAAI,CAAC,cAAc,GAAG,cAAc,CAAC;YACrC,iPAAI,EAAC,IAAI,CAAC,QAAQ,CAAC,CAAC;IACtB,CAAC;IAED;;OAEG,CACH,IAAI,GAAA;QACF,OAAO,IAAI,UAAU,CACjB,CAAC;eAAG,IAAI,CAAC,OAAO;SAAC,EAAE,IAAI,CAAC,YAAY,EAAE,IAAI,CAAC,YAAY,CAAC,CAAC;IAC/D,CAAC;IAED;;OAEG,CACH,aAAa,CAAC,OAAqB,EAAA;QACjC,IAAI,CAAC,OAAO,CAAC,OAAO,EAAC,MAAM,CAAC,EAAE;YAC5B,IAAI,OAAO,IAAI,IAAI,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,MAAM,CAAC,EAAE,CAAC,EAAE;gBAC9C,MAAM,CAAC,OAAO,EAAE,CAAC;aAClB;QACH,CAAC,CAAC,CAAC;QACH,IAAI,CAAC,OAAO,CAAC,MAAM,GAAG,CAAC,CAAC;QACxB,IAAI,CAAC,QAAQ,CAAC,OAAO,EAAE,CAAC;IAC1B,CAAC;IACD;;OAEG,CACH,IAAI,GAAA;QACF,OAAO,IAAI,CAAC,OAAO,CAAC,MAAM,CAAC;IAC7B,CAAC;IAED;;;;;;OAMG,CACH,KAAK,CAAC,YAAsB,EAAE,YAAsB,EAAE,WAAW,GAAG,CAAC,CAAC,EAAA;QAEpE,IAAI,YAAY,KAAK,IAAI,CAAC,YAAY,EAAE;YACtC,MAAM,IAAI,KAAK,CAAC,CAAA,gCAAA,EACZ,YAAY,CAAA,oBAAA,EAAuB,IAAI,CAAC,YAAY,EAAE,CAAC,CAAC;SAC7D;QACD,IAAI,WAAW,KAAK,CAAC,CAAC,IAAI,IAAI,CAAC,OAAO,CAAC,MAAM,KAAK,WAAW,EAAE;YAC7D,MAAM,IAAI,KAAK,CAAC,CAAA,+BAAA,EACZ,WAAW,CAAA,8BAAA,EACX,IAAI,CAAC,OAAO,CAAC,MAAM,CAAA,UAAA,CAAY,CAAC,CAAC;SACtC;YACD,0VAAmC,EAC/B,YAAY,EAAE,IAAI,CAAC,YAAY,EAAE,6BAA6B,CAAC,CAAC;QACpE,MAAM,kBAAkB,OACpB,wUAAiB,EAAC,IAAI,CAAC,YAAY,EAAE,IAAI,CAAC,OAAO,EAAE,YAAY,CAAC,CAAC;QACrE,WAAO,iPAAI,EAAC,GAAG,EAAE;YACf,MAAM,eAAe,GACjB,IAAI,CAAC,OAAO,CAAC,GAAG,EAAC,MAAM,CAAC,EAAE,IAAC,2PAAO,EAAC,MAAM,EAAE,kBAAkB,CAAC,CAAC,CAAC;YACpE,WAAO,uPAAK,EAAC,eAAe,EAAE,CAAC,CAAC,CAAC;QACnC,CAAC,CAAC,CAAC;IACL,CAAC;IAED;;;;OAIG,CACH,OAAO,CAAC,YAAsB,EAAE,YAAsB,EAAA;QACpD,IAAI,YAAY,KAAK,IAAI,CAAC,YAAY,EAAE;YACtC,MAAM,IAAI,KAAK,CAAC,CAAA,gCAAA,EACZ,YAAY,CAAA,oBAAA,EAAuB,IAAI,CAAC,YAAY,EAAE,CAAC,CAAC;SAC7D;QAED,IAAI,IAAI,CAAC,IAAI,EAAE,KAAK,CAAC,EAAE;YACrB,MAAM,IAAI,KAAK,CAAC,mCAAmC,CAAC,CAAC;SACtD;QACD,MAAM,kBAAkB,OACpB,wUAAiB,EAAC,IAAI,CAAC,YAAY,EAAE,IAAI,CAAC,OAAO,EAAE,YAAY,CAAC,CAAC;QACrE,MAAM,MAAM,GAAG,IAAI,CAAC,OAAO,CAAC,GAAG,EAAE,CAAC;QAClC,MAAM,CAAC,IAAI,GAAG,KAAK,CAAC;YAEpB,0VAAmC,EAC/B,MAAM,CAAC,KAAK,EAAE,YAAY,EAAE,6BAA6B,CAAC,CAAC;QAE/D,WAAO,2PAAO,EAAC,MAAM,EAAE,kBAAkB,CAAC,CAAC;IAC7C,CAAC;IAED;;;OAGG,CACH,QAAQ,CAAC,MAAc,EAAA;QACrB,IAAI,MAAM,CAAC,KAAK,KAAK,IAAI,CAAC,YAAY,EAAE;YACtC,MAAM,IAAI,KAAK,CAAC,CAAA,gCAAA,EACZ,MAAM,CAAC,KAAK,CAAA,oBAAA,EAAuB,IAAI,CAAC,YAAY,EAAE,CAAC,CAAC;SAC7D;YAED,0VAAmC,EAC/B,MAAM,CAAC,KAAK,EAAE,IAAI,CAAC,YAAY,EAAE,6BAA6B,CAAC,CAAC;QAEpE,IAAI,IAAI,CAAC,cAAc,KAAK,IAAI,CAAC,IAAI,EAAE,EAAE;YACvC,MAAM,IAAI,KAAK,CAAC,CAAA,wCAAA,CAA0C,CAAC,CAAC;SAC7D;YACD,iPAAI,EAAC,MAAM,CAAC,CAAC;QACb,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;IAC5B,CAAC;IAED;;;OAGG,CACH,MAAM,CAAC,IAAY,EAAA;QACjB,IAAI,IAAI,GAAG,CAAC,EAAE;YACZ,MAAM,IAAI,KAAK,CACX,CAAA,uDAAA,EAA0D,IAAI,EAAE,CAAC,CAAC;SACvE;QAED,IAAI,IAAI,CAAC,cAAc,KAAK,CAAC,CAAC,IAAI,IAAI,GAAG,IAAI,CAAC,cAAc,EAAE;YAC5D,MAAM,IAAI,KAAK,CAAC,CAAA,4BAAA,EACZ,IAAI,CAAA,0BAAA,EAA6B,IAAI,CAAC,cAAc,CAAA,CAAA,CAAG,CAAC,CAAC;SAC9D;QAED,MAAM,cAAc,GAAe,IAAI,UAAU,CAC7C,EAAE,EAAE,IAAI,CAAC,YAAY,EAAE,IAAI,CAAC,YAAY,EAAE,IAAI,CAAC,cAAc,CAAC,CAAC;QACnE,cAAc,CAAC,OAAO,CAAC,MAAM,GAAG,IAAI,CAAC;QACrC,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,GAAG,CAAC,IAAI,CAAC,OAAO,CAAC,MAAM,EAAE,IAAI,CAAC,EAAE,EAAE,CAAC,CAAE;YAC5D,cAAc,CAAC,OAAO,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;SAC7C;QACD,OAAO,cAAc,CAAC;IACxB,CAAC;IAED;;;;;OAKG,CACH,OAAO,CAAC,YAAoB,EAAE,YAAsB,EAAE,YAAsB,EAAA;QAE1E,IAAI,YAAY,KAAK,IAAI,CAAC,YAAY,EAAE;YACtC,MAAM,IAAI,KAAK,CAAC,CAAA,gCAAA,EACZ,YAAY,CAAA,oBAAA,EAAuB,IAAI,CAAC,YAAY,EAAE,CAAC,CAAC;SAC7D;QACD,IAAI,YAAY,GAAG,CAAC,IAAI,YAAY,GAAG,IAAI,CAAC,OAAO,CAAC,MAAM,EAAE;YAC1D,MAAM,IAAI,KAAK,CAAC,CAAA,yBAAA,EACZ,YAAY,CAAA,gBAAA,EAAmB,IAAI,CAAC,OAAO,CAAC,MAAM,CAAA,UAAA,CAAY,CAAC,CAAC;SACrE;QAED,IAAI,IAAI,CAAC,OAAO,CAAC,YAAY,CAAC,IAAI,IAAI,EAAE;YACtC,MAAM,IAAI,KAAK,CAAC,CAAA,iBAAA,EAAoB,YAAY,CAAA,SAAA,CAAW,CAAC,CAAC;SAC9D;YAED,0VAAmC,EAC/B,IAAI,CAAC,OAAO,CAAC,YAAY,CAAC,CAAC,KAAK,EAAE,YAAY,EAC9C,6BAA6B,CAAC,CAAC;QACnC,MAAM,kBAAkB,OACpB,wUAAiB,EAAC,IAAI,CAAC,YAAY,EAAE,IAAI,CAAC,OAAO,EAAE,YAAY,CAAC,CAAC;QACrE,WAAO,2PAAO,EAAC,IAAI,CAAC,OAAO,CAAC,YAAY,CAAC,EAAE,kBAAkB,CAAC,CAAC;IACjE,CAAC;IAED;;;;OAIG,CACH,OAAO,CAAC,YAAoB,EAAE,MAAc,EAAA;QAC1C,IAAI,MAAM,CAAC,KAAK,KAAK,IAAI,CAAC,YAAY,EAAE;YACtC,MAAM,IAAI,KAAK,CAAC,CAAA,gCAAA,EACZ,MAAM,CAAC,KAAK,CAAA,oBAAA,EAAuB,IAAI,CAAC,YAAY,EAAE,CAAC,CAAC;SAC7D;QAED,IAAI,YAAY,GAAG,CAAC,IAChB,IAAI,CAAC,cAAc,KAAK,CAAC,CAAC,IAAI,YAAY,IAAI,IAAI,CAAC,cAAc,EAAE;YACrE,MAAM,IAAI,KAAK,CAAC,CAAA,sBAAA,EACZ,YAAY,CAAA,oBAAA,EAAuB,IAAI,CAAC,cAAc,CAAA,UAAA,CAAY,CAAC,CAAC;SACzE;YAED,0VAAmC,EAC/B,IAAI,CAAC,YAAY,EAAE,MAAM,CAAC,KAAK,EAAE,6BAA6B,CAAC,CAAC;YACpE,iPAAI,EAAC,MAAM,CAAC,CAAC;QAEb,iDAAiD;QACjD,IAAI,IAAI,CAAC,OAAO,CAAC,YAAY,CAAC,IAAI,IAAI,EAAE;YACtC,IAAI,CAAC,OAAO,CAAC,YAAY,CAAC,CAAC,IAAI,GAAG,KAAK,CAAC;SACzC;QAED,IAAI,CAAC,OAAO,CAAC,YAAY,CAAC,GAAG,MAAM,CAAC;IACtC,CAAC;IAED;;;;;;OAMG,CACH,MAAM,CAAC,OAAiB,EAAE,YAAsB,EAAE,YAAsB,EAAA;QAEtE,IAAI,YAAY,KAAK,IAAI,CAAC,YAAY,EAAE;YACtC,MAAM,IAAI,KAAK,CAAC,CAAA,gCAAA,EACZ,YAAY,CAAA,oBAAA,EAAuB,IAAI,CAAC,YAAY,EAAE,CAAC,CAAC;SAC7D;YAED,0VAAmC,EAC/B,IAAI,CAAC,YAAY,EAAE,YAAY,EAAE,6BAA6B,CAAC,CAAC;QAEpE,wEAAwE;QACxE,gCAAgC;QAChC,OAAO,GAAG,OAAO,CAAC,KAAK,CAAC,CAAC,EAAE,IAAI,CAAC,IAAI,EAAE,CAAC,CAAC;QACxC,MAAM,kBAAkB,OACpB,wUAAiB,EAAC,IAAI,CAAC,YAAY,EAAE,IAAI,CAAC,OAAO,EAAE,YAAY,CAAC,CAAC;QACrE,IAAI,OAAO,CAAC,MAAM,KAAK,CAAC,EAAE;YACxB,WAAO,yPAAM,EAAC,EAAE,EAAE;gBAAC,CAAC;aAAC,CAAC,MAAM,CAAC,kBAAkB,CAAC,CAAC,CAAC;SACnD;QAED,WAAO,iPAAI,EAAC,GAAG,EAAE;YACf,MAAM,OAAO,GACT,OAAO,CAAC,GAAG,EAAC,CAAC,CAAC,EAAE,IAAC,2PAAO,EAAC,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE,kBAAkB,CAAC,CAAC,CAAC;YACnE,WAAO,uPAAK,EAAC,OAAO,EAAE,CAAC,CAAC,CAAC;QAC3B,CAAC,CAAC,CAAC;IACL,CAAC;IAED;;;;OAIG,CACH,MAAM,CAAC,YAAsB,EAAE,YAAsB,EAAA;QACnD,IAAI,CAAC,CAAC,YAAY,IAAI,YAAY,KAAK,IAAI,CAAC,YAAY,EAAE;YACxD,MAAM,IAAI,KAAK,CAAC,CAAA,oBAAA,EACZ,IAAI,CAAC,YAAY,CAAA,4BAAA,EAA+B,YAAY,EAAE,CAAC,CAAC;SACrE;YAED,0VAAmC,EAC/B,IAAI,CAAC,YAAY,EAAE,YAAY,EAAE,6BAA6B,CAAC,CAAC;QACpE,MAAM,kBAAkB,OACpB,wUAAiB,EAAC,IAAI,CAAC,YAAY,EAAE,IAAI,CAAC,OAAO,EAAE,YAAY,CAAC,CAAC;QAErE,IAAI,IAAI,CAAC,IAAI,EAAE,KAAK,CAAC,EAAE;YACrB,WAAO,yPAAM,EAAC,EAAE,EAAE;gBAAC,CAAC;aAAC,CAAC,MAAM,CAAC,kBAAkB,CAAC,CAAC,CAAC;SACnD;QACD,WAAO,iPAAI,EAAC,GAAG,EAAE;YACf,MAAM,OAAO,GAAG,IAAI,CAAC,OAAO,CAAC,GAAG,EAAC,CAAC,CAAC,EAAE,IAAC,2PAAO,EAAC,CAAC,EAAE,kBAAkB,CAAC,CAAC,CAAC;YACtE,WAAO,yPAAM,EAAC,OAAO,EAAE,CAAC,CAAC,CAAC;QAC5B,CAAC,CAAC,CAAC;IACL,CAAC;CACF;AAOK,SAAU,UAAU,CACtB,MAAc,EAAE,YAAsB,EAAE,YAAsB;IAChE,MAAM,KAAK,GAAG,MAAM,CAAC,KAAK,CAAC;IAC3B,IAAI,MAAM,CAAC,KAAK,CAAC,MAAM,GAAG,CAAC,EAAE;QAC3B,MAAM,IAAI,KAAK,CACX,CAAA,iDAAA,EAAoD,MAAM,CAAC,KAAK,EAAE,CAAC,CAAC;KACzE;IACD,IAAI,MAAM,CAAC,KAAK,KAAK,YAAY,EAAE;QACjC,MAAM,IAAI,KAAK,CAAC,CAAA,gCAAA,EACZ,MAAM,CAAC,KAAK,CAAA,oBAAA,EAAuB,YAAY,EAAE,CAAC,CAAC;KACxD;IACD,MAAM,kBAAkB,GAAG,MAAM,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;QACjD,0VAAmC,EAC/B,kBAAkB,EAAE,YAAY,EAAE,6BAA6B,CAAC,CAAC;IACrE,MAAM,UAAU,OAAa,2PAAO,EAAC,MAAM,CAAC,CAAC;IAC7C,OAAO,IAAI,UAAU,CAAC,UAAU,EAAE,YAAY,EAAE,KAAK,CAAC,CAAC;AACzD,CAAC;AASK,SAAU,OAAO,CACnB,YAAsB,EAAE,YAAsB,EAAE,WAAmB,EACnE,cAAsB;IACxB,OAAO,IAAI,UAAU,CAAC,EAAE,EAAE,YAAY,EAAE,YAAY,EAAE,cAAc,CAAC,CAAC;AACxE,CAAC;AASK,SAAU,OAAO,CACnB,MAAc,EAAE,OAAiB,EAAE,YAAsB,EACzD,WAAoB;IACtB,IAAI,OAAO,CAAC,MAAM,KAAK,MAAM,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE;QACtC,MAAM,IAAI,KAAK,CAAC,CAAA,mDAAA,EACZ,OAAO,CAAC,MAAM,CAAA,KAAA,EAAQ,MAAM,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,CAAC;KAC9C;IAED,MAAM,QAAQ,GAAG,IAAI,CAAC,GAAG,CAAC,GAAG,OAAO,CAAC,CAAC;IAEtC,IAAI,WAAW,IAAI,IAAI,IAAI,WAAW,KAAK,CAAC,CAAC,IAAI,QAAQ,IAAI,WAAW,EAAE;QACxE,MAAM,IAAI,KAAK,CACX,CAAA,gCAAA,EAAmC,QAAQ,CAAA,MAAA,EAAS,WAAW,CAAA,CAAA,CAAG,CAAC,CAAC;KACzE;IAED,MAAM,IAAI,GAAG,IAAI,UAAU,CAAC,EAAE,EAAE,YAAY,EAAE,MAAM,CAAC,KAAK,EAAE,WAAW,CAAC,CAAC;IACzE,MAAM,OAAO,OAAG,2PAAO,EAAC,MAAM,EAAE,CAAC,CAAC,CAAC;IACnC,OAAO,CAAC,OAAO,CAAC,CAAC,KAAK,EAAE,KAAK,EAAE,EAAE;QAC/B,IAAI,CAAC,OAAO,CAAC,KAAK,EAAE,OAAO,CAAC,KAAK,CAAC,CAAC,CAAC;IACtC,CAAC,CAAC,CAAC;IACH,OAAO,IAAI,CAAC;AACd,CAAC;AASK,SAAU,KAAK,CACjB,MAAc,EAAE,MAAgB,EAAE,YAAsB;IAC1D,IAAI,WAAW,GAAG,CAAC,CAAC;IACpB,MAAM,iBAAiB,GAAG,MAAM,CAAC,GAAG,EAAC,GAAG,CAAC,EAAE;QACzC,WAAW,IAAI,GAAG,CAAC;QACnB,OAAO,WAAW,CAAC;IACrB,CAAC,CAAC,CAAC;IAEH,IAAI,WAAW,KAAK,MAAM,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE;QACnC,MAAM,IAAI,KAAK,CAAC,CAAA;;UAEV,WAAW,CAAA,yBAAA,EAA4B,MAAM,CAAC,KAAK,EAAE,CAAC,CAAC;KAC9D;IAED,MAAM,oBAAoB,GAAG,MAAM,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;IACnD,MAAM,kBAAkB,OACpB,wUAAiB,EAAC,oBAAoB,EAAE,YAAY,CAAC,CAAC;IAC1D,MAAM,aAAa,GAAG,WAAW,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC,IAAI,GAAG,WAAW,CAAC;IACxE,MAAM,OAAO,OAAa,iPAAI,EAAC,GAAG,EAAE;QAClC,MAAM,OAAO,GAAG,EAAE,CAAC;QACnB,MAAM,OAAG,2PAAO,EAAC,MAAM,EAAE;YAAC,CAAC;YAAE,WAAW;YAAE,aAAa;SAAC,CAAC,CAAC;QAC1D,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,CAAE;YACtC,MAAM,cAAc,GAAG,AAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,AAAC,CAAC,CAAC,CAAC,CAAC,iBAAiB,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC;YAChE,MAAM,OAAO,GAAG;gBAAC,CAAC;gBAAE,cAAc;gBAAE,CAAC;aAAC,CAAC;YACvC,MAAM,KAAK,GAAG;gBAAC,CAAC;gBAAE,MAAM,CAAC,CAAC,CAAC;gBAAE,aAAa;aAAC,CAAC;YAC5C,OAAO,CAAC,CAAC,CAAC,OAAG,2PAAO,MAChB,uPAAK,EAAC,MAAM,EAAE,OAAO,EAAE,KAAK,CAAC,EAAE,kBAA8B,CAAC,CAAC;SACpE;QACD,MAAM,CAAC,OAAO,EAAE,CAAC;QACjB,OAAO,OAAO,CAAC;IACjB,CAAC,CAAC,CAAC;IAEH,MAAM,IAAI,GAAG,IAAI,UAAU,CAAC,EAAE,EAAE,YAAY,EAAE,MAAM,CAAC,KAAK,EAAE,MAAM,CAAC,MAAM,CAAC,CAAC;IAE3E,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,OAAO,CAAC,MAAM,EAAE,CAAC,EAAE,CAAE;QACvC,IAAI,CAAC,OAAO,CAAC,CAAC,EAAE,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC;KAC7B;IACD,OAAO,IAAI,CAAC;AACd,CAAC"}},
    {"offset": {"line": 673, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-converter@4.22.0_@tensorflow+tfjs-core@4.22.0/node_modules/@tensorflow/tfjs-converter/dist/executor/hash_table.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-converter/src/executor/hash_table.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {DataType, keep, scalar, stack, Tensor, tidy, unstack, util} from '@tensorflow/tfjs-core';\n// tslint:disable-next-line: no-imports-from-dist\nimport * as tfOps from '@tensorflow/tfjs-core/dist/ops/ops_for_converter';\n\n/**\n * Hashtable contains a set of tensors, which can be accessed by key.\n */\nexport class HashTable {\n  readonly handle: Tensor;\n\n  // tslint:disable-next-line: no-any\n  private tensorMap: Map<any, Tensor>;\n\n  get id() {\n    return this.handle.id;\n  }\n\n  /**\n   * Constructor of HashTable. Creates a hash table.\n   *\n   * @param keyDType `dtype` of the table keys.\n   * @param valueDType `dtype` of the table values.\n   */\n  constructor(readonly keyDType: DataType, readonly valueDType: DataType) {\n    this.handle = scalar(0);\n    // tslint:disable-next-line: no-any\n    this.tensorMap = new Map<any, Tensor>();\n\n    keep(this.handle);\n  }\n\n  /**\n   * Dispose the tensors and handle and clear the hashtable.\n   */\n  clearAndClose() {\n    this.tensorMap.forEach(value => value.dispose());\n    this.tensorMap.clear();\n    this.handle.dispose();\n  }\n\n  /**\n   * The number of items in the hash table.\n   */\n  size(): number {\n    return this.tensorMap.size;\n  }\n\n  /**\n   * The number of items in the hash table as a rank-0 tensor.\n   */\n  tensorSize(): Tensor {\n    return tfOps.scalar(this.size(), 'int32');\n  }\n\n  /**\n   * Replaces the contents of the table with the specified keys and values.\n   * @param keys Keys to store in the hashtable.\n   * @param values Values to store in the hashtable.\n   */\n  async import(keys: Tensor, values: Tensor): Promise<Tensor> {\n    this.checkKeyAndValueTensor(keys, values);\n\n    // We only store the primitive values of the keys, this allows lookup\n    // to be O(1).\n    const $keys = await keys.data();\n\n    // Clear the hashTable before inserting new values.\n    this.tensorMap.forEach(value => value.dispose());\n    this.tensorMap.clear();\n\n    return tidy(() => {\n      const $values = unstack(values);\n\n      const keysLength = $keys.length;\n      const valuesLength = $values.length;\n\n      util.assert(\n          keysLength === valuesLength,\n          () => `The number of elements doesn't match, keys has ` +\n              `${keysLength} elements, the values has ${valuesLength} ` +\n              `elements.`);\n\n      for (let i = 0; i < keysLength; i++) {\n        const key = $keys[i];\n        const value = $values[i];\n\n        keep(value);\n        this.tensorMap.set(key, value);\n      }\n\n      return this.handle;\n    });\n  }\n\n  /**\n   * Looks up keys in a hash table, outputs the corresponding values.\n   *\n   * Performs batch lookups, for every element in the key tensor, `find`\n   * stacks the corresponding value into the return tensor.\n   *\n   * If an element is not present in the table, the given `defaultValue` is\n   * used.\n   *\n   * @param keys Keys to look up. Must have the same type as the keys of the\n   *     table.\n   * @param defaultValue The scalar `defaultValue` is the value output for keys\n   *     not present in the table. It must also be of the same type as the\n   *     table values.\n   */\n  async find(keys: Tensor, defaultValue: Tensor): Promise<Tensor> {\n    this.checkKeyAndValueTensor(keys, defaultValue);\n\n    const $keys = await keys.data();\n\n    return tidy(() => {\n      const result: Tensor[] = [];\n\n      for (let i = 0; i < $keys.length; i++) {\n        const key = $keys[i];\n\n        const value = this.findWithDefault(key, defaultValue);\n        result.push(value);\n      }\n\n      return stack(result);\n    });\n  }\n\n  // tslint:disable-next-line: no-any\n  private findWithDefault(key: any, defaultValue: Tensor): Tensor {\n    const result = this.tensorMap.get(key);\n\n    return result != null ? result : defaultValue;\n  }\n\n  private checkKeyAndValueTensor(key: Tensor, value: Tensor) {\n    if (key.dtype !== this.keyDType) {\n      throw new Error(\n          `Expect key dtype ${this.keyDType}, but got ` +\n          `${key.dtype}`);\n    }\n\n    if (value.dtype !== this.valueDType) {\n      throw new Error(\n          `Expect value dtype ${this.valueDType}, but got ` +\n          `${value.dtype}`);\n    }\n  }\n}\n"],"names":[],"mappings":";;;;AAAA;;;;;;;;;;;;;;;GAeG;;;;;AACH,OAAO,EAAW,IAAI,EAAE,MAAM,EAAE,KAAK,EAAU,IAAI,EAAE,OAAO,EAAE,IAAI,EAAC,MAAM,uBAAuB,CAAC;;;AAO3F,MAAO,SAAS;IAMpB,IAAI,EAAE,GAAA;QACJ,OAAO,IAAI,CAAC,MAAM,CAAC,EAAE,CAAC;IACxB,CAAC;IAED;;;;;OAKG,CACH,YAAqB,QAAkB,EAAW,UAAoB,CAAA;QAAjD,IAAA,CAAA,QAAQ,GAAR,QAAQ,CAAU;QAAW,IAAA,CAAA,UAAU,GAAV,UAAU,CAAU;QACpE,IAAI,CAAC,MAAM,OAAG,yPAAM,EAAC,CAAC,CAAC,CAAC;QACxB,mCAAmC;QACnC,IAAI,CAAC,SAAS,GAAG,IAAI,GAAG,EAAe,CAAC;YAExC,iPAAI,EAAC,IAAI,CAAC,MAAM,CAAC,CAAC;IACpB,CAAC;IAED;;OAEG,CACH,aAAa,GAAA;QACX,IAAI,CAAC,SAAS,CAAC,OAAO,EAAC,KAAK,CAAC,EAAE,AAAC,KAAK,CAAC,OAAO,EAAE,CAAC,CAAC;QACjD,IAAI,CAAC,SAAS,CAAC,KAAK,EAAE,CAAC;QACvB,IAAI,CAAC,MAAM,CAAC,OAAO,EAAE,CAAC;IACxB,CAAC;IAED;;OAEG,CACH,IAAI,GAAA;QACF,OAAO,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC;IAC7B,CAAC;IAED;;OAEG,CACH,UAAU,GAAA;QACR,OAAO,KAAK,CAAC,mPAAM,CAAC,IAAI,CAAC,IAAI,EAAE,EAAE,OAAO,CAAC,CAAC;IAC5C,CAAC;IAED;;;;OAIG,CACH,KAAK,CAAC,MAAM,CAAC,IAAY,EAAE,MAAc,EAAA;QACvC,IAAI,CAAC,sBAAsB,CAAC,IAAI,EAAE,MAAM,CAAC,CAAC;QAE1C,qEAAqE;QACrE,cAAc;QACd,MAAM,KAAK,GAAG,MAAM,IAAI,CAAC,IAAI,EAAE,CAAC;QAEhC,mDAAmD;QACnD,IAAI,CAAC,SAAS,CAAC,OAAO,EAAC,KAAK,CAAC,EAAE,AAAC,KAAK,CAAC,OAAO,EAAE,CAAC,CAAC;QACjD,IAAI,CAAC,SAAS,CAAC,KAAK,EAAE,CAAC;QAEvB,WAAO,iPAAI,EAAC,GAAG,EAAE;YACf,MAAM,OAAO,OAAG,2PAAO,EAAC,MAAM,CAAC,CAAC;YAEhC,MAAM,UAAU,GAAG,KAAK,CAAC,MAAM,CAAC;YAChC,MAAM,YAAY,GAAG,OAAO,CAAC,MAAM,CAAC;YAEpC,8QAAI,CAAC,MAAM,CACP,UAAU,KAAK,YAAY,EAC3B,GAAG,CAAG,CAAD,AAAC,+CAAA,CAAiD,GACnD,GAAG,UAAU,CAAA,0BAAA,EAA6B,YAAY,CAAA,CAAA,CAAG,GACzD,CAAA,SAAA,CAAW,CAAC,CAAC;YAErB,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,UAAU,EAAE,CAAC,EAAE,CAAE;gBACnC,MAAM,GAAG,GAAG,KAAK,CAAC,CAAC,CAAC,CAAC;gBACrB,MAAM,KAAK,GAAG,OAAO,CAAC,CAAC,CAAC,CAAC;oBAEzB,iPAAI,EAAC,KAAK,CAAC,CAAC;gBACZ,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,GAAG,EAAE,KAAK,CAAC,CAAC;aAChC;YAED,OAAO,IAAI,CAAC,MAAM,CAAC;QACrB,CAAC,CAAC,CAAC;IACL,CAAC;IAED;;;;;;;;;;;;;;OAcG,CACH,KAAK,CAAC,IAAI,CAAC,IAAY,EAAE,YAAoB,EAAA;QAC3C,IAAI,CAAC,sBAAsB,CAAC,IAAI,EAAE,YAAY,CAAC,CAAC;QAEhD,MAAM,KAAK,GAAG,MAAM,IAAI,CAAC,IAAI,EAAE,CAAC;QAEhC,WAAO,iPAAI,EAAC,GAAG,EAAE;YACf,MAAM,MAAM,GAAa,EAAE,CAAC;YAE5B,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,KAAK,CAAC,MAAM,EAAE,CAAC,EAAE,CAAE;gBACrC,MAAM,GAAG,GAAG,KAAK,CAAC,CAAC,CAAC,CAAC;gBAErB,MAAM,KAAK,GAAG,IAAI,CAAC,eAAe,CAAC,GAAG,EAAE,YAAY,CAAC,CAAC;gBACtD,MAAM,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;aACpB;YAED,WAAO,uPAAK,EAAC,MAAM,CAAC,CAAC;QACvB,CAAC,CAAC,CAAC;IACL,CAAC;IAED,mCAAmC;IAC3B,eAAe,CAAC,GAAQ,EAAE,YAAoB,EAAA;QACpD,MAAM,MAAM,GAAG,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC;QAEvC,OAAO,MAAM,IAAI,IAAI,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC,YAAY,CAAC;IAChD,CAAC;IAEO,sBAAsB,CAAC,GAAW,EAAE,KAAa,EAAA;QACvD,IAAI,GAAG,CAAC,KAAK,KAAK,IAAI,CAAC,QAAQ,EAAE;YAC/B,MAAM,IAAI,KAAK,CACX,CAAA,iBAAA,EAAoB,IAAI,CAAC,QAAQ,CAAA,UAAA,CAAY,GAC7C,GAAG,GAAG,CAAC,KAAK,EAAE,CAAC,CAAC;SACrB;QAED,IAAI,KAAK,CAAC,KAAK,KAAK,IAAI,CAAC,UAAU,EAAE;YACnC,MAAM,IAAI,KAAK,CACX,CAAA,mBAAA,EAAsB,IAAI,CAAC,UAAU,CAAA,UAAA,CAAY,GACjD,GAAG,KAAK,CAAC,KAAK,EAAE,CAAC,CAAC;SACvB;IACH,CAAC;CACF"}},
    {"offset": {"line": 805, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-converter@4.22.0_@tensorflow+tfjs-core@4.22.0/node_modules/@tensorflow/tfjs-converter/dist/executor/execution_context.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-converter/src/executor/execution_context.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Tensor} from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap, TensorArrayMap, TensorListMap} from '../data/types';\n\nimport {TensorArray} from './tensor_array';\nimport {TensorList} from './tensor_list';\nimport {FunctionExecutor} from './types';\n\nexport interface ExecutionContextInfo {\n  id: number;           // the unique id of the context info\n  frameName: string;    // The frame name of the loop, this comes from\n                        // the TensorFlow NodeDef.\n  iterationId: number;  // The iteration id of the loop\n}\n\n/**\n * ExecutionContext captures the runtime environment of the node. It keeps\n * track of the current frame and iteration for the control flow ops.\n *\n * For example, typical Dynamic RNN model may contain loops, for which\n * TensorFlow will generate graphs with Enter/Exit nodes to control the\n * current execution frame, and NextIteration Nodes for iteration id increment.\n * For model with branch logic, TensorFLow will generate Switch/Merge ops.\n */\nexport class ExecutionContext {\n  private rootContext = {id: 0, frameName: '', iterationId: 0};\n  private contexts: ExecutionContextInfo[] = [this.rootContext];\n  private lastId = 0;\n  private _currentContextIds: string[];\n\n  constructor(\n      readonly weightMap: NamedTensorsMap = {},\n      readonly tensorArrayMap: TensorArrayMap = {},\n      readonly tensorListMap: TensorListMap = {},\n      readonly functionMap: {[key: string]: FunctionExecutor} = {},\n      readonly parseNodeNameCache?: Map<string, [string, number, string?]>) {\n    this.generateCurrentContextIds();\n  }\n\n  private newFrame(id: number, frameName: string) {\n    return {id, frameName, iterationId: 0};\n  }\n\n  /**\n   * Set the current context\n   * @param contexts: ExecutionContextInfo[] the current path of execution\n   * frames\n   */\n  set currentContext(contexts: ExecutionContextInfo[]) {\n    if (this.contexts !== contexts) {\n      this.contexts = contexts;\n      this.generateCurrentContextIds();\n    }\n  }\n\n  get currentContext(): ExecutionContextInfo[] {\n    return this.contexts;\n  }\n\n  /**\n   * Returns the current context in string format.\n   */\n  get currentContextId(): string {\n    return this._currentContextIds[0];\n  }\n\n  /**\n   * Returns the current context and all parent contexts in string format.\n   * This allow access to the nodes in the current and parent frames.\n   */\n  get currentContextIds(): string[] {\n    return this._currentContextIds;\n  }\n\n  private generateCurrentContextIds() {\n    const names = [];\n    for (let i = 0; i < this.contexts.length - 1; i++) {\n      const contexts = this.contexts.slice(0, this.contexts.length - i);\n      names.push(this.contextIdforContexts(contexts));\n    }\n    names.push('');\n    this._currentContextIds = names;\n  }\n\n  private contextIdforContexts(contexts: ExecutionContextInfo[]) {\n    return contexts ?\n        contexts\n            .map(\n                context => (context.id === 0 && context.iterationId === 0) ?\n                    '' :\n                    `${context.frameName}-${context.iterationId}`)\n            .join('/') :\n        '';\n  }\n\n  /**\n   * Enter a new frame, a new context is pushed on the current context list.\n   * @param frameId new frame id\n   */\n  enterFrame(frameId: string) {\n    if (this.contexts) {\n      this.lastId++;\n      this.contexts = this.contexts.slice();\n      this.contexts.push(this.newFrame(this.lastId, frameId));\n      this._currentContextIds.unshift(this.contextIdforContexts(this.contexts));\n    }\n  }\n\n  /**\n   * Exit the current frame, the last context is removed from the current\n   * context list.\n   */\n  exitFrame() {\n    if (this.contexts && this.contexts.length > 1) {\n      this.contexts = this.contexts.slice();\n      this.contexts.splice(-1);\n      this.currentContextIds.shift();\n    } else {\n      throw new Error('Cannot exit frame, the context is empty');\n    }\n  }\n\n  /**\n   * Enter the next iteration of a loop, the iteration id of last context is\n   * increased.\n   */\n  nextIteration() {\n    if (this.contexts && this.contexts.length > 0) {\n      this.contexts = this.contexts.slice();\n      this.lastId++;\n      const context =\n          Object.assign({}, this.contexts[this.contexts.length - 1]);\n      context.iterationId += 1;\n      context.id = this.lastId;\n      this.contexts.splice(-1, 1, context);\n      this._currentContextIds.splice(\n          0, 1, this.contextIdforContexts(this.contexts));\n    } else {\n      throw new Error('Cannot increase frame iteration, the context is empty');\n    }\n  }\n\n  getWeight(name: string): Tensor[] {\n    return this.weightMap[name];\n  }\n\n  addTensorArray(tensorArray: TensorArray) {\n    this.tensorArrayMap[tensorArray.id] = tensorArray;\n  }\n\n  getTensorArray(id: number): TensorArray {\n    return this.tensorArrayMap[id];\n  }\n\n  addTensorList(tensorList: TensorList) {\n    this.tensorListMap[tensorList.id] = tensorList;\n  }\n\n  getTensorList(id: number): TensorList {\n    return this.tensorListMap[id];\n  }\n\n  dispose(keepIds: Set<number>) {\n    for (const key in this.tensorArrayMap) {\n      this.tensorArrayMap[key].clearAndClose(keepIds);\n    }\n\n    for (const key in this.tensorListMap) {\n      this.tensorListMap[key].clearAndClose(keepIds);\n    }\n  }\n}\n"],"names":[],"mappings":"AA+BA;;;;;;;;GAQG;;;;AACG,MAAO,gBAAgB;IAM3B,YACa,YAA6B,CAAA,CAAE,EAC/B,iBAAiC,CAAA,CAAE,EACnC,gBAA+B,CAAA,CAAE,EACjC,cAAiD,CAAA,CAAE,EACnD,kBAA2D,CAAA;QAJ3D,IAAA,CAAA,SAAS,GAAT,SAAS,CAAsB;QAC/B,IAAA,CAAA,cAAc,GAAd,cAAc,CAAqB;QACnC,IAAA,CAAA,aAAa,GAAb,aAAa,CAAoB;QACjC,IAAA,CAAA,WAAW,GAAX,WAAW,CAAwC;QACnD,IAAA,CAAA,kBAAkB,GAAlB,kBAAkB,CAAyC;QAVhE,IAAA,CAAA,WAAW,GAAG;YAAC,EAAE,EAAE,CAAC;YAAE,SAAS,EAAE,EAAE;YAAE,WAAW,EAAE,CAAC;QAAA,CAAC,CAAC;QACrD,IAAA,CAAA,QAAQ,GAA2B;YAAC,IAAI,CAAC,WAAW;SAAC,CAAC;QACtD,IAAA,CAAA,MAAM,GAAG,CAAC,CAAC;QASjB,IAAI,CAAC,yBAAyB,EAAE,CAAC;IACnC,CAAC;IAEO,QAAQ,CAAC,EAAU,EAAE,SAAiB,EAAA;QAC5C,OAAO;YAAC,EAAE;YAAE,SAAS;YAAE,WAAW,EAAE,CAAC;QAAA,CAAC,CAAC;IACzC,CAAC;IAED;;;;OAIG,CACH,IAAI,cAAc,CAAC,QAAgC,EAAA;QACjD,IAAI,IAAI,CAAC,QAAQ,KAAK,QAAQ,EAAE;YAC9B,IAAI,CAAC,QAAQ,GAAG,QAAQ,CAAC;YACzB,IAAI,CAAC,yBAAyB,EAAE,CAAC;SAClC;IACH,CAAC;IAED,IAAI,cAAc,GAAA;QAChB,OAAO,IAAI,CAAC,QAAQ,CAAC;IACvB,CAAC;IAED;;OAEG,CACH,IAAI,gBAAgB,GAAA;QAClB,OAAO,IAAI,CAAC,kBAAkB,CAAC,CAAC,CAAC,CAAC;IACpC,CAAC;IAED;;;OAGG,CACH,IAAI,iBAAiB,GAAA;QACnB,OAAO,IAAI,CAAC,kBAAkB,CAAC;IACjC,CAAC;IAEO,yBAAyB,GAAA;QAC/B,MAAM,KAAK,GAAG,EAAE,CAAC;QACjB,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,QAAQ,CAAC,MAAM,GAAG,CAAC,EAAE,CAAC,EAAE,CAAE;YACjD,MAAM,QAAQ,GAAG,IAAI,CAAC,QAAQ,CAAC,KAAK,CAAC,CAAC,EAAE,IAAI,CAAC,QAAQ,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;YAClE,KAAK,CAAC,IAAI,CAAC,IAAI,CAAC,oBAAoB,CAAC,QAAQ,CAAC,CAAC,CAAC;SACjD;QACD,KAAK,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC;QACf,IAAI,CAAC,kBAAkB,GAAG,KAAK,CAAC;IAClC,CAAC;IAEO,oBAAoB,CAAC,QAAgC,EAAA;QAC3D,OAAO,QAAQ,CAAC,CAAC,CACb,QAAQ,CACH,GAAG,EACA,OAAO,CAAC,EAAE,AAAC,AAAC,OAAO,CAAC,EAAE,KAAK,CAAC,IAAI,OAAO,CAAC,WAAW,KAAK,CAAC,CAAC,CAAC,CAAC,AACxD,EAAE,CAAC,CAAC,CACJ,GAAG,OAAO,CAAC,SAAS,CAAA,CAAA,EAAI,OAAO,CAAC,WAAW,EAAE,CAAC,CACrD,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC,CAChB,EAAE,CAAC;IACT,CAAC;IAED;;;OAGG,CACH,UAAU,CAAC,OAAe,EAAA;QACxB,IAAI,IAAI,CAAC,QAAQ,EAAE;YACjB,IAAI,CAAC,MAAM,EAAE,CAAC;YACd,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC,QAAQ,CAAC,KAAK,EAAE,CAAC;YACtC,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAC,MAAM,EAAE,OAAO,CAAC,CAAC,CAAC;YACxD,IAAI,CAAC,kBAAkB,CAAC,OAAO,CAAC,IAAI,CAAC,oBAAoB,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC;SAC3E;IACH,CAAC;IAED;;;OAGG,CACH,SAAS,GAAA;QACP,IAAI,IAAI,CAAC,QAAQ,IAAI,IAAI,CAAC,QAAQ,CAAC,MAAM,GAAG,CAAC,EAAE;YAC7C,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC,QAAQ,CAAC,KAAK,EAAE,CAAC;YACtC,IAAI,CAAC,QAAQ,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC;YACzB,IAAI,CAAC,iBAAiB,CAAC,KAAK,EAAE,CAAC;SAChC,MAAM;YACL,MAAM,IAAI,KAAK,CAAC,yCAAyC,CAAC,CAAC;SAC5D;IACH,CAAC;IAED;;;OAGG,CACH,aAAa,GAAA;QACX,IAAI,IAAI,CAAC,QAAQ,IAAI,IAAI,CAAC,QAAQ,CAAC,MAAM,GAAG,CAAC,EAAE;YAC7C,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC,QAAQ,CAAC,KAAK,EAAE,CAAC;YACtC,IAAI,CAAC,MAAM,EAAE,CAAC;YACd,MAAM,OAAO,GACT,MAAM,CAAC,MAAM,CAAC,CAAA,CAAE,EAAE,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAC,QAAQ,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC,CAAC;YAC/D,OAAO,CAAC,WAAW,IAAI,CAAC,CAAC;YACzB,OAAO,CAAC,EAAE,GAAG,IAAI,CAAC,MAAM,CAAC;YACzB,IAAI,CAAC,QAAQ,CAAC,MAAM,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,OAAO,CAAC,CAAC;YACrC,IAAI,CAAC,kBAAkB,CAAC,MAAM,CAC1B,CAAC,EAAE,CAAC,EAAE,IAAI,CAAC,oBAAoB,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC;SACrD,MAAM;YACL,MAAM,IAAI,KAAK,CAAC,uDAAuD,CAAC,CAAC;SAC1E;IACH,CAAC;IAED,SAAS,CAAC,IAAY,EAAA;QACpB,OAAO,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,CAAC;IAC9B,CAAC;IAED,cAAc,CAAC,WAAwB,EAAA;QACrC,IAAI,CAAC,cAAc,CAAC,WAAW,CAAC,EAAE,CAAC,GAAG,WAAW,CAAC;IACpD,CAAC;IAED,cAAc,CAAC,EAAU,EAAA;QACvB,OAAO,IAAI,CAAC,cAAc,CAAC,EAAE,CAAC,CAAC;IACjC,CAAC;IAED,aAAa,CAAC,UAAsB,EAAA;QAClC,IAAI,CAAC,aAAa,CAAC,UAAU,CAAC,EAAE,CAAC,GAAG,UAAU,CAAC;IACjD,CAAC;IAED,aAAa,CAAC,EAAU,EAAA;QACtB,OAAO,IAAI,CAAC,aAAa,CAAC,EAAE,CAAC,CAAC;IAChC,CAAC;IAED,OAAO,CAAC,OAAoB,EAAA;QAC1B,IAAK,MAAM,GAAG,IAAI,IAAI,CAAC,cAAc,CAAE;YACrC,IAAI,CAAC,cAAc,CAAC,GAAG,CAAC,CAAC,aAAa,CAAC,OAAO,CAAC,CAAC;SACjD;QAED,IAAK,MAAM,GAAG,IAAI,IAAI,CAAC,aAAa,CAAE;YACpC,IAAI,CAAC,aAAa,CAAC,GAAG,CAAC,CAAC,aAAa,CAAC,OAAO,CAAC,CAAC;SAChD;IACH,CAAC;CACF"}},
    {"offset": {"line": 945, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-converter@4.22.0_@tensorflow+tfjs-core@4.22.0/node_modules/@tensorflow/tfjs-converter/dist/executor/model_analysis.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-converter/src/executor/model_analysis.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {NamedTensorMap} from '@tensorflow/tfjs-core';\n\nimport {NamedTensorsMap} from '../data/types';\nimport {parseNodeName} from '../operations/executors/utils';\nimport {Graph, Node} from '../operations/types';\n\nexport interface ExecutionInfo {\n  inputs: NamedTensorMap;\n  outputs: Node[];\n  usedNodes: Set<string>;\n  missingInputs: string[];\n  dynamicNode: Node;\n  syncInputs: string[];\n}\n\n/**\n * Given graph inputs and desired outputs, find the minimal set of nodes\n * to execute in order to compute the outputs. In addition return other useful\n * info such:\n * - Missing inputs needed to compute the output.\n * - Whether the subgraph contains dynamic ops (control flow, dynamic shape).\n * - Alternative inputs in order to avoid async (dynamic op) execution.\n */\nexport function getExecutionSubgraph(\n    inputs: NamedTensorMap, outputs: Node[], weightMap: NamedTensorsMap,\n    initNodes?: Node[]): ExecutionInfo {\n  const usedNodes = new Set<string>();\n  const missingInputs: string[] = [];\n  let dynamicNode: Node = null;\n  let syncInputs: string[] = null;\n\n  // Start with the outputs, going backwards and find all the nodes that are\n  // needed to compute those outputs.\n  const seen = new Set<string>();\n  const inputNodeNames =\n      new Set(Object.keys(inputs).map((name) => parseNodeName(name)[0]));\n\n  initNodes = initNodes || [];\n  const initNodeNames =\n      new Set(initNodes.map((node) => parseNodeName(node.name)[0]));\n\n  const frontier = [...outputs];\n  while (frontier.length > 0) {\n    const node = frontier.pop();\n    if (isControlFlow(node) || isDynamicShape(node) || isHashTable(node)) {\n      if (dynamicNode == null) {\n        dynamicNode = node;\n        syncInputs = dynamicNode.children.map(child => child.name)\n                         .filter(name => usedNodes.has(name));\n      }\n    }\n    usedNodes.add(node.name);\n\n    // Weights are dead end since we already have their values.\n    if (weightMap[node.name] != null) {\n      continue;\n    }\n    // This node is a dead end since it's one of the user-provided inputs.\n    if (inputNodeNames.has(node.name)) {\n      continue;\n    }\n    // This node is a dead end since it doesn't have any inputs.\n    if (initNodeNames.has(node.name)) {\n      continue;\n    }\n    if (node.inputs.length === 0) {\n      missingInputs.push(node.name);\n      continue;\n    }\n    node.inputs.forEach(input => {\n      // Don't add to the frontier if it is already there.\n      if (seen.has(input.name)) {\n        return;\n      }\n      seen.add(input.name);\n      frontier.push(input);\n    });\n  }\n  return {inputs, outputs, usedNodes, missingInputs, dynamicNode, syncInputs};\n}\n\n/**\n * Given the execution info, return a list of nodes in topological order that\n * need to be executed to compute the output.\n */\nexport function getNodesInTopologicalOrder(\n    graph: Graph, executionInfo: ExecutionInfo): Node[] {\n  const {usedNodes, inputs} = executionInfo;\n  const inputNodes = Object.keys(inputs)\n                         .map(name => parseNodeName(name)[0])\n                         .map(name => graph.nodes[name]);\n  const initNodes = graph.initNodes || [];\n\n  const isUsed = (node: Node|string) =>\n      usedNodes.has(typeof node === 'string' ? node : node.name);\n\n  function unique(nodes: Node[]): Node[] {\n    return [...new Map(nodes.map((node) => [node.name, node])).values()];\n  }\n  const predefinedNodes = unique([\n                            ...inputNodes,\n                            ...graph.weights,\n                            ...initNodes,\n                          ]).filter(isUsed);\n  const allNodes = unique([\n                     ...predefinedNodes,\n                     ...Object.values(graph.nodes),\n                   ]).filter(isUsed);\n  const nameToNode =\n      new Map<string, Node>(allNodes.map((node) => [node.name, node]));\n\n  const inCounts: Record<string, number> = {};\n  for (const node of allNodes) {\n    inCounts[node.name] = inCounts[node.name] || 0;\n    for (const child of node.children) {\n      // When the child is unused, set in counts to infinity so that it will\n      // never be decreased to 0 and added to the execution list.\n      if (!isUsed(child)) {\n        inCounts[child.name] = Number.POSITIVE_INFINITY;\n      }\n      inCounts[child.name] = (inCounts[child.name] || 0) + 1;\n    }\n  }\n\n  // Build execution order for all used nodes regardless whether they are\n  // predefined or not.\n  const frontier = Object.entries(inCounts)\n                       .filter(([, inCount]) => inCount === 0)\n                       .map(([name]) => name);\n  const orderedNodeNames = [...frontier];\n  while (frontier.length > 0) {\n    const nodeName = frontier.pop();\n    const node = nameToNode.get(nodeName)!;\n    for (const child of node.children.filter(isUsed)) {\n      if (--inCounts[child.name] === 0) {\n        orderedNodeNames.push(child.name);\n        frontier.push(child.name);\n      }\n    }\n  }\n\n  const orderedNodes = orderedNodeNames.map((name) => nameToNode.get(name));\n  const filteredOrderedNodes =\n      filterPredefinedReachableNodes(orderedNodes, predefinedNodes);\n\n  // TODO: Turn validation on/off with tf env flag.\n  validateNodesExecutionOrder(filteredOrderedNodes, predefinedNodes);\n\n  return filteredOrderedNodes;\n}\n\n/**\n * This is a helper function of `getNodesInTopologicalOrder`.\n * Returns ordered nodes reachable by at least one predefined node.\n * This can help us filter out redundant nodes from the returned node list.\n * For example:\n * If we have four nodes with dependencies like this:\n *   a --> b --> c --> d\n * when node `c` is predefined (e.g. given as an input tensor), we can\n * skip node `a` and `b` since their outputs will never be used.\n *\n * @param orderedNodes Graph nodes in execution order.\n * @param predefinedNodes Graph inputs, weights, and init nodes. Nodes in this\n *     list must have distinct names.\n */\nfunction filterPredefinedReachableNodes(\n    orderedNodes: Node[], predefinedNodes: Node[]) {\n  const nameToNode =\n      new Map<string, Node>(orderedNodes.map((node) => [node.name, node]));\n\n  // TODO: Filter out more nodes when >=2 nodes are predefined in a path.\n  const stack = predefinedNodes.map((node) => node.name);\n  const predefinedReachableNodeNames = new Set(stack);\n  // Perform a DFS starting from the set of all predefined nodes\n  // to find the set of all nodes reachable from the predefined nodes.\n  while (stack.length > 0) {\n    const nodeName = stack.pop();\n    const node = nameToNode.get(nodeName)!;\n    for (const child of node.children) {\n      if (!nameToNode.has(child.name) ||\n          predefinedReachableNodeNames.has(child.name)) {\n        continue;\n      }\n      predefinedReachableNodeNames.add(child.name);\n      stack.push(child.name);\n    }\n  }\n\n  // Filter out unreachable nodes and build the ordered node list.\n  const filteredOrderedNodes = orderedNodes.filter(\n      (node) => predefinedReachableNodeNames.has(node.name));\n\n  return filteredOrderedNodes;\n}\n\nclass NodesExecutionOrderError extends Error {\n  constructor(message: string) {\n    super(`NodesExecutionOrderError: ${message}`);\n  }\n}\n\n/**\n * This is a helper function of `getNodesInTopologicalOrder`.\n * Validates property: given nodes `a` and `b`, Order(a) > Order(b) if `a`\n * is a child of `b`. This function throws an error if validation fails.\n *\n * @param orderedNodes Graph nodes in execution order.\n * @param predefinedNodes Graph inputs, weights, and init nodes. Nodes in this\n *     list must have distinct names.\n */\nfunction validateNodesExecutionOrder(\n    orderedNodes: Node[], predefinedNodes: Node[]) {\n  const nodeNameToOrder = new Map<string, number>(\n      orderedNodes.map((node, order) => [node.name, order]));\n  const predefinedNodeNames = new Set(predefinedNodes.map((node) => node.name));\n  const isPredefined = (node: Node|string) =>\n      predefinedNodeNames.has(typeof node === 'string' ? node : node.name);\n  const willBeExecutedNodeNames =\n      new Set(orderedNodes.map((node) => node.name));\n  const willBeExecuted = (node: Node|string) =>\n      willBeExecutedNodeNames.has(typeof node === 'string' ? node : node.name);\n\n  for (const node of orderedNodes) {\n    for (const child of node.children.filter(willBeExecuted)) {\n      if (!nodeNameToOrder.has(child.name)) {\n        throw new NodesExecutionOrderError(\n            `Child ${child.name} of node ${node.name} is unreachable.`);\n      }\n      if (nodeNameToOrder.get(node.name) > nodeNameToOrder.get(child.name)) {\n        throw new NodesExecutionOrderError(`Node ${\n            node.name} is scheduled to run after its child ${child.name}.`);\n      }\n    }\n    if (!isPredefined(node)) {\n      for (const input of node.inputs) {\n        if (!nodeNameToOrder.has(input.name)) {\n          throw new NodesExecutionOrderError(\n              `Input ${input.name} of node ${node.name} is unreachable.`);\n        }\n        if (nodeNameToOrder.get(input.name) > nodeNameToOrder.get(node.name)) {\n          throw new NodesExecutionOrderError(`Node ${\n              node.name} is scheduled to run before its input ${input.name}.`);\n        }\n      }\n    }\n  }\n}\n\n/**\n * Given the execution info, return a map from node name to the disposable\n * node name list after its execution.\n *\n * @returns A map from node name to disposable nodes after its\n *     execution. That is, for a node `x`, `nodeLiveUntilMap[x]` indicates\n *     all nodes which their intermediate tensors should be disposed after `x`\n *     being executed.\n */\nexport function getNodeLiveUntilMap(orderedNodes: Node[]): Map<string, Node[]> {\n  const nodeNameToOrder = new Map<string, number>(\n      orderedNodes.map((node, order) => [node.name, order]));\n\n  const INF_LIFE = Number.MAX_SAFE_INTEGER;\n  // Make control flow nodes (and consequently their direct parents)\n  // live forever since they're tricky to track correctly.\n  const selfLifespans = orderedNodes.map(\n      (node, nodeOrder) => isControlFlow(node) ? INF_LIFE : nodeOrder);\n  const getSelfLifeSpan = (node: Node) => {\n    const selfLife = selfLifespans[nodeNameToOrder.get(node.name)!];\n    if (selfLife == null) {\n      // If nodeToOrder does not contain the node, it is unused or\n      // unreachable in graph.\n      return -1;\n    }\n    return selfLife;\n  };\n\n  // `liveUntil[i]` points to the last node in the `orderedNodes` array that\n  // may depend on tensors from node `i`. It indicates that all the\n  // intermediate tensors from `orderedNodes[i]` should be disposed after\n  // `orderedNodes[liveUntil[i]]` is executed.\n  // A node lives long enough to pass on its tensors to its children.\n  // It lives until at least `max(node's position, children's positions)`.\n  const liveUntilOrders = orderedNodes.map((node, nodeOrder) => {\n    return node.children.map(getSelfLifeSpan)\n        .reduce((a, b) => Math.max(a, b), selfLifespans[nodeOrder]);\n  });\n\n  // liveUntilMap:\n  // - Key: Name of a node `x`\n  // - Values: All nodes whose intermediate tensors should be disposed\n  //           after `x` is executed.\n  const liveUntilMap = new Map<string, Node[]>();\n  for (let nodeOrder = 0; nodeOrder < orderedNodes.length; ++nodeOrder) {\n    const liveUntilOrder = liveUntilOrders[nodeOrder];\n    if (liveUntilOrder === INF_LIFE) {\n      continue;\n    }\n    const node = orderedNodes[nodeOrder];\n    const liveUntilNode = orderedNodes[liveUntilOrder];\n    if (!liveUntilMap.has(liveUntilNode.name)) {\n      liveUntilMap.set(liveUntilNode.name, []);\n    }\n    liveUntilMap.get(liveUntilNode.name)!.push(node);\n  }\n  return liveUntilMap;\n}\n\nconst CONTROL_FLOW_OPS = new Set([\n  'Switch', 'Merge', 'Enter', 'Exit', 'NextIteration', 'StatelessIf',\n  'StatelessWhile', 'if', 'While'\n]);\nconst DYNAMIC_SHAPE_OPS = new Set([\n  'NonMaxSuppressionV2', 'NonMaxSuppressionV3', 'NonMaxSuppressionV5', 'Where'\n]);\nconst HASH_TABLE_OPS = new Set([\n  'HashTable', 'HashTableV2', 'LookupTableImport', 'LookupTableImportV2',\n  'LookupTableFind', 'LookupTableFindV2', 'LookupTableSize', 'LookupTableSizeV2'\n]);\n\nexport function isControlFlow(node: Node) {\n  return CONTROL_FLOW_OPS.has(node.op);\n}\n\nexport function isDynamicShape(node: Node) {\n  return DYNAMIC_SHAPE_OPS.has(node.op);\n}\n\nexport function isHashTable(node: Node) {\n  return HASH_TABLE_OPS.has(node.op);\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;AAAA;;;;;;;;;;;;;;;GAeG,CAKH,OAAO,EAAC,aAAa,EAAC,MAAM,+BAA+B,CAAC;;AAoBtD,SAAU,oBAAoB,CAChC,MAAsB,EAAE,OAAe,EAAE,SAA0B,EACnE,SAAkB;IACpB,MAAM,SAAS,GAAG,IAAI,GAAG,EAAU,CAAC;IACpC,MAAM,aAAa,GAAa,EAAE,CAAC;IACnC,IAAI,WAAW,GAAS,IAAI,CAAC;IAC7B,IAAI,UAAU,GAAa,IAAI,CAAC;IAEhC,0EAA0E;IAC1E,mCAAmC;IACnC,MAAM,IAAI,GAAG,IAAI,GAAG,EAAU,CAAC;IAC/B,MAAM,cAAc,GAChB,IAAI,GAAG,CAAC,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,GAAG,CAAC,CAAC,IAAI,EAAE,EAAE,GAAC,4UAAa,EAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;IAEvE,SAAS,GAAG,SAAS,IAAI,EAAE,CAAC;IAC5B,MAAM,aAAa,GACf,IAAI,GAAG,CAAC,SAAS,CAAC,GAAG,CAAC,CAAC,IAAI,EAAE,EAAE,GAAC,4UAAa,EAAC,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;IAElE,MAAM,QAAQ,GAAG,CAAC;WAAG,OAAO;KAAC,CAAC;IAC9B,MAAO,QAAQ,CAAC,MAAM,GAAG,CAAC,CAAE;QAC1B,MAAM,IAAI,GAAG,QAAQ,CAAC,GAAG,EAAE,CAAC;QAC5B,IAAI,aAAa,CAAC,IAAI,CAAC,IAAI,cAAc,CAAC,IAAI,CAAC,IAAI,WAAW,CAAC,IAAI,CAAC,EAAE;YACpE,IAAI,WAAW,IAAI,IAAI,EAAE;gBACvB,WAAW,GAAG,IAAI,CAAC;gBACnB,UAAU,GAAG,WAAW,CAAC,QAAQ,CAAC,GAAG,EAAC,KAAK,CAAC,EAAG,AAAD,KAAM,CAAC,IAAI,CAAC,CACxC,MAAM,EAAC,IAAI,CAAC,EAAE,AAAC,SAAS,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC;aACvD;SACF;QACD,SAAS,CAAC,GAAG,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;QAEzB,2DAA2D;QAC3D,IAAI,SAAS,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,IAAI,EAAE;YAChC,SAAS;SACV;QACD,sEAAsE;QACtE,IAAI,cAAc,CAAC,GAAG,CAAC,IAAI,CAAC,IAAI,CAAC,EAAE;YACjC,SAAS;SACV;QACD,4DAA4D;QAC5D,IAAI,aAAa,CAAC,GAAG,CAAC,IAAI,CAAC,IAAI,CAAC,EAAE;YAChC,SAAS;SACV;QACD,IAAI,IAAI,CAAC,MAAM,CAAC,MAAM,KAAK,CAAC,EAAE;YAC5B,aAAa,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;YAC9B,SAAS;SACV;QACD,IAAI,CAAC,MAAM,CAAC,OAAO,EAAC,KAAK,CAAC,EAAE;YAC1B,oDAAoD;YACpD,IAAI,IAAI,CAAC,GAAG,CAAC,KAAK,CAAC,IAAI,CAAC,EAAE;gBACxB,OAAO;aACR;YACD,IAAI,CAAC,GAAG,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC;YACrB,QAAQ,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;QACvB,CAAC,CAAC,CAAC;KACJ;IACD,OAAO;QAAC,MAAM;QAAE,OAAO;QAAE,SAAS;QAAE,aAAa;QAAE,WAAW;QAAE,UAAU;IAAA,CAAC,CAAC;AAC9E,CAAC;AAMK,SAAU,0BAA0B,CACtC,KAAY,EAAE,aAA4B;IAC5C,MAAM,EAAC,SAAS,EAAE,MAAM,EAAC,GAAG,aAAa,CAAC;IAC1C,MAAM,UAAU,GAAG,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,CACd,GAAG,EAAC,IAAI,CAAC,EAAE,IAAC,4UAAa,EAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,CACnC,GAAG,EAAC,IAAI,CAAC,EAAE,AAAC,KAAK,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC,CAAC;IACvD,MAAM,SAAS,GAAG,KAAK,CAAC,SAAS,IAAI,EAAE,CAAC;IAExC,MAAM,MAAM,GAAG,CAAC,IAAiB,EAAE,CAC/B,CADiC,QACxB,CAAC,GAAG,CAAC,OAAO,IAAI,KAAK,QAAQ,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;IAE/D,SAAS,MAAM,CAAC,KAAa;QAC3B,OAAO,CAAC;eAAG,IAAI,GAAG,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC,IAAI,EAAE,CAAG,CAAD;oBAAE,IAAI,CAAC,IAAI;oBAAE,IAAI;iBAAC,CAAC,CAAC,CAAC,MAAM,EAAE;SAAC,CAAC;IACvE,CAAC;IACD,MAAM,eAAe,GAAG,MAAM,CAAC;WACF,UAAU;WACV,KAAK,CAAC,OAAO;WACb,SAAS;KACb,CAAC,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;IAC1C,MAAM,QAAQ,GAAG,MAAM,CAAC;WACF,eAAe;WACf,MAAM,CAAC,MAAM,CAAC,KAAK,CAAC,KAAK,CAAC;KAC9B,CAAC,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;IACnC,MAAM,UAAU,GACZ,IAAI,GAAG,CAAe,QAAQ,CAAC,GAAG,CAAC,CAAC,IAAI,EAAE,CAAG,CAAD;YAAE,IAAI,CAAC,IAAI;YAAE,IAAI;SAAC,CAAC,CAAC,CAAC;IAErE,MAAM,QAAQ,GAA2B,CAAA,CAAE,CAAC;IAC5C,KAAK,MAAM,IAAI,IAAI,QAAQ,CAAE;QAC3B,QAAQ,CAAC,IAAI,CAAC,IAAI,CAAC,GAAG,QAAQ,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;QAC/C,KAAK,MAAM,KAAK,IAAI,IAAI,CAAC,QAAQ,CAAE;YACjC,sEAAsE;YACtE,2DAA2D;YAC3D,IAAI,CAAC,MAAM,CAAC,KAAK,CAAC,EAAE;gBAClB,QAAQ,CAAC,KAAK,CAAC,IAAI,CAAC,GAAG,MAAM,CAAC,iBAAiB,CAAC;aACjD;YACD,QAAQ,CAAC,KAAK,CAAC,IAAI,CAAC,GAAG,CAAC,QAAQ,CAAC,KAAK,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC,GAAG,CAAC,CAAC;SACxD;KACF;IAED,uEAAuE;IACvE,qBAAqB;IACrB,MAAM,QAAQ,GAAG,MAAM,CAAC,OAAO,CAAC,QAAQ,CAAC,CACnB,MAAM,CAAC,CAAC,CAAC,EAAE,OAAO,CAAC,EAAE,CAAG,CAAD,MAAQ,KAAK,CAAC,CAAC,CACtC,GAAG,CAAC,CAAC,CAAC,IAAI,CAAC,EAAE,CAAG,CAAD,GAAK,CAAC,CAAC;IAC5C,MAAM,gBAAgB,GAAG,CAAC;WAAG,QAAQ;KAAC,CAAC;IACvC,MAAO,QAAQ,CAAC,MAAM,GAAG,CAAC,CAAE;QAC1B,MAAM,QAAQ,GAAG,QAAQ,CAAC,GAAG,EAAE,CAAC;QAChC,MAAM,IAAI,GAAG,UAAU,CAAC,GAAG,CAAC,QAAQ,CAAE,CAAC;QACvC,KAAK,MAAM,KAAK,IAAI,IAAI,CAAC,QAAQ,CAAC,MAAM,CAAC,MAAM,CAAC,CAAE;YAChD,IAAI,EAAE,QAAQ,CAAC,KAAK,CAAC,IAAI,CAAC,KAAK,CAAC,EAAE;gBAChC,gBAAgB,CAAC,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC;gBAClC,QAAQ,CAAC,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC;aAC3B;SACF;KACF;IAED,MAAM,YAAY,GAAG,gBAAgB,CAAC,GAAG,CAAC,CAAC,IAAI,EAAE,CAAG,CAAD,SAAW,CAAC,GAAG,CAAC,IAAI,CAAC,CAAC,CAAC;IAC1E,MAAM,oBAAoB,GACtB,8BAA8B,CAAC,YAAY,EAAE,eAAe,CAAC,CAAC;IAElE,iDAAiD;IACjD,2BAA2B,CAAC,oBAAoB,EAAE,eAAe,CAAC,CAAC;IAEnE,OAAO,oBAAoB,CAAC;AAC9B,CAAC;AAED;;;;;;;;;;;;;GAaG,CACH,SAAS,8BAA8B,CACnC,YAAoB,EAAE,eAAuB;IAC/C,MAAM,UAAU,GACZ,IAAI,GAAG,CAAe,YAAY,CAAC,GAAG,CAAC,CAAC,IAAI,EAAE,CAAG,CAAD;YAAE,IAAI,CAAC,IAAI;YAAE,IAAI;SAAC,CAAC,CAAC,CAAC;IAEzE,uEAAuE;IACvE,MAAM,KAAK,GAAG,eAAe,CAAC,GAAG,CAAC,CAAC,IAAI,EAAE,CAAG,CAAD,GAAK,CAAC,IAAI,CAAC,CAAC;IACvD,MAAM,4BAA4B,GAAG,IAAI,GAAG,CAAC,KAAK,CAAC,CAAC;IACpD,8DAA8D;IAC9D,oEAAoE;IACpE,MAAO,KAAK,CAAC,MAAM,GAAG,CAAC,CAAE;QACvB,MAAM,QAAQ,GAAG,KAAK,CAAC,GAAG,EAAE,CAAC;QAC7B,MAAM,IAAI,GAAG,UAAU,CAAC,GAAG,CAAC,QAAQ,CAAE,CAAC;QACvC,KAAK,MAAM,KAAK,IAAI,IAAI,CAAC,QAAQ,CAAE;YACjC,IAAI,CAAC,UAAU,CAAC,GAAG,CAAC,KAAK,CAAC,IAAI,CAAC,IAC3B,4BAA4B,CAAC,GAAG,CAAC,KAAK,CAAC,IAAI,CAAC,EAAE;gBAChD,SAAS;aACV;YACD,4BAA4B,CAAC,GAAG,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC;YAC7C,KAAK,CAAC,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC;SACxB;KACF;IAED,gEAAgE;IAChE,MAAM,oBAAoB,GAAG,YAAY,CAAC,MAAM,CAC5C,CAAC,IAAI,EAAE,CAAG,CAAD,2BAA6B,CAAC,GAAG,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC;IAE3D,OAAO,oBAAoB,CAAC;AAC9B,CAAC;AAED,MAAM,wBAAyB,SAAQ,KAAK;IAC1C,YAAY,OAAe,CAAA;QACzB,KAAK,CAAC,CAAA,0BAAA,EAA6B,OAAO,EAAE,CAAC,CAAC;IAChD,CAAC;CACF;AAED;;;;;;;;GAQG,CACH,SAAS,2BAA2B,CAChC,YAAoB,EAAE,eAAuB;IAC/C,MAAM,eAAe,GAAG,IAAI,GAAG,CAC3B,YAAY,CAAC,GAAG,CAAC,CAAC,IAAI,EAAE,KAAK,EAAE,CAAG,CAAD;YAAE,IAAI,CAAC,IAAI;YAAE,KAAK;SAAC,CAAC,CAAC,CAAC;IAC3D,MAAM,mBAAmB,GAAG,IAAI,GAAG,CAAC,eAAe,CAAC,GAAG,CAAC,CAAC,IAAI,EAAE,CAAG,CAAD,GAAK,CAAC,IAAI,CAAC,CAAC,CAAC;IAC9E,MAAM,YAAY,GAAG,CAAC,IAAiB,EAAE,CACrC,CADuC,kBACpB,CAAC,GAAG,CAAC,OAAO,IAAI,KAAK,QAAQ,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;IACzE,MAAM,uBAAuB,GACzB,IAAI,GAAG,CAAC,YAAY,CAAC,GAAG,CAAC,CAAC,IAAI,EAAE,CAAG,CAAD,GAAK,CAAC,IAAI,CAAC,CAAC,CAAC;IACnD,MAAM,cAAc,GAAG,CAAC,IAAiB,EAAE,CACvC,CADyC,sBAClB,CAAC,GAAG,CAAC,OAAO,IAAI,KAAK,QAAQ,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;IAE7E,KAAK,MAAM,IAAI,IAAI,YAAY,CAAE;QAC/B,KAAK,MAAM,KAAK,IAAI,IAAI,CAAC,QAAQ,CAAC,MAAM,CAAC,cAAc,CAAC,CAAE;YACxD,IAAI,CAAC,eAAe,CAAC,GAAG,CAAC,KAAK,CAAC,IAAI,CAAC,EAAE;gBACpC,MAAM,IAAI,wBAAwB,CAC9B,CAAA,MAAA,EAAS,KAAK,CAAC,IAAI,CAAA,SAAA,EAAY,IAAI,CAAC,IAAI,CAAA,gBAAA,CAAkB,CAAC,CAAC;aACjE;YACD,IAAI,eAAe,CAAC,GAAG,CAAC,IAAI,CAAC,IAAI,CAAC,GAAG,eAAe,CAAC,GAAG,CAAC,KAAK,CAAC,IAAI,CAAC,EAAE;gBACpE,MAAM,IAAI,wBAAwB,CAAC,CAAA,KAAA,EAC/B,IAAI,CAAC,IAAI,CAAA,qCAAA,EAAwC,KAAK,CAAC,IAAI,CAAA,CAAA,CAAG,CAAC,CAAC;aACrE;SACF;QACD,IAAI,CAAC,YAAY,CAAC,IAAI,CAAC,EAAE;YACvB,KAAK,MAAM,KAAK,IAAI,IAAI,CAAC,MAAM,CAAE;gBAC/B,IAAI,CAAC,eAAe,CAAC,GAAG,CAAC,KAAK,CAAC,IAAI,CAAC,EAAE;oBACpC,MAAM,IAAI,wBAAwB,CAC9B,CAAA,MAAA,EAAS,KAAK,CAAC,IAAI,CAAA,SAAA,EAAY,IAAI,CAAC,IAAI,CAAA,gBAAA,CAAkB,CAAC,CAAC;iBACjE;gBACD,IAAI,eAAe,CAAC,GAAG,CAAC,KAAK,CAAC,IAAI,CAAC,GAAG,eAAe,CAAC,GAAG,CAAC,IAAI,CAAC,IAAI,CAAC,EAAE;oBACpE,MAAM,IAAI,wBAAwB,CAAC,CAAA,KAAA,EAC/B,IAAI,CAAC,IAAI,CAAA,sCAAA,EAAyC,KAAK,CAAC,IAAI,CAAA,CAAA,CAAG,CAAC,CAAC;iBACtE;aACF;SACF;KACF;AACH,CAAC;AAWK,SAAU,mBAAmB,CAAC,YAAoB;IACtD,MAAM,eAAe,GAAG,IAAI,GAAG,CAC3B,YAAY,CAAC,GAAG,CAAC,CAAC,IAAI,EAAE,KAAK,EAAE,CAAG,CAAD;YAAE,IAAI,CAAC,IAAI;YAAE,KAAK;SAAC,CAAC,CAAC,CAAC;IAE3D,MAAM,QAAQ,GAAG,MAAM,CAAC,gBAAgB,CAAC;IACzC,kEAAkE;IAClE,wDAAwD;IACxD,MAAM,aAAa,GAAG,YAAY,CAAC,GAAG,CAClC,CAAC,IAAI,EAAE,SAAS,EAAE,CAAG,CAAD,YAAc,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,QAAQ,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC;IACrE,MAAM,eAAe,GAAG,CAAC,IAAU,EAAE,EAAE;QACrC,MAAM,QAAQ,GAAG,aAAa,CAAC,eAAe,CAAC,GAAG,CAAC,IAAI,CAAC,IAAI,CAAE,CAAC,CAAC;QAChE,IAAI,QAAQ,IAAI,IAAI,EAAE;YACpB,4DAA4D;YAC5D,wBAAwB;YACxB,OAAO,CAAC,CAAC,CAAC;SACX;QACD,OAAO,QAAQ,CAAC;IAClB,CAAC,CAAC;IAEF,0EAA0E;IAC1E,iEAAiE;IACjE,uEAAuE;IACvE,4CAA4C;IAC5C,mEAAmE;IACnE,wEAAwE;IACxE,MAAM,eAAe,GAAG,YAAY,CAAC,GAAG,CAAC,CAAC,IAAI,EAAE,SAAS,EAAE,EAAE;QAC3D,OAAO,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,eAAe,CAAC,CACpC,MAAM,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAG,CAAD,GAAK,CAAC,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,EAAE,aAAa,CAAC,SAAS,CAAC,CAAC,CAAC;IAClE,CAAC,CAAC,CAAC;IAEH,gBAAgB;IAChB,4BAA4B;IAC5B,oEAAoE;IACpE,mCAAmC;IACnC,MAAM,YAAY,GAAG,IAAI,GAAG,EAAkB,CAAC;IAC/C,IAAK,IAAI,SAAS,GAAG,CAAC,EAAE,SAAS,GAAG,YAAY,CAAC,MAAM,EAAE,EAAE,SAAS,CAAE;QACpE,MAAM,cAAc,GAAG,eAAe,CAAC,SAAS,CAAC,CAAC;QAClD,IAAI,cAAc,KAAK,QAAQ,EAAE;YAC/B,SAAS;SACV;QACD,MAAM,IAAI,GAAG,YAAY,CAAC,SAAS,CAAC,CAAC;QACrC,MAAM,aAAa,GAAG,YAAY,CAAC,cAAc,CAAC,CAAC;QACnD,IAAI,CAAC,YAAY,CAAC,GAAG,CAAC,aAAa,CAAC,IAAI,CAAC,EAAE;YACzC,YAAY,CAAC,GAAG,CAAC,aAAa,CAAC,IAAI,EAAE,EAAE,CAAC,CAAC;SAC1C;QACD,YAAY,CAAC,GAAG,CAAC,aAAa,CAAC,IAAI,CAAE,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;KAClD;IACD,OAAO,YAAY,CAAC;AACtB,CAAC;AAED,MAAM,gBAAgB,GAAG,IAAI,GAAG,CAAC;IAC/B,QAAQ;IAAE,OAAO;IAAE,OAAO;IAAE,MAAM;IAAE,eAAe;IAAE,aAAa;IAClE,gBAAgB;IAAE,IAAI;IAAE,OAAO;CAChC,CAAC,CAAC;AACH,MAAM,iBAAiB,GAAG,IAAI,GAAG,CAAC;IAChC,qBAAqB;IAAE,qBAAqB;IAAE,qBAAqB;IAAE,OAAO;CAC7E,CAAC,CAAC;AACH,MAAM,cAAc,GAAG,IAAI,GAAG,CAAC;IAC7B,WAAW;IAAE,aAAa;IAAE,mBAAmB;IAAE,qBAAqB;IACtE,iBAAiB;IAAE,mBAAmB;IAAE,iBAAiB;IAAE,mBAAmB;CAC/E,CAAC,CAAC;AAEG,SAAU,aAAa,CAAC,IAAU;IACtC,OAAO,gBAAgB,CAAC,GAAG,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC;AACvC,CAAC;AAEK,SAAU,cAAc,CAAC,IAAU;IACvC,OAAO,iBAAiB,CAAC,GAAG,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC;AACxC,CAAC;AAEK,SAAU,WAAW,CAAC,IAAU;IACpC,OAAO,cAAc,CAAC,GAAG,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC;AACrC,CAAC"}},
    {"offset": {"line": 1260, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-converter@4.22.0_@tensorflow+tfjs-core@4.22.0/node_modules/@tensorflow/tfjs-converter/dist/executor/graph_executor.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-converter/src/executor/graph_executor.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, env, keep, NamedTensorMap, Tensor, tidy, util} from '@tensorflow/tfjs-core';\n\nimport {ISignatureDef} from '../data/compiled_api';\nimport {NamedTensorsMap, TensorArrayMap, TensorInfo, TensorListMap} from '../data/types';\nimport {getNodeNameAndIndex, getParamValue, getTensor, getTensorsForCurrentContext, parseNodeName} from '../operations/executors/utils';\nimport {executeOp} from '../operations/operation_executor';\nimport {Graph, Node} from '../operations/types';\n\nimport {ExecutionContext, ExecutionContextInfo} from './execution_context';\nimport {getExecutionSubgraph, getNodeLiveUntilMap, getNodesInTopologicalOrder, isControlFlow} from './model_analysis';\nimport {ResourceManager} from './resource_manager';\nimport {FunctionExecutor} from './types';\n\ninterface NodeWithContexts {\n  contexts: ExecutionContextInfo[];\n  node: Node;\n}\n\nexport class GraphExecutor implements FunctionExecutor {\n  private compiledMap = new Map<string, ReturnType<typeof this.compile>>();\n  private parseNodeNameCache = new Map<string, [string, number, string?]>();\n  private _weightMap: NamedTensorsMap = {};\n  private _weightIds: number[];\n  private _signature: ISignatureDef;\n  private _inputs: Node[];\n  private _outputs: Node[];\n  private _initNodes: Node[];  // Internal init nodes to start initialization.\n  private SEPARATOR = ',';\n  private _functions: {[key: string]: Graph} = {};\n  private _functionExecutorMap: {[key: string]: FunctionExecutor} = {};\n  private _resourceManager: ResourceManager;\n  private clonedTensorsMap: NamedTensorsMap;\n  private keepIntermediateTensors = false;\n\n  get weightIds(): number[] {\n    return this.parent ? this.parent.weightIds : this._weightIds;\n  }\n\n  get functionExecutorMap(): {[key: string]: FunctionExecutor} {\n    return this.parent ? this.parent.functionExecutorMap :\n                         this._functionExecutorMap;\n  }\n\n  get weightMap(): NamedTensorsMap {\n    return this.parent ? this.parent.weightMap : this._weightMap;\n  }\n\n  set weightMap(weightMap: NamedTensorsMap) {\n    const weightIds = Object.keys(weightMap).map(\n        key => weightMap[key].map(tensor => tensor.id));\n    this._weightIds = [].concat(...weightIds);\n    this._weightMap = weightMap;\n  }\n\n  /**\n   * Set `ResourceManager` shared by executors of a model.\n   * @param resourceManager: `ResourceManager` of the `GraphModel`.\n   */\n  set resourceManager(resourceManager: ResourceManager) {\n    this._resourceManager = resourceManager;\n  }\n\n  get inputs(): TensorInfo[] {\n    return this._inputs.map(node => {\n      return {\n        name: node.name,\n        shape: node.attrParams['shape'] ?\n            node.attrParams['shape'].value as number[] :\n            undefined,\n        dtype: node.attrParams['dtype'] ?\n            node.attrParams['dtype'].value as DataType :\n            undefined\n      };\n    });\n  }\n\n  get outputs(): TensorInfo[] {\n    return this._outputs.map(node => {\n      return {\n        name: node.name,\n        shape: node.attrParams['shape'] ?\n            node.attrParams['shape'].value as number[] :\n            undefined,\n        dtype: node.attrParams['dtype'] ?\n            node.attrParams['dtype'].value as DataType :\n            undefined\n      };\n    });\n  }\n\n  get inputNodes(): string[] {\n    return this._inputs.map(node => node.signatureKey || node.name);\n  }\n\n  get outputNodes(): string[] {\n    return this._outputs.map((node) => {\n      const name = node.signatureKey || node.name;\n      return node.defaultOutput ? (`${name}:${node.defaultOutput}`) : name;\n    });\n  }\n\n  get functions(): {[key: string]: ISignatureDef} {\n    return Object.keys(this._functions).reduce((map, key) => {\n      map[key] = this._functions[key].signature;\n      return map;\n    }, {} as {[key: string]: ISignatureDef});\n  }\n\n  /**\n   *\n   * @param graph Graph the model or function graph to be executed.\n   * @param parent When building function exector you need to set the parent\n   * executor. Since the weights and function executor maps are set at parant\n   * level, that function executor can access the function maps and weight maps\n   * through the parent.\n   */\n  constructor(private graph: Graph, private parent?: GraphExecutor) {\n    this._outputs = graph.outputs;\n    this._inputs = graph.inputs;\n    this._initNodes = graph.initNodes;\n    this._signature = graph.signature;\n    this._functions = graph.functions;\n    // create sub-graph executors\n    if (graph.functions != null) {\n      Object.keys(graph.functions).forEach(name => {\n        this._functionExecutorMap[name] =\n            new GraphExecutor(graph.functions[name], this);\n      });\n    }\n  }\n\n  private getCompilationKey(inputs: Node[], outputs: Node[]): string {\n    const sortedInputs = inputs.map(node => node.name).sort();\n    const sortedOutputs = outputs.map(node => node.name).sort();\n    return sortedInputs.join(this.SEPARATOR) + '--' +\n        sortedOutputs.join(this.SEPARATOR);\n  }\n\n  /**\n   * Compiles the inference graph and returns the minimal set of nodes that are\n   * required for execution, in the correct execution order.\n   * @returns {Object} compilation The compile result.\n   * @returns {Node[]} compilation.orderedNodes Nodes in the correct execution\n   *     order.\n   * @returns {Map<string, Node[]>} compilation.nodeLiveUntilMap A map from node\n   *     to disposable nodes after its execution. That is, for a node `x`,\n   *     `nodeLiveUntilMap[x]` indicates all nodes whose intermediate\n   *     tensors should be disposed after `x` is executed.\n   */\n  private compile(inputs: NamedTensorMap, outputs: Node[]):\n      {orderedNodes: Node[], nodeLiveUntilMap: Map<string, Node[]>} {\n    const executionInfo =\n        getExecutionSubgraph(inputs, outputs, this.weightMap, this._initNodes);\n    const {missingInputs, dynamicNode, syncInputs} = executionInfo;\n    if (dynamicNode != null) {\n      throw new Error(\n          `This execution contains the node '${dynamicNode.name}', which has ` +\n          `the dynamic op '${dynamicNode.op}'. Please use ` +\n          `model.executeAsync() instead. Alternatively, to avoid the ` +\n          `dynamic ops, specify the inputs [${syncInputs}]`);\n    }\n\n    if (missingInputs.length > 0) {\n      const outNames = outputs.map(n => n.name);\n      const inNames = Object.keys(inputs);\n      throw new Error(\n          `Cannot compute the outputs [${outNames}] from the provided inputs ` +\n          `[${inNames}]. Missing the following inputs: [${missingInputs}]`);\n    }\n\n    const orderedNodes = getNodesInTopologicalOrder(this.graph, executionInfo);\n    const nodeLiveUntilMap = getNodeLiveUntilMap(orderedNodes);\n    return {orderedNodes, nodeLiveUntilMap};\n  }\n\n  private cloneAndKeepTensor(tensor: Tensor) {\n    if (tensor == null) {\n      return null;\n    }\n    const clone = tensor.clone();\n    // Keep the clone because`model.execute()` may be called within\n    // a `tidy()`, but the user may inspect these tensors after the\n    // tidy.\n    keep(clone);\n    return clone;\n  }\n\n  private cloneTensorList(tensors: Tensor[]) {\n    if (!tensors) {\n      return null;\n    }\n    const clonedTensor = tensors.map(tensor => {\n      return this.cloneAndKeepTensor(tensor);\n    });\n    return clonedTensor;\n  }\n\n  private cloneTensorMap(tensorsMap: NamedTensorsMap): NamedTensorsMap {\n    return Object.fromEntries(\n        Object.entries(tensorsMap).map(([name, tensorsList]) => {\n          return [name, this.cloneTensorList(tensorsList)];\n        }));\n  }\n\n  /**\n   * Executes the inference for given input tensors.\n   * @param inputs Tensor map for the model inputs, keyed by the input node\n   * names.\n   * @param outputs Optional. output node name from the Tensorflow model, if\n   * no outputs are specified, the default outputs of the model would be used.\n   * You can inspect intermediate nodes of the model by adding them to the\n   * outputs array.\n   */\n  execute(inputs: NamedTensorMap, outputs?: string[]): Tensor[] {\n    // Dispose any tensors from a prior run to avoid leaking them.\n    this.disposeIntermediateTensors();\n    inputs = this.mapInputs(inputs);\n    const names = Object.keys(inputs).sort();\n    this.checkInputs(inputs);\n    this.checkInputShapeAndType(inputs);\n    outputs = this.mapOutputs(outputs);\n    this.checkOutputs(outputs);\n    const inputNodes =\n        names.map(name => this.graph.nodes[parseNodeName(name)[0]]);\n    const outputNodeNames = outputs.map(name => parseNodeName(name)[0]);\n    const outputNodeNameSet = new Set(outputNodeNames);\n    let outputNodes = outputNodeNames.map(name => this.graph.nodes[name]);\n    // If no outputs are specified, then use the default outputs of the model.\n    if (outputNodes.length === 0) {\n      outputNodes = this._outputs;\n    }\n\n    const compilationKey = this.getCompilationKey(inputNodes, outputNodes);\n\n    // Do nothing if the compiled graph cache contains the input.\n    let compilation = this.compiledMap.get(compilationKey);\n    if (compilation == null) {\n      compilation = this.compile(inputs, outputNodes);\n      this.compiledMap.set(compilationKey, compilation);\n    }\n\n    // Keep tensors if KEEP_INTERMEDIATE_TENSORS is on.\n    try {\n      this.keepIntermediateTensors = env().getBool('KEEP_INTERMEDIATE_TENSORS');\n    } catch (e) {\n      this.keepIntermediateTensors = false;\n      console.warn(e.message);\n    }\n    const tensorArrayMap: TensorArrayMap = {};\n    const tensorListMap: TensorListMap = {};\n\n    return tidy(() => {\n      const context = new ExecutionContext(\n          this.weightMap, tensorArrayMap, tensorListMap,\n          this.functionExecutorMap, this.parseNodeNameCache);\n      const tensorsMap: NamedTensorsMap = {...this.weightMap};\n      if (this.keepIntermediateTensors) {\n        this.clonedTensorsMap = this.cloneTensorMap(this.weightMap);\n      }\n\n      Object.keys(inputs).forEach(name => {\n        const [nodeName, index] = parseNodeName(name, context);\n        const tensors: Tensor[] = [];\n        tensors[index] = inputs[name];\n        tensorsMap[nodeName] = tensors;\n        if (this.keepIntermediateTensors) {\n          this.clonedTensorsMap[nodeName] = this.cloneTensorList(tensors);\n        }\n      });\n\n      const tensorsToKeep = this.getFrozenTensorIds(tensorsMap);\n      const {orderedNodes, nodeLiveUntilMap} = compilation;\n      for (const node of orderedNodes) {\n        if (tensorsMap[node.name]) {\n          continue;\n        }\n        const tensors =\n            executeOp(node, tensorsMap, context, this._resourceManager) as\n            Tensor[];\n        if (util.isPromise(tensors)) {\n          throw new Error(\n              `The execution of the op '${node.op}' returned a promise. ` +\n              `Please use model.executeAsync() instead.`);\n        }\n        tensorsMap[node.name] = tensors;\n        if (this.keepIntermediateTensors) {\n          this.clonedTensorsMap[node.name] = this.cloneTensorList(tensors);\n        }\n        this.checkTensorForDisposalWithNodeLiveUntilInfo(\n            node, tensorsMap, context, tensorsToKeep, outputNodeNameSet,\n            nodeLiveUntilMap.get(node.name));\n      }\n\n      // dispose the context for the root executor\n      if (this.parent == null) {\n        context.dispose(tensorsToKeep);\n      }\n\n      return outputs.map(name => getTensor(name, tensorsMap, context));\n    });\n  }\n\n  private getFrozenTensorIds(tensorMap: NamedTensorsMap): Set<number> {\n    const ids = [].concat.apply(\n        [],\n        Object.keys(tensorMap)\n            .map(key => tensorMap[key])\n            .map(tensors => tensors.map(tensor => tensor.id)));\n    return new Set(ids);\n  }\n\n  private checkTensorForDisposal(\n      nodeName: string, node: Node, tensorMap: NamedTensorsMap,\n      context: ExecutionContext, tensorsToKeep: Set<number>,\n      outputNodeNameSet: Set<string>,\n      intermediateTensorConsumerCount: {[key: string]: number}) {\n    // Skip output nodes and any control flow nodes, since its dependency is\n    // tricky to track correctly.\n    if (isControlFlow(node) || outputNodeNameSet.has(nodeName)) {\n      return;\n    }\n\n    for (const tensor of tensorMap[nodeName]) {\n      if (tensor == null) {\n        continue;\n      }\n      intermediateTensorConsumerCount[tensor.id] =\n          (intermediateTensorConsumerCount[tensor.id] || 0) +\n          node.children.length;\n    }\n\n    for (const input of node.inputs) {\n      // Skip any control flow nodes, since its dependency is tricky to track\n      // correctly.\n      if (isControlFlow(input)) {\n        continue;\n      }\n\n      const tensors =\n          getTensorsForCurrentContext(input.name, tensorMap, context);\n      if (tensors == null) {\n        continue;\n      }\n\n      for (const tensor of tensors) {\n        if (!tensor || tensor.kept || tensorsToKeep.has(tensor.id)) {\n          continue;\n        }\n\n        // Only intermediate nodes' tensors have counts set, not marked as\n        // kept, and not in `tensorsToKeep`.\n        // Input and weight nodes' tensors should exist in `tensorsToKeep`.\n        // Output and control flow nodes' tensors should never have count set.\n        const count = intermediateTensorConsumerCount[tensor.id];\n        if (count === 1) {\n          tensor.dispose();\n          delete intermediateTensorConsumerCount[tensor.id];\n        } else if (count != null) {\n          intermediateTensorConsumerCount[tensor.id]--;\n        }\n      }\n    }\n  }\n\n  private checkTensorForDisposalWithNodeLiveUntilInfo(\n      node: Node, tensorMap: NamedTensorsMap, context: ExecutionContext,\n      tensorsToKeep: Set<number>, outputNodeNameSet: Set<string>,\n      liveUntilNodes?: Node[]) {\n    function isNonDisposableNode(node: Node) {\n      // Skip output nodes and any control flow nodes, since its dependency is\n      // tricky to track correctly.\n      return isControlFlow(node) || outputNodeNameSet.has(node.name);\n    }\n\n    if (isControlFlow(node) || liveUntilNodes == null) {\n      return;\n    }\n\n    for (const nodeToDispose of liveUntilNodes) {\n      if (isNonDisposableNode(nodeToDispose)) {\n        continue;\n      }\n      const tensors = getTensorsForCurrentContext(\n          nodeToDispose.name, tensorMap, context);\n      for (const tensor of tensors) {\n        if (!tensor || tensor.kept || tensorsToKeep.has(tensor.id)) {\n          continue;\n        }\n        tensor.dispose();\n      }\n    }\n  }\n\n  /**\n   * Executes the inference for given input tensors in Async fashion.\n   * @param inputs Tensor map for the model inputs, keyed by the input node\n   * names.\n   * @param outputs output node name from the Tensorflow model, if no outputs\n   * are specified, the default outputs of the model would be used. You can\n   * inspect intermediate nodes of the model by adding them to the outputs\n   * array.\n   */\n  async executeAsync(inputs: NamedTensorMap, outputs?: string[]):\n      Promise<Tensor[]> {\n    return this._executeAsync(inputs, outputs);\n  }\n\n  disposeIntermediateTensors() {\n    if (!this.clonedTensorsMap) {\n      return;\n    }\n    Object.values(this.clonedTensorsMap).forEach(tensorsList => {\n      for (const tensor of tensorsList) {\n        if (tensor && !tensor.isDisposed) {\n          tensor.dispose();\n        }\n      }\n    });\n\n    this.clonedTensorsMap = null;\n  }\n\n  getIntermediateTensors(): NamedTensorsMap {\n    return this.clonedTensorsMap;\n  }\n\n  /**\n   * Executes the inference for given input tensors in Async fashion.\n   * @param inputs Tensor map for the model inputs, keyed by the input node\n   * names.\n   * @param outputs Optional. output node name from the Tensorflow model,\n   * if no outputs are specified, the default outputs of the model would be\n   * used. You can inspect intermediate nodes of the model by adding them to\n   * the outputs array.\n   * @param isFunctionExecution Optional. Flag for executing a function.\n   * @param tensorArrayMap Optional, global TensorArray map by id. Used for\n   * function execution.\n   * @param tensorArrayMap Optional global TensorList map by id. Used for\n   * function execution.\n   */\n  private async _executeAsync(\n      inputs: NamedTensorMap, outputs?: string[], isFunctionExecution = false,\n      tensorArrayMap: TensorArrayMap = {},\n      tensorListMap: TensorListMap = {}): Promise<Tensor[]> {\n    // Dispose any tensors from a prior run to avoid leaking them.\n    this.disposeIntermediateTensors();\n    if (!isFunctionExecution) {\n      inputs = this.mapInputs(inputs);\n      this.checkInputs(inputs);\n      this.checkInputShapeAndType(inputs);\n      outputs = this.mapOutputs(outputs);\n      this.checkOutputs(outputs);\n    }\n\n    // Keep tensors if KEEP_INTERMEDIATE_TENSORS is on.\n    try {\n      this.keepIntermediateTensors = env().getBool('KEEP_INTERMEDIATE_TENSORS');\n    } catch (e) {\n      this.keepIntermediateTensors = false;\n      console.warn(e.message);\n    }\n\n    const context = new ExecutionContext(\n        this.weightMap, tensorArrayMap, tensorListMap, this.functionExecutorMap,\n        this.parseNodeNameCache);\n\n    if (this.keepIntermediateTensors) {\n      this.clonedTensorsMap = this.cloneTensorMap(this.weightMap);\n    }\n\n    // Graph with control flow op requires runtime evaluation of the execution\n    // order, while without control flow the execution order is pre-determined\n    // in the compile method.\n    const tensorsMap = await this.executeWithControlFlow(\n        inputs, context, outputs, isFunctionExecution);\n    const results = outputs.map(name => getTensor(name, tensorsMap, context));\n\n    // dispose all the intermediate tensors\n    const outputIds = results.map(t => t.id);\n    const inputIds = Object.keys(inputs).map(name => inputs[name].id);\n    const keepIds =\n        new Set<number>([...outputIds, ...inputIds, ...this.weightIds]);\n\n    Object.values(tensorsMap).forEach(tensorsList => {\n      tensorsList.forEach(tensor => {\n        if (tensor && !tensor.isDisposed && !keepIds.has(tensor.id)) {\n          tensor.dispose();\n        }\n      });\n    });\n\n    // dispose the context for the root executor\n    if (this.parent == null) {\n      context.dispose(keepIds);\n    }\n\n    return results;\n  }\n\n  async executeFunctionAsync(\n      inputs: Tensor[], tensorArrayMap: TensorArrayMap,\n      tensorListMap: TensorListMap): Promise<Tensor[]> {\n    const mappedInputs = inputs.reduce((map, tensor, index) => {\n      map[this.inputs[index].name] = tensor;\n      return map;\n    }, {} as NamedTensorMap);\n\n    return this._executeAsync(\n        mappedInputs, this.outputNodes, true, tensorArrayMap, tensorListMap);\n  }\n\n  /**\n   * When there are control flow nodes in the graph, the graph execution use\n   * ExecutionContext to keep track of the frames and loop iterators.\n   * @param inputs placeholder tensors for the graph.\n   * @param context the execution context object for current execution.\n   * @param outputNames Optional. output node name from the Tensorflow model,\n   * if no outputs are specified, the default outputs of the model would be\n   * used. You can inspect intermediate nodes of the model by adding them to\n   * the outputs array.\n   * @param isFunctionExecution Flag for executing a function.\n   */\n  private async executeWithControlFlow(\n      inputs: NamedTensorMap, context: ExecutionContext, outputNames?: string[],\n      isFunctionExecution?: boolean): Promise<NamedTensorsMap> {\n    const names = Object.keys(inputs);\n    const inputNodes =\n        names.map(name => this.graph.nodes[parseNodeName(name)[0]]);\n    const outputNodeNames = outputNames.map(name => parseNodeName(name)[0]);\n    const outputNodeNameSet = new Set(outputNodeNames);\n    let outputNodes = outputNodeNames.map(name => this.graph.nodes[name]);\n\n    // If no outputs are specified, then use the default outputs of the model.\n    if (outputNodes.length === 0) {\n      outputNodes = this._outputs;\n    }\n\n    const {usedNodes, missingInputs, dynamicNode, syncInputs} =\n        getExecutionSubgraph(\n            inputs, outputNodes, this.weightMap, this._initNodes);\n\n    // First nodes to execute include inputNodes, weights, and initNodes.\n    const stack: NodeWithContexts[] = [\n      ...inputNodes, ...this.graph.weights, ...(this._initNodes || [])\n    ].map(node => {\n      return {node, contexts: context.currentContext};\n    });\n    const tensorsMap: NamedTensorsMap = {...this.weightMap};\n    Object.keys(inputs).forEach(name => {\n      const [nodeName, index] = parseNodeName(name);\n      const tensors: Tensor[] = [];\n      tensors[index] = inputs[name];\n      tensorsMap[nodeName] = tensors;\n    });\n    const intermediateTensorConsumerCount: {[key: number]: number} = {};\n    const tensorsToKeep = this.getFrozenTensorIds(tensorsMap);\n    const added: {[key: string]: boolean} = {};\n    while (stack.length > 0) {\n      const promises = this.processStack(\n          inputNodes, stack, context, tensorsMap, added, tensorsToKeep,\n          outputNodeNameSet, intermediateTensorConsumerCount, usedNodes);\n      await Promise.all(promises);\n    }\n    if (dynamicNode == null && !isFunctionExecution) {\n      console.warn(\n          `This model execution did not contain any nodes with control flow ` +\n          `or dynamic output shapes. You can use model.execute() instead.`);\n    }\n    const missingOutputs =\n        outputNodes\n            .filter(\n                node => !isControlFlow(node) &&\n                    !getTensor(node.name, tensorsMap, context))\n            .map(node => node.name);\n    if (missingOutputs.length > 0) {\n      let alternativeMsg = '';\n      if (dynamicNode != null) {\n        alternativeMsg =\n            `Alternatively, to avoid the dynamic ops, use model.execute() ` +\n            `and specify the inputs [${syncInputs}]`;\n      }\n      throw new Error(\n          `Cannot compute the outputs [${missingOutputs}] from the provided ` +\n          `inputs [${names}]. Consider providing the following inputs: ` +\n          `[${missingInputs}]. ${alternativeMsg}`);\n    }\n    return tensorsMap;\n  }\n\n  private processStack(\n      inputNodes: Node[], stack: NodeWithContexts[], context: ExecutionContext,\n      tensorMap: NamedTensorsMap, added: {[key: string]: boolean},\n      tensorsToKeep: Set<number>, outputNodeNameSet: Set<string>,\n      intermediateTensorConsumerCount: {[key: number]: number},\n      usedNodes: Set<string>) {\n    const promises: Array<Promise<Tensor[]>> = [];\n    while (stack.length > 0) {\n      const item = stack.pop();\n      context.currentContext = item.contexts;\n      let nodeName = '';\n      // The tensor of the Enter op with isConstant set should be set\n      // in the parent scope, so it will be available as constant for the\n      // whole loop.\n      if (item.node.op === 'Enter' &&\n          getParamValue('isConstant', item.node, tensorMap, context)) {\n        [nodeName] = getNodeNameAndIndex(item.node.name, context);\n      }\n\n      // only process nodes that are not in the tensorMap yet, this include\n      // inputNodes and internal initNodes.\n      if (tensorMap[item.node.name] == null) {\n        const tensors =\n            executeOp(item.node, tensorMap, context, this._resourceManager);\n        if (!nodeName) {\n          [nodeName] = getNodeNameAndIndex(item.node.name, context);\n        }\n        const currentContext = context.currentContext;\n        if (util.isPromise(tensors)) {\n          promises.push(tensors.then(t => {\n            tensorMap[nodeName] = t;\n            if (this.keepIntermediateTensors) {\n              this.clonedTensorsMap[nodeName] = this.cloneTensorList(t);\n            }\n            context.currentContext = currentContext;\n            this.checkTensorForDisposal(\n                nodeName, item.node, tensorMap, context, tensorsToKeep,\n                outputNodeNameSet, intermediateTensorConsumerCount);\n            this.processChildNodes(\n                item.node, stack, context, tensorMap, added, usedNodes);\n            return t;\n          }));\n        } else {\n          tensorMap[nodeName] = tensors;\n          if (this.keepIntermediateTensors) {\n            this.clonedTensorsMap[nodeName] = this.cloneTensorList(tensors);\n          }\n          this.checkTensorForDisposal(\n              nodeName, item.node, tensorMap, context, tensorsToKeep,\n              outputNodeNameSet, intermediateTensorConsumerCount);\n          this.processChildNodes(\n              item.node, stack, context, tensorMap, added, usedNodes);\n        }\n      } else {\n        this.processChildNodes(\n            item.node, stack, context, tensorMap, added, usedNodes);\n      }\n    }\n    return promises;\n  }\n\n  private processChildNodes(\n      node: Node, stack: NodeWithContexts[], context: ExecutionContext,\n      tensorMap: NamedTensorsMap, added: {[key: string]: boolean},\n      usedNodes: Set<string>) {\n    node.children.forEach((childNode) => {\n      const [nodeName, ] = getNodeNameAndIndex(childNode.name, context);\n      if (added[nodeName] || !usedNodes.has(childNode.name)) {\n        return;\n      }\n      // Merge op can be pushed if any of its inputs has value.\n      if (childNode.op === 'Merge') {\n        if (childNode.inputNames.some(name => {\n              return !!getTensor(name, tensorMap, context);\n            })) {\n          added[nodeName] = true;\n          stack.push({contexts: context.currentContext, node: childNode});\n        }\n      } else  // Otherwise all inputs must to have value.\n          if (childNode.inputNames.every(name => {\n                return !!getTensor(name, tensorMap, context);\n              })) {\n        added[nodeName] = true;\n        stack.push({contexts: context.currentContext, node: childNode});\n      }\n    });\n  }\n\n  /**\n   * Releases the memory used by the weight tensors.\n   */\n  dispose() {\n    Object.keys(this.weightMap)\n        .forEach(\n            key => this.weightMap[key].forEach(tensor => tensor.dispose()));\n  }\n\n  private checkInputShapeAndType(inputs: NamedTensorMap) {\n    Object.keys(inputs).forEach(name => {\n      const input = inputs[name];\n      const [nodeName, ] = parseNodeName(name);\n      const node = this.graph.nodes[nodeName];\n      if (node.attrParams['shape'] && node.attrParams['shape'].value) {\n        const shape = node.attrParams['shape'].value as number[];\n        const match = shape.length === input.shape.length &&\n            input.shape.every(\n                (dim, index) => shape[index] === -1 || shape[index] === dim);\n        util.assert(\n            match,\n            () => `The shape of dict['${node.name}'] provided in ` +\n                `model.execute(dict) must be [${shape}], but was ` +\n                `[${input.shape}]`);\n      }\n      if (node.attrParams['dtype'] && node.attrParams['dtype'].value) {\n        util.assert(\n            input.dtype === node.attrParams['dtype'].value as string,\n            () => `The dtype of dict['${node.name}'] provided in ` +\n                `model.execute(dict) must be ` +\n                `${node.attrParams['dtype'].value}, but was ${input.dtype}`);\n      }\n    });\n  }\n\n  private mapInputs(inputs: NamedTensorMap) {\n    const result: NamedTensorMap = {};\n    for (const inputName in inputs) {\n      const tensor = this._signature ?.inputs ?.[inputName];\n      if (tensor != null) {\n        result[tensor.name] = inputs[inputName];\n      } else {\n        result[inputName] = inputs[inputName];\n      }\n    }\n    return result;\n  }\n\n  private checkInputs(inputs: NamedTensorMap) {\n    const notInGraph = Object.keys(inputs).filter(name => {\n      const [nodeName] = parseNodeName(name);\n      return this.graph.nodes[nodeName] == null;\n    });\n    if (notInGraph.length > 0) {\n      throw new Error(\n          `The dict provided in model.execute(dict) has ` +\n          `keys: [${notInGraph}] that are not part of graph`);\n    }\n  }\n\n  private mapOutputs(outputs: string[]) {\n    return outputs.map(name => {\n      const tensor = this._signature ?.outputs ?.[name];\n      if (tensor != null) {\n        return tensor.name;\n      }\n      return name;\n    }, {});\n  }\n\n  private checkOutputs(outputs: string[]): void {\n    outputs.forEach(name => {\n      const [normalizedName] = parseNodeName(name);\n      if (!this.graph.nodes[normalizedName]) {\n        throw new Error(`The output '${name}' is not found in the graph`);\n      }\n    });\n  }\n}\n"],"names":[],"mappings":";;;;AAAA;;;;;;;;;;;;;;;GAeG;;;AAEH,OAAO,EAAW,GAAG,EAAE,IAAI,EAA0B,IAAI,EAAE,IAAI,EAAC,MAAM,uBAAuB,CAAC;AAI9F,OAAO,EAAC,mBAAmB,EAAE,aAAa,EAAE,SAAS,EAAE,2BAA2B,EAAE,aAAa,EAAC,MAAM,+BAA+B,CAAC;AACxI,OAAO,EAAC,SAAS,EAAC,MAAM,kCAAkC,CAAC;AAG3D,OAAO,EAAC,gBAAgB,EAAuB,MAAM,qBAAqB,CAAC;AAC3E,OAAO,EAAC,oBAAoB,EAAE,mBAAmB,EAAE,0BAA0B,EAAE,aAAa,EAAC,MAAM,kBAAkB,CAAC;;;;;;AAShH,MAAO,aAAa;IAgBxB,IAAI,SAAS,GAAA;QACX,OAAO,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC,IAAI,CAAC,MAAM,CAAC,SAAS,CAAC,CAAC,CAAC,IAAI,CAAC,UAAU,CAAC;IAC/D,CAAC;IAED,IAAI,mBAAmB,GAAA;QACrB,OAAO,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC,IAAI,CAAC,MAAM,CAAC,mBAAmB,CAAC,CAAC,CACjC,IAAI,CAAC,oBAAoB,CAAC;IACjD,CAAC;IAED,IAAI,SAAS,GAAA;QACX,OAAO,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC,IAAI,CAAC,MAAM,CAAC,SAAS,CAAC,CAAC,CAAC,IAAI,CAAC,UAAU,CAAC;IAC/D,CAAC;IAED,IAAI,SAAS,CAAC,SAA0B,EAAA;QACtC,MAAM,SAAS,GAAG,MAAM,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC,GAAG,EACxC,GAAG,CAAC,EAAE,AAAC,SAAS,CAAC,GAAG,CAAC,CAAC,GAAG,EAAC,MAAM,CAAC,EAAG,AAAD,MAAO,CAAC,EAAE,CAAC,CAAC,CAAC;QACpD,IAAI,CAAC,UAAU,GAAG,EAAE,CAAC,MAAM,CAAC,GAAG,SAAS,CAAC,CAAC;QAC1C,IAAI,CAAC,UAAU,GAAG,SAAS,CAAC;IAC9B,CAAC;IAED;;;OAGG,CACH,IAAI,eAAe,CAAC,eAAgC,EAAA;QAClD,IAAI,CAAC,gBAAgB,GAAG,eAAe,CAAC;IAC1C,CAAC;IAED,IAAI,MAAM,GAAA;QACR,OAAO,IAAI,CAAC,OAAO,CAAC,GAAG,EAAC,IAAI,CAAC,EAAE;YAC7B,OAAO;gBACL,IAAI,EAAE,IAAI,CAAC,IAAI;gBACf,KAAK,EAAE,IAAI,CAAC,UAAU,CAAC,OAAO,CAAC,CAAC,CAAC,CAC7B,IAAI,CAAC,UAAU,CAAC,OAAO,CAAC,CAAC,KAAiB,CAAC,CAAC,CAC5C,SAAS;gBACb,KAAK,EAAE,IAAI,CAAC,UAAU,CAAC,OAAO,CAAC,CAAC,CAAC,CAC7B,IAAI,CAAC,UAAU,CAAC,OAAO,CAAC,CAAC,KAAiB,CAAC,CAAC,CAC5C,SAAS;aACd,CAAC;QACJ,CAAC,CAAC,CAAC;IACL,CAAC;IAED,IAAI,OAAO,GAAA;QACT,OAAO,IAAI,CAAC,QAAQ,CAAC,GAAG,EAAC,IAAI,CAAC,EAAE;YAC9B,OAAO;gBACL,IAAI,EAAE,IAAI,CAAC,IAAI;gBACf,KAAK,EAAE,IAAI,CAAC,UAAU,CAAC,OAAO,CAAC,CAAC,CAAC,CAC7B,IAAI,CAAC,UAAU,CAAC,OAAO,CAAC,CAAC,KAAiB,CAAC,CAAC,CAC5C,SAAS;gBACb,KAAK,EAAE,IAAI,CAAC,UAAU,CAAC,OAAO,CAAC,CAAC,CAAC,CAC7B,IAAI,CAAC,UAAU,CAAC,OAAO,CAAC,CAAC,KAAiB,CAAC,CAAC,CAC5C,SAAS;aACd,CAAC;QACJ,CAAC,CAAC,CAAC;IACL,CAAC;IAED,IAAI,UAAU,GAAA;QACZ,OAAO,IAAI,CAAC,OAAO,CAAC,GAAG,EAAC,IAAI,CAAC,EAAE,AAAC,IAAI,CAAC,YAAY,IAAI,IAAI,CAAC,IAAI,CAAC,CAAC;IAClE,CAAC;IAED,IAAI,WAAW,GAAA;QACb,OAAO,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC,IAAI,EAAE,EAAE;YAChC,MAAM,IAAI,GAAG,IAAI,CAAC,YAAY,IAAI,IAAI,CAAC,IAAI,CAAC;YAC5C,OAAO,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC,AAAC,GAAG,IAAI,CAAA,CAAA,EAAI,IAAI,CAAC,aAAa,EAAE,CAAC,CAAC,CAAC,AAAC,IAAI,CAAC;QACvE,CAAC,CAAC,CAAC;IACL,CAAC;IAED,IAAI,SAAS,GAAA;QACX,OAAO,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC,UAAU,CAAC,CAAC,MAAM,CAAC,CAAC,GAAG,EAAE,GAAG,EAAE,EAAE;YACtD,GAAG,CAAC,GAAG,CAAC,GAAG,IAAI,CAAC,UAAU,CAAC,GAAG,CAAC,CAAC,SAAS,CAAC;YAC1C,OAAO,GAAG,CAAC;QACb,CAAC,EAAE,CAAA,CAAoC,CAAC,CAAC;IAC3C,CAAC;IAED;;;;;;;OAOG,CACH,YAAoB,KAAY,EAAU,MAAsB,CAAA;QAA5C,IAAA,CAAA,KAAK,GAAL,KAAK,CAAO;QAAU,IAAA,CAAA,MAAM,GAAN,MAAM,CAAgB;QAjGxD,IAAA,CAAA,WAAW,GAAG,IAAI,GAAG,EAA2C,CAAC;QACjE,IAAA,CAAA,kBAAkB,GAAG,IAAI,GAAG,EAAqC,CAAC;QAClE,IAAA,CAAA,UAAU,GAAoB,CAAA,CAAE,CAAC;QAMjC,IAAA,CAAA,SAAS,GAAG,GAAG,CAAC;QAChB,IAAA,CAAA,UAAU,GAA2B,CAAA,CAAE,CAAC;QACxC,IAAA,CAAA,oBAAoB,GAAsC,CAAA,CAAE,CAAC;QAG7D,IAAA,CAAA,uBAAuB,GAAG,KAAK,CAAC;QAqFtC,IAAI,CAAC,QAAQ,GAAG,KAAK,CAAC,OAAO,CAAC;QAC9B,IAAI,CAAC,OAAO,GAAG,KAAK,CAAC,MAAM,CAAC;QAC5B,IAAI,CAAC,UAAU,GAAG,KAAK,CAAC,SAAS,CAAC;QAClC,IAAI,CAAC,UAAU,GAAG,KAAK,CAAC,SAAS,CAAC;QAClC,IAAI,CAAC,UAAU,GAAG,KAAK,CAAC,SAAS,CAAC;QAClC,6BAA6B;QAC7B,IAAI,KAAK,CAAC,SAAS,IAAI,IAAI,EAAE;YAC3B,MAAM,CAAC,IAAI,CAAC,KAAK,CAAC,SAAS,CAAC,CAAC,OAAO,EAAC,IAAI,CAAC,EAAE;gBAC1C,IAAI,CAAC,oBAAoB,CAAC,IAAI,CAAC,GAC3B,IAAI,aAAa,CAAC,KAAK,CAAC,SAAS,CAAC,IAAI,CAAC,EAAE,IAAI,CAAC,CAAC;YACrD,CAAC,CAAC,CAAC;SACJ;IACH,CAAC;IAEO,iBAAiB,CAAC,MAAc,EAAE,OAAe,EAAA;QACvD,MAAM,YAAY,GAAG,MAAM,CAAC,GAAG,EAAC,IAAI,CAAC,EAAE,AAAC,IAAI,CAAC,IAAI,CAAC,CAAC,IAAI,EAAE,CAAC;QAC1D,MAAM,aAAa,GAAG,OAAO,CAAC,GAAG,EAAC,IAAI,CAAC,EAAE,AAAC,IAAI,CAAC,IAAI,CAAC,CAAC,IAAI,EAAE,CAAC;QAC5D,OAAO,YAAY,CAAC,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,GAAG,IAAI,GAC3C,aAAa,CAAC,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC;IACzC,CAAC;IAED;;;;;;;;;;OAUG,CACK,OAAO,CAAC,MAAsB,EAAE,OAAe,EAAA;QAErD,MAAM,aAAa,OACf,6UAAoB,EAAC,MAAM,EAAE,OAAO,EAAE,IAAI,CAAC,SAAS,EAAE,IAAI,CAAC,UAAU,CAAC,CAAC;QAC3E,MAAM,EAAC,aAAa,EAAE,WAAW,EAAE,UAAU,EAAC,GAAG,aAAa,CAAC;QAC/D,IAAI,WAAW,IAAI,IAAI,EAAE;YACvB,MAAM,IAAI,KAAK,CACX,CAAA,kCAAA,EAAqC,WAAW,CAAC,IAAI,CAAA,aAAA,CAAe,GACpE,CAAA,gBAAA,EAAmB,WAAW,CAAC,EAAE,CAAA,cAAA,CAAgB,GACjD,CAAA,0DAAA,CAA4D,GAC5D,CAAA,iCAAA,EAAoC,UAAU,CAAA,CAAA,CAAG,CAAC,CAAC;SACxD;QAED,IAAI,aAAa,CAAC,MAAM,GAAG,CAAC,EAAE;YAC5B,MAAM,QAAQ,GAAG,OAAO,CAAC,GAAG,EAAC,CAAC,CAAC,EAAE,AAAC,CAAC,CAAC,IAAI,CAAC,CAAC;YAC1C,MAAM,OAAO,GAAG,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;YACpC,MAAM,IAAI,KAAK,CACX,CAAA,4BAAA,EAA+B,QAAQ,CAAA,2BAAA,CAA6B,GACpE,CAAA,CAAA,EAAI,OAAO,CAAA,kCAAA,EAAqC,aAAa,CAAA,CAAA,CAAG,CAAC,CAAC;SACvE;QAED,MAAM,YAAY,OAAG,mVAA0B,EAAC,IAAI,CAAC,KAAK,EAAE,aAAa,CAAC,CAAC;QAC3E,MAAM,gBAAgB,OAAG,4UAAmB,EAAC,YAAY,CAAC,CAAC;QAC3D,OAAO;YAAC,YAAY;YAAE,gBAAgB;QAAA,CAAC,CAAC;IAC1C,CAAC;IAEO,kBAAkB,CAAC,MAAc,EAAA;QACvC,IAAI,MAAM,IAAI,IAAI,EAAE;YAClB,OAAO,IAAI,CAAC;SACb;QACD,MAAM,KAAK,GAAG,MAAM,CAAC,KAAK,EAAE,CAAC;QAC7B,+DAA+D;QAC/D,+DAA+D;QAC/D,QAAQ;YACR,iPAAI,EAAC,KAAK,CAAC,CAAC;QACZ,OAAO,KAAK,CAAC;IACf,CAAC;IAEO,eAAe,CAAC,OAAiB,EAAA;QACvC,IAAI,CAAC,OAAO,EAAE;YACZ,OAAO,IAAI,CAAC;SACb;QACD,MAAM,YAAY,GAAG,OAAO,CAAC,GAAG,EAAC,MAAM,CAAC,EAAE;YACxC,OAAO,IAAI,CAAC,kBAAkB,CAAC,MAAM,CAAC,CAAC;QACzC,CAAC,CAAC,CAAC;QACH,OAAO,YAAY,CAAC;IACtB,CAAC;IAEO,cAAc,CAAC,UAA2B,EAAA;QAChD,OAAO,MAAM,CAAC,WAAW,CACrB,MAAM,CAAC,OAAO,CAAC,UAAU,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC,IAAI,EAAE,WAAW,CAAC,EAAE,EAAE;YACrD,OAAO;gBAAC,IAAI;gBAAE,IAAI,CAAC,eAAe,CAAC,WAAW,CAAC;aAAC,CAAC;QACnD,CAAC,CAAC,CAAC,CAAC;IACV,CAAC;IAED;;;;;;;;OAQG,CACH,OAAO,CAAC,MAAsB,EAAE,OAAkB,EAAA;QAChD,8DAA8D;QAC9D,IAAI,CAAC,0BAA0B,EAAE,CAAC;QAClC,MAAM,GAAG,IAAI,CAAC,SAAS,CAAC,MAAM,CAAC,CAAC;QAChC,MAAM,KAAK,GAAG,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,IAAI,EAAE,CAAC;QACzC,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC,CAAC;QACzB,IAAI,CAAC,sBAAsB,CAAC,MAAM,CAAC,CAAC;QACpC,OAAO,GAAG,IAAI,CAAC,UAAU,CAAC,OAAO,CAAC,CAAC;QACnC,IAAI,CAAC,YAAY,CAAC,OAAO,CAAC,CAAC;QAC3B,MAAM,UAAU,GACZ,KAAK,CAAC,GAAG,EAAC,IAAI,CAAC,EAAE,AAAC,IAAI,CAAC,KAAK,CAAC,KAAK,KAAC,4UAAa,EAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAChE,MAAM,eAAe,GAAG,OAAO,CAAC,GAAG,EAAC,IAAI,CAAC,EAAE,IAAC,4UAAa,EAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QACpE,MAAM,iBAAiB,GAAG,IAAI,GAAG,CAAC,eAAe,CAAC,CAAC;QACnD,IAAI,WAAW,GAAG,eAAe,CAAC,GAAG,EAAC,IAAI,CAAC,EAAE,AAAC,IAAI,CAAC,KAAK,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC,CAAC;QACtE,0EAA0E;QAC1E,IAAI,WAAW,CAAC,MAAM,KAAK,CAAC,EAAE;YAC5B,WAAW,GAAG,IAAI,CAAC,QAAQ,CAAC;SAC7B;QAED,MAAM,cAAc,GAAG,IAAI,CAAC,iBAAiB,CAAC,UAAU,EAAE,WAAW,CAAC,CAAC;QAEvE,6DAA6D;QAC7D,IAAI,WAAW,GAAG,IAAI,CAAC,WAAW,CAAC,GAAG,CAAC,cAAc,CAAC,CAAC;QACvD,IAAI,WAAW,IAAI,IAAI,EAAE;YACvB,WAAW,GAAG,IAAI,CAAC,OAAO,CAAC,MAAM,EAAE,WAAW,CAAC,CAAC;YAChD,IAAI,CAAC,WAAW,CAAC,GAAG,CAAC,cAAc,EAAE,WAAW,CAAC,CAAC;SACnD;QAED,mDAAmD;QACnD,IAAI;YACF,IAAI,CAAC,uBAAuB,OAAG,oPAAG,EAAE,EAAC,OAAO,CAAC,2BAA2B,CAAC,CAAC;SAC3E,CAAC,OAAO,CAAC,EAAE;YACV,IAAI,CAAC,uBAAuB,GAAG,KAAK,CAAC;YACrC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC;SACzB;QACD,MAAM,cAAc,GAAmB,CAAA,CAAE,CAAC;QAC1C,MAAM,aAAa,GAAkB,CAAA,CAAE,CAAC;QAExC,WAAO,iPAAI,EAAC,GAAG,EAAE;YACf,MAAM,OAAO,GAAG,IAAI,4UAAgB,CAChC,IAAI,CAAC,SAAS,EAAE,cAAc,EAAE,aAAa,EAC7C,IAAI,CAAC,mBAAmB,EAAE,IAAI,CAAC,kBAAkB,CAAC,CAAC;YACvD,MAAM,UAAU,GAAA,OAAA,MAAA,CAAA,CAAA,GAAwB,IAAI,CAAC,SAAS,CAAC,CAAC;YACxD,IAAI,IAAI,CAAC,uBAAuB,EAAE;gBAChC,IAAI,CAAC,gBAAgB,GAAG,IAAI,CAAC,cAAc,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC;aAC7D;YAED,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,EAAC,IAAI,CAAC,EAAE;gBACjC,MAAM,CAAC,QAAQ,EAAE,KAAK,CAAC,OAAG,4UAAa,EAAC,IAAI,EAAE,OAAO,CAAC,CAAC;gBACvD,MAAM,OAAO,GAAa,EAAE,CAAC;gBAC7B,OAAO,CAAC,KAAK,CAAC,GAAG,MAAM,CAAC,IAAI,CAAC,CAAC;gBAC9B,UAAU,CAAC,QAAQ,CAAC,GAAG,OAAO,CAAC;gBAC/B,IAAI,IAAI,CAAC,uBAAuB,EAAE;oBAChC,IAAI,CAAC,gBAAgB,CAAC,QAAQ,CAAC,GAAG,IAAI,CAAC,eAAe,CAAC,OAAO,CAAC,CAAC;iBACjE;YACH,CAAC,CAAC,CAAC;YAEH,MAAM,aAAa,GAAG,IAAI,CAAC,kBAAkB,CAAC,UAAU,CAAC,CAAC;YAC1D,MAAM,EAAC,YAAY,EAAE,gBAAgB,EAAC,GAAG,WAAW,CAAC;YACrD,KAAK,MAAM,IAAI,IAAI,YAAY,CAAE;gBAC/B,IAAI,UAAU,CAAC,IAAI,CAAC,IAAI,CAAC,EAAE;oBACzB,SAAS;iBACV;gBACD,MAAM,OAAO,OACT,wUAAS,EAAC,IAAI,EAAE,UAAU,EAAE,OAAO,EAAE,IAAI,CAAC,gBAAgB,CAClD,CAAC;gBACb,IAAI,8QAAI,CAAC,SAAS,CAAC,OAAO,CAAC,EAAE;oBAC3B,MAAM,IAAI,KAAK,CACX,CAAA,yBAAA,EAA4B,IAAI,CAAC,EAAE,CAAA,sBAAA,CAAwB,GAC3D,CAAA,wCAAA,CAA0C,CAAC,CAAC;iBACjD;gBACD,UAAU,CAAC,IAAI,CAAC,IAAI,CAAC,GAAG,OAAO,CAAC;gBAChC,IAAI,IAAI,CAAC,uBAAuB,EAAE;oBAChC,IAAI,CAAC,gBAAgB,CAAC,IAAI,CAAC,IAAI,CAAC,GAAG,IAAI,CAAC,eAAe,CAAC,OAAO,CAAC,CAAC;iBAClE;gBACD,IAAI,CAAC,2CAA2C,CAC5C,IAAI,EAAE,UAAU,EAAE,OAAO,EAAE,aAAa,EAAE,iBAAiB,EAC3D,gBAAgB,CAAC,GAAG,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC;aACtC;YAED,4CAA4C;YAC5C,IAAI,IAAI,CAAC,MAAM,IAAI,IAAI,EAAE;gBACvB,OAAO,CAAC,OAAO,CAAC,aAAa,CAAC,CAAC;aAChC;YAED,OAAO,OAAO,CAAC,GAAG,EAAC,IAAI,CAAC,EAAE,IAAC,wUAAS,EAAC,IAAI,EAAE,UAAU,EAAE,OAAO,CAAC,CAAC,CAAC;QACnE,CAAC,CAAC,CAAC;IACL,CAAC;IAEO,kBAAkB,CAAC,SAA0B,EAAA;QACnD,MAAM,GAAG,GAAG,EAAE,CAAC,MAAM,CAAC,KAAK,CACvB,EAAE,EACF,MAAM,CAAC,IAAI,CAAC,SAAS,CAAC,CACjB,GAAG,EAAC,GAAG,CAAC,EAAE,AAAC,SAAS,CAAC,GAAG,CAAC,CAAC,CAC1B,GAAG,EAAC,OAAO,CAAC,EAAE,AAAC,OAAO,CAAC,GAAG,EAAC,MAAM,CAAC,EAAE,AAAC,MAAM,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;QAC3D,OAAO,IAAI,GAAG,CAAC,GAAG,CAAC,CAAC;IACtB,CAAC;IAEO,sBAAsB,CAC1B,QAAgB,EAAE,IAAU,EAAE,SAA0B,EACxD,OAAyB,EAAE,aAA0B,EACrD,iBAA8B,EAC9B,+BAAwD,EAAA;QAC1D,wEAAwE;QACxE,6BAA6B;QAC7B,QAAI,sUAAa,EAAC,IAAI,CAAC,IAAI,iBAAiB,CAAC,GAAG,CAAC,QAAQ,CAAC,EAAE;YAC1D,OAAO;SACR;QAED,KAAK,MAAM,MAAM,IAAI,SAAS,CAAC,QAAQ,CAAC,CAAE;YACxC,IAAI,MAAM,IAAI,IAAI,EAAE;gBAClB,SAAS;aACV;YACD,+BAA+B,CAAC,MAAM,CAAC,EAAE,CAAC,GACtC,CAAC,+BAA+B,CAAC,MAAM,CAAC,EAAE,CAAC,IAAI,CAAC,CAAC,GACjD,IAAI,CAAC,QAAQ,CAAC,MAAM,CAAC;SAC1B;QAED,KAAK,MAAM,KAAK,IAAI,IAAI,CAAC,MAAM,CAAE;YAC/B,uEAAuE;YACvE,aAAa;YACb,QAAI,sUAAa,EAAC,KAAK,CAAC,EAAE;gBACxB,SAAS;aACV;YAED,MAAM,OAAO,OACT,0VAA2B,EAAC,KAAK,CAAC,IAAI,EAAE,SAAS,EAAE,OAAO,CAAC,CAAC;YAChE,IAAI,OAAO,IAAI,IAAI,EAAE;gBACnB,SAAS;aACV;YAED,KAAK,MAAM,MAAM,IAAI,OAAO,CAAE;gBAC5B,IAAI,CAAC,MAAM,IAAI,MAAM,CAAC,IAAI,IAAI,aAAa,CAAC,GAAG,CAAC,MAAM,CAAC,EAAE,CAAC,EAAE;oBAC1D,SAAS;iBACV;gBAED,kEAAkE;gBAClE,oCAAoC;gBACpC,mEAAmE;gBACnE,sEAAsE;gBACtE,MAAM,KAAK,GAAG,+BAA+B,CAAC,MAAM,CAAC,EAAE,CAAC,CAAC;gBACzD,IAAI,KAAK,KAAK,CAAC,EAAE;oBACf,MAAM,CAAC,OAAO,EAAE,CAAC;oBACjB,OAAO,+BAA+B,CAAC,MAAM,CAAC,EAAE,CAAC,CAAC;iBACnD,MAAM,IAAI,KAAK,IAAI,IAAI,EAAE;oBACxB,+BAA+B,CAAC,MAAM,CAAC,EAAE,CAAC,EAAE,CAAC;iBAC9C;aACF;SACF;IACH,CAAC;IAEO,2CAA2C,CAC/C,IAAU,EAAE,SAA0B,EAAE,OAAyB,EACjE,aAA0B,EAAE,iBAA8B,EAC1D,cAAuB,EAAA;QACzB,SAAS,mBAAmB,CAAC,IAAU;YACrC,wEAAwE;YACxE,6BAA6B;YAC7B,WAAO,sUAAa,EAAC,IAAI,CAAC,IAAI,iBAAiB,CAAC,GAAG,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;QACjE,CAAC;QAED,QAAI,sUAAa,EAAC,IAAI,CAAC,IAAI,cAAc,IAAI,IAAI,EAAE;YACjD,OAAO;SACR;QAED,KAAK,MAAM,aAAa,IAAI,cAAc,CAAE;YAC1C,IAAI,mBAAmB,CAAC,aAAa,CAAC,EAAE;gBACtC,SAAS;aACV;YACD,MAAM,OAAO,OAAG,0VAA2B,EACvC,aAAa,CAAC,IAAI,EAAE,SAAS,EAAE,OAAO,CAAC,CAAC;YAC5C,KAAK,MAAM,MAAM,IAAI,OAAO,CAAE;gBAC5B,IAAI,CAAC,MAAM,IAAI,MAAM,CAAC,IAAI,IAAI,aAAa,CAAC,GAAG,CAAC,MAAM,CAAC,EAAE,CAAC,EAAE;oBAC1D,SAAS;iBACV;gBACD,MAAM,CAAC,OAAO,EAAE,CAAC;aAClB;SACF;IACH,CAAC;IAED;;;;;;;;OAQG,CACH,KAAK,CAAC,YAAY,CAAC,MAAsB,EAAE,OAAkB,EAAA;QAE3D,OAAO,IAAI,CAAC,aAAa,CAAC,MAAM,EAAE,OAAO,CAAC,CAAC;IAC7C,CAAC;IAED,0BAA0B,GAAA;QACxB,IAAI,CAAC,IAAI,CAAC,gBAAgB,EAAE;YAC1B,OAAO;SACR;QACD,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,gBAAgB,CAAC,CAAC,OAAO,EAAC,WAAW,CAAC,EAAE;YACzD,KAAK,MAAM,MAAM,IAAI,WAAW,CAAE;gBAChC,IAAI,MAAM,IAAI,CAAC,MAAM,CAAC,UAAU,EAAE;oBAChC,MAAM,CAAC,OAAO,EAAE,CAAC;iBAClB;aACF;QACH,CAAC,CAAC,CAAC;QAEH,IAAI,CAAC,gBAAgB,GAAG,IAAI,CAAC;IAC/B,CAAC;IAED,sBAAsB,GAAA;QACpB,OAAO,IAAI,CAAC,gBAAgB,CAAC;IAC/B,CAAC;IAED;;;;;;;;;;;;;OAaG,CACK,KAAK,CAAC,aAAa,CACvB,MAAsB,EAAE,OAAkB,EAAE,mBAAmB,GAAG,KAAK,EACvE,iBAAiC,CAAA,CAAE,EACnC,gBAA+B,CAAA,CAAE,EAAA;QACnC,8DAA8D;QAC9D,IAAI,CAAC,0BAA0B,EAAE,CAAC;QAClC,IAAI,CAAC,mBAAmB,EAAE;YACxB,MAAM,GAAG,IAAI,CAAC,SAAS,CAAC,MAAM,CAAC,CAAC;YAChC,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC,CAAC;YACzB,IAAI,CAAC,sBAAsB,CAAC,MAAM,CAAC,CAAC;YACpC,OAAO,GAAG,IAAI,CAAC,UAAU,CAAC,OAAO,CAAC,CAAC;YACnC,IAAI,CAAC,YAAY,CAAC,OAAO,CAAC,CAAC;SAC5B;QAED,mDAAmD;QACnD,IAAI;YACF,IAAI,CAAC,uBAAuB,OAAG,oPAAG,EAAE,EAAC,OAAO,CAAC,2BAA2B,CAAC,CAAC;SAC3E,CAAC,OAAO,CAAC,EAAE;YACV,IAAI,CAAC,uBAAuB,GAAG,KAAK,CAAC;YACrC,OAAO,CAAC,IAAI,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC;SACzB;QAED,MAAM,OAAO,GAAG,IAAI,4UAAgB,CAChC,IAAI,CAAC,SAAS,EAAE,cAAc,EAAE,aAAa,EAAE,IAAI,CAAC,mBAAmB,EACvE,IAAI,CAAC,kBAAkB,CAAC,CAAC;QAE7B,IAAI,IAAI,CAAC,uBAAuB,EAAE;YAChC,IAAI,CAAC,gBAAgB,GAAG,IAAI,CAAC,cAAc,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC;SAC7D;QAED,0EAA0E;QAC1E,0EAA0E;QAC1E,yBAAyB;QACzB,MAAM,UAAU,GAAG,MAAM,IAAI,CAAC,sBAAsB,CAChD,MAAM,EAAE,OAAO,EAAE,OAAO,EAAE,mBAAmB,CAAC,CAAC;QACnD,MAAM,OAAO,GAAG,OAAO,CAAC,GAAG,EAAC,IAAI,CAAC,EAAE,IAAC,wUAAS,EAAC,IAAI,EAAE,UAAU,EAAE,OAAO,CAAC,CAAC,CAAC;QAE1E,uCAAuC;QACvC,MAAM,SAAS,GAAG,OAAO,CAAC,GAAG,EAAC,CAAC,CAAC,EAAG,AAAD,CAAE,CAAC,EAAE,CAAC,CAAC;QACzC,MAAM,QAAQ,GAAG,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,GAAG,EAAC,IAAI,CAAC,EAAE,AAAC,MAAM,CAAC,IAAI,CAAC,CAAC,EAAE,CAAC,CAAC;QAClE,MAAM,OAAO,GACT,IAAI,GAAG,CAAS,CAAC;eAAG,SAAS,EAAE;eAAG,QAAQ,EAAE;eAAG,IAAI,CAAC,SAAS;SAAC,CAAC,CAAC;QAEpE,MAAM,CAAC,MAAM,CAAC,UAAU,CAAC,CAAC,OAAO,EAAC,WAAW,CAAC,EAAE;YAC9C,WAAW,CAAC,OAAO,EAAC,MAAM,CAAC,EAAE;gBAC3B,IAAI,MAAM,IAAI,CAAC,MAAM,CAAC,UAAU,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,MAAM,CAAC,EAAE,CAAC,EAAE;oBAC3D,MAAM,CAAC,OAAO,EAAE,CAAC;iBAClB;YACH,CAAC,CAAC,CAAC;QACL,CAAC,CAAC,CAAC;QAEH,4CAA4C;QAC5C,IAAI,IAAI,CAAC,MAAM,IAAI,IAAI,EAAE;YACvB,OAAO,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC;SAC1B;QAED,OAAO,OAAO,CAAC;IACjB,CAAC;IAED,KAAK,CAAC,oBAAoB,CACtB,MAAgB,EAAE,cAA8B,EAChD,aAA4B,EAAA;QAC9B,MAAM,YAAY,GAAG,MAAM,CAAC,MAAM,CAAC,CAAC,GAAG,EAAE,MAAM,EAAE,KAAK,EAAE,EAAE;YACxD,GAAG,CAAC,IAAI,CAAC,MAAM,CAAC,KAAK,CAAC,CAAC,IAAI,CAAC,GAAG,MAAM,CAAC;YACtC,OAAO,GAAG,CAAC;QACb,CAAC,EAAE,CAAA,CAAoB,CAAC,CAAC;QAEzB,OAAO,IAAI,CAAC,aAAa,CACrB,YAAY,EAAE,IAAI,CAAC,WAAW,EAAE,IAAI,EAAE,cAAc,EAAE,aAAa,CAAC,CAAC;IAC3E,CAAC;IAED;;;;;;;;;;OAUG,CACK,KAAK,CAAC,sBAAsB,CAChC,MAAsB,EAAE,OAAyB,EAAE,WAAsB,EACzE,mBAA6B,EAAA;QAC/B,MAAM,KAAK,GAAG,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC;QAClC,MAAM,UAAU,GACZ,KAAK,CAAC,GAAG,EAAC,IAAI,CAAC,EAAE,AAAC,IAAI,CAAC,KAAK,CAAC,KAAK,KAAC,4UAAa,EAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAChE,MAAM,eAAe,GAAG,WAAW,CAAC,GAAG,EAAC,IAAI,CAAC,EAAE,IAAC,4UAAa,EAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QACxE,MAAM,iBAAiB,GAAG,IAAI,GAAG,CAAC,eAAe,CAAC,CAAC;QACnD,IAAI,WAAW,GAAG,eAAe,CAAC,GAAG,EAAC,IAAI,CAAC,EAAE,AAAC,IAAI,CAAC,KAAK,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC,CAAC;QAEtE,0EAA0E;QAC1E,IAAI,WAAW,CAAC,MAAM,KAAK,CAAC,EAAE;YAC5B,WAAW,GAAG,IAAI,CAAC,QAAQ,CAAC;SAC7B;QAED,MAAM,EAAC,SAAS,EAAE,aAAa,EAAE,WAAW,EAAE,UAAU,EAAC,OACrD,6UAAoB,EAChB,MAAM,EAAE,WAAW,EAAE,IAAI,CAAC,SAAS,EAAE,IAAI,CAAC,UAAU,CAAC,CAAC;QAE9D,qEAAqE;QACrE,MAAM,KAAK,GAAuB;eAC7B,UAAU,EAAE;eAAG,IAAI,CAAC,KAAK,CAAC,OAAO,EAAE,GAAG;eAAC,IAAI,CAAC,UAAU,IAAI,EAAE,CAAC;SACjE,CAAC,GAAG,EAAC,IAAI,CAAC,EAAE;YACX,OAAO;gBAAC,IAAI;gBAAE,QAAQ,EAAE,OAAO,CAAC,cAAc;YAAA,CAAC,CAAC;QAClD,CAAC,CAAC,CAAC;QACH,MAAM,UAAU,GAAA,OAAA,MAAA,CAAA,CAAA,GAAwB,IAAI,CAAC,SAAS,CAAC,CAAC;QACxD,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,EAAC,IAAI,CAAC,EAAE;YACjC,MAAM,CAAC,QAAQ,EAAE,KAAK,CAAC,OAAG,4UAAa,EAAC,IAAI,CAAC,CAAC;YAC9C,MAAM,OAAO,GAAa,EAAE,CAAC;YAC7B,OAAO,CAAC,KAAK,CAAC,GAAG,MAAM,CAAC,IAAI,CAAC,CAAC;YAC9B,UAAU,CAAC,QAAQ,CAAC,GAAG,OAAO,CAAC;QACjC,CAAC,CAAC,CAAC;QACH,MAAM,+BAA+B,GAA4B,CAAA,CAAE,CAAC;QACpE,MAAM,aAAa,GAAG,IAAI,CAAC,kBAAkB,CAAC,UAAU,CAAC,CAAC;QAC1D,MAAM,KAAK,GAA6B,CAAA,CAAE,CAAC;QAC3C,MAAO,KAAK,CAAC,MAAM,GAAG,CAAC,CAAE;YACvB,MAAM,QAAQ,GAAG,IAAI,CAAC,YAAY,CAC9B,UAAU,EAAE,KAAK,EAAE,OAAO,EAAE,UAAU,EAAE,KAAK,EAAE,aAAa,EAC5D,iBAAiB,EAAE,+BAA+B,EAAE,SAAS,CAAC,CAAC;YACnE,MAAM,OAAO,CAAC,GAAG,CAAC,QAAQ,CAAC,CAAC;SAC7B;QACD,IAAI,WAAW,IAAI,IAAI,IAAI,CAAC,mBAAmB,EAAE;YAC/C,OAAO,CAAC,IAAI,CACR,CAAA,iEAAA,CAAmE,GACnE,CAAA,8DAAA,CAAgE,CAAC,CAAC;SACvE;QACD,MAAM,cAAc,GAChB,WAAW,CACN,MAAM,EACH,IAAI,CAAC,EAAE,AAAC,KAAC,sUAAa,EAAC,IAAI,CAAC,IACxB,KAAC,wUAAS,EAAC,IAAI,CAAC,IAAI,EAAE,UAAU,EAAE,OAAO,CAAC,CAAC,CAClD,GAAG,EAAC,IAAI,CAAC,EAAE,AAAC,IAAI,CAAC,IAAI,CAAC,CAAC;QAChC,IAAI,cAAc,CAAC,MAAM,GAAG,CAAC,EAAE;YAC7B,IAAI,cAAc,GAAG,EAAE,CAAC;YACxB,IAAI,WAAW,IAAI,IAAI,EAAE;gBACvB,cAAc,GACV,CAAA,6DAAA,CAA+D,GAC/D,CAAA,wBAAA,EAA2B,UAAU,CAAA,CAAA,CAAG,CAAC;aAC9C;YACD,MAAM,IAAI,KAAK,CACX,CAAA,4BAAA,EAA+B,cAAc,CAAA,oBAAA,CAAsB,GACnE,CAAA,QAAA,EAAW,KAAK,CAAA,4CAAA,CAA8C,GAC9D,CAAA,CAAA,EAAI,aAAa,CAAA,GAAA,EAAM,cAAc,EAAE,CAAC,CAAC;SAC9C;QACD,OAAO,UAAU,CAAC;IACpB,CAAC;IAEO,YAAY,CAChB,UAAkB,EAAE,KAAyB,EAAE,OAAyB,EACxE,SAA0B,EAAE,KAA+B,EAC3D,aAA0B,EAAE,iBAA8B,EAC1D,+BAAwD,EACxD,SAAsB,EAAA;QACxB,MAAM,QAAQ,GAA6B,EAAE,CAAC;QAC9C,MAAO,KAAK,CAAC,MAAM,GAAG,CAAC,CAAE;YACvB,MAAM,IAAI,GAAG,KAAK,CAAC,GAAG,EAAE,CAAC;YACzB,OAAO,CAAC,cAAc,GAAG,IAAI,CAAC,QAAQ,CAAC;YACvC,IAAI,QAAQ,GAAG,EAAE,CAAC;YAClB,+DAA+D;YAC/D,mEAAmE;YACnE,cAAc;YACd,IAAI,IAAI,CAAC,IAAI,CAAC,EAAE,KAAK,OAAO,QACxB,4UAAa,EAAC,YAAY,EAAE,IAAI,CAAC,IAAI,EAAE,SAAS,EAAE,OAAO,CAAC,EAAE;gBAC9D,CAAC,QAAQ,CAAC,OAAG,kVAAmB,EAAC,IAAI,CAAC,IAAI,CAAC,IAAI,EAAE,OAAO,CAAC,CAAC;aAC3D;YAED,qEAAqE;YACrE,qCAAqC;YACrC,IAAI,SAAS,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,IAAI,EAAE;gBACrC,MAAM,OAAO,OACT,wUAAS,EAAC,IAAI,CAAC,IAAI,EAAE,SAAS,EAAE,OAAO,EAAE,IAAI,CAAC,gBAAgB,CAAC,CAAC;gBACpE,IAAI,CAAC,QAAQ,EAAE;oBACb,CAAC,QAAQ,CAAC,OAAG,kVAAmB,EAAC,IAAI,CAAC,IAAI,CAAC,IAAI,EAAE,OAAO,CAAC,CAAC;iBAC3D;gBACD,MAAM,cAAc,GAAG,OAAO,CAAC,cAAc,CAAC;gBAC9C,IAAI,8QAAI,CAAC,SAAS,CAAC,OAAO,CAAC,EAAE;oBAC3B,QAAQ,CAAC,IAAI,CAAC,OAAO,CAAC,IAAI,EAAC,CAAC,CAAC,EAAE;wBAC7B,SAAS,CAAC,QAAQ,CAAC,GAAG,CAAC,CAAC;wBACxB,IAAI,IAAI,CAAC,uBAAuB,EAAE;4BAChC,IAAI,CAAC,gBAAgB,CAAC,QAAQ,CAAC,GAAG,IAAI,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC;yBAC3D;wBACD,OAAO,CAAC,cAAc,GAAG,cAAc,CAAC;wBACxC,IAAI,CAAC,sBAAsB,CACvB,QAAQ,EAAE,IAAI,CAAC,IAAI,EAAE,SAAS,EAAE,OAAO,EAAE,aAAa,EACtD,iBAAiB,EAAE,+BAA+B,CAAC,CAAC;wBACxD,IAAI,CAAC,iBAAiB,CAClB,IAAI,CAAC,IAAI,EAAE,KAAK,EAAE,OAAO,EAAE,SAAS,EAAE,KAAK,EAAE,SAAS,CAAC,CAAC;wBAC5D,OAAO,CAAC,CAAC;oBACX,CAAC,CAAC,CAAC,CAAC;iBACL,MAAM;oBACL,SAAS,CAAC,QAAQ,CAAC,GAAG,OAAO,CAAC;oBAC9B,IAAI,IAAI,CAAC,uBAAuB,EAAE;wBAChC,IAAI,CAAC,gBAAgB,CAAC,QAAQ,CAAC,GAAG,IAAI,CAAC,eAAe,CAAC,OAAO,CAAC,CAAC;qBACjE;oBACD,IAAI,CAAC,sBAAsB,CACvB,QAAQ,EAAE,IAAI,CAAC,IAAI,EAAE,SAAS,EAAE,OAAO,EAAE,aAAa,EACtD,iBAAiB,EAAE,+BAA+B,CAAC,CAAC;oBACxD,IAAI,CAAC,iBAAiB,CAClB,IAAI,CAAC,IAAI,EAAE,KAAK,EAAE,OAAO,EAAE,SAAS,EAAE,KAAK,EAAE,SAAS,CAAC,CAAC;iBAC7D;aACF,MAAM;gBACL,IAAI,CAAC,iBAAiB,CAClB,IAAI,CAAC,IAAI,EAAE,KAAK,EAAE,OAAO,EAAE,SAAS,EAAE,KAAK,EAAE,SAAS,CAAC,CAAC;aAC7D;SACF;QACD,OAAO,QAAQ,CAAC;IAClB,CAAC;IAEO,iBAAiB,CACrB,IAAU,EAAE,KAAyB,EAAE,OAAyB,EAChE,SAA0B,EAAE,KAA+B,EAC3D,SAAsB,EAAA;QACxB,IAAI,CAAC,QAAQ,CAAC,OAAO,CAAC,CAAC,SAAS,EAAE,EAAE;YAClC,MAAM,CAAC,QAAQ,CAAG,OAAG,kVAAmB,EAAC,SAAS,CAAC,IAAI,EAAE,OAAO,CAAC,CAAC;YAClE,IAAI,KAAK,CAAC,QAAQ,CAAC,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,SAAS,CAAC,IAAI,CAAC,EAAE;gBACrD,OAAO;aACR;YACD,yDAAyD;YACzD,IAAI,SAAS,CAAC,EAAE,KAAK,OAAO,EAAE;gBAC5B,IAAI,SAAS,CAAC,UAAU,CAAC,IAAI,EAAC,IAAI,CAAC,EAAE;oBAC/B,OAAO,CAAC,KAAC,wUAAS,EAAC,IAAI,EAAE,SAAS,EAAE,OAAO,CAAC,CAAC;gBAC/C,CAAC,CAAC,EAAE;oBACN,KAAK,CAAC,QAAQ,CAAC,GAAG,IAAI,CAAC;oBACvB,KAAK,CAAC,IAAI,CAAC;wBAAC,QAAQ,EAAE,OAAO,CAAC,cAAc;wBAAE,IAAI,EAAE,SAAS;oBAAA,CAAC,CAAC,CAAC;iBACjE;aACF,MACG,IAAI,SAAS,CAAC,UAAU,CAAC,KAAK,EAAC,IAAI,CAAC,EAAE;gBAChC,OAAO,CAAC,KAAC,wUAAS,EAAC,IAAI,EAAE,SAAS,EAAE,OAAO,CAAC,CAAC;YAC/C,CAAC,CAAC,EAAE;gBACV,KAAK,CAAC,QAAQ,CAAC,GAAG,IAAI,CAAC;gBACvB,KAAK,CAAC,IAAI,CAAC;oBAAC,QAAQ,EAAE,OAAO,CAAC,cAAc;oBAAE,IAAI,EAAE,SAAS;gBAAA,CAAC,CAAC,CAAC;aACjE;QACH,CAAC,CAAC,CAAC;IACL,CAAC;IAED;;OAEG,CACH,OAAO,GAAA;QACL,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,CACtB,OAAO,EACJ,GAAG,CAAC,EAAE,AAAC,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,CAAC,OAAO,EAAC,MAAM,CAAC,EAAE,AAAC,MAAM,CAAC,OAAO,EAAE,CAAC,CAAC,CAAC;IAC1E,CAAC;IAEO,sBAAsB,CAAC,MAAsB,EAAA;QACnD,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,OAAO,EAAC,IAAI,CAAC,EAAE;YACjC,MAAM,KAAK,GAAG,MAAM,CAAC,IAAI,CAAC,CAAC;YAC3B,MAAM,CAAC,QAAQ,CAAG,OAAG,4UAAa,EAAC,IAAI,CAAC,CAAC;YACzC,MAAM,IAAI,GAAG,IAAI,CAAC,KAAK,CAAC,KAAK,CAAC,QAAQ,CAAC,CAAC;YACxC,IAAI,IAAI,CAAC,UAAU,CAAC,OAAO,CAAC,IAAI,IAAI,CAAC,UAAU,CAAC,OAAO,CAAC,CAAC,KAAK,EAAE;gBAC9D,MAAM,KAAK,GAAG,IAAI,CAAC,UAAU,CAAC,OAAO,CAAC,CAAC,KAAiB,CAAC;gBACzD,MAAM,KAAK,GAAG,KAAK,CAAC,MAAM,KAAK,KAAK,CAAC,KAAK,CAAC,MAAM,IAC7C,KAAK,CAAC,KAAK,CAAC,KAAK,CACb,CAAC,GAAG,EAAE,KAAK,EAAE,CAAG,CAAD,IAAM,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,IAAI,KAAK,CAAC,KAAK,CAAC,KAAK,GAAG,CAAC,CAAC;gBACrE,8QAAI,CAAC,MAAM,CACP,KAAK,EACL,GAAG,CAAG,CAAA,AAAD,mBAAC,EAAsB,IAAI,CAAC,IAAI,CAAA,eAAA,CAAiB,GAClD,CAAA,6BAAA,EAAgC,KAAK,CAAA,WAAA,CAAa,GAClD,CAAA,CAAA,EAAI,KAAK,CAAC,KAAK,CAAA,CAAA,CAAG,CAAC,CAAC;aAC7B;YACD,IAAI,IAAI,CAAC,UAAU,CAAC,OAAO,CAAC,IAAI,IAAI,CAAC,UAAU,CAAC,OAAO,CAAC,CAAC,KAAK,EAAE;gBAC9D,8QAAI,CAAC,MAAM,CACP,KAAK,CAAC,KAAK,KAAK,IAAI,CAAC,UAAU,CAAC,OAAO,CAAC,CAAC,KAAe,EACxD,GAAG,CAAG,CAAD,AAAC,mBAAA,EAAsB,IAAI,CAAC,IAAI,CAAA,eAAA,CAAiB,GAClD,CAAA,4BAAA,CAA8B,GAC9B,GAAG,IAAI,CAAC,UAAU,CAAC,OAAO,CAAC,CAAC,KAAK,CAAA,UAAA,EAAa,KAAK,CAAC,KAAK,EAAE,CAAC,CAAC;aACtE;QACH,CAAC,CAAC,CAAC;IACL,CAAC;IAEO,SAAS,CAAC,MAAsB,EAAA;;QACtC,MAAM,MAAM,GAAmB,CAAA,CAAE,CAAC;QAClC,IAAK,MAAM,SAAS,IAAI,MAAM,CAAE;YAC9B,MAAM,MAAM,GAAG,CAAA,KAAA,CAAA,KAAA,IAAI,CAAC,UAAU,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GAAG,MAAM,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,EAAA,CAAI,SAAS,CAAC,CAAC;YACtD,IAAI,MAAM,IAAI,IAAI,EAAE;gBAClB,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC,GAAG,MAAM,CAAC,SAAS,CAAC,CAAC;aACzC,MAAM;gBACL,MAAM,CAAC,SAAS,CAAC,GAAG,MAAM,CAAC,SAAS,CAAC,CAAC;aACvC;SACF;QACD,OAAO,MAAM,CAAC;IAChB,CAAC;IAEO,WAAW,CAAC,MAAsB,EAAA;QACxC,MAAM,UAAU,GAAG,MAAM,CAAC,IAAI,CAAC,MAAM,CAAC,CAAC,MAAM,EAAC,IAAI,CAAC,EAAE;YACnD,MAAM,CAAC,QAAQ,CAAC,OAAG,4UAAa,EAAC,IAAI,CAAC,CAAC;YACvC,OAAO,IAAI,CAAC,KAAK,CAAC,KAAK,CAAC,QAAQ,CAAC,IAAI,IAAI,CAAC;QAC5C,CAAC,CAAC,CAAC;QACH,IAAI,UAAU,CAAC,MAAM,GAAG,CAAC,EAAE;YACzB,MAAM,IAAI,KAAK,CACX,CAAA,6CAAA,CAA+C,GAC/C,CAAA,OAAA,EAAU,UAAU,CAAA,4BAAA,CAA8B,CAAC,CAAC;SACzD;IACH,CAAC;IAEO,UAAU,CAAC,OAAiB,EAAA;QAClC,OAAO,OAAO,CAAC,GAAG,EAAC,IAAI,CAAC,EAAE;;YACxB,MAAM,MAAM,GAAG,CAAA,KAAA,CAAA,KAAA,IAAI,CAAC,UAAU,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GAAG,OAAO,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,EAAA,CAAI,IAAI,CAAC,CAAC;YAClD,IAAI,MAAM,IAAI,IAAI,EAAE;gBAClB,OAAO,MAAM,CAAC,IAAI,CAAC;aACpB;YACD,OAAO,IAAI,CAAC;QACd,CAAC,EAAE,CAAA,CAAE,CAAC,CAAC;IACT,CAAC;IAEO,YAAY,CAAC,OAAiB,EAAA;QACpC,OAAO,CAAC,OAAO,EAAC,IAAI,CAAC,EAAE;YACrB,MAAM,CAAC,cAAc,CAAC,OAAG,4UAAa,EAAC,IAAI,CAAC,CAAC;YAC7C,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC,KAAK,CAAC,cAAc,CAAC,EAAE;gBACrC,MAAM,IAAI,KAAK,CAAC,CAAA,YAAA,EAAe,IAAI,CAAA,2BAAA,CAA6B,CAAC,CAAC;aACnE;QACH,CAAC,CAAC,CAAC;IACL,CAAC;CACF"}},
    {"offset": {"line": 1872, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-converter@4.22.0_@tensorflow+tfjs-core@4.22.0/node_modules/@tensorflow/tfjs-converter/dist/executor/resource_manager.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-converter/src/executor/resource_manager.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {HashTableMap, NamedTensorMap} from '../data/types';\nimport {HashTable} from './hash_table';\n\n/**\n * Contains global resources of a model.\n */\nexport class ResourceManager {\n  constructor(\n      readonly hashTableNameToHandle: NamedTensorMap = {},\n      readonly hashTableMap: HashTableMap = {}) {}\n\n  /**\n   * Register a `HashTable` in the resource manager.\n   *\n   * The `HashTable` can be retrieved by `resourceManager.getHashTableById`,\n   * where id is the table handle tensor's id.\n   *\n   * @param name Op node name that creates the `HashTable`.\n   * @param hashTable The `HashTable` to be added to resource manager.\n   */\n  addHashTable(name: string, hashTable: HashTable) {\n    this.hashTableNameToHandle[name] = hashTable.handle;\n    this.hashTableMap[hashTable.id] = hashTable;\n  }\n\n  /**\n   * Get the table handle by node name.\n   * @param name Op node name that creates the `HashTable`. This name is also\n   *     used in the inputs list of lookup and import `HashTable` ops.\n   */\n  getHashTableHandleByName(name: string) {\n    return this.hashTableNameToHandle[name];\n  }\n\n  /**\n   * Get the actual `HashTable` by its handle tensor's id.\n   * @param id The id of the handle tensor.\n   */\n  getHashTableById(id: number): HashTable {\n    return this.hashTableMap[id];\n  }\n\n  /**\n   * Dispose `ResourceManager`, including its hashTables and tensors in them.\n   */\n  dispose() {\n    for (const key in this.hashTableMap) {\n      this.hashTableMap[key].clearAndClose();\n      delete this.hashTableMap[key];\n    }\n\n    for (const name in this.hashTableNameToHandle) {\n      this.hashTableNameToHandle[name].dispose();\n      delete this.hashTableNameToHandle[name];\n    }\n  }\n}\n"],"names":[],"mappings":"AAmBA;;GAEG;;;;AACG,MAAO,eAAe;IAC1B,YACa,wBAAwC,CAAA,CAAE,EAC1C,eAA6B,CAAA,CAAE,CAAA;QAD/B,IAAA,CAAA,qBAAqB,GAArB,qBAAqB,CAAqB;QAC1C,IAAA,CAAA,YAAY,GAAZ,YAAY,CAAmB;IAAG,CAAC;IAEhD;;;;;;;;OAQG,CACH,YAAY,CAAC,IAAY,EAAE,SAAoB,EAAA;QAC7C,IAAI,CAAC,qBAAqB,CAAC,IAAI,CAAC,GAAG,SAAS,CAAC,MAAM,CAAC;QACpD,IAAI,CAAC,YAAY,CAAC,SAAS,CAAC,EAAE,CAAC,GAAG,SAAS,CAAC;IAC9C,CAAC;IAED;;;;OAIG,CACH,wBAAwB,CAAC,IAAY,EAAA;QACnC,OAAO,IAAI,CAAC,qBAAqB,CAAC,IAAI,CAAC,CAAC;IAC1C,CAAC;IAED;;;OAGG,CACH,gBAAgB,CAAC,EAAU,EAAA;QACzB,OAAO,IAAI,CAAC,YAAY,CAAC,EAAE,CAAC,CAAC;IAC/B,CAAC;IAED;;OAEG,CACH,OAAO,GAAA;QACL,IAAK,MAAM,GAAG,IAAI,IAAI,CAAC,YAAY,CAAE;YACnC,IAAI,CAAC,YAAY,CAAC,GAAG,CAAC,CAAC,aAAa,EAAE,CAAC;YACvC,OAAO,IAAI,CAAC,YAAY,CAAC,GAAG,CAAC,CAAC;SAC/B;QAED,IAAK,MAAM,IAAI,IAAI,IAAI,CAAC,qBAAqB,CAAE;YAC7C,IAAI,CAAC,qBAAqB,CAAC,IAAI,CAAC,CAAC,OAAO,EAAE,CAAC;YAC3C,OAAO,IAAI,CAAC,qBAAqB,CAAC,IAAI,CAAC,CAAC;SACzC;IACH,CAAC;CACF"}},
    {"offset": {"line": 1925, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-converter@4.22.0_@tensorflow+tfjs-core@4.22.0/node_modules/@tensorflow/tfjs-converter/dist/executor/graph_model.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-converter/src/executor/graph_model.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {dispose, InferenceModel, io, ModelPredictConfig, NamedTensorMap, Tensor, util} from '@tensorflow/tfjs-core';\n\nimport * as tensorflow from '../data/compiled_api';\nimport {NamedTensorsMap, TensorInfo} from '../data/types';\nimport {OperationMapper} from '../operations/operation_mapper';\n\nimport {GraphExecutor} from './graph_executor';\nimport {ResourceManager} from './resource_manager';\n// tslint:disable-next-line: no-imports-from-dist\nimport {decodeWeightsStream} from '@tensorflow/tfjs-core/dist/io/io_utils';\n\nexport const TFHUB_SEARCH_PARAM = '?tfjs-format=file';\nexport const DEFAULT_MODEL_NAME = 'model.json';\ntype Url = string|io.IOHandler|io.IOHandlerSync;\ntype UrlIOHandler<T extends Url> = T extends string ? io.IOHandler : T;\n\n/**\n * A `tf.GraphModel` is a directed, acyclic graph built from a\n * SavedModel GraphDef and allows inference execution.\n *\n * A `tf.GraphModel` can only be created by loading from a model converted from\n * a [TensorFlow SavedModel](https://www.tensorflow.org/guide/saved_model) using\n * the command line converter tool and loaded via `tf.loadGraphModel`.\n *\n * @doc {heading: 'Models', subheading: 'Classes'}\n */\nexport class GraphModel<ModelURL extends Url = string | io.IOHandler> implements\n    InferenceModel {\n  private executor: GraphExecutor;\n  private version = 'n/a';\n  private handler: UrlIOHandler<ModelURL>;\n  private artifacts: io.ModelArtifacts;\n  private initializer: GraphExecutor;\n  private resourceIdToCapturedInput: {[key: number]: Tensor};\n  private resourceManager: ResourceManager;\n  private signature: tensorflow.ISignatureDef;\n  private initializerSignature: tensorflow.ISignatureDef;\n  private structuredOutputKeys: string[];\n  private readonly io: typeof io;\n\n  // Returns the version information for the tensorflow model GraphDef.\n  get modelVersion(): string {\n    return this.version;\n  }\n\n  get inputNodes(): string[] {\n    return this.executor.inputNodes;\n  }\n\n  get outputNodes(): string[] {\n    return this.executor.outputNodes;\n  }\n\n  get inputs(): TensorInfo[] {\n    return this.executor.inputs;\n  }\n\n  get outputs(): TensorInfo[] {\n    return this.executor.outputs;\n  }\n\n  get weights(): NamedTensorsMap {\n    return this.executor.weightMap;\n  }\n\n  get metadata(): {} {\n    return this.artifacts.userDefinedMetadata;\n  }\n\n  get modelSignature(): {} {\n    return this.signature;\n  }\n\n  get modelStructuredOutputKeys(): {} {\n    return this.structuredOutputKeys;\n  }\n\n  /**\n   * @param modelUrl url for the model, or an `io.IOHandler`.\n   * @param weightManifestUrl url for the weight file generated by\n   * scripts/convert.py script.\n   * @param requestOption options for Request, which allows to send credentials\n   * and custom headers.\n   * @param onProgress Optional, progress callback function, fired periodically\n   * before the load is completed.\n   */\n  constructor(\n      private modelUrl: ModelURL, private loadOptions: io.LoadOptions = {},\n      tfio = io) {\n    this.io = tfio;\n    if (loadOptions == null) {\n      this.loadOptions = {};\n    }\n    this.resourceManager = new ResourceManager();\n  }\n\n  private findIOHandler() {\n    type IOHandler = UrlIOHandler<ModelURL>;\n    const path = this.modelUrl;\n    if ((path as io.IOHandler).load != null) {\n      // Path is an IO Handler.\n      this.handler = path as IOHandler;\n    } else if (this.loadOptions.requestInit != null) {\n      this.handler = this.io.browserHTTPRequest(\n                         path as string, this.loadOptions) as IOHandler;\n    } else {\n      const handlers =\n          this.io.getLoadHandlers(path as string, this.loadOptions);\n      if (handlers.length === 0) {\n        // For backward compatibility: if no load handler can be found,\n        // assume it is a relative http path.\n        handlers.push(\n            this.io.browserHTTPRequest(path as string, this.loadOptions));\n      } else if (handlers.length > 1) {\n        throw new Error(\n            `Found more than one (${handlers.length}) load handlers for ` +\n            `URL '${[path]}'`);\n      }\n      this.handler = handlers[0] as IOHandler;\n    }\n  }\n\n  /**\n   * Loads the model and weight files, construct the in memory weight map and\n   * compile the inference graph.\n   */\n  load(): UrlIOHandler<ModelURL> extends io.IOHandlerSync? boolean:\n                                             Promise<boolean> {\n    type IOHandler = UrlIOHandler<ModelURL>;\n    this.findIOHandler();\n    if (this.handler.load == null) {\n      throw new Error(\n          'Cannot proceed with model loading because the IOHandler provided ' +\n          'does not have the `load` method implemented.');\n    }\n\n    type Result =\n        IOHandler extends io.IOHandlerSync ? boolean : Promise<boolean>;\n\n    const loadResult = this.handler.load() as ReturnType<IOHandler['load']>;\n    if (util.isPromise(loadResult)) {\n      return loadResult.then(artifacts => {\n        if (artifacts.getWeightStream == null) {\n          return this.loadSync(artifacts);\n        }\n        return this.loadStreaming(artifacts);\n      }) as Result;\n    }\n\n    return this.loadSync(loadResult) as Result;\n  }\n\n  /**\n   * Synchronously construct the in memory weight map and\n   * compile the inference graph.\n   *\n   * @doc {heading: 'Models', subheading: 'Classes', ignoreCI: true}\n   */\n  loadSync(artifacts: io.ModelArtifacts) {\n    const weightMap = this.io.decodeWeights(\n        artifacts.weightData, artifacts.weightSpecs);\n\n    return this.loadWithWeightMap(artifacts, weightMap);\n  }\n\n  private async loadStreaming(artifacts: io.ModelArtifacts): Promise<boolean> {\n    if (artifacts.getWeightStream == null) {\n      throw new Error('Model artifacts missing streamWeights function');\n    }\n\n    const weightMap = await decodeWeightsStream(\n      artifacts.getWeightStream(), artifacts.weightSpecs);\n\n    return this.loadWithWeightMap(artifacts, weightMap);\n  }\n\n  private loadWithWeightMap(artifacts: io.ModelArtifacts,\n                            weightMap: NamedTensorMap) {\n    this.artifacts = artifacts;\n    const graph = this.artifacts.modelTopology as tensorflow.IGraphDef;\n\n    let signature = this.artifacts.signature;\n    if (this.artifacts.userDefinedMetadata != null) {\n      const metadata = this.artifacts.userDefinedMetadata;\n      if (metadata.signature != null) {\n        signature = metadata.signature;\n      }\n\n      if (metadata.structuredOutputKeys != null) {\n        this.structuredOutputKeys = metadata.structuredOutputKeys as string[];\n      }\n    }\n    this.signature = signature;\n\n    this.version = `${graph.versions.producer}.${graph.versions.minConsumer}`;\n    this.executor = new GraphExecutor(\n        OperationMapper.Instance.transformGraph(graph, this.signature));\n    this.executor.weightMap = this.convertTensorMapToTensorsMap(weightMap);\n    // Attach a model-level resourceManager to each executor to share resources,\n    // such as `HashTable`.\n    this.executor.resourceManager = this.resourceManager;\n\n    if (artifacts.modelInitializer != null &&\n        (artifacts.modelInitializer as tensorflow.IGraphDef).node != null) {\n      const initializer =\n          OperationMapper.Instance.transformGraph(artifacts.modelInitializer);\n      this.initializer = new GraphExecutor(initializer);\n      this.initializer.weightMap = this.executor.weightMap;\n      // Attach a model-level resourceManager to the initializer, the\n      // hashTables created from when executing the initializer will be stored\n      // in the resourceManager.\n      this.initializer.resourceManager = this.resourceManager;\n      this.initializerSignature = artifacts.initializerSignature;\n    }\n\n    return true;\n  }\n\n  /**\n   * Save the configuration and/or weights of the GraphModel.\n   *\n   * An `IOHandler` is an object that has a `save` method of the proper\n   * signature defined. The `save` method manages the storing or\n   * transmission of serialized data (\"artifacts\") that represent the\n   * model's topology and weights onto or via a specific medium, such as\n   * file downloads, local storage, IndexedDB in the web browser and HTTP\n   * requests to a server. TensorFlow.js provides `IOHandler`\n   * implementations for a number of frequently used saving mediums, such as\n   * `tf.io.browserDownloads` and `tf.io.browserLocalStorage`. See `tf.io`\n   * for more details.\n   *\n   * This method also allows you to refer to certain types of `IOHandler`s\n   * as URL-like string shortcuts, such as 'localstorage://' and\n   * 'indexeddb://'.\n   *\n   * Example 1: Save `model`'s topology and weights to browser [local\n   * storage](https://developer.mozilla.org/en-US/docs/Web/API/Window/localStorage);\n   * then load it back.\n   *\n   * ```js\n   * const modelUrl =\n   *    'https://storage.googleapis.com/tfjs-models/savedmodel/mobilenet_v2_1.0_224/model.json';\n   * const model = await tf.loadGraphModel(modelUrl);\n   * const zeros = tf.zeros([1, 224, 224, 3]);\n   * model.predict(zeros).print();\n   *\n   * const saveResults = await model.save('localstorage://my-model-1');\n   *\n   * const loadedModel = await tf.loadGraphModel('localstorage://my-model-1');\n   * console.log('Prediction from loaded model:');\n   * model.predict(zeros).print();\n   * ```\n   *\n   * @param handlerOrURL An instance of `IOHandler` or a URL-like,\n   * scheme-based string shortcut for `IOHandler`.\n   * @param config Options for saving the model.\n   * @returns A `Promise` of `SaveResult`, which summarizes the result of\n   * the saving, such as byte sizes of the saved artifacts for the model's\n   *   topology and weight values.\n   *\n   * @doc {heading: 'Models', subheading: 'Classes', ignoreCI: true}\n   */\n  async save(handlerOrURL: io.IOHandler|string, config?: io.SaveConfig):\n      Promise<io.SaveResult> {\n    if (typeof handlerOrURL === 'string') {\n      const handlers = this.io.getSaveHandlers(handlerOrURL);\n      if (handlers.length === 0) {\n        throw new Error(\n            `Cannot find any save handlers for URL '${handlerOrURL}'`);\n      } else if (handlers.length > 1) {\n        throw new Error(\n            `Found more than one (${handlers.length}) save handlers for ` +\n            `URL '${handlerOrURL}'`);\n      }\n      handlerOrURL = handlers[0];\n    }\n    if (handlerOrURL.save == null) {\n      throw new Error(\n          'GraphModel.save() cannot proceed because the IOHandler ' +\n          'provided does not have the `save` attribute defined.');\n    }\n\n    return handlerOrURL.save(this.artifacts);\n  }\n\n  private addStructuredOutputNames(outputTensors: Tensor|Tensor[]) {\n    if (this.structuredOutputKeys) {\n      const outputTensorsArray =\n          outputTensors instanceof Tensor ? [outputTensors] : outputTensors;\n      const outputTensorMap: NamedTensorMap = {};\n\n      outputTensorsArray.forEach(\n          (outputTensor, i) => outputTensorMap[this.structuredOutputKeys[i]] =\n              outputTensor);\n\n      return outputTensorMap;\n    }\n    return outputTensors;\n  }\n\n  /**\n   * Execute the inference for the input tensors.\n   *\n   * @param input The input tensors, when there is single input for the model,\n   * inputs param should be a `tf.Tensor`. For models with multiple inputs,\n   * inputs params should be in either `tf.Tensor`[] if the input order is\n   * fixed, or otherwise NamedTensorMap format.\n   *\n   * For model with multiple inputs, we recommend you use NamedTensorMap as the\n   * input type, if you use `tf.Tensor`[], the order of the array needs to\n   * follow the\n   * order of inputNodes array. @see {@link GraphModel.inputNodes}\n   *\n   * You can also feed any intermediate nodes using the NamedTensorMap as the\n   * input type. For example, given the graph\n   *    InputNode => Intermediate => OutputNode,\n   * you can execute the subgraph Intermediate => OutputNode by calling\n   *    model.execute('IntermediateNode' : tf.tensor(...));\n   *\n   * This is useful for models that uses tf.dynamic_rnn, where the intermediate\n   * state needs to be fed manually.\n   *\n   * For batch inference execution, the tensors for each input need to be\n   * concatenated together. For example with mobilenet, the required input shape\n   * is [1, 244, 244, 3], which represents the [batch, height, width, channel].\n   * If we are provide a batched data of 100 images, the input tensor should be\n   * in the shape of [100, 244, 244, 3].\n   *\n   * @param config Prediction configuration for specifying the batch size.\n   * Currently the batch size option is ignored for graph model.\n   *\n   * @returns Inference result tensors. If the model is converted and it\n   * originally had structured_outputs in tensorflow, then a NamedTensorMap\n   * will be returned matching the structured_outputs. If no structured_outputs\n   * are present, the output will be single `tf.Tensor` if the model has single\n   * output node, otherwise Tensor[].\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n  predict(inputs: Tensor|Tensor[]|NamedTensorMap, config?: ModelPredictConfig):\n      Tensor|Tensor[]|NamedTensorMap {\n    const outputTensors = this.execute(inputs, this.outputNodes);\n    return this.addStructuredOutputNames(outputTensors);\n  }\n\n  /**\n   * Execute the inference for the input tensors in async fashion, use this\n   * method when your model contains control flow ops.\n   *\n   * @param input The input tensors, when there is single input for the model,\n   * inputs param should be a `tf.Tensor`. For models with mutliple inputs,\n   * inputs params should be in either `tf.Tensor`[] if the input order is\n   * fixed, or otherwise NamedTensorMap format.\n   *\n   * For model with multiple inputs, we recommend you use NamedTensorMap as the\n   * input type, if you use `tf.Tensor`[], the order of the array needs to\n   * follow the\n   * order of inputNodes array. @see {@link GraphModel.inputNodes}\n   *\n   * You can also feed any intermediate nodes using the NamedTensorMap as the\n   * input type. For example, given the graph\n   *    InputNode => Intermediate => OutputNode,\n   * you can execute the subgraph Intermediate => OutputNode by calling\n   *    model.execute('IntermediateNode' : tf.tensor(...));\n   *\n   * This is useful for models that uses tf.dynamic_rnn, where the intermediate\n   * state needs to be fed manually.\n   *\n   * For batch inference execution, the tensors for each input need to be\n   * concatenated together. For example with mobilenet, the required input shape\n   * is [1, 244, 244, 3], which represents the [batch, height, width, channel].\n   * If we are provide a batched data of 100 images, the input tensor should be\n   * in the shape of [100, 244, 244, 3].\n   *\n   * @param config Prediction configuration for specifying the batch size.\n   * Currently the batch size option is ignored for graph model.\n   *\n   * @returns A Promise of inference result tensors. If the model is converted\n   * and it originally had structured_outputs in tensorflow, then a\n   * NamedTensorMap will be returned matching the structured_outputs. If no\n   * structured_outputs are present, the output will be single `tf.Tensor` if\n   * the model has single output node, otherwise Tensor[].\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n  async predictAsync(\n      inputs: Tensor|Tensor[]|NamedTensorMap,\n      config?: ModelPredictConfig): Promise<Tensor|Tensor[]|NamedTensorMap> {\n    const outputTensors = await this.executeAsync(inputs, this.outputNodes);\n    return this.addStructuredOutputNames(outputTensors);\n  }\n\n  private normalizeInputs(inputs: Tensor|Tensor[]|\n                          NamedTensorMap): NamedTensorMap {\n    if (!(inputs instanceof Tensor) && !Array.isArray(inputs)) {\n      // The input is already a NamedTensorMap.\n      const signatureInputs = this.signature?.inputs;\n      if (signatureInputs != null) {\n        for (const input in signatureInputs) {\n          const tensor = signatureInputs[input];\n          if (tensor.resourceId != null) {\n            inputs[input] = this.resourceIdToCapturedInput[tensor.resourceId];\n          }\n        }\n      }\n      return inputs;\n    }\n    inputs = Array.isArray(inputs) ? inputs : [inputs];\n\n    const numCapturedInputs =\n        Object.keys(this.resourceIdToCapturedInput).length;\n    if (inputs.length + numCapturedInputs !== this.inputNodes.length) {\n      throw new Error(`Input tensor count mismatch, the graph model has ${\n          this.inputNodes.length -\n          numCapturedInputs} non-resource placeholders, while there are ${\n          inputs.length} input tensors provided.`);\n    }\n\n    let inputIndex = 0;\n    return this.inputNodes.reduce((map, inputName) => {\n      const resourceId = this.signature?.inputs?.[inputName]?.resourceId;\n      if (resourceId != null) {\n        map[inputName] = this.resourceIdToCapturedInput[resourceId];\n      } else {\n        map[inputName] = (inputs as Tensor[])[inputIndex++];\n      }\n      return map;\n    }, {} as NamedTensorMap);\n  }\n\n  private normalizeOutputs(outputs: string|string[]): string[] {\n    outputs = outputs || this.outputNodes;\n    return !Array.isArray(outputs) ? [outputs] : outputs;\n  }\n\n  private executeInitializerGraph() {\n    if (this.initializer == null) {\n      return [];\n    }\n    if (this.initializerSignature == null) {\n      return this.initializer.execute({}, []);\n    } else {\n      return this.initializer.execute(\n          {}, Object.keys(this.initializerSignature.outputs));\n    }\n  }\n\n  private async executeInitializerGraphAsync() {\n    if (this.initializer == null) {\n      return [];\n    }\n    if (this.initializerSignature == null) {\n      return this.initializer.executeAsync({}, []);\n    } else {\n      return this.initializer.executeAsync(\n          {}, Object.keys(this.initializerSignature.outputs));\n    }\n  }\n\n  private setResourceIdToCapturedInput(outputs: Tensor[]) {\n    this.resourceIdToCapturedInput = {};\n\n    if (this.initializerSignature) {\n      const signatureOutputs = this.initializerSignature.outputs;\n      const outputNames = Object.keys(signatureOutputs);\n      for (let i = 0; i < outputNames.length; i++) {\n        const outputName = outputNames[i];\n        const tensorInfo = signatureOutputs[outputName];\n        this.resourceIdToCapturedInput[tensorInfo.resourceId] = outputs[i];\n      }\n    }\n  }\n\n  /**\n   * Executes inference for the model for given input tensors.\n   * @param inputs tensor, tensor array or tensor map of the inputs for the\n   * model, keyed by the input node names.\n   * @param outputs output node name from the TensorFlow model, if no\n   * outputs are specified, the default outputs of the model would be used.\n   * You can inspect intermediate nodes of the model by adding them to the\n   * outputs array.\n   *\n   * @returns A single tensor if provided with a single output or no outputs\n   * are provided and there is only one default output, otherwise return a\n   * tensor array. The order of the tensor array is the same as the outputs\n   * if provided, otherwise the order of outputNodes attribute of the model.\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n  execute(inputs: Tensor|Tensor[]|NamedTensorMap, outputs?: string|string[]):\n      Tensor|Tensor[] {\n    if (this.resourceIdToCapturedInput == null) {\n      this.setResourceIdToCapturedInput(this.executeInitializerGraph());\n    }\n    inputs = this.normalizeInputs(inputs);\n    outputs = this.normalizeOutputs(outputs);\n    const result = this.executor.execute(inputs, outputs);\n    return result.length > 1 ? result : result[0];\n  }\n\n  /**\n   * Executes inference for the model for given input tensors in async\n   * fashion, use this method when your model contains control flow ops.\n   * @param inputs tensor, tensor array or tensor map of the inputs for the\n   * model, keyed by the input node names.\n   * @param outputs output node name from the TensorFlow model, if no outputs\n   * are specified, the default outputs of the model would be used. You can\n   * inspect intermediate nodes of the model by adding them to the outputs\n   * array.\n   *\n   * @returns A Promise of single tensor if provided with a single output or\n   * no outputs are provided and there is only one default output, otherwise\n   * return a tensor map.\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n  async executeAsync(\n      inputs: Tensor|Tensor[]|NamedTensorMap,\n      outputs?: string|string[]): Promise<Tensor|Tensor[]> {\n    if (this.resourceIdToCapturedInput == null) {\n      this.setResourceIdToCapturedInput(\n          await this.executeInitializerGraphAsync());\n    }\n    inputs = this.normalizeInputs(inputs);\n    outputs = this.normalizeOutputs(outputs);\n    const result = await this.executor.executeAsync(inputs, outputs);\n    return result.length > 1 ? result : result[0];\n  }\n\n  /**\n   * Get intermediate tensors for model debugging mode (flag\n   * KEEP_INTERMEDIATE_TENSORS is true).\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n  getIntermediateTensors(): NamedTensorsMap {\n    return this.executor.getIntermediateTensors();\n  }\n\n  /**\n   * Dispose intermediate tensors for model debugging mode (flag\n   * KEEP_INTERMEDIATE_TENSORS is true).\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n  disposeIntermediateTensors() {\n    this.executor.disposeIntermediateTensors();\n  }\n\n  private convertTensorMapToTensorsMap(map: NamedTensorMap): NamedTensorsMap {\n    return Object.keys(map).reduce((newMap: NamedTensorsMap, key) => {\n      newMap[key] = [map[key]];\n      return newMap;\n    }, {});\n  }\n\n  /**\n   * Releases the memory used by the weight tensors and resourceManager.\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n  dispose() {\n    this.executor.dispose();\n\n    if (this.initializer) {\n      this.initializer.dispose();\n      if (this.resourceIdToCapturedInput) {\n        dispose(this.resourceIdToCapturedInput);\n      }\n    }\n\n    this.resourceManager.dispose();\n  }\n}\n\n/**\n * Load a graph model given a URL to the model definition.\n *\n * Example of loading MobileNetV2 from a URL and making a prediction with a\n * zeros input:\n *\n * ```js\n * const modelUrl =\n *    'https://storage.googleapis.com/tfjs-models/savedmodel/mobilenet_v2_1.0_224/model.json';\n * const model = await tf.loadGraphModel(modelUrl);\n * const zeros = tf.zeros([1, 224, 224, 3]);\n * model.predict(zeros).print();\n * ```\n *\n * Example of loading MobileNetV2 from a TF Hub URL and making a prediction\n * with a zeros input:\n *\n * ```js\n * const modelUrl =\n *    'https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/classification/2';\n * const model = await tf.loadGraphModel(modelUrl, {fromTFHub: true});\n * const zeros = tf.zeros([1, 224, 224, 3]);\n * model.predict(zeros).print();\n * ```\n * @param modelUrl The url or an `io.IOHandler` that loads the model.\n * @param options Options for the HTTP request, which allows to send\n *     credentials\n *    and custom headers.\n *\n * @doc {heading: 'Models', subheading: 'Loading'}\n */\nexport async function loadGraphModel(\n    modelUrl: string|io.IOHandler, options: io.LoadOptions = {},\n    tfio = io): Promise<GraphModel> {\n  if (modelUrl == null) {\n    throw new Error(\n        'modelUrl in loadGraphModel() cannot be null. Please provide a url ' +\n        'or an IOHandler that loads the model');\n  }\n  if (options == null) {\n    options = {};\n  }\n\n  if (options.fromTFHub && typeof modelUrl === 'string') {\n    modelUrl = getTFHubUrl(modelUrl);\n  }\n  const model = new GraphModel(modelUrl, options, tfio);\n  await model.load();\n  return model;\n}\n\n/**\n * Load a graph model given a synchronous IO handler with a 'load' method.\n *\n * @param modelSource The `io.IOHandlerSync` that loads the model, or the\n *     `io.ModelArtifacts` that encode the model, or a tuple of\n *     `[io.ModelJSON, ArrayBuffer]` of which the first element encodes the\n *      model and the second contains the weights.\n *\n * @doc {heading: 'Models', subheading: 'Loading'}\n */\nexport function loadGraphModelSync(\n    modelSource: io.IOHandlerSync|\n    io.ModelArtifacts|[io.ModelJSON, /* Weights */ ArrayBuffer]):\n    GraphModel<io.IOHandlerSync> {\n  if (modelSource == null) {\n    throw new Error(\n        'modelUrl in loadGraphModelSync() cannot be null. Please provide ' +\n        'model artifacts or an IOHandler that loads the model');\n  }\n\n  let ioHandler: io.IOHandlerSync;\n  if (modelSource instanceof Array) {\n    const [modelJSON, weights] = modelSource;\n    if (!modelJSON) {\n      throw new Error('modelJSON must be the first element of the array');\n    }\n    if (!weights || !(weights instanceof ArrayBuffer)) {\n      throw new Error(\n          'An ArrayBuffer of weights must be the second element of' +\n          ' the array');\n    }\n    if (!('modelTopology' in modelJSON)) {\n      throw new Error('Model JSON is missing \\'modelTopology\\'');\n    }\n    if (!('weightsManifest' in modelJSON)) {\n      throw new Error('Model JSON is missing \\'weightsManifest\\'');\n    }\n\n    const weightSpecs = io.getWeightSpecs(modelJSON.weightsManifest);\n    const modelArtifacts =\n        io.getModelArtifactsForJSONSync(modelJSON, weightSpecs, weights);\n    ioHandler = io.fromMemorySync(modelArtifacts);\n  } else if ('load' in modelSource) {\n    // Then modelSource is already an IOHandlerSync.\n    ioHandler = modelSource;\n  } else if (\n      'modelTopology' in modelSource && 'weightSpecs' in modelSource &&\n      'weightData' in modelSource) {\n    // modelSource is of type ModelArtifacts.\n    ioHandler = io.fromMemorySync(modelSource);\n  } else {\n    throw new Error('Unknown model format');\n  }\n\n  const model = new GraphModel(ioHandler);\n  model.load();\n  return model;\n}\n\nfunction getTFHubUrl(modelUrl: string): string {\n  if (!modelUrl.endsWith('/')) {\n    modelUrl = (modelUrl) + '/';\n  }\n  return `${modelUrl}${DEFAULT_MODEL_NAME}${TFHUB_SEARCH_PARAM}`;\n}\n"],"names":[],"mappings":";;;;;;;;;;;;AAAA;;;;;;;;;;;;;;;GAeG;;;;AAEH,OAAO,EAAC,OAAO,EAAkB,EAAE,EAAsC,MAAM,EAAE,IAAI,EAAC,MAAM,uBAAuB,CAAC;AAIpH,OAAO,EAAC,eAAe,EAAC,MAAM,gCAAgC,CAAC;AAE/D,OAAO,EAAC,aAAa,EAAC,MAAM,kBAAkB,CAAC;AAC/C,OAAO,EAAC,eAAe,EAAC,MAAM,oBAAoB,CAAC;AACnD,iDAAiD;AACjD,OAAO,EAAC,mBAAmB,EAAC,MAAM,wCAAwC,CAAC;;;;;;AAEpE,MAAM,kBAAkB,GAAG,mBAAmB,CAAC;AAC/C,MAAM,kBAAkB,GAAG,YAAY,CAAC;AAczC,MAAO,UAAU;IAcrB,qEAAqE;IACrE,IAAI,YAAY,GAAA;QACd,OAAO,IAAI,CAAC,OAAO,CAAC;IACtB,CAAC;IAED,IAAI,UAAU,GAAA;QACZ,OAAO,IAAI,CAAC,QAAQ,CAAC,UAAU,CAAC;IAClC,CAAC;IAED,IAAI,WAAW,GAAA;QACb,OAAO,IAAI,CAAC,QAAQ,CAAC,WAAW,CAAC;IACnC,CAAC;IAED,IAAI,MAAM,GAAA;QACR,OAAO,IAAI,CAAC,QAAQ,CAAC,MAAM,CAAC;IAC9B,CAAC;IAED,IAAI,OAAO,GAAA;QACT,OAAO,IAAI,CAAC,QAAQ,CAAC,OAAO,CAAC;IAC/B,CAAC;IAED,IAAI,OAAO,GAAA;QACT,OAAO,IAAI,CAAC,QAAQ,CAAC,SAAS,CAAC;IACjC,CAAC;IAED,IAAI,QAAQ,GAAA;QACV,OAAO,IAAI,CAAC,SAAS,CAAC,mBAAmB,CAAC;IAC5C,CAAC;IAED,IAAI,cAAc,GAAA;QAChB,OAAO,IAAI,CAAC,SAAS,CAAC;IACxB,CAAC;IAED,IAAI,yBAAyB,GAAA;QAC3B,OAAO,IAAI,CAAC,oBAAoB,CAAC;IACnC,CAAC;IAED;;;;;;;;OAQG,CACH,YACY,QAAkB,EAAU,cAA8B,CAAA,CAAE,EACpE,IAAI,GAAG,8QAAE,CAAA;QADD,IAAA,CAAA,QAAQ,GAAR,QAAQ,CAAU;QAAU,IAAA,CAAA,WAAW,GAAX,WAAW,CAAqB;QA1DhE,IAAA,CAAA,OAAO,GAAG,KAAK,CAAC;QA4DtB,IAAI,CAAC,EAAE,GAAG,IAAI,CAAC;QACf,IAAI,WAAW,IAAI,IAAI,EAAE;YACvB,IAAI,CAAC,WAAW,GAAG,CAAA,CAAE,CAAC;SACvB;QACD,IAAI,CAAC,eAAe,GAAG,IAAI,0UAAe,EAAE,CAAC;IAC/C,CAAC;IAEO,aAAa,GAAA;QAEnB,MAAM,IAAI,GAAG,IAAI,CAAC,QAAQ,CAAC;QAC3B,IAAK,IAAqB,CAAC,IAAI,IAAI,IAAI,EAAE;YACvC,yBAAyB;YACzB,IAAI,CAAC,OAAO,GAAG,IAAiB,CAAC;SAClC,MAAM,IAAI,IAAI,CAAC,WAAW,CAAC,WAAW,IAAI,IAAI,EAAE;YAC/C,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC,EAAE,CAAC,kBAAkB,CACtB,IAAc,EAAE,IAAI,CAAC,WAAW,CAAc,CAAC;SACnE,MAAM;YACL,MAAM,QAAQ,GACV,IAAI,CAAC,EAAE,CAAC,eAAe,CAAC,IAAc,EAAE,IAAI,CAAC,WAAW,CAAC,CAAC;YAC9D,IAAI,QAAQ,CAAC,MAAM,KAAK,CAAC,EAAE;gBACzB,+DAA+D;gBAC/D,qCAAqC;gBACrC,QAAQ,CAAC,IAAI,CACT,IAAI,CAAC,EAAE,CAAC,kBAAkB,CAAC,IAAc,EAAE,IAAI,CAAC,WAAW,CAAC,CAAC,CAAC;aACnE,MAAM,IAAI,QAAQ,CAAC,MAAM,GAAG,CAAC,EAAE;gBAC9B,MAAM,IAAI,KAAK,CACX,CAAA,qBAAA,EAAwB,QAAQ,CAAC,MAAM,CAAA,oBAAA,CAAsB,GAC7D,CAAA,KAAA,EAAQ;oBAAC,IAAI;iBAAC,CAAA,CAAA,CAAG,CAAC,CAAC;aACxB;YACD,IAAI,CAAC,OAAO,GAAG,QAAQ,CAAC,CAAC,CAAc,CAAC;SACzC;IACH,CAAC;IAED;;;OAGG,CACH,IAAI,GAAA;QAGF,IAAI,CAAC,aAAa,EAAE,CAAC;QACrB,IAAI,IAAI,CAAC,OAAO,CAAC,IAAI,IAAI,IAAI,EAAE;YAC7B,MAAM,IAAI,KAAK,CACX,mEAAmE,GACnE,8CAA8C,CAAC,CAAC;SACrD;QAKD,MAAM,UAAU,GAAG,IAAI,CAAC,OAAO,CAAC,IAAI,EAAmC,CAAC;QACxE,IAAI,8QAAI,CAAC,SAAS,CAAC,UAAU,CAAC,EAAE;YAC9B,OAAO,UAAU,CAAC,IAAI,EAAC,SAAS,CAAC,EAAE;gBACjC,IAAI,SAAS,CAAC,eAAe,IAAI,IAAI,EAAE;oBACrC,OAAO,IAAI,CAAC,QAAQ,CAAC,SAAS,CAAC,CAAC;iBACjC;gBACD,OAAO,IAAI,CAAC,aAAa,CAAC,SAAS,CAAC,CAAC;YACvC,CAAC,CAAW,CAAC;SACd;QAED,OAAO,IAAI,CAAC,QAAQ,CAAC,UAAU,CAAW,CAAC;IAC7C,CAAC;IAED;;;;;OAKG,CACH,QAAQ,CAAC,SAA4B,EAAA;QACnC,MAAM,SAAS,GAAG,IAAI,CAAC,EAAE,CAAC,aAAa,CACnC,SAAS,CAAC,UAAU,EAAE,SAAS,CAAC,WAAW,CAAC,CAAC;QAEjD,OAAO,IAAI,CAAC,iBAAiB,CAAC,SAAS,EAAE,SAAS,CAAC,CAAC;IACtD,CAAC;IAEO,KAAK,CAAC,aAAa,CAAC,SAA4B,EAAA;QACtD,IAAI,SAAS,CAAC,eAAe,IAAI,IAAI,EAAE;YACrC,MAAM,IAAI,KAAK,CAAC,gDAAgD,CAAC,CAAC;SACnE;QAED,MAAM,SAAS,GAAG,UAAM,uQAAmB,EACzC,SAAS,CAAC,eAAe,EAAE,EAAE,SAAS,CAAC,WAAW,CAAC,CAAC;QAEtD,OAAO,IAAI,CAAC,iBAAiB,CAAC,SAAS,EAAE,SAAS,CAAC,CAAC;IACtD,CAAC;IAEO,iBAAiB,CAAC,SAA4B,EAC5B,SAAyB,EAAA;QACjD,IAAI,CAAC,SAAS,GAAG,SAAS,CAAC;QAC3B,MAAM,KAAK,GAAG,IAAI,CAAC,SAAS,CAAC,aAAqC,CAAC;QAEnE,IAAI,SAAS,GAAG,IAAI,CAAC,SAAS,CAAC,SAAS,CAAC;QACzC,IAAI,IAAI,CAAC,SAAS,CAAC,mBAAmB,IAAI,IAAI,EAAE;YAC9C,MAAM,QAAQ,GAAG,IAAI,CAAC,SAAS,CAAC,mBAAmB,CAAC;YACpD,IAAI,QAAQ,CAAC,SAAS,IAAI,IAAI,EAAE;gBAC9B,SAAS,GAAG,QAAQ,CAAC,SAAS,CAAC;aAChC;YAED,IAAI,QAAQ,CAAC,oBAAoB,IAAI,IAAI,EAAE;gBACzC,IAAI,CAAC,oBAAoB,GAAG,QAAQ,CAAC,oBAAgC,CAAC;aACvE;SACF;QACD,IAAI,CAAC,SAAS,GAAG,SAAS,CAAC;QAE3B,IAAI,CAAC,OAAO,GAAG,GAAG,KAAK,CAAC,QAAQ,CAAC,QAAQ,CAAA,CAAA,EAAI,KAAK,CAAC,QAAQ,CAAC,WAAW,EAAE,CAAC;QAC1E,IAAI,CAAC,QAAQ,GAAG,IAAI,sUAAa,CAC7B,4UAAe,CAAC,QAAQ,CAAC,cAAc,CAAC,KAAK,EAAE,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC;QACpE,IAAI,CAAC,QAAQ,CAAC,SAAS,GAAG,IAAI,CAAC,4BAA4B,CAAC,SAAS,CAAC,CAAC;QACvE,4EAA4E;QAC5E,uBAAuB;QACvB,IAAI,CAAC,QAAQ,CAAC,eAAe,GAAG,IAAI,CAAC,eAAe,CAAC;QAErD,IAAI,SAAS,CAAC,gBAAgB,IAAI,IAAI,IACjC,SAAS,CAAC,gBAAyC,CAAC,IAAI,IAAI,IAAI,EAAE;YACrE,MAAM,WAAW,GACb,4UAAe,CAAC,QAAQ,CAAC,cAAc,CAAC,SAAS,CAAC,gBAAgB,CAAC,CAAC;YACxE,IAAI,CAAC,WAAW,GAAG,IAAI,sUAAa,CAAC,WAAW,CAAC,CAAC;YAClD,IAAI,CAAC,WAAW,CAAC,SAAS,GAAG,IAAI,CAAC,QAAQ,CAAC,SAAS,CAAC;YACrD,+DAA+D;YAC/D,wEAAwE;YACxE,0BAA0B;YAC1B,IAAI,CAAC,WAAW,CAAC,eAAe,GAAG,IAAI,CAAC,eAAe,CAAC;YACxD,IAAI,CAAC,oBAAoB,GAAG,SAAS,CAAC,oBAAoB,CAAC;SAC5D;QAED,OAAO,IAAI,CAAC;IACd,CAAC;IAED;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;OA2CG,CACH,KAAK,CAAC,IAAI,CAAC,YAAiC,EAAE,MAAsB,EAAA;QAElE,IAAI,OAAO,YAAY,KAAK,QAAQ,EAAE;YACpC,MAAM,QAAQ,GAAG,IAAI,CAAC,EAAE,CAAC,eAAe,CAAC,YAAY,CAAC,CAAC;YACvD,IAAI,QAAQ,CAAC,MAAM,KAAK,CAAC,EAAE;gBACzB,MAAM,IAAI,KAAK,CACX,CAAA,uCAAA,EAA0C,YAAY,CAAA,CAAA,CAAG,CAAC,CAAC;aAChE,MAAM,IAAI,QAAQ,CAAC,MAAM,GAAG,CAAC,EAAE;gBAC9B,MAAM,IAAI,KAAK,CACX,CAAA,qBAAA,EAAwB,QAAQ,CAAC,MAAM,CAAA,oBAAA,CAAsB,GAC7D,CAAA,KAAA,EAAQ,YAAY,CAAA,CAAA,CAAG,CAAC,CAAC;aAC9B;YACD,YAAY,GAAG,QAAQ,CAAC,CAAC,CAAC,CAAC;SAC5B;QACD,IAAI,YAAY,CAAC,IAAI,IAAI,IAAI,EAAE;YAC7B,MAAM,IAAI,KAAK,CACX,yDAAyD,GACzD,sDAAsD,CAAC,CAAC;SAC7D;QAED,OAAO,YAAY,CAAC,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC;IAC3C,CAAC;IAEO,wBAAwB,CAAC,aAA8B,EAAA;QAC7D,IAAI,IAAI,CAAC,oBAAoB,EAAE;YAC7B,MAAM,kBAAkB,GACpB,aAAa,YAAY,kPAAM,CAAC,CAAC,CAAC;gBAAC,aAAa;aAAC,CAAC,CAAC,CAAC,aAAa,CAAC;YACtE,MAAM,eAAe,GAAmB,CAAA,CAAE,CAAC;YAE3C,kBAAkB,CAAC,OAAO,CACtB,CAAC,YAAY,EAAE,CAAC,EAAE,CAAG,CAAD,cAAgB,CAAC,IAAI,CAAC,oBAAoB,CAAC,CAAC,CAAC,CAAC,GAC9D,YAAY,CAAC,CAAC;YAEtB,OAAO,eAAe,CAAC;SACxB;QACD,OAAO,aAAa,CAAC;IACvB,CAAC;IAED;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;OAsCG,CACH,OAAO,CAAC,MAAsC,EAAE,MAA2B,EAAA;QAEzE,MAAM,aAAa,GAAG,IAAI,CAAC,OAAO,CAAC,MAAM,EAAE,IAAI,CAAC,WAAW,CAAC,CAAC;QAC7D,OAAO,IAAI,CAAC,wBAAwB,CAAC,aAAa,CAAC,CAAC;IACtD,CAAC;IAED;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;OAuCG,CACH,KAAK,CAAC,YAAY,CACd,MAAsC,EACtC,MAA2B,EAAA;QAC7B,MAAM,aAAa,GAAG,MAAM,IAAI,CAAC,YAAY,CAAC,MAAM,EAAE,IAAI,CAAC,WAAW,CAAC,CAAC;QACxE,OAAO,IAAI,CAAC,wBAAwB,CAAC,aAAa,CAAC,CAAC;IACtD,CAAC;IAEO,eAAe,CAAC,MACc,EAAA;;QACpC,IAAI,CAAC,CAAC,MAAM,YAAY,kPAAM,CAAC,IAAI,CAAC,KAAK,CAAC,OAAO,CAAC,MAAM,CAAC,EAAE;YACzD,yCAAyC;YACzC,MAAM,eAAe,GAAG,CAAA,KAAA,IAAI,CAAC,SAAS,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GAAE,MAAM,CAAC;YAC/C,IAAI,eAAe,IAAI,IAAI,EAAE;gBAC3B,IAAK,MAAM,KAAK,IAAI,eAAe,CAAE;oBACnC,MAAM,MAAM,GAAG,eAAe,CAAC,KAAK,CAAC,CAAC;oBACtC,IAAI,MAAM,CAAC,UAAU,IAAI,IAAI,EAAE;wBAC7B,MAAM,CAAC,KAAK,CAAC,GAAG,IAAI,CAAC,yBAAyB,CAAC,MAAM,CAAC,UAAU,CAAC,CAAC;qBACnE;iBACF;aACF;YACD,OAAO,MAAM,CAAC;SACf;QACD,MAAM,GAAG,KAAK,CAAC,OAAO,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC;YAAC,MAAM;SAAC,CAAC;QAEnD,MAAM,iBAAiB,GACnB,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC,yBAAyB,CAAC,CAAC,MAAM,CAAC;QACvD,IAAI,MAAM,CAAC,MAAM,GAAG,iBAAiB,KAAK,IAAI,CAAC,UAAU,CAAC,MAAM,EAAE;YAChE,MAAM,IAAI,KAAK,CAAC,CAAA,iDAAA,EACZ,IAAI,CAAC,UAAU,CAAC,MAAM,GACtB,iBAAiB,CAAA,4CAAA,EACjB,MAAM,CAAC,MAAM,CAAA,wBAAA,CAA0B,CAAC,CAAC;SAC9C;QAED,IAAI,UAAU,GAAG,CAAC,CAAC;QACnB,OAAO,IAAI,CAAC,UAAU,CAAC,MAAM,CAAC,CAAC,GAAG,EAAE,SAAS,EAAE,EAAE;;YAC/C,MAAM,UAAU,GAAG,CAAA,KAAA,CAAA,KAAA,CAAA,KAAA,IAAI,CAAC,SAAS,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GAAE,MAAM,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,EAAA,CAAG,SAAS,CAAC,MAAA,QAAA,OAAA,KAAA,IAAA,KAAA,IAAA,GAAE,UAAU,CAAC;YACnE,IAAI,UAAU,IAAI,IAAI,EAAE;gBACtB,GAAG,CAAC,SAAS,CAAC,GAAG,IAAI,CAAC,yBAAyB,CAAC,UAAU,CAAC,CAAC;aAC7D,MAAM;gBACL,GAAG,CAAC,SAAS,CAAC,GAAI,MAAmB,CAAC,UAAU,EAAE,CAAC,CAAC;aACrD;YACD,OAAO,GAAG,CAAC;QACb,CAAC,EAAE,CAAA,CAAoB,CAAC,CAAC;IAC3B,CAAC;IAEO,gBAAgB,CAAC,OAAwB,EAAA;QAC/C,OAAO,GAAG,OAAO,IAAI,IAAI,CAAC,WAAW,CAAC;QACtC,OAAO,CAAC,KAAK,CAAC,OAAO,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC;YAAC,OAAO;SAAC,CAAC,CAAC,CAAC,OAAO,CAAC;IACvD,CAAC;IAEO,uBAAuB,GAAA;QAC7B,IAAI,IAAI,CAAC,WAAW,IAAI,IAAI,EAAE;YAC5B,OAAO,EAAE,CAAC;SACX;QACD,IAAI,IAAI,CAAC,oBAAoB,IAAI,IAAI,EAAE;YACrC,OAAO,IAAI,CAAC,WAAW,CAAC,OAAO,CAAC,CAAA,CAAE,EAAE,EAAE,CAAC,CAAC;SACzC,MAAM;YACL,OAAO,IAAI,CAAC,WAAW,CAAC,OAAO,CAC3B,CAAA,CAAE,EAAE,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC,oBAAoB,CAAC,OAAO,CAAC,CAAC,CAAC;SACzD;IACH,CAAC;IAEO,KAAK,CAAC,4BAA4B,GAAA;QACxC,IAAI,IAAI,CAAC,WAAW,IAAI,IAAI,EAAE;YAC5B,OAAO,EAAE,CAAC;SACX;QACD,IAAI,IAAI,CAAC,oBAAoB,IAAI,IAAI,EAAE;YACrC,OAAO,IAAI,CAAC,WAAW,CAAC,YAAY,CAAC,CAAA,CAAE,EAAE,EAAE,CAAC,CAAC;SAC9C,MAAM;YACL,OAAO,IAAI,CAAC,WAAW,CAAC,YAAY,CAChC,CAAA,CAAE,EAAE,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC,oBAAoB,CAAC,OAAO,CAAC,CAAC,CAAC;SACzD;IACH,CAAC;IAEO,4BAA4B,CAAC,OAAiB,EAAA;QACpD,IAAI,CAAC,yBAAyB,GAAG,CAAA,CAAE,CAAC;QAEpC,IAAI,IAAI,CAAC,oBAAoB,EAAE;YAC7B,MAAM,gBAAgB,GAAG,IAAI,CAAC,oBAAoB,CAAC,OAAO,CAAC;YAC3D,MAAM,WAAW,GAAG,MAAM,CAAC,IAAI,CAAC,gBAAgB,CAAC,CAAC;YAClD,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,WAAW,CAAC,MAAM,EAAE,CAAC,EAAE,CAAE;gBAC3C,MAAM,UAAU,GAAG,WAAW,CAAC,CAAC,CAAC,CAAC;gBAClC,MAAM,UAAU,GAAG,gBAAgB,CAAC,UAAU,CAAC,CAAC;gBAChD,IAAI,CAAC,yBAAyB,CAAC,UAAU,CAAC,UAAU,CAAC,GAAG,OAAO,CAAC,CAAC,CAAC,CAAC;aACpE;SACF;IACH,CAAC;IAED;;;;;;;;;;;;;;;OAeG,CACH,OAAO,CAAC,MAAsC,EAAE,OAAyB,EAAA;QAEvE,IAAI,IAAI,CAAC,yBAAyB,IAAI,IAAI,EAAE;YAC1C,IAAI,CAAC,4BAA4B,CAAC,IAAI,CAAC,uBAAuB,EAAE,CAAC,CAAC;SACnE;QACD,MAAM,GAAG,IAAI,CAAC,eAAe,CAAC,MAAM,CAAC,CAAC;QACtC,OAAO,GAAG,IAAI,CAAC,gBAAgB,CAAC,OAAO,CAAC,CAAC;QACzC,MAAM,MAAM,GAAG,IAAI,CAAC,QAAQ,CAAC,OAAO,CAAC,MAAM,EAAE,OAAO,CAAC,CAAC;QACtD,OAAO,MAAM,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC;IAChD,CAAC;IAED;;;;;;;;;;;;;;;OAeG,CACH,KAAK,CAAC,YAAY,CACd,MAAsC,EACtC,OAAyB,EAAA;QAC3B,IAAI,IAAI,CAAC,yBAAyB,IAAI,IAAI,EAAE;YAC1C,IAAI,CAAC,4BAA4B,CAC7B,MAAM,IAAI,CAAC,4BAA4B,EAAE,CAAC,CAAC;SAChD;QACD,MAAM,GAAG,IAAI,CAAC,eAAe,CAAC,MAAM,CAAC,CAAC;QACtC,OAAO,GAAG,IAAI,CAAC,gBAAgB,CAAC,OAAO,CAAC,CAAC;QACzC,MAAM,MAAM,GAAG,MAAM,IAAI,CAAC,QAAQ,CAAC,YAAY,CAAC,MAAM,EAAE,OAAO,CAAC,CAAC;QACjE,OAAO,MAAM,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC;IAChD,CAAC;IAED;;;;;OAKG,CACH,sBAAsB,GAAA;QACpB,OAAO,IAAI,CAAC,QAAQ,CAAC,sBAAsB,EAAE,CAAC;IAChD,CAAC;IAED;;;;;OAKG,CACH,0BAA0B,GAAA;QACxB,IAAI,CAAC,QAAQ,CAAC,0BAA0B,EAAE,CAAC;IAC7C,CAAC;IAEO,4BAA4B,CAAC,GAAmB,EAAA;QACtD,OAAO,MAAM,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,MAAM,CAAC,CAAC,MAAuB,EAAE,GAAG,EAAE,EAAE;YAC9D,MAAM,CAAC,GAAG,CAAC,GAAG;gBAAC,GAAG,CAAC,GAAG,CAAC;aAAC,CAAC;YACzB,OAAO,MAAM,CAAC;QAChB,CAAC,EAAE,CAAA,CAAE,CAAC,CAAC;IACT,CAAC;IAED;;;;OAIG,CACH,OAAO,GAAA;QACL,IAAI,CAAC,QAAQ,CAAC,OAAO,EAAE,CAAC;QAExB,IAAI,IAAI,CAAC,WAAW,EAAE;YACpB,IAAI,CAAC,WAAW,CAAC,OAAO,EAAE,CAAC;YAC3B,IAAI,IAAI,CAAC,yBAAyB,EAAE;oBAClC,oPAAO,EAAC,IAAI,CAAC,yBAAyB,CAAC,CAAC;aACzC;SACF;QAED,IAAI,CAAC,eAAe,CAAC,OAAO,EAAE,CAAC;IACjC,CAAC;CACF;AAiCM,KAAK,UAAU,cAAc,CAChC,QAA6B,EAAE,UAA0B,CAAA,CAAE,EAC3D,IAAI,GAAG,8QAAE;IACX,IAAI,QAAQ,IAAI,IAAI,EAAE;QACpB,MAAM,IAAI,KAAK,CACX,oEAAoE,GACpE,sCAAsC,CAAC,CAAC;KAC7C;IACD,IAAI,OAAO,IAAI,IAAI,EAAE;QACnB,OAAO,GAAG,CAAA,CAAE,CAAC;KACd;IAED,IAAI,OAAO,CAAC,SAAS,IAAI,OAAO,QAAQ,KAAK,QAAQ,EAAE;QACrD,QAAQ,GAAG,WAAW,CAAC,QAAQ,CAAC,CAAC;KAClC;IACD,MAAM,KAAK,GAAG,IAAI,UAAU,CAAC,QAAQ,EAAE,OAAO,EAAE,IAAI,CAAC,CAAC;IACtD,MAAM,KAAK,CAAC,IAAI,EAAE,CAAC;IACnB,OAAO,KAAK,CAAC;AACf,CAAC;AAYK,SAAU,kBAAkB,CAC9B,WAC2D;IAE7D,IAAI,WAAW,IAAI,IAAI,EAAE;QACvB,MAAM,IAAI,KAAK,CACX,kEAAkE,GAClE,sDAAsD,CAAC,CAAC;KAC7D;IAED,IAAI,SAA2B,CAAC;IAChC,IAAI,WAAW,YAAY,KAAK,EAAE;QAChC,MAAM,CAAC,SAAS,EAAE,OAAO,CAAC,GAAG,WAAW,CAAC;QACzC,IAAI,CAAC,SAAS,EAAE;YACd,MAAM,IAAI,KAAK,CAAC,kDAAkD,CAAC,CAAC;SACrE;QACD,IAAI,CAAC,OAAO,IAAI,CAAC,CAAC,OAAO,YAAY,WAAW,CAAC,EAAE;YACjD,MAAM,IAAI,KAAK,CACX,yDAAyD,GACzD,YAAY,CAAC,CAAC;SACnB;QACD,IAAI,CAAC,CAAC,eAAe,IAAI,SAAS,CAAC,EAAE;YACnC,MAAM,IAAI,KAAK,CAAC,yCAAyC,CAAC,CAAC;SAC5D;QACD,IAAI,CAAC,CAAC,iBAAiB,IAAI,SAAS,CAAC,EAAE;YACrC,MAAM,IAAI,KAAK,CAAC,2CAA2C,CAAC,CAAC;SAC9D;QAED,MAAM,WAAW,GAAG,8QAAE,CAAC,cAAc,CAAC,SAAS,CAAC,eAAe,CAAC,CAAC;QACjE,MAAM,cAAc,GAChB,8QAAE,CAAC,4BAA4B,CAAC,SAAS,EAAE,WAAW,EAAE,OAAO,CAAC,CAAC;QACrE,SAAS,GAAG,8QAAE,CAAC,cAAc,CAAC,cAAc,CAAC,CAAC;KAC/C,MAAM,IAAI,MAAM,IAAI,WAAW,EAAE;QAChC,gDAAgD;QAChD,SAAS,GAAG,WAAW,CAAC;KACzB,MAAM,IACH,eAAe,IAAI,WAAW,IAAI,aAAa,IAAI,WAAW,IAC9D,YAAY,IAAI,WAAW,EAAE;QAC/B,yCAAyC;QACzC,SAAS,GAAG,8QAAE,CAAC,cAAc,CAAC,WAAW,CAAC,CAAC;KAC5C,MAAM;QACL,MAAM,IAAI,KAAK,CAAC,sBAAsB,CAAC,CAAC;KACzC;IAED,MAAM,KAAK,GAAG,IAAI,UAAU,CAAC,SAAS,CAAC,CAAC;IACxC,KAAK,CAAC,IAAI,EAAE,CAAC;IACb,OAAO,KAAK,CAAC;AACf,CAAC;AAED,SAAS,WAAW,CAAC,QAAgB;IACnC,IAAI,CAAC,QAAQ,CAAC,QAAQ,CAAC,GAAG,CAAC,EAAE;QAC3B,QAAQ,GAAG,AAAC,QAAQ,CAAC,EAAG,GAAG,CAAC;KAC7B;IACD,OAAO,GAAG,QAAQ,GAAG,kBAAkB,GAAG,kBAAkB,EAAE,CAAC;AACjE,CAAC"}}]
}