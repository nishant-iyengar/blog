{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 4, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-layers@4.22.0_@tensorflow+tfjs-core@4.22.0/node_modules/@tensorflow/tfjs-layers/dist/layers/serialization.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-layers/src/layers/serialization.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/* Original Source layers/__init__.py */\nimport {serialization} from '@tensorflow/tfjs-core';\n\nimport {deserializeKerasObject} from '../utils/generic_utils';\n\n/**\n * Instantiate a layer from a config dictionary.\n * @param config dict of the form {class_name: str, config: dict}\n * @param customObjects dict mapping class names (or function names)\n *   of custom (non-Keras) objects to class/functions\n * @param fastWeightInit Optional flag to use fast weight initialization\n *   during deserialization. This is applicable to cases in which\n *   the initialization will be immediately overwritten by loaded weight\n *   values. Default: `false`.\n * @returns Layer instance (may be LayersModel, Sequential, Layer...)\n */\nexport function deserialize(\n    config: serialization.ConfigDict,\n    customObjects = {} as serialization.ConfigDict,\n    fastWeightInit = false): serialization.Serializable {\n  return deserializeKerasObject(\n      config, serialization.SerializationMap.getMap().classNameMap,\n      customObjects, 'layer', fastWeightInit);\n}\n"],"names":[],"mappings":";;;;AAAA;;;;;;;;GAQG,CAEH,sCAAA,EAAwC;AACxC,OAAO,EAAC,aAAa,EAAC,MAAM,uBAAuB,CAAC;AAEpD,OAAO,EAAC,sBAAsB,EAAC,MAAM,wBAAwB,CAAC;;;AAaxD,SAAU,WAAW,CACvB,MAAgC,EAChC,gBAAgB,CAAA,CAA8B,EAC9C,cAAc,GAAG,KAAK;IACxB,WAAO,qUAAsB,EACzB,MAAM,EAAE,ySAAa,CAAC,gBAAgB,CAAC,MAAM,EAAE,CAAC,YAAY,EAC5D,aAAa,EAAE,OAAO,EAAE,cAAc,CAAC,CAAC;AAC9C,CAAC"}},
    {"offset": {"line": 28, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-layers@4.22.0_@tensorflow+tfjs-core@4.22.0/node_modules/@tensorflow/tfjs-layers/dist/layers/advanced_activations.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-layers/src/layers/advanced_activations.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n *  Advanced activation layers.\n */\n\nimport {add, cast, clipByValue, elu, exp, greater, leakyRelu, logSumExp, mul, ones, prelu, relu, scalar, serialization, sub, Tensor, tidy} from '@tensorflow/tfjs-core';\n\nimport {Softmax as softmaxActivation} from '../activations';\nimport {Constraint, getConstraint, serializeConstraint} from '../constraints';\nimport {InputSpec, Layer, LayerArgs} from '../engine/topology';\nimport {NotImplementedError, ValueError} from '../errors';\nimport {getInitializer, Initializer, InitializerIdentifier, serializeInitializer} from '../initializers';\nimport {Shape} from '../keras_format/common';\nimport {getRegularizer, Regularizer, serializeRegularizer} from '../regularizers';\nimport {Kwargs} from '../types';\nimport {getExactlyOneShape, getExactlyOneTensor} from '../utils/types_utils';\nimport {LayerVariable} from '../variables';\n\nexport declare interface ReLULayerArgs extends LayerArgs {\n  /**\n   * Float, the maximum output value.\n   */\n  maxValue?: number;\n}\n\nexport class ReLU extends Layer {\n  /** @nocollapse */\n  static className = 'ReLU';\n  maxValue: number;\n\n  constructor(args?: ReLULayerArgs) {\n    super(args == null ? {} : args);\n    this.supportsMasking = true;\n    if (args != null) {\n      this.maxValue = args.maxValue;\n    }\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    inputs = getExactlyOneTensor(inputs);\n    let output = relu(inputs);\n    if (this.maxValue != null) {\n      output = clipByValue(output, 0, this.maxValue);\n    }\n    return output;\n  }\n\n  override computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    return inputShape;\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config: serialization.ConfigDict = {maxValue: this.maxValue};\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(ReLU);\n\nexport declare interface LeakyReLULayerArgs extends LayerArgs {\n  /**\n   * Float `>= 0`. Negative slope coefficient. Defaults to `0.3`.\n   */\n  alpha?: number;\n}\n\nexport class LeakyReLU extends Layer {\n  /** @nocollapse */\n  static className = 'LeakyReLU';\n  readonly alpha: number;\n\n  readonly DEFAULT_ALPHA = 0.3;\n\n  constructor(args?: LeakyReLULayerArgs) {\n    super(args == null ? {} : args);\n    if (args == null) {\n      args = {};\n    }\n    this.alpha = args.alpha == null ? this.DEFAULT_ALPHA : args.alpha;\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    const x = getExactlyOneTensor(inputs);\n    return leakyRelu(x, this.alpha);\n  }\n\n  override computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    return inputShape;\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config: serialization.ConfigDict = {alpha: this.alpha};\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(LeakyReLU);\n\nexport declare interface PReLULayerArgs extends LayerArgs {\n  /**\n   * Initializer for the learnable alpha.\n   */\n  alphaInitializer?: Initializer|InitializerIdentifier;\n\n  /**\n   * Regularizer for the learnable alpha.\n   */\n  alphaRegularizer?: Regularizer;\n\n  /**\n   * Constraint for the learnable alpha.\n   */\n  alphaConstraint?: Constraint;\n\n  /**\n   * The axes along which to share learnable parameters for the activation\n   * function. For example, if the incoming feature maps are from a 2D\n   * convolution with output shape `[numExamples, height, width, channels]`,\n   * and you wish to share parameters across space (height and width) so that\n   * each filter channels has only one set of parameters, set\n   * `shared_axes: [1, 2]`.\n   */\n  sharedAxes?: number|number[];\n}\n\nexport class PReLU extends Layer {\n  /** @nocollapse */\n  static className = 'PReLU';\n  private readonly alphaInitializer: Initializer;\n  private readonly alphaRegularizer: Regularizer;\n  private readonly alphaConstraint: Constraint;\n  private readonly sharedAxes: number[];\n  private alpha: LayerVariable;\n\n  readonly DEFAULT_ALPHA_INITIALIZER: InitializerIdentifier = 'zeros';\n\n  constructor(args?: PReLULayerArgs) {\n    super(args == null ? {} : args);\n    if (args == null) {\n      args = {};\n    }\n\n    this.supportsMasking = true;\n    this.alphaInitializer =\n        getInitializer(args.alphaInitializer || this.DEFAULT_ALPHA_INITIALIZER);\n    this.alphaRegularizer = getRegularizer(args.alphaRegularizer);\n    this.alphaConstraint = getConstraint(args.alphaConstraint);\n    if (args.sharedAxes == null) {\n      this.sharedAxes = null;\n    } else if (Array.isArray(args.sharedAxes)) {\n      this.sharedAxes = args.sharedAxes;\n    } else if (typeof args.sharedAxes === 'number') {\n      this.sharedAxes = [args.sharedAxes];\n    } else {\n      throw new ValueError(\n          `Expected sharedAxes to be a number or an array of numbers, ` +\n          `but got ${args.sharedAxes}`);\n    }\n  }\n\n  override build(inputShape: Shape|Shape[]) {\n    inputShape = getExactlyOneShape(inputShape);\n    const paramShape: Shape = inputShape.slice(1);\n    if (this.sharedAxes != null) {\n      for (const i of this.sharedAxes) {\n        paramShape[i - 1] = 1;\n      }\n    }\n    this.alpha = this.addWeight(\n        'alpha', paramShape, 'float32', this.alphaInitializer,\n        this.alphaRegularizer, true, this.alphaConstraint);\n    // Set input spec.\n    const axes: {[axis: number]: number} = {};\n    if (this.sharedAxes != null) {\n      for (let i = 1; i < inputShape.length; ++i) {\n        axes[i] = inputShape[i];\n      }\n    }\n    this.inputSpec = [new InputSpec({\n      ndim: inputShape.length,\n      axes,\n    })];\n    this.built = true;\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    inputs = getExactlyOneTensor(inputs);\n    return prelu(inputs, this.alpha.read());\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config: serialization.ConfigDict = {\n      alphaInitializer: serializeInitializer(this.alphaInitializer),\n      alphaRegularizer: serializeRegularizer(this.alphaRegularizer),\n      alphaConstraint: serializeConstraint(this.alphaConstraint),\n      sharedAxes: this.sharedAxes\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(PReLU);\n\nexport declare interface ELULayerArgs extends LayerArgs {\n  /**\n   * Float `>= 0`. Negative slope coefficient. Defaults to `1.0`.\n   */\n  alpha?: number;\n}\n\nexport class ELU extends Layer {\n  /** @nocollapse */\n  static className = 'ELU';\n  readonly alpha: number;\n\n  readonly DEFAULT_ALPHA = 1.0;\n\n  constructor(args?: ELULayerArgs) {\n    super(args == null ? {} : args);\n    if (args == null) {\n      args = {};\n    }\n\n    if (args.alpha != null && args.alpha !== this.DEFAULT_ALPHA) {\n      throw new NotImplementedError(\n          `Non-default alpha value (${args.alpha}) is not supported by the ` +\n          `ELU layer yet.`);\n    }\n\n    this.alpha = args.alpha == null ? this.DEFAULT_ALPHA : args.alpha;\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    const x = getExactlyOneTensor(inputs);\n    return elu(x);\n  }\n\n  override computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    return inputShape;\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config: serialization.ConfigDict = {alpha: this.alpha};\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(ELU);\n\nexport declare interface ThresholdedReLULayerArgs extends LayerArgs {\n  /**\n   * Float >= 0. Threshold location of activation.\n   */\n  theta?: number;\n}\n\nexport class ThresholdedReLU extends Layer {\n  /** @nocollapse */\n  static className = 'ThresholdedReLU';\n  readonly theta: number;\n\n  readonly DEFAULT_THETA = 1.0;\n\n  constructor(args?: ThresholdedReLULayerArgs) {\n    super(args == null ? {} : args);\n    if (args == null) {\n      args = {};\n    }\n\n    this.theta = args.theta == null ? this.DEFAULT_THETA : args.theta;\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    const x = getExactlyOneTensor(inputs);\n    return mul(x, cast(greater(x, this.theta), 'float32'));\n  }\n\n  override computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    return inputShape;\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config: serialization.ConfigDict = {theta: this.theta};\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(ThresholdedReLU);\n\nexport declare interface SoftmaxLayerArgs extends LayerArgs {\n  /**\n   * Integer, axis along which the softmax normalization is applied.\n   * Defaults to `-1` (i.e., the last axis).\n   */\n  axis?: number|number[];\n}\n\nexport class Softmax extends Layer {\n  /** @nocollapse */\n  static className = 'Softmax';\n  readonly axis: number|number[];\n  readonly softmax: (t: Tensor, a?: number) => Tensor;\n  readonly DEFAULT_AXIS = 1.0;\n\n  constructor(args?: SoftmaxLayerArgs) {\n    super(args == null ? {} : args);\n    if (args == null) {\n      args = {};\n    }\n    this.softmax = new softmaxActivation().apply;\n    this.axis = args.axis == null ? this.DEFAULT_AXIS : args.axis;\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    // TODO(pforderique): Add tests for when `this.axis` is a number[].\n    return tidy(() => {\n      let x = getExactlyOneTensor(inputs);\n      const mask = kwargs['mask'] as Tensor;\n      if (mask != null) {\n        // Since mask is 1.0 for positions we want to keep and 0.0 for masked\n        // positions, this operation will create a tensor which is 0.0 for\n        // positions we want to attend and -1e.9 for masked positions.\n        const adder =\n          mul(sub(ones(x.shape), cast(mask, x.dtype)), scalar(-1e9));\n\n        // Since we are adding it to the raw scores before the softmax, this\n        // is effectively the same as removing these entirely.\n        x = add(x, adder);\n      }\n      if (this.axis instanceof Array) {\n        if (this.axis.length > 1) {\n          return exp(sub(x, logSumExp(x, this.axis, true)));\n        } else {\n          return this.softmax(x, this.axis[0]);\n        }\n      }\n      return this.softmax(x, this.axis);\n    });\n  }\n\n  override computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    return inputShape;\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config: serialization.ConfigDict = {axis: this.axis};\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(Softmax);\n"],"names":[],"mappings":";;;;;;;;;;;;;;AAAA;;;;;;;;GAQG,CAEH;;GAEG;;;;;;;;;;;;;;;;AAEH,OAAO,EAAC,GAAG,EAAE,IAAI,EAAE,WAAW,EAAE,GAAG,EAAE,GAAG,EAAE,OAAO,EAAE,SAAS,EAAE,SAAS,EAAE,GAAG,EAAE,IAAI,EAAE,KAAK,EAAE,IAAI,EAAE,MAAM,EAAE,aAAa,EAAE,GAAG,EAAU,IAAI,EAAC,MAAM,uBAAuB,CAAC;AAExK,OAAO,EAAC,OAAO,IAAI,iBAAiB,EAAC,MAAM,gBAAgB,CAAC;AAC5D,OAAO,EAAa,aAAa,EAAE,mBAAmB,EAAC,MAAM,gBAAgB,CAAC;AAC9E,OAAO,EAAC,SAAS,EAAE,KAAK,EAAY,MAAM,oBAAoB,CAAC;AAC/D,OAAO,EAAC,mBAAmB,EAAE,UAAU,EAAC,MAAM,WAAW,CAAC;AAC1D,OAAO,EAAC,cAAc,EAAsC,oBAAoB,EAAC,MAAM,iBAAiB,CAAC;AAEzG,OAAO,EAAC,cAAc,EAAe,oBAAoB,EAAC,MAAM,iBAAiB,CAAC;AAElF,OAAO,EAAC,kBAAkB,EAAE,mBAAmB,EAAC,MAAM,sBAAsB,CAAC;;;;;;;;;AAU7E,MAAa,IAAK,SAAQ,gTAAK;IAK7B,YAAY,IAAoB,CAAA;QAC9B,KAAK,CAAC,IAAI,IAAI,IAAI,CAAC,CAAC,CAAC,CAAA,CAAE,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;QAChC,IAAI,CAAC,eAAe,GAAG,IAAI,CAAC;QAC5B,IAAI,IAAI,IAAI,IAAI,EAAE;YAChB,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC,QAAQ,CAAC;SAC/B;IACH,CAAC;IAEQ,IAAI,CAAC,MAAuB,EAAE,MAAc,EAAA;QACnD,MAAM,OAAG,gUAAmB,EAAC,MAAM,CAAC,CAAC;QACrC,IAAI,MAAM,OAAG,qPAAI,EAAC,MAAM,CAAC,CAAC;QAC1B,IAAI,IAAI,CAAC,QAAQ,IAAI,IAAI,EAAE;YACzB,MAAM,OAAG,qQAAW,EAAC,MAAM,EAAE,CAAC,EAAE,IAAI,CAAC,QAAQ,CAAC,CAAC;SAChD;QACD,OAAO,MAAM,CAAC;IAChB,CAAC;IAEQ,kBAAkB,CAAC,UAAyB,EAAA;QACnD,OAAO,UAAU,CAAC;IACpB,CAAC;IAEQ,SAAS,GAAA;QAChB,MAAM,MAAM,GAA6B;YAAC,QAAQ,EAAE,IAAI,CAAC,QAAQ;QAAA,CAAC,CAAC;QACnE,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;QACrC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;;AA9BD,gBAAA,EAAkB,CACX,KAAA,SAAS,GAAG,MAAM,CAAC;;AA+B5B,ySAAa,CAAC,aAAa,CAAC,IAAI,CAAC,CAAC;AASlC,MAAa,SAAU,SAAQ,gTAAK;IAOlC,YAAY,IAAyB,CAAA;QACnC,KAAK,CAAC,IAAI,IAAI,IAAI,CAAC,CAAC,CAAC,CAAA,CAAE,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;QAHzB,IAAA,CAAA,aAAa,GAAG,GAAG,CAAC;QAI3B,IAAI,IAAI,IAAI,IAAI,EAAE;YAChB,IAAI,GAAG,CAAA,CAAE,CAAC;SACX;QACD,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC,KAAK,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC;IACpE,CAAC;IAEQ,IAAI,CAAC,MAAuB,EAAE,MAAc,EAAA;QACnD,MAAM,CAAC,OAAG,gUAAmB,EAAC,MAAM,CAAC,CAAC;QACtC,WAAO,gQAAS,EAAC,CAAC,EAAE,IAAI,CAAC,KAAK,CAAC,CAAC;IAClC,CAAC;IAEQ,kBAAkB,CAAC,UAAyB,EAAA;QACnD,OAAO,UAAU,CAAC;IACpB,CAAC;IAEQ,SAAS,GAAA;QAChB,MAAM,MAAM,GAA6B;YAAC,KAAK,EAAE,IAAI,CAAC,KAAK;QAAA,CAAC,CAAC;QAC7D,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;QACrC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;;AA5BD,gBAAA,EAAkB,CACX,UAAA,SAAS,GAAG,WAAW,AAAd,CAAe;;AA6BjC,ySAAa,CAAC,aAAa,CAAC,SAAS,CAAC,CAAC;AA6BvC,MAAa,KAAM,SAAQ,gTAAK;IAW9B,YAAY,IAAqB,CAAA;QAC/B,KAAK,CAAC,IAAI,IAAI,IAAI,CAAC,CAAC,CAAC,CAAA,CAAE,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;QAHzB,IAAA,CAAA,yBAAyB,GAA0B,OAAO,CAAC;QAIlE,IAAI,IAAI,IAAI,IAAI,EAAE;YAChB,IAAI,GAAG,CAAA,CAAE,CAAC;SACX;QAED,IAAI,CAAC,eAAe,GAAG,IAAI,CAAC;QAC5B,IAAI,CAAC,gBAAgB,OACjB,mTAAc,EAAC,IAAI,CAAC,gBAAgB,IAAI,IAAI,CAAC,yBAAyB,CAAC,CAAC;QAC5E,IAAI,CAAC,gBAAgB,OAAG,mTAAc,EAAC,IAAI,CAAC,gBAAgB,CAAC,CAAC;QAC9D,IAAI,CAAC,eAAe,OAAG,iTAAa,EAAC,IAAI,CAAC,eAAe,CAAC,CAAC;QAC3D,IAAI,IAAI,CAAC,UAAU,IAAI,IAAI,EAAE;YAC3B,IAAI,CAAC,UAAU,GAAG,IAAI,CAAC;SACxB,MAAM,IAAI,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,UAAU,CAAC,EAAE;YACzC,IAAI,CAAC,UAAU,GAAG,IAAI,CAAC,UAAU,CAAC;SACnC,MAAM,IAAI,OAAO,IAAI,CAAC,UAAU,KAAK,QAAQ,EAAE;YAC9C,IAAI,CAAC,UAAU,GAAG;gBAAC,IAAI,CAAC,UAAU;aAAC,CAAC;SACrC,MAAM;YACL,MAAM,IAAI,ySAAU,CAChB,CAAA,2DAAA,CAA6D,GAC7D,CAAA,QAAA,EAAW,IAAI,CAAC,UAAU,EAAE,CAAC,CAAC;SACnC;IACH,CAAC;IAEQ,KAAK,CAAC,UAAyB,EAAA;QACtC,UAAU,OAAG,+TAAkB,EAAC,UAAU,CAAC,CAAC;QAC5C,MAAM,UAAU,GAAU,UAAU,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;QAC9C,IAAI,IAAI,CAAC,UAAU,IAAI,IAAI,EAAE;YAC3B,KAAK,MAAM,CAAC,IAAI,IAAI,CAAC,UAAU,CAAE;gBAC/B,UAAU,CAAC,CAAC,GAAG,CAAC,CAAC,GAAG,CAAC,CAAC;aACvB;SACF;QACD,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC,SAAS,CACvB,OAAO,EAAE,UAAU,EAAE,SAAS,EAAE,IAAI,CAAC,gBAAgB,EACrD,IAAI,CAAC,gBAAgB,EAAE,IAAI,EAAE,IAAI,CAAC,eAAe,CAAC,CAAC;QACvD,kBAAkB;QAClB,MAAM,IAAI,GAA6B,CAAA,CAAE,CAAC;QAC1C,IAAI,IAAI,CAAC,UAAU,IAAI,IAAI,EAAE;YAC3B,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,UAAU,CAAC,MAAM,EAAE,EAAE,CAAC,CAAE;gBAC1C,IAAI,CAAC,CAAC,CAAC,GAAG,UAAU,CAAC,CAAC,CAAC,CAAC;aACzB;SACF;QACD,IAAI,CAAC,SAAS,GAAG;YAAC,IAAI,oTAAS,CAAC;gBAC9B,IAAI,EAAE,UAAU,CAAC,MAAM;gBACvB,IAAI;aACL,CAAC;SAAC,CAAC;QACJ,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC;IACpB,CAAC;IAEQ,IAAI,CAAC,MAAuB,EAAE,MAAc,EAAA;QACnD,MAAM,OAAG,gUAAmB,EAAC,MAAM,CAAC,CAAC;QACrC,WAAO,uPAAK,EAAC,MAAM,EAAE,IAAI,CAAC,KAAK,CAAC,IAAI,EAAE,CAAC,CAAC;IAC1C,CAAC;IAEQ,SAAS,GAAA;QAChB,MAAM,MAAM,GAA6B;YACvC,gBAAgB,MAAE,yTAAoB,EAAC,IAAI,CAAC,gBAAgB,CAAC;YAC7D,gBAAgB,MAAE,yTAAoB,EAAC,IAAI,CAAC,gBAAgB,CAAC;YAC7D,eAAe,MAAE,uTAAmB,EAAC,IAAI,CAAC,eAAe,CAAC;YAC1D,UAAU,EAAE,IAAI,CAAC,UAAU;SAC5B,CAAC;QACF,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;QACrC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;;AA1ED,gBAAA,EAAkB,CACX,MAAA,SAAS,GAAG,OAAO,AAAV,CAAW;;AA2E7B,ySAAa,CAAC,aAAa,CAAC,KAAK,CAAC,CAAC;AASnC,MAAa,GAAI,SAAQ,gTAAK;IAO5B,YAAY,IAAmB,CAAA;QAC7B,KAAK,CAAC,IAAI,IAAI,IAAI,CAAC,CAAC,CAAC,CAAA,CAAE,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;QAHzB,IAAA,CAAA,aAAa,GAAG,GAAG,CAAC;QAI3B,IAAI,IAAI,IAAI,IAAI,EAAE;YAChB,IAAI,GAAG,CAAA,CAAE,CAAC;SACX;QAED,IAAI,IAAI,CAAC,KAAK,IAAI,IAAI,IAAI,IAAI,CAAC,KAAK,KAAK,IAAI,CAAC,aAAa,EAAE;YAC3D,MAAM,IAAI,kTAAmB,CACzB,CAAA,yBAAA,EAA4B,IAAI,CAAC,KAAK,CAAA,0BAAA,CAA4B,GAClE,CAAA,cAAA,CAAgB,CAAC,CAAC;SACvB;QAED,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC,KAAK,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC;IACpE,CAAC;IAEQ,IAAI,CAAC,MAAuB,EAAE,MAAc,EAAA;QACnD,MAAM,CAAC,OAAG,gUAAmB,EAAC,MAAM,CAAC,CAAC;QACtC,WAAO,mPAAG,EAAC,CAAC,CAAC,CAAC;IAChB,CAAC;IAEQ,kBAAkB,CAAC,UAAyB,EAAA;QACnD,OAAO,UAAU,CAAC;IACpB,CAAC;IAEQ,SAAS,GAAA;QAChB,MAAM,MAAM,GAA6B;YAAC,KAAK,EAAE,IAAI,CAAC,KAAK;QAAA,CAAC,CAAC;QAC7D,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;QACrC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;;AAnCD,gBAAA,EAAkB,CACX,IAAA,SAAS,GAAG,KAAK,AAAR,CAAS;;AAoC3B,ySAAa,CAAC,aAAa,CAAC,GAAG,CAAC,CAAC;AASjC,MAAa,eAAgB,SAAQ,gTAAK;IAOxC,YAAY,IAA+B,CAAA;QACzC,KAAK,CAAC,IAAI,IAAI,IAAI,CAAC,CAAC,CAAC,CAAA,CAAE,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;QAHzB,IAAA,CAAA,aAAa,GAAG,GAAG,CAAC;QAI3B,IAAI,IAAI,IAAI,IAAI,EAAE;YAChB,IAAI,GAAG,CAAA,CAAE,CAAC;SACX;QAED,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC,KAAK,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,aAAa,CAAC,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC;IACpE,CAAC;IAEQ,IAAI,CAAC,MAAuB,EAAE,MAAc,EAAA;QACnD,MAAM,CAAC,OAAG,gUAAmB,EAAC,MAAM,CAAC,CAAC;QACtC,WAAO,mPAAG,EAAC,CAAC,MAAE,qPAAI,MAAC,2PAAO,EAAC,CAAC,EAAE,IAAI,CAAC,KAAK,CAAC,EAAE,SAAS,CAAC,CAAC,CAAC;IACzD,CAAC;IAEQ,kBAAkB,CAAC,UAAyB,EAAA;QACnD,OAAO,UAAU,CAAC;IACpB,CAAC;IAEQ,SAAS,GAAA;QAChB,MAAM,MAAM,GAA6B;YAAC,KAAK,EAAE,IAAI,CAAC,KAAK;QAAA,CAAC,CAAC;QAC7D,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;QACrC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;;AA7BD,gBAAA,EAAkB,CACX,gBAAA,SAAS,GAAG,iBAAiB,AAApB,CAAqB;;AA8BvC,ySAAa,CAAC,aAAa,CAAC,eAAe,CAAC,CAAC;AAU7C,MAAa,OAAQ,SAAQ,gTAAK;IAOhC,YAAY,IAAuB,CAAA;QACjC,KAAK,CAAC,IAAI,IAAI,IAAI,CAAC,CAAC,CAAC,CAAA,CAAE,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;QAHzB,IAAA,CAAA,YAAY,GAAG,GAAG,CAAC;QAI1B,IAAI,IAAI,IAAI,IAAI,EAAE;YAChB,IAAI,GAAG,CAAA,CAAE,CAAC;SACX;QACD,IAAI,CAAC,OAAO,GAAG,IAAI,2SAAiB,EAAE,CAAC,KAAK,CAAC;QAC7C,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC,IAAI,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,YAAY,CAAC,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC;IAChE,CAAC;IAEQ,IAAI,CAAC,MAAuB,EAAE,MAAc,EAAA;QACnD,mEAAmE;QACnE,WAAO,iPAAI,EAAC,GAAG,EAAE;YACf,IAAI,CAAC,OAAG,gUAAmB,EAAC,MAAM,CAAC,CAAC;YACpC,MAAM,IAAI,GAAG,MAAM,CAAC,MAAM,CAAW,CAAC;YACtC,IAAI,IAAI,IAAI,IAAI,EAAE;gBAChB,qEAAqE;gBACrE,kEAAkE;gBAClE,8DAA8D;gBAC9D,MAAM,KAAK,OACT,mPAAG,MAAC,mPAAG,MAAC,qPAAI,EAAC,CAAC,CAAC,KAAK,CAAC,MAAE,qPAAI,EAAC,IAAI,EAAE,CAAC,CAAC,KAAK,CAAC,CAAC,MAAE,yPAAM,EAAC,CAAC,GAAG,CAAC,CAAC,CAAC;gBAE7D,oEAAoE;gBACpE,sDAAsD;gBACtD,CAAC,OAAG,mPAAG,EAAC,CAAC,EAAE,KAAK,CAAC,CAAC;aACnB;YACD,IAAI,IAAI,CAAC,IAAI,YAAY,KAAK,EAAE;gBAC9B,IAAI,IAAI,CAAC,IAAI,CAAC,MAAM,GAAG,CAAC,EAAE;oBACxB,WAAO,mPAAG,MAAC,mPAAG,EAAC,CAAC,MAAE,iQAAS,EAAC,CAAC,EAAE,IAAI,CAAC,IAAI,EAAE,IAAI,CAAC,CAAC,CAAC,CAAC;iBACnD,MAAM;oBACL,OAAO,IAAI,CAAC,OAAO,CAAC,CAAC,EAAE,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC;iBACtC;aACF;YACD,OAAO,IAAI,CAAC,OAAO,CAAC,CAAC,EAAE,IAAI,CAAC,IAAI,CAAC,CAAC;QACpC,CAAC,CAAC,CAAC;IACL,CAAC;IAEQ,kBAAkB,CAAC,UAAyB,EAAA;QACnD,OAAO,UAAU,CAAC;IACpB,CAAC;IAEQ,SAAS,GAAA;QAChB,MAAM,MAAM,GAA6B;YAAC,IAAI,EAAE,IAAI,CAAC,IAAI;QAAA,CAAC,CAAC;QAC3D,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;QACrC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;;AAnDD,gBAAA,EAAkB,CACX,QAAA,SAAS,GAAG,SAAS,AAAZ,CAAa;;AAoD/B,ySAAa,CAAC,aAAa,CAAC,OAAO,CAAC,CAAC"}},
    {"offset": {"line": 321, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-layers@4.22.0_@tensorflow+tfjs-core@4.22.0/node_modules/@tensorflow/tfjs-layers/dist/layers/convolutional_depthwise.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-layers/src/layers/convolutional_depthwise.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * TensorFlow.js Layers: Depthwise Convolutional Layers\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\nimport {serialization, Tensor, Tensor4D, tidy} from '@tensorflow/tfjs-core';\n\nimport {imageDataFormat} from '../backend/common';\nimport * as K from '../backend/tfjs_backend';\nimport {checkDataFormat} from '../common';\nimport {Constraint, ConstraintIdentifier, getConstraint, serializeConstraint} from '../constraints';\nimport {ValueError} from '../errors';\nimport {getInitializer, Initializer, InitializerIdentifier, serializeInitializer} from '../initializers';\nimport {DataFormat, Shape} from '../keras_format/common';\nimport {getRegularizer, Regularizer, RegularizerIdentifier, serializeRegularizer} from '../regularizers';\nimport {Kwargs} from '../types';\nimport {convOutputLength} from '../utils/conv_utils';\nimport {getExactlyOneShape, getExactlyOneTensor} from '../utils/types_utils';\nimport {LayerVariable} from '../variables';\n\nimport {BaseConv, BaseConvLayerArgs, ConvLayerArgs, preprocessConv2DInput} from './convolutional';\n\n/**\n * 2D convolution with separable filters.\n * @param x Input tensor.\n * @param depthwiseKernel Convolution kernel for depthwise convolution.\n * @param strides Strides (Array of two integers).\n * @param padding Padding model.\n * @param dataFormat Data format.\n * @param dilationRate Array of two integers, dilation rates for the separable\n *   convolution.\n * @returns Output tensor.\n * @throws ValueError If depthwiseKernel is not a 4D array.\n */\nexport function depthwiseConv2d(\n    x: Tensor, depthwiseKernel: Tensor, strides: [number, number] = [1, 1],\n    padding = 'valid', dataFormat?: DataFormat,\n    dilationRate?: [number, number]): Tensor {\n  return tidy(() => {\n    if (dataFormat == null) {\n      dataFormat = imageDataFormat();\n    }\n    checkDataFormat(dataFormat);\n    let y = preprocessConv2DInput(x, dataFormat);\n    if (x.rank !== 4) {\n      throw new ValueError(\n          `Input for depthwiseConv2d is required to be 4-D, but is instead ` +\n          `${x.rank}-D`);\n    }\n    if (depthwiseKernel.rank !== 4) {\n      throw new ValueError(\n          `depthwiseKernel is required to be 4-D, but is instead ` +\n          `${depthwiseKernel.rank}-D`);\n    }\n    y = tfc.depthwiseConv2d(\n        y as Tensor4D, depthwiseKernel as Tensor4D, strides,\n        padding === 'same' ? 'same' : 'valid', 'NHWC', dilationRate);\n    if (dataFormat === 'channelsFirst') {\n      y = tfc.transpose(y, [0, 3, 1, 2]);\n    }\n    return y;\n  });\n}\n\nexport declare interface DepthwiseConv2DLayerArgs extends BaseConvLayerArgs {\n  /**\n   * An integer or Array of 2 integers, specifying the width and height of the\n   * 2D convolution window. Can be a single integer to specify the same value\n   * for all spatial dimensions.\n   */\n  kernelSize: number|[number, number];\n\n  /**\n   * The number of depthwise convolution output channels for each input\n   * channel.\n   * The total number of depthwise convolution output channels will be equal to\n   * `filtersIn * depthMultiplier`.\n   * Default: 1.\n   */\n  depthMultiplier?: number;\n\n  /**\n   * Initializer for the depthwise kernel matrix.\n   * Default: GlorotNormal.\n   */\n  depthwiseInitializer?: InitializerIdentifier|Initializer;\n\n  /**\n   * Constraint for the depthwise kernel matrix.\n   */\n  depthwiseConstraint?: ConstraintIdentifier|Constraint;\n\n  /**\n   * Regularizer function for the depthwise kernel matrix.\n   */\n  depthwiseRegularizer?: RegularizerIdentifier|Regularizer;\n}\n\nexport class DepthwiseConv2D extends BaseConv {\n  /** @nocollapse */\n  static className = 'DepthwiseConv2D';\n  private readonly depthMultiplier: number;\n  private readonly depthwiseInitializer: Initializer;\n  private readonly depthwiseConstraint: Constraint;\n  private readonly depthwiseRegularizer: Regularizer;\n\n  private depthwiseKernel: LayerVariable = null;\n\n  constructor(args: DepthwiseConv2DLayerArgs) {\n    super(2, args as ConvLayerArgs);\n    this.depthMultiplier =\n        args.depthMultiplier == null ? 1 : args.depthMultiplier;\n    this.depthwiseInitializer = getInitializer(\n        args.depthwiseInitializer || this.DEFAULT_KERNEL_INITIALIZER);\n    this.depthwiseConstraint = getConstraint(args.depthwiseConstraint);\n    this.depthwiseRegularizer = getRegularizer(args.depthwiseRegularizer);\n  }\n\n  override build(inputShape: Shape|Shape[]): void {\n    inputShape = getExactlyOneShape(inputShape);\n    if (inputShape.length < 4) {\n      throw new ValueError(\n          `Inputs to DepthwiseConv2D should have rank 4. ` +\n          `Received input shape: ${JSON.stringify(inputShape)}.`);\n    }\n    const channelAxis = this.dataFormat === 'channelsFirst' ? 1 : 3;\n    if (inputShape[channelAxis] == null || inputShape[channelAxis] < 0) {\n      throw new ValueError(\n          'The channel dimension of the inputs to DepthwiseConv2D should ' +\n          `be defined, but is not (${inputShape[channelAxis]}).`);\n    }\n    const inputDim = inputShape[channelAxis];\n    const depthwiseKernelShape: Shape = [\n      this.kernelSize[0], this.kernelSize[1], inputDim, this.depthMultiplier\n    ];\n\n    this.depthwiseKernel = this.addWeight(\n        'depthwise_kernel', depthwiseKernelShape, null,\n        this.depthwiseInitializer, this.depthwiseRegularizer, true,\n        this.depthwiseConstraint);\n    if (this.useBias) {\n      this.bias = this.addWeight(\n          'bias', [inputDim * this.depthMultiplier], null, this.biasInitializer,\n          this.biasRegularizer, true, this.biasConstraint);\n    } else {\n      this.bias = null;\n    }\n    this.built = true;\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      inputs = getExactlyOneTensor(inputs);\n      let outputs = depthwiseConv2d(\n          inputs, this.depthwiseKernel.read(), this.strides as [number, number],\n          this.padding, this.dataFormat, null);\n      // TODO(cais): Add support for dilation.\n      if (this.useBias) {\n        outputs = K.biasAdd(outputs, this.bias.read(), this.dataFormat);\n      }\n      if (this.activation != null) {\n        outputs = this.activation.apply(outputs);\n      }\n      return outputs;\n    });\n  }\n\n  override computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    inputShape = getExactlyOneShape(inputShape);\n    const rows =\n        this.dataFormat === 'channelsFirst' ? inputShape[2] : inputShape[1];\n    const cols =\n        this.dataFormat === 'channelsFirst' ? inputShape[3] : inputShape[2];\n    const outFilters = this.dataFormat === 'channelsFirst' ?\n        inputShape[1] * this.depthMultiplier :\n        inputShape[3] * this.depthMultiplier;\n    const outRows = convOutputLength(\n        rows, this.kernelSize[0], this.padding, this.strides[0]);\n    const outCols = convOutputLength(\n        cols, this.kernelSize[1], this.padding, this.strides[1]);\n    if (this.dataFormat === 'channelsFirst') {\n      return [inputShape[0], outFilters, outRows, outCols];\n    } else {\n      // In this case, assume 'channelsLast'.\n      return [inputShape[0], outRows, outCols, outFilters];\n    }\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config = super.getConfig();\n    config['depthMultiplier'] = this.depthMultiplier;\n    config['depthwiseInitializer'] =\n        serializeInitializer(this.depthwiseInitializer);\n    config['depthwiseRegularizer'] =\n        serializeRegularizer(this.depthwiseRegularizer);\n    config['depthwiseConstraint'] =\n        serializeConstraint(this.depthwiseRegularizer);\n    return config;\n  }\n}\nserialization.registerClass(DepthwiseConv2D);\n"],"names":[],"mappings":";;;;;;AAAA;;;;;;;;GAQG,CAEH;;GAEG;;AAEH,OAAO,KAAK,GAAG,MAAM,uBAAuB,CAAC;;AAC7C,OAAO,EAAC,aAAa,EAAoB,IAAI,EAAC,MAAM,uBAAuB,CAAC;AAE5E,OAAO,EAAC,eAAe,EAAC,MAAM,mBAAmB,CAAC;AAClD,OAAO,KAAK,CAAC,MAAM,yBAAyB,CAAC;AAC7C,OAAO,EAAC,eAAe,EAAC,MAAM,WAAW,CAAC;AAC1C,OAAO,EAAmC,aAAa,EAAE,mBAAmB,EAAC,MAAM,gBAAgB,CAAC;AACpG,OAAO,EAAC,UAAU,EAAC,MAAM,WAAW,CAAC;AACrC,OAAO,EAAC,cAAc,EAAsC,oBAAoB,EAAC,MAAM,iBAAiB,CAAC;AAEzG,OAAO,EAAC,cAAc,EAAsC,oBAAoB,EAAC,MAAM,iBAAiB,CAAC;AAEzG,OAAO,EAAC,gBAAgB,EAAC,MAAM,qBAAqB,CAAC;AACrD,OAAO,EAAC,kBAAkB,EAAE,mBAAmB,EAAC,MAAM,sBAAsB,CAAC;AAG7E,OAAO,EAAC,QAAQ,EAAoC,qBAAqB,EAAC,MAAM,iBAAiB,CAAC;;;;;;;;;;;;;AAc5F,SAAU,eAAe,CAC3B,CAAS,EAAE,eAAuB,EAAE,UAA4B;IAAC,CAAC;IAAE,CAAC;CAAC,EACtE,OAAO,GAAG,OAAO,EAAE,UAAuB,EAC1C,YAA+B;IACjC,WAAO,iPAAI,EAAC,GAAG,EAAE;QACf,IAAI,UAAU,IAAI,IAAI,EAAE;YACtB,UAAU,OAAG,yTAAe,EAAE,CAAC;SAChC;YACD,8SAAe,EAAC,UAAU,CAAC,CAAC;QAC5B,IAAI,CAAC,OAAG,qUAAqB,EAAC,CAAC,EAAE,UAAU,CAAC,CAAC;QAC7C,IAAI,CAAC,CAAC,IAAI,KAAK,CAAC,EAAE;YAChB,MAAM,IAAI,ySAAU,CAChB,CAAA,gEAAA,CAAkE,GAClE,GAAG,CAAC,CAAC,IAAI,CAAA,EAAA,CAAI,CAAC,CAAC;SACpB;QACD,IAAI,eAAe,CAAC,IAAI,KAAK,CAAC,EAAE;YAC9B,MAAM,IAAI,ySAAU,CAChB,CAAA,sDAAA,CAAwD,GACxD,GAAG,eAAe,CAAC,IAAI,CAAA,EAAA,CAAI,CAAC,CAAC;SAClC;QACD,CAAC,GAAG,GAAG,CAAC,wQAAe,CACnB,CAAa,EAAE,eAA2B,EAAE,OAAO,EACnD,OAAO,KAAK,MAAM,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC,OAAO,EAAE,MAAM,EAAE,YAAY,CAAC,CAAC;QACjE,IAAI,UAAU,KAAK,eAAe,EAAE;YAClC,CAAC,GAAG,GAAG,CAAC,2PAAS,CAAC,CAAC,EAAE;gBAAC,CAAC;gBAAE,CAAC;gBAAE,CAAC;gBAAE,CAAC;aAAC,CAAC,CAAC;SACpC;QACD,OAAO,CAAC,CAAC;IACX,CAAC,CAAC,CAAC;AACL,CAAC;AAoCD,MAAa,eAAgB,SAAQ,wTAAQ;IAU3C,YAAY,IAA8B,CAAA;QACxC,KAAK,CAAC,CAAC,EAAE,IAAqB,CAAC,CAAC;QAH1B,IAAA,CAAA,eAAe,GAAkB,IAAI,CAAC;QAI5C,IAAI,CAAC,eAAe,GAChB,IAAI,CAAC,eAAe,IAAI,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,eAAe,CAAC;QAC5D,IAAI,CAAC,oBAAoB,OAAG,mTAAc,EACtC,IAAI,CAAC,oBAAoB,IAAI,IAAI,CAAC,0BAA0B,CAAC,CAAC;QAClE,IAAI,CAAC,mBAAmB,OAAG,iTAAa,EAAC,IAAI,CAAC,mBAAmB,CAAC,CAAC;QACnE,IAAI,CAAC,oBAAoB,OAAG,mTAAc,EAAC,IAAI,CAAC,oBAAoB,CAAC,CAAC;IACxE,CAAC;IAEQ,KAAK,CAAC,UAAyB,EAAA;QACtC,UAAU,OAAG,+TAAkB,EAAC,UAAU,CAAC,CAAC;QAC5C,IAAI,UAAU,CAAC,MAAM,GAAG,CAAC,EAAE;YACzB,MAAM,IAAI,ySAAU,CAChB,CAAA,8CAAA,CAAgD,GAChD,CAAA,sBAAA,EAAyB,IAAI,CAAC,SAAS,CAAC,UAAU,CAAC,CAAA,CAAA,CAAG,CAAC,CAAC;SAC7D;QACD,MAAM,WAAW,GAAG,IAAI,CAAC,UAAU,KAAK,eAAe,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAChE,IAAI,UAAU,CAAC,WAAW,CAAC,IAAI,IAAI,IAAI,UAAU,CAAC,WAAW,CAAC,GAAG,CAAC,EAAE;YAClE,MAAM,IAAI,ySAAU,CAChB,gEAAgE,GAChE,CAAA,wBAAA,EAA2B,UAAU,CAAC,WAAW,CAAC,CAAA,EAAA,CAAI,CAAC,CAAC;SAC7D;QACD,MAAM,QAAQ,GAAG,UAAU,CAAC,WAAW,CAAC,CAAC;QACzC,MAAM,oBAAoB,GAAU;YAClC,IAAI,CAAC,UAAU,CAAC,CAAC,CAAC;YAAE,IAAI,CAAC,UAAU,CAAC,CAAC,CAAC;YAAE,QAAQ;YAAE,IAAI,CAAC,eAAe;SACvE,CAAC;QAEF,IAAI,CAAC,eAAe,GAAG,IAAI,CAAC,SAAS,CACjC,kBAAkB,EAAE,oBAAoB,EAAE,IAAI,EAC9C,IAAI,CAAC,oBAAoB,EAAE,IAAI,CAAC,oBAAoB,EAAE,IAAI,EAC1D,IAAI,CAAC,mBAAmB,CAAC,CAAC;QAC9B,IAAI,IAAI,CAAC,OAAO,EAAE;YAChB,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC,SAAS,CACtB,MAAM,EAAE;gBAAC,QAAQ,GAAG,IAAI,CAAC,eAAe;aAAC,EAAE,IAAI,EAAE,IAAI,CAAC,eAAe,EACrE,IAAI,CAAC,eAAe,EAAE,IAAI,EAAE,IAAI,CAAC,cAAc,CAAC,CAAC;SACtD,MAAM;YACL,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC;SAClB;QACD,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC;IACpB,CAAC;IAEQ,IAAI,CAAC,MAAuB,EAAE,MAAc,EAAA;QACnD,WAAO,iPAAI,EAAC,GAAG,EAAE;YACf,MAAM,OAAG,gUAAmB,EAAC,MAAM,CAAC,CAAC;YACrC,IAAI,OAAO,GAAG,eAAe,CACzB,MAAM,EAAE,IAAI,CAAC,eAAe,CAAC,IAAI,EAAE,EAAE,IAAI,CAAC,OAA2B,EACrE,IAAI,CAAC,OAAO,EAAE,IAAI,CAAC,UAAU,EAAE,IAAI,CAAC,CAAC;YACzC,wCAAwC;YACxC,IAAI,IAAI,CAAC,OAAO,EAAE;gBAChB,OAAO,GAAG,CAAC,CAAC,qTAAO,CAAC,OAAO,EAAE,IAAI,CAAC,IAAI,CAAC,IAAI,EAAE,EAAE,IAAI,CAAC,UAAU,CAAC,CAAC;aACjE;YACD,IAAI,IAAI,CAAC,UAAU,IAAI,IAAI,EAAE;gBAC3B,OAAO,GAAG,IAAI,CAAC,UAAU,CAAC,KAAK,CAAC,OAAO,CAAC,CAAC;aAC1C;YACD,OAAO,OAAO,CAAC;QACjB,CAAC,CAAC,CAAC;IACL,CAAC;IAEQ,kBAAkB,CAAC,UAAyB,EAAA;QACnD,UAAU,OAAG,+TAAkB,EAAC,UAAU,CAAC,CAAC;QAC5C,MAAM,IAAI,GACN,IAAI,CAAC,UAAU,KAAK,eAAe,CAAC,CAAC,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC;QACxE,MAAM,IAAI,GACN,IAAI,CAAC,UAAU,KAAK,eAAe,CAAC,CAAC,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC;QACxE,MAAM,UAAU,GAAG,IAAI,CAAC,UAAU,KAAK,eAAe,CAAC,CAAC,CACpD,UAAU,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,eAAe,CAAC,CAAC,CACtC,UAAU,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,eAAe,CAAC;QACzC,MAAM,OAAO,OAAG,4TAAgB,EAC5B,IAAI,EAAE,IAAI,CAAC,UAAU,CAAC,CAAC,CAAC,EAAE,IAAI,CAAC,OAAO,EAAE,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC;QAC7D,MAAM,OAAO,OAAG,4TAAgB,EAC5B,IAAI,EAAE,IAAI,CAAC,UAAU,CAAC,CAAC,CAAC,EAAE,IAAI,CAAC,OAAO,EAAE,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC;QAC7D,IAAI,IAAI,CAAC,UAAU,KAAK,eAAe,EAAE;YACvC,OAAO;gBAAC,UAAU,CAAC,CAAC,CAAC;gBAAE,UAAU;gBAAE,OAAO;gBAAE,OAAO;aAAC,CAAC;SACtD,MAAM;YACL,uCAAuC;YACvC,OAAO;gBAAC,UAAU,CAAC,CAAC,CAAC;gBAAE,OAAO;gBAAE,OAAO;gBAAE,UAAU;aAAC,CAAC;SACtD;IACH,CAAC;IAEQ,SAAS,GAAA;QAChB,MAAM,MAAM,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;QACjC,MAAM,CAAC,iBAAiB,CAAC,GAAG,IAAI,CAAC,eAAe,CAAC;QACjD,MAAM,CAAC,sBAAsB,CAAC,OAC1B,yTAAoB,EAAC,IAAI,CAAC,oBAAoB,CAAC,CAAC;QACpD,MAAM,CAAC,sBAAsB,CAAC,OAC1B,yTAAoB,EAAC,IAAI,CAAC,oBAAoB,CAAC,CAAC;QACpD,MAAM,CAAC,qBAAqB,CAAC,OACzB,uTAAmB,EAAC,IAAI,CAAC,oBAAoB,CAAC,CAAC;QACnD,OAAO,MAAM,CAAC;IAChB,CAAC;;AAnGD,gBAAA,EAAkB,CACX,gBAAA,SAAS,GAAG,iBAAiB,AAApB,CAAqB;;AAoGvC,ySAAa,CAAC,aAAa,CAAC,eAAe,CAAC,CAAC"}},
    {"offset": {"line": 481, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-layers@4.22.0_@tensorflow+tfjs-core@4.22.0/node_modules/@tensorflow/tfjs-layers/dist/layers/convolutional_recurrent.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-layers/src/layers/convolutional_recurrent.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\nimport {Tensor, util} from '@tensorflow/tfjs-core';\n\nimport {Activation} from '../activations';\nimport * as K from '../backend/tfjs_backend';\nimport {checkDataFormat, checkPaddingMode} from '../common';\nimport {Constraint} from '../constraints';\nimport {InputSpec} from '../engine/topology';\nimport {AttributeError, NotImplementedError, ValueError} from '../errors';\nimport {Initializer} from '../initializers';\nimport {DataFormat, DataType, PaddingMode, Shape} from '../keras_format/common';\nimport {Regularizer} from '../regularizers';\nimport {Kwargs} from '../types';\nimport {convOutputLength, normalizeArray} from '../utils/conv_utils';\nimport {assertPositiveInteger} from '../utils/generic_utils';\nimport {getExactlyOneShape} from '../utils/types_utils';\n\nimport {BaseRNNLayerArgs, generateDropoutMask, LSTMCell, LSTMCellLayerArgs, LSTMLayerArgs, RNN, RNNCell, RNNLayerArgs, SimpleRNNCellLayerArgs} from './recurrent';\n\ndeclare interface ConvRNN2DCellArgs extends\n    Omit<SimpleRNNCellLayerArgs, 'units'> {\n  /**\n   * The dimensionality of the output space (i.e. the number of filters in the\n   * convolution).\n   */\n  filters: number;\n\n  /**\n   * The dimensions of the convolution window. If kernelSize is a number, the\n   * convolutional window will be square.\n   */\n  kernelSize: number|number[];\n\n  /**\n   * The strides of the convolution in each dimension. If strides is a number,\n   * strides in both dimensions are equal.\n   *\n   * Specifying any stride value != 1 is incompatible with specifying any\n   * `dilationRate` value != 1.\n   */\n  strides?: number|number[];\n\n  /**\n   * Padding mode.\n   */\n  padding?: PaddingMode;\n\n  /**\n   * Format of the data, which determines the ordering of the dimensions in\n   * the inputs.\n   *\n   * `channels_last` corresponds to inputs with shape\n   *   `(batch, ..., channels)`\n   *\n   *  `channels_first` corresponds to inputs with shape `(batch, channels,\n   * ...)`.\n   *\n   * Defaults to `channels_last`.\n   */\n  dataFormat?: DataFormat;\n\n  /**\n   * The dilation rate to use for the dilated convolution in each dimension.\n   * Should be an integer or array of two or three integers.\n   *\n   * Currently, specifying any `dilationRate` value != 1 is incompatible with\n   * specifying any `strides` value != 1.\n   */\n  dilationRate?: number|[number]|[number, number];\n}\n\nabstract class ConvRNN2DCell extends RNNCell {\n  readonly filters: number;\n  readonly kernelSize: number[];\n  readonly strides: number[];\n  readonly padding: PaddingMode;\n  readonly dataFormat: DataFormat;\n  readonly dilationRate: number[];\n\n  readonly activation: Activation;\n  readonly useBias: boolean;\n\n  readonly kernelInitializer: Initializer;\n  readonly recurrentInitializer: Initializer;\n  readonly biasInitializer: Initializer;\n\n  readonly kernelConstraint: Constraint;\n  readonly recurrentConstraint: Constraint;\n  readonly biasConstraint: Constraint;\n\n  readonly kernelRegularizer: Regularizer;\n  readonly recurrentRegularizer: Regularizer;\n  readonly biasRegularizer: Regularizer;\n\n  readonly dropout: number;\n  readonly recurrentDropout: number;\n}\n\ndeclare interface ConvRNN2DLayerArgs extends BaseRNNLayerArgs,\n                                             ConvRNN2DCellArgs {}\n\n/**\n * Base class for convolutional-recurrent layers.\n */\nclass ConvRNN2D extends RNN {\n  /** @nocollapse */\n  static override className = 'ConvRNN2D';\n\n  declare readonly cell: ConvRNN2DCell;\n\n  constructor(args: ConvRNN2DLayerArgs) {\n    if (args.unroll) {\n      throw new NotImplementedError(\n          'Unrolling is not possible with convolutional RNNs.');\n    }\n\n    if (Array.isArray(args.cell)) {\n      throw new NotImplementedError(\n          'It is not possible at the moment to stack convolutional cells.');\n    }\n\n    super(args as RNNLayerArgs);\n\n    this.inputSpec = [new InputSpec({ndim: 5})];\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tfc.tidy(() => {\n      if (this.cell.dropoutMask != null) {\n        tfc.dispose(this.cell.dropoutMask);\n\n        this.cell.dropoutMask = null;\n      }\n\n      if (this.cell.recurrentDropoutMask != null) {\n        tfc.dispose(this.cell.recurrentDropoutMask);\n\n        this.cell.recurrentDropoutMask = null;\n      }\n\n      if (kwargs && kwargs['constants']) {\n        throw new ValueError('ConvRNN2D cell does not support constants');\n      }\n\n      const mask = kwargs == null ? null : kwargs['mask'];\n\n      const training = kwargs == null ? null : kwargs['training'];\n\n      const initialState: Tensor[] =\n          kwargs == null ? null : kwargs['initialState'];\n\n      return super.call(inputs, {mask, training, initialState});\n    });\n  }\n\n  override computeOutputShape(inputShape: Shape): Shape|Shape[] {\n    let outShape: Shape = this.computeSingleOutputShape(inputShape);\n\n    if (!this.returnSequences) {\n      outShape = [outShape[0], ...outShape.slice(2)];\n    }\n\n    if (this.returnState) {\n      outShape =\n          [outShape, ...Array(2).fill([inputShape[0], ...outShape.slice(-3)])];\n    }\n\n    return outShape;\n  }\n\n  override getInitialState(inputs: tfc.Tensor): tfc.Tensor[] {\n    return tfc.tidy(() => {\n      const {stateSize} = this.cell;\n\n      const inputShape = inputs.shape;\n\n      const outputShape = this.computeSingleOutputShape(inputShape);\n\n      const stateShape = [outputShape[0], ...outputShape.slice(2)];\n\n      const initialState = tfc.zeros(stateShape);\n\n      if (Array.isArray(stateSize)) {\n        return Array(stateSize.length).fill(initialState);\n      }\n\n      return [initialState];\n    });\n  }\n\n  override resetStates(states?: Tensor|Tensor[], training = false): void {\n    tfc.tidy(() => {\n      if (!this.stateful) {\n        throw new AttributeError(\n            'Cannot call resetStates() on an RNN Layer that is not stateful.');\n      }\n\n      const inputShape = this.inputSpec[0].shape;\n\n      const outputShape = this.computeSingleOutputShape(inputShape);\n\n      const stateShape = [outputShape[0], ...outputShape.slice(2)];\n\n      const batchSize = inputShape[0];\n\n      if (batchSize == null) {\n        throw new ValueError(\n            'If an RNN is stateful, it needs to know its batch size. Specify ' +\n            'the batch size of your input tensors: \\n' +\n            '- If using a Sequential model, specify the batch size by ' +\n            'passing a `batchInputShape` option to your first layer.\\n' +\n            '- If using the functional API, specify the batch size by ' +\n            'passing a `batchShape` option to your Input layer.');\n      }\n\n      // Initialize state if null.\n      if (this.getStates() == null) {\n        if (Array.isArray(this.cell.stateSize)) {\n          this.states_ = this.cell.stateSize.map(() => tfc.zeros(stateShape));\n        } else {\n          this.states_ = [tfc.zeros(stateShape)];\n        }\n      } else if (states == null) {\n        // Dispose old state tensors.\n        tfc.dispose(this.states_);\n\n        // For stateful RNNs, fully dispose kept old states.\n        if (this.keptStates != null) {\n          tfc.dispose(this.keptStates);\n          this.keptStates = [];\n        }\n\n        if (Array.isArray(this.cell.stateSize)) {\n          this.states_ = this.cell.stateSize.map(() => tfc.zeros(stateShape));\n        } else {\n          this.states_[0] = tfc.zeros(stateShape);\n        }\n      } else {\n        if (!Array.isArray(states)) {\n          states = [states];\n        }\n\n        if (states.length !== this.states_.length) {\n          throw new ValueError(\n              `Layer ${this.name} expects ${this.states_.length} state(s), ` +\n              `but it received ${states.length} state value(s). Input ` +\n              `received: ${states}`);\n        }\n\n        if (training) {\n          // Store old state tensors for complete disposal later, i.e., during\n          // the next no-arg call to this method. We do not dispose the old\n          // states immediately because that BPTT (among other things) require\n          // them.\n          this.keptStates.push(this.states_.slice());\n        } else {\n          tfc.dispose(this.states_);\n        }\n\n        for (let index = 0; index < this.states_.length; ++index) {\n          const value = states[index];\n\n          const expectedShape = stateShape;\n\n          if (!util.arraysEqual(value.shape, expectedShape)) {\n            throw new ValueError(\n                `State ${index} is incompatible with layer ${this.name}: ` +\n                `expected shape=${expectedShape}, received shape=${\n                    value.shape}`);\n          }\n\n          this.states_[index] = value;\n        }\n      }\n\n      this.states_ = this.states_.map(state => tfc.keep(state.clone()));\n    });\n  }\n\n  protected computeSingleOutputShape(inputShape: Shape): Shape {\n    const {dataFormat, filters, kernelSize, padding, strides, dilationRate} =\n        this.cell;\n\n    const isChannelsFirst = dataFormat === 'channelsFirst';\n\n    const h = inputShape[isChannelsFirst ? 3 : 2];\n    const w = inputShape[isChannelsFirst ? 4 : 3];\n\n    const hOut = convOutputLength(\n        h, kernelSize[0], padding, strides[0], dilationRate[0]);\n    const wOut = convOutputLength(\n        w, kernelSize[1], padding, strides[1], dilationRate[1]);\n\n    const outShape: Shape = [\n      ...inputShape.slice(0, 2),\n      ...(isChannelsFirst ? [filters, hOut, wOut] : [hOut, wOut, filters])\n    ];\n\n    return outShape;\n  }\n}\n\nexport declare interface ConvLSTM2DCellArgs extends\n    Omit<LSTMCellLayerArgs, 'units'>, ConvRNN2DCellArgs {}\n\nexport class ConvLSTM2DCell extends LSTMCell implements ConvRNN2DCell {\n  /** @nocollapse */\n  static override className = 'ConvLSTM2DCell';\n\n  readonly filters: number;\n  readonly kernelSize: number[];\n  readonly strides: number[];\n  readonly padding: PaddingMode;\n  readonly dataFormat: DataFormat;\n  readonly dilationRate: number[];\n\n  constructor(args: ConvLSTM2DCellArgs) {\n    const {\n      filters,\n      kernelSize,\n      strides,\n      padding,\n      dataFormat,\n      dilationRate,\n    } = args;\n\n    super({...args, units: filters});\n\n    this.filters = filters;\n    assertPositiveInteger(this.filters, 'filters');\n\n    this.kernelSize = normalizeArray(kernelSize, 2, 'kernelSize');\n    this.kernelSize.forEach(size => assertPositiveInteger(size, 'kernelSize'));\n\n    this.strides = normalizeArray(strides || 1, 2, 'strides');\n    this.strides.forEach(stride => assertPositiveInteger(stride, 'strides'));\n\n    this.padding = padding || 'valid';\n    checkPaddingMode(this.padding);\n\n    this.dataFormat = dataFormat || 'channelsLast';\n    checkDataFormat(this.dataFormat);\n\n    this.dilationRate = normalizeArray(dilationRate || 1, 2, 'dilationRate');\n    this.dilationRate.forEach(\n        rate => assertPositiveInteger(rate, 'dilationRate'));\n  }\n\n  public override build(inputShape: Shape|Shape[]): void {\n    inputShape = getExactlyOneShape(inputShape);\n\n    const channelAxis =\n        this.dataFormat === 'channelsFirst' ? 1 : inputShape.length - 1;\n\n    if (inputShape[channelAxis] == null) {\n      throw new ValueError(\n          `The channel dimension of the input should be defined. ` +\n          `Found ${inputShape[channelAxis]}`);\n    }\n\n    const inputDim = inputShape[channelAxis];\n\n    const numOfKernels = 4;\n\n    const kernelShape =\n        this.kernelSize.concat([inputDim, this.filters * numOfKernels]);\n\n    this.kernel = this.addWeight(\n        'kernel', kernelShape, null, this.kernelInitializer,\n        this.kernelRegularizer, true, this.kernelConstraint);\n\n    const recurrentKernelShape =\n        this.kernelSize.concat([this.filters, this.filters * numOfKernels]);\n\n    this.recurrentKernel = this.addWeight(\n        'recurrent_kernel', recurrentKernelShape, null,\n        this.recurrentInitializer, this.recurrentRegularizer, true,\n        this.recurrentConstraint);\n\n    if (this.useBias) {\n      let biasInitializer: Initializer;\n\n      if (this.unitForgetBias) {\n        const init = this.biasInitializer;\n\n        const filters = this.filters;\n\n        biasInitializer = new (class CustomInit extends Initializer {\n          /** @nocollapse */\n          static className = 'CustomInit';\n\n          apply(shape: Shape, dtype?: DataType): tfc.Tensor {\n            const biasI = init.apply([filters]);\n            const biasF = tfc.ones([filters]);\n            const biasCAndO = init.apply([filters * 2]);\n            return K.concatenate([biasI, biasF, biasCAndO]);\n          }\n        })();\n      } else {\n        biasInitializer = this.biasInitializer;\n      }\n\n      this.bias = this.addWeight(\n          'bias', [this.filters * numOfKernels], null, biasInitializer,\n          this.biasRegularizer, true, this.biasConstraint);\n    }\n\n    this.built = true;\n  }\n\n  override call(inputs: tfc.Tensor[], kwargs: Kwargs): tfc.Tensor[] {\n    return tfc.tidy(() => {\n      if (inputs.length !== 3) {\n        throw new ValueError(\n            `ConvLSTM2DCell expects 3 input Tensors (inputs, h, c), got ` +\n            `${inputs.length}.`);\n      }\n\n      const training = kwargs['training'] || false;\n\n      const x = inputs[0];         // Current input\n      const hTMinus1 = inputs[1];  // Previous memory state.\n      const cTMinus1 = inputs[2];  // Previous carry state.\n\n      const numOfKernels = 4;\n\n      type DropoutMasks = [tfc.Tensor, tfc.Tensor, tfc.Tensor, tfc.Tensor];\n\n      if (0 < this.dropout && this.dropout < 1 && this.dropoutMask == null) {\n        this.dropoutMask = generateDropoutMask({\n                             ones: () => tfc.onesLike(x),\n                             rate: this.dropout,\n                             training,\n                             count: numOfKernels,\n                             dropoutFunc: this.dropoutFunc\n                           }) as tfc.Tensor[];\n      }\n\n      const dropoutMask = this.dropoutMask as DropoutMasks;\n\n      const applyDropout =\n          (x: tfc.Tensor, mask: tfc.Tensor[], index: number) => {\n            if (!mask || !mask[index]) {\n              return x;\n            }\n\n            return tfc.mul(mask[index], x);\n          };\n\n      let xI = applyDropout(x, dropoutMask, 0);\n      let xF = applyDropout(x, dropoutMask, 1);\n      let xC = applyDropout(x, dropoutMask, 2);\n      let xO = applyDropout(x, dropoutMask, 3);\n\n      if (0 < this.recurrentDropout && this.recurrentDropout < 1 &&\n          this.recurrentDropoutMask == null) {\n        this.recurrentDropoutMask = generateDropoutMask({\n                                      ones: () => tfc.onesLike(hTMinus1),\n                                      rate: this.recurrentDropout,\n                                      training,\n                                      count: numOfKernels,\n                                      dropoutFunc: this.dropoutFunc\n                                    }) as tfc.Tensor[];\n      }\n\n      const recDropoutMask = this.recurrentDropoutMask as DropoutMasks;\n\n      let hI = applyDropout(hTMinus1, recDropoutMask, 0);\n      let hF = applyDropout(hTMinus1, recDropoutMask, 1);\n      let hC = applyDropout(hTMinus1, recDropoutMask, 2);\n      let hO = applyDropout(hTMinus1, recDropoutMask, 3);\n\n      const kernelChannelAxis = 3;\n\n      const [kernelI, kernelF, kernelC, kernelO]: tfc.Tensor[] =\n          tfc.split(this.kernel.read(), numOfKernels, kernelChannelAxis);\n\n      const [biasI, biasF, biasC, biasO]: tfc.Tensor[] = this.useBias ?\n          tfc.split(this.bias.read(), numOfKernels) :\n          [null, null, null, null];\n\n      xI = this.inputConv(xI, kernelI, biasI, this.padding);\n      xF = this.inputConv(xF, kernelF, biasF, this.padding);\n      xC = this.inputConv(xC, kernelC, biasC, this.padding);\n      xO = this.inputConv(xO, kernelO, biasO, this.padding);\n\n      const [recKernelI, recKernelF, recKernelC, recKernelO]: tfc.Tensor[] =\n          tfc.split(\n              this.recurrentKernel.read(), numOfKernels, kernelChannelAxis);\n\n      hI = this.recurrentConv(hI, recKernelI);\n      hF = this.recurrentConv(hF, recKernelF);\n      hC = this.recurrentConv(hC, recKernelC);\n      hO = this.recurrentConv(hO, recKernelO);\n\n      const i = this.recurrentActivation.apply(tfc.add(xI, hI));\n      const f = this.recurrentActivation.apply(tfc.add(xF, hF));\n      const c = tfc.add(\n          tfc.mul(f, cTMinus1),\n          tfc.mul(i, this.activation.apply(tfc.add(xC, hC))));\n      const h = tfc.mul(\n          this.recurrentActivation.apply(tfc.add(xO, hO)),\n          this.activation.apply(c));\n\n      return [h, h, c];\n    });\n  }\n\n  override getConfig(): tfc.serialization.ConfigDict {\n    const {'units': _, ...baseConfig} = super.getConfig();\n\n    const config: tfc.serialization.ConfigDict = {\n      filters: this.filters,\n      kernelSize: this.kernelSize,\n      padding: this.padding,\n      dataFormat: this.dataFormat,\n      dilationRate: this.dilationRate,\n      strides: this.strides,\n    };\n\n    return {...baseConfig, ...config};\n  }\n\n  inputConv(x: Tensor, w: Tensor, b?: Tensor, padding?: PaddingMode) {\n    const out = tfc.conv2d(\n        x as tfc.Tensor3D, w as tfc.Tensor4D, this.strides as [number, number],\n        (padding || 'valid') as 'same' | 'valid',\n        this.dataFormat === 'channelsFirst' ? 'NCHW' : 'NHWC',\n        this.dilationRate as [number, number]);\n\n    if (b) {\n      return K.biasAdd(out, b, this.dataFormat) as tfc.Tensor3D;\n    }\n\n    return out;\n  }\n\n  recurrentConv(x: Tensor, w: Tensor) {\n    const strides = 1;\n\n    return tfc.conv2d(\n        x as tfc.Tensor3D, w as tfc.Tensor4D, strides, 'same',\n        this.dataFormat === 'channelsFirst' ? 'NCHW' : 'NHWC');\n  }\n}\n\ntfc.serialization.registerClass(ConvLSTM2DCell);\n\nexport declare interface ConvLSTM2DArgs extends\n    Omit<LSTMLayerArgs, 'units'|'cell'>, ConvRNN2DLayerArgs {}\n\nexport class ConvLSTM2D extends ConvRNN2D {\n  /** @nocollapse */\n  static override className = 'ConvLSTM2D';\n\n  constructor(args: ConvLSTM2DArgs) {\n    const cell = new ConvLSTM2DCell(args);\n\n    super({...args, cell} as ConvRNN2DLayerArgs);\n  }\n\n  /** @nocollapse */\n  static override fromConfig<T extends tfc.serialization.Serializable>(\n      cls: tfc.serialization.SerializableConstructor<T>,\n      config: tfc.serialization.ConfigDict): T {\n    return new cls(config);\n  }\n}\n\ntfc.serialization.registerClass(ConvLSTM2D);\n"],"names":[],"mappings":";;;;;;;AAUA,OAAO,KAAK,GAAG,MAAM,uBAAuB,CAAC;;;;;;;;;AAC7C,OAAO,EAAS,IAAI,EAAC,MAAM,uBAAuB,CAAC;AAGnD,OAAO,KAAK,CAAC,MAAM,yBAAyB,CAAC;AAC7C,OAAO,EAAC,eAAe,EAAE,gBAAgB,EAAC,MAAM,WAAW,CAAC;AAE5D,OAAO,EAAC,SAAS,EAAC,MAAM,oBAAoB,CAAC;AAC7C,OAAO,EAAC,cAAc,EAAE,mBAAmB,EAAE,UAAU,EAAC,MAAM,WAAW,CAAC;AAC1E,OAAO,EAAC,WAAW,EAAC,MAAM,iBAAiB,CAAC;AAI5C,OAAO,EAAC,gBAAgB,EAAE,cAAc,EAAC,MAAM,qBAAqB,CAAC;AACrE,OAAO,EAAC,qBAAqB,EAAC,MAAM,wBAAwB,CAAC;AAC7D,OAAO,EAAC,kBAAkB,EAAC,MAAM,sBAAsB,CAAC;AAExD,OAAO,EAAmB,mBAAmB,EAAE,QAAQ,EAAoC,GAAG,EAAE,OAAO,EAAuC,MAAM,aAAa,CAAC;AA3BlK;;;;;;;;GAQG;;;;;;;;;;;;;;;;;;;AAyEH,MAAe,aAAc,SAAQ,mTAAO;CAyB3C;AAKD;;GAEG,CACH,MAAM,SAAU,SAAQ,+SAAG;IAMzB,YAAY,IAAwB,CAAA;QAClC,IAAI,IAAI,CAAC,MAAM,EAAE;YACf,MAAM,IAAI,kTAAmB,CACzB,oDAAoD,CAAC,CAAC;SAC3D;QAED,IAAI,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,CAAC,EAAE;YAC5B,MAAM,IAAI,kTAAmB,CACzB,gEAAgE,CAAC,CAAC;SACvE;QAED,KAAK,CAAC,IAAoB,CAAC,CAAC;QAE5B,IAAI,CAAC,SAAS,GAAG;YAAC,IAAI,oTAAS,CAAC;gBAAC,IAAI,EAAE,CAAC;YAAA,CAAC,CAAC;SAAC,CAAC;IAC9C,CAAC;IAEQ,IAAI,CAAC,MAAuB,EAAE,MAAc,EAAA;QACnD,OAAO,GAAG,CAAC,6OAAI,CAAC,GAAG,EAAE;YACnB,IAAI,IAAI,CAAC,IAAI,CAAC,WAAW,IAAI,IAAI,EAAE;gBACjC,GAAG,CAAC,gPAAO,CAAC,IAAI,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;gBAEnC,IAAI,CAAC,IAAI,CAAC,WAAW,GAAG,IAAI,CAAC;aAC9B;YAED,IAAI,IAAI,CAAC,IAAI,CAAC,oBAAoB,IAAI,IAAI,EAAE;gBAC1C,GAAG,CAAC,gPAAO,CAAC,IAAI,CAAC,IAAI,CAAC,oBAAoB,CAAC,CAAC;gBAE5C,IAAI,CAAC,IAAI,CAAC,oBAAoB,GAAG,IAAI,CAAC;aACvC;YAED,IAAI,MAAM,IAAI,MAAM,CAAC,WAAW,CAAC,EAAE;gBACjC,MAAM,IAAI,ySAAU,CAAC,2CAA2C,CAAC,CAAC;aACnE;YAED,MAAM,IAAI,GAAG,MAAM,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;YAEpD,MAAM,QAAQ,GAAG,MAAM,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,MAAM,CAAC,UAAU,CAAC,CAAC;YAE5D,MAAM,YAAY,GACd,MAAM,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,MAAM,CAAC,cAAc,CAAC,CAAC;YAEnD,OAAO,KAAK,CAAC,IAAI,CAAC,MAAM,EAAE;gBAAC,IAAI;gBAAE,QAAQ;gBAAE,YAAY;YAAA,CAAC,CAAC,CAAC;QAC5D,CAAC,CAAC,CAAC;IACL,CAAC;IAEQ,kBAAkB,CAAC,UAAiB,EAAA;QAC3C,IAAI,QAAQ,GAAU,IAAI,CAAC,wBAAwB,CAAC,UAAU,CAAC,CAAC;QAEhE,IAAI,CAAC,IAAI,CAAC,eAAe,EAAE;YACzB,QAAQ,GAAG;gBAAC,QAAQ,CAAC,CAAC,CAAC,EAAE;mBAAG,QAAQ,CAAC,KAAK,CAAC,CAAC,CAAC;aAAC,CAAC;SAChD;QAED,IAAI,IAAI,CAAC,WAAW,EAAE;YACpB,QAAQ,GACJ;gBAAC,QAAQ,EAAE;mBAAG,KAAK,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC;oBAAC,UAAU,CAAC,CAAC,CAAC,EAAE;uBAAG,QAAQ,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;iBAAC,CAAC;aAAC,CAAC;SAC1E;QAED,OAAO,QAAQ,CAAC;IAClB,CAAC;IAEQ,eAAe,CAAC,MAAkB,EAAA;QACzC,OAAO,GAAG,CAAC,6OAAI,CAAC,GAAG,EAAE;YACnB,MAAM,EAAC,SAAS,EAAC,GAAG,IAAI,CAAC,IAAI,CAAC;YAE9B,MAAM,UAAU,GAAG,MAAM,CAAC,KAAK,CAAC;YAEhC,MAAM,WAAW,GAAG,IAAI,CAAC,wBAAwB,CAAC,UAAU,CAAC,CAAC;YAE9D,MAAM,UAAU,GAAG;gBAAC,WAAW,CAAC,CAAC,CAAC,EAAE;mBAAG,WAAW,CAAC,KAAK,CAAC,CAAC,CAAC;aAAC,CAAC;YAE7D,MAAM,YAAY,GAAG,GAAG,CAAC,mPAAK,CAAC,UAAU,CAAC,CAAC;YAE3C,IAAI,KAAK,CAAC,OAAO,CAAC,SAAS,CAAC,EAAE;gBAC5B,OAAO,KAAK,CAAC,SAAS,CAAC,MAAM,CAAC,CAAC,IAAI,CAAC,YAAY,CAAC,CAAC;aACnD;YAED,OAAO;gBAAC,YAAY;aAAC,CAAC;QACxB,CAAC,CAAC,CAAC;IACL,CAAC;IAEQ,WAAW,CAAC,MAAwB,EAAE,QAAQ,GAAG,KAAK,EAAA;QAC7D,GAAG,CAAC,6OAAI,CAAC,GAAG,EAAE;YACZ,IAAI,CAAC,IAAI,CAAC,QAAQ,EAAE;gBAClB,MAAM,IAAI,6SAAc,CACpB,iEAAiE,CAAC,CAAC;aACxE;YAED,MAAM,UAAU,GAAG,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC,KAAK,CAAC;YAE3C,MAAM,WAAW,GAAG,IAAI,CAAC,wBAAwB,CAAC,UAAU,CAAC,CAAC;YAE9D,MAAM,UAAU,GAAG;gBAAC,WAAW,CAAC,CAAC,CAAC,EAAE;mBAAG,WAAW,CAAC,KAAK,CAAC,CAAC,CAAC;aAAC,CAAC;YAE7D,MAAM,SAAS,GAAG,UAAU,CAAC,CAAC,CAAC,CAAC;YAEhC,IAAI,SAAS,IAAI,IAAI,EAAE;gBACrB,MAAM,IAAI,ySAAU,CAChB,kEAAkE,GAClE,0CAA0C,GAC1C,2DAA2D,GAC3D,2DAA2D,GAC3D,2DAA2D,GAC3D,oDAAoD,CAAC,CAAC;aAC3D;YAED,4BAA4B;YAC5B,IAAI,IAAI,CAAC,SAAS,EAAE,IAAI,IAAI,EAAE;gBAC5B,IAAI,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,EAAE;oBACtC,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,GAAG,CAAG,CAAD,EAAI,CAAC,mPAAK,CAAC,UAAU,CAAC,CAAC,CAAC;iBACrE,MAAM;oBACL,IAAI,CAAC,OAAO,GAAG;wBAAC,GAAG,CAAC,mPAAK,CAAC,UAAU,CAAC;qBAAC,CAAC;iBACxC;aACF,MAAM,IAAI,MAAM,IAAI,IAAI,EAAE;gBACzB,6BAA6B;gBAC7B,GAAG,CAAC,gPAAO,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC;gBAE1B,oDAAoD;gBACpD,IAAI,IAAI,CAAC,UAAU,IAAI,IAAI,EAAE;oBAC3B,GAAG,CAAC,gPAAO,CAAC,IAAI,CAAC,UAAU,CAAC,CAAC;oBAC7B,IAAI,CAAC,UAAU,GAAG,EAAE,CAAC;iBACtB;gBAED,IAAI,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,EAAE;oBACtC,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,GAAG,CAAG,CAAD,EAAI,CAAC,mPAAK,CAAC,UAAU,CAAC,CAAC,CAAC;iBACrE,MAAM;oBACL,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,GAAG,GAAG,CAAC,mPAAK,CAAC,UAAU,CAAC,CAAC;iBACzC;aACF,MAAM;gBACL,IAAI,CAAC,KAAK,CAAC,OAAO,CAAC,MAAM,CAAC,EAAE;oBAC1B,MAAM,GAAG;wBAAC,MAAM;qBAAC,CAAC;iBACnB;gBAED,IAAI,MAAM,CAAC,MAAM,KAAK,IAAI,CAAC,OAAO,CAAC,MAAM,EAAE;oBACzC,MAAM,IAAI,ySAAU,CAChB,CAAA,MAAA,EAAS,IAAI,CAAC,IAAI,CAAA,SAAA,EAAY,IAAI,CAAC,OAAO,CAAC,MAAM,CAAA,WAAA,CAAa,GAC9D,CAAA,gBAAA,EAAmB,MAAM,CAAC,MAAM,CAAA,uBAAA,CAAyB,GACzD,CAAA,UAAA,EAAa,MAAM,EAAE,CAAC,CAAC;iBAC5B;gBAED,IAAI,QAAQ,EAAE;oBACZ,oEAAoE;oBACpE,iEAAiE;oBACjE,oEAAoE;oBACpE,QAAQ;oBACR,IAAI,CAAC,UAAU,CAAC,IAAI,CAAC,IAAI,CAAC,OAAO,CAAC,KAAK,EAAE,CAAC,CAAC;iBAC5C,MAAM;oBACL,GAAG,CAAC,gPAAO,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC;iBAC3B;gBAED,IAAK,IAAI,KAAK,GAAG,CAAC,EAAE,KAAK,GAAG,IAAI,CAAC,OAAO,CAAC,MAAM,EAAE,EAAE,KAAK,CAAE;oBACxD,MAAM,KAAK,GAAG,MAAM,CAAC,KAAK,CAAC,CAAC;oBAE5B,MAAM,aAAa,GAAG,UAAU,CAAC;oBAEjC,IAAI,CAAC,8QAAI,CAAC,WAAW,CAAC,KAAK,CAAC,KAAK,EAAE,aAAa,CAAC,EAAE;wBACjD,MAAM,IAAI,ySAAU,CAChB,CAAA,MAAA,EAAS,KAAK,CAAA,4BAAA,EAA+B,IAAI,CAAC,IAAI,CAAA,EAAA,CAAI,GAC1D,CAAA,eAAA,EAAkB,aAAa,CAAA,iBAAA,EAC3B,KAAK,CAAC,KAAK,EAAE,CAAC,CAAC;qBACxB;oBAED,IAAI,CAAC,OAAO,CAAC,KAAK,CAAC,GAAG,KAAK,CAAC;iBAC7B;aACF;YAED,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC,OAAO,CAAC,GAAG,CAAC,KAAK,CAAC,EAAE,CAAC,GAAG,CAAC,6OAAI,CAAC,KAAK,CAAC,KAAK,EAAE,CAAC,CAAC,CAAC;QACpE,CAAC,CAAC,CAAC;IACL,CAAC;IAES,wBAAwB,CAAC,UAAiB,EAAA;QAClD,MAAM,EAAC,UAAU,EAAE,OAAO,EAAE,UAAU,EAAE,OAAO,EAAE,OAAO,EAAE,YAAY,EAAC,GACnE,IAAI,CAAC,IAAI,CAAC;QAEd,MAAM,eAAe,GAAG,UAAU,KAAK,eAAe,CAAC;QAEvD,MAAM,CAAC,GAAG,UAAU,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAC9C,MAAM,CAAC,GAAG,UAAU,CAAC,eAAe,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;QAE9C,MAAM,IAAI,OAAG,4TAAgB,EACzB,CAAC,EAAE,UAAU,CAAC,CAAC,CAAC,EAAE,OAAO,EAAE,OAAO,CAAC,CAAC,CAAC,EAAE,YAAY,CAAC,CAAC,CAAC,CAAC,CAAC;QAC5D,MAAM,IAAI,OAAG,4TAAgB,EACzB,CAAC,EAAE,UAAU,CAAC,CAAC,CAAC,EAAE,OAAO,EAAE,OAAO,CAAC,CAAC,CAAC,EAAE,YAAY,CAAC,CAAC,CAAC,CAAC,CAAC;QAE5D,MAAM,QAAQ,GAAU;eACnB,UAAU,CAAC,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC;eACrB,eAAe,CAAC,CAAC,CAAC;gBAAC,OAAO;gBAAE,IAAI;gBAAE,IAAI;aAAC,CAAC,CAAC,CAAC;gBAAC,IAAI;gBAAE,IAAI;gBAAE,OAAO;aAAC,CAAC;SACrE,CAAC;QAEF,OAAO,QAAQ,CAAC;IAClB,CAAC;;AAlMD,gBAAA,EAAkB,CACF,UAAA,SAAS,GAAG,WAAW,CAAC;AAuM1C,MAAa,cAAe,SAAQ,oTAAQ;IAW1C,YAAY,IAAwB,CAAA;QAClC,MAAM,EACJ,OAAO,EACP,UAAU,EACV,OAAO,EACP,OAAO,EACP,UAAU,EACV,YAAY,EACb,GAAG,IAAI,CAAC;QAET,KAAK,CAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GAAK,IAAI,GAAA;YAAE,KAAK,EAAE,OAAO;QAAA,GAAE,CAAC;QAEjC,IAAI,CAAC,OAAO,GAAG,OAAO,CAAC;YACvB,oUAAqB,EAAC,IAAI,CAAC,OAAO,EAAE,SAAS,CAAC,CAAC;QAE/C,IAAI,CAAC,UAAU,OAAG,0TAAc,EAAC,UAAU,EAAE,CAAC,EAAE,YAAY,CAAC,CAAC;QAC9D,IAAI,CAAC,UAAU,CAAC,OAAO,EAAC,IAAI,CAAC,EAAE,AAAC,wUAAqB,EAAC,IAAI,EAAE,YAAY,CAAC,CAAC,CAAC;QAE3E,IAAI,CAAC,OAAO,OAAG,0TAAc,EAAC,OAAO,IAAI,CAAC,EAAE,CAAC,EAAE,SAAS,CAAC,CAAC;QAC1D,IAAI,CAAC,OAAO,CAAC,OAAO,EAAC,MAAM,CAAC,EAAE,IAAC,oUAAqB,EAAC,MAAM,EAAE,SAAS,CAAC,CAAC,CAAC;QAEzE,IAAI,CAAC,OAAO,GAAG,OAAO,IAAI,OAAO,CAAC;YAClC,+SAAgB,EAAC,IAAI,CAAC,OAAO,CAAC,CAAC;QAE/B,IAAI,CAAC,UAAU,GAAG,UAAU,IAAI,cAAc,CAAC;YAC/C,8SAAe,EAAC,IAAI,CAAC,UAAU,CAAC,CAAC;QAEjC,IAAI,CAAC,YAAY,OAAG,0TAAc,EAAC,YAAY,IAAI,CAAC,EAAE,CAAC,EAAE,cAAc,CAAC,CAAC;QACzE,IAAI,CAAC,YAAY,CAAC,OAAO,EACrB,IAAI,CAAC,EAAE,IAAC,oUAAqB,EAAC,IAAI,EAAE,cAAc,CAAC,CAAC,CAAC;IAC3D,CAAC;IAEe,KAAK,CAAC,UAAyB,EAAA;;QAC7C,UAAU,OAAG,+TAAkB,EAAC,UAAU,CAAC,CAAC;QAE5C,MAAM,WAAW,GACb,IAAI,CAAC,UAAU,KAAK,eAAe,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,UAAU,CAAC,MAAM,GAAG,CAAC,CAAC;QAEpE,IAAI,UAAU,CAAC,WAAW,CAAC,IAAI,IAAI,EAAE;YACnC,MAAM,IAAI,ySAAU,CAChB,CAAA,sDAAA,CAAwD,GACxD,CAAA,MAAA,EAAS,UAAU,CAAC,WAAW,CAAC,EAAE,CAAC,CAAC;SACzC;QAED,MAAM,QAAQ,GAAG,UAAU,CAAC,WAAW,CAAC,CAAC;QAEzC,MAAM,YAAY,GAAG,CAAC,CAAC;QAEvB,MAAM,WAAW,GACb,IAAI,CAAC,UAAU,CAAC,MAAM,CAAC;YAAC,QAAQ;YAAE,IAAI,CAAC,OAAO,GAAG,YAAY;SAAC,CAAC,CAAC;QAEpE,IAAI,CAAC,MAAM,GAAG,IAAI,CAAC,SAAS,CACxB,QAAQ,EAAE,WAAW,EAAE,IAAI,EAAE,IAAI,CAAC,iBAAiB,EACnD,IAAI,CAAC,iBAAiB,EAAE,IAAI,EAAE,IAAI,CAAC,gBAAgB,CAAC,CAAC;QAEzD,MAAM,oBAAoB,GACtB,IAAI,CAAC,UAAU,CAAC,MAAM,CAAC;YAAC,IAAI,CAAC,OAAO;YAAE,IAAI,CAAC,OAAO,GAAG,YAAY;SAAC,CAAC,CAAC;QAExE,IAAI,CAAC,eAAe,GAAG,IAAI,CAAC,SAAS,CACjC,kBAAkB,EAAE,oBAAoB,EAAE,IAAI,EAC9C,IAAI,CAAC,oBAAoB,EAAE,IAAI,CAAC,oBAAoB,EAAE,IAAI,EAC1D,IAAI,CAAC,mBAAmB,CAAC,CAAC;QAE9B,IAAI,IAAI,CAAC,OAAO,EAAE;YAChB,IAAI,eAA4B,CAAC;YAEjC,IAAI,IAAI,CAAC,cAAc,EAAE;gBACvB,MAAM,IAAI,GAAG,IAAI,CAAC,eAAe,CAAC;gBAElC,MAAM,OAAO,GAAG,IAAI,CAAC,OAAO,CAAC;gBAE7B,eAAe,GAAG,IAAI,CAAA,KAAC,MAAM,UAAW,SAAQ,gTAAW;oBAIzD,KAAK,CAAC,KAAY,EAAE,KAAgB,EAAA;wBAClC,MAAM,KAAK,GAAG,IAAI,CAAC,KAAK,CAAC;4BAAC,OAAO;yBAAC,CAAC,CAAC;wBACpC,MAAM,KAAK,GAAG,GAAG,CAAC,iPAAI,CAAC;4BAAC,OAAO;yBAAC,CAAC,CAAC;wBAClC,MAAM,SAAS,GAAG,IAAI,CAAC,KAAK,CAAC;4BAAC,OAAO,GAAG,CAAC;yBAAC,CAAC,CAAC;wBAC5C,OAAO,CAAC,CAAC,yTAAW,CAAC;4BAAC,KAAK;4BAAE,KAAK;4BAAE,SAAS;yBAAC,CAAC,CAAC;oBAClD,CAAC;iBACF,EATC,gBAAA,EAAkB,CACX,GAAA,SAAS,GAAG,YAAa,KAQhC,EAAE,CAAC;aACN,MAAM;gBACL,eAAe,GAAG,IAAI,CAAC,eAAe,CAAC;aACxC;YAED,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC,SAAS,CACtB,MAAM,EAAE;gBAAC,IAAI,CAAC,OAAO,GAAG,YAAY;aAAC,EAAE,IAAI,EAAE,eAAe,EAC5D,IAAI,CAAC,eAAe,EAAE,IAAI,EAAE,IAAI,CAAC,cAAc,CAAC,CAAC;SACtD;QAED,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC;IACpB,CAAC;IAEQ,IAAI,CAAC,MAAoB,EAAE,MAAc,EAAA;QAChD,OAAO,GAAG,CAAC,6OAAI,CAAC,GAAG,EAAE;YACnB,IAAI,MAAM,CAAC,MAAM,KAAK,CAAC,EAAE;gBACvB,MAAM,IAAI,ySAAU,CAChB,CAAA,2DAAA,CAA6D,GAC7D,GAAG,MAAM,CAAC,MAAM,CAAA,CAAA,CAAG,CAAC,CAAC;aAC1B;YAED,MAAM,QAAQ,GAAG,MAAM,CAAC,UAAU,CAAC,IAAI,KAAK,CAAC;YAE7C,MAAM,CAAC,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC,CAAS,gBAAgB;YAC7C,MAAM,QAAQ,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC,CAAE,yBAAyB;YACtD,MAAM,QAAQ,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC,CAAE,wBAAwB;YAErD,MAAM,YAAY,GAAG,CAAC,CAAC;YAIvB,IAAI,CAAC,GAAG,IAAI,CAAC,OAAO,IAAI,IAAI,CAAC,OAAO,GAAG,CAAC,IAAI,IAAI,CAAC,WAAW,IAAI,IAAI,EAAE;gBACpE,IAAI,CAAC,WAAW,OAAG,+TAAmB,EAAC;oBAClB,IAAI,EAAE,GAAG,CAAG,CAAD,EAAI,CAAC,0PAAQ,CAAC,CAAC,CAAC;oBAC3B,IAAI,EAAE,IAAI,CAAC,OAAO;oBAClB,QAAQ;oBACR,KAAK,EAAE,YAAY;oBACnB,WAAW,EAAE,IAAI,CAAC,WAAW;iBAC9B,CAAiB,CAAC;aACvC;YAED,MAAM,WAAW,GAAG,IAAI,CAAC,WAA2B,CAAC;YAErD,MAAM,YAAY,GACd,CAAC,CAAa,EAAE,IAAkB,EAAE,KAAa,EAAE,EAAE;gBACnD,IAAI,CAAC,IAAI,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC,EAAE;oBACzB,OAAO,CAAC,CAAC;iBACV;gBAED,OAAO,GAAG,CAAC,+OAAG,CAAC,IAAI,CAAC,KAAK,CAAC,EAAE,CAAC,CAAC,CAAC;YACjC,CAAC,CAAC;YAEN,IAAI,EAAE,GAAG,YAAY,CAAC,CAAC,EAAE,WAAW,EAAE,CAAC,CAAC,CAAC;YACzC,IAAI,EAAE,GAAG,YAAY,CAAC,CAAC,EAAE,WAAW,EAAE,CAAC,CAAC,CAAC;YACzC,IAAI,EAAE,GAAG,YAAY,CAAC,CAAC,EAAE,WAAW,EAAE,CAAC,CAAC,CAAC;YACzC,IAAI,EAAE,GAAG,YAAY,CAAC,CAAC,EAAE,WAAW,EAAE,CAAC,CAAC,CAAC;YAEzC,IAAI,CAAC,GAAG,IAAI,CAAC,gBAAgB,IAAI,IAAI,CAAC,gBAAgB,GAAG,CAAC,IACtD,IAAI,CAAC,oBAAoB,IAAI,IAAI,EAAE;gBACrC,IAAI,CAAC,oBAAoB,OAAG,+TAAmB,EAAC;oBAClB,IAAI,EAAE,GAAG,CAAG,CAAD,EAAI,CAAC,0PAAQ,CAAC,QAAQ,CAAC;oBAClC,IAAI,EAAE,IAAI,CAAC,gBAAgB;oBAC3B,QAAQ;oBACR,KAAK,EAAE,YAAY;oBACnB,WAAW,EAAE,IAAI,CAAC,WAAW;iBAC9B,CAAiB,CAAC;aAChD;YAED,MAAM,cAAc,GAAG,IAAI,CAAC,oBAAoC,CAAC;YAEjE,IAAI,EAAE,GAAG,YAAY,CAAC,QAAQ,EAAE,cAAc,EAAE,CAAC,CAAC,CAAC;YACnD,IAAI,EAAE,GAAG,YAAY,CAAC,QAAQ,EAAE,cAAc,EAAE,CAAC,CAAC,CAAC;YACnD,IAAI,EAAE,GAAG,YAAY,CAAC,QAAQ,EAAE,cAAc,EAAE,CAAC,CAAC,CAAC;YACnD,IAAI,EAAE,GAAG,YAAY,CAAC,QAAQ,EAAE,cAAc,EAAE,CAAC,CAAC,CAAC;YAEnD,MAAM,iBAAiB,GAAG,CAAC,CAAC;YAE5B,MAAM,CAAC,OAAO,EAAE,OAAO,EAAE,OAAO,EAAE,OAAO,CAAC,GACtC,GAAG,CAAC,mPAAK,CAAC,IAAI,CAAC,MAAM,CAAC,IAAI,EAAE,EAAE,YAAY,EAAE,iBAAiB,CAAC,CAAC;YAEnE,MAAM,CAAC,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,CAAC,GAAiB,IAAI,CAAC,OAAO,CAAC,CAAC,CAC7D,GAAG,CAAC,mPAAK,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,EAAE,EAAE,YAAY,CAAC,CAAC,CAAC,CAC3C;gBAAC,IAAI;gBAAE,IAAI;gBAAE,IAAI;gBAAE,IAAI;aAAC,CAAC;YAE7B,EAAE,GAAG,IAAI,CAAC,SAAS,CAAC,EAAE,EAAE,OAAO,EAAE,KAAK,EAAE,IAAI,CAAC,OAAO,CAAC,CAAC;YACtD,EAAE,GAAG,IAAI,CAAC,SAAS,CAAC,EAAE,EAAE,OAAO,EAAE,KAAK,EAAE,IAAI,CAAC,OAAO,CAAC,CAAC;YACtD,EAAE,GAAG,IAAI,CAAC,SAAS,CAAC,EAAE,EAAE,OAAO,EAAE,KAAK,EAAE,IAAI,CAAC,OAAO,CAAC,CAAC;YACtD,EAAE,GAAG,IAAI,CAAC,SAAS,CAAC,EAAE,EAAE,OAAO,EAAE,KAAK,EAAE,IAAI,CAAC,OAAO,CAAC,CAAC;YAEtD,MAAM,CAAC,UAAU,EAAE,UAAU,EAAE,UAAU,EAAE,UAAU,CAAC,GAClD,GAAG,CAAC,mPAAK,CACL,IAAI,CAAC,eAAe,CAAC,IAAI,EAAE,EAAE,YAAY,EAAE,iBAAiB,CAAC,CAAC;YAEtE,EAAE,GAAG,IAAI,CAAC,aAAa,CAAC,EAAE,EAAE,UAAU,CAAC,CAAC;YACxC,EAAE,GAAG,IAAI,CAAC,aAAa,CAAC,EAAE,EAAE,UAAU,CAAC,CAAC;YACxC,EAAE,GAAG,IAAI,CAAC,aAAa,CAAC,EAAE,EAAE,UAAU,CAAC,CAAC;YACxC,EAAE,GAAG,IAAI,CAAC,aAAa,CAAC,EAAE,EAAE,UAAU,CAAC,CAAC;YAExC,MAAM,CAAC,GAAG,IAAI,CAAC,mBAAmB,CAAC,KAAK,CAAC,GAAG,CAAC,+OAAG,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC;YAC1D,MAAM,CAAC,GAAG,IAAI,CAAC,mBAAmB,CAAC,KAAK,CAAC,GAAG,CAAC,+OAAG,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC;YAC1D,MAAM,CAAC,GAAG,GAAG,CAAC,+OAAG,CACb,GAAG,CAAC,+OAAG,CAAC,CAAC,EAAE,QAAQ,CAAC,EACpB,GAAG,CAAC,+OAAG,CAAC,CAAC,EAAE,IAAI,CAAC,UAAU,CAAC,KAAK,CAAC,GAAG,CAAC,+OAAG,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC,CAAC,CAAC,CAAC;YACxD,MAAM,CAAC,GAAG,GAAG,CAAC,+OAAG,CACb,IAAI,CAAC,mBAAmB,CAAC,KAAK,CAAC,GAAG,CAAC,+OAAG,CAAC,EAAE,EAAE,EAAE,CAAC,CAAC,EAC/C,IAAI,CAAC,UAAU,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;YAE9B,OAAO;gBAAC,CAAC;gBAAE,CAAC;gBAAE,CAAC;aAAC,CAAC;QACnB,CAAC,CAAC,CAAC;IACL,CAAC;IAEQ,SAAS,GAAA;QAChB,MAAM,KAA8B,KAAK,CAAC,SAAS,EAAE,EAA/C,EAAC,OAAO,EAAE,CAAC,EAAA,GAAA,EAAoC,EAA/B,UAAU,GAAA,OAAA,IAA1B;YAAA;SAA2B,CAAoB,CAAC;QAEtD,MAAM,MAAM,GAAiC;YAC3C,OAAO,EAAE,IAAI,CAAC,OAAO;YACrB,UAAU,EAAE,IAAI,CAAC,UAAU;YAC3B,OAAO,EAAE,IAAI,CAAC,OAAO;YACrB,UAAU,EAAE,IAAI,CAAC,UAAU;YAC3B,YAAY,EAAE,IAAI,CAAC,YAAY;YAC/B,OAAO,EAAE,IAAI,CAAC,OAAO;SACtB,CAAC;QAEF,OAAA,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GAAW,UAAU,GAAK,MAAM,EAAE;IACpC,CAAC;IAED,SAAS,CAAC,CAAS,EAAE,CAAS,EAAE,CAAU,EAAE,OAAqB,EAAA;QAC/D,MAAM,GAAG,GAAG,GAAG,CAAC,qPAAM,CAClB,CAAiB,EAAE,CAAiB,EAAE,IAAI,CAAC,OAA2B,EACtE,AAAC,OAAO,IAAI,OAAO,CAAqB,CACxC,IAAI,CAAC,UAAU,KAAK,eAAe,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC,MAAM,EACrD,IAAI,CAAC,YAAgC,CAAC,CAAC;QAE3C,IAAI,CAAC,EAAE;YACL,OAAO,CAAC,CAAC,qTAAO,CAAC,GAAG,EAAE,CAAC,EAAE,IAAI,CAAC,UAAU,CAAiB,CAAC;SAC3D;QAED,OAAO,GAAG,CAAC;IACb,CAAC;IAED,aAAa,CAAC,CAAS,EAAE,CAAS,EAAA;QAChC,MAAM,OAAO,GAAG,CAAC,CAAC;QAElB,OAAO,GAAG,CAAC,qPAAM,CACb,CAAiB,EAAE,CAAiB,EAAE,OAAO,EAAE,MAAM,EACrD,IAAI,CAAC,UAAU,KAAK,eAAe,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC,CAAC,MAAM,CAAC,CAAC;IAC7D,CAAC;;AA7OD,gBAAA,EAAkB,CACF,eAAA,SAAS,GAAG,gBAAgB,CAAC;;AA+O/C,GAAG,CAAC,qSAAa,CAAC,aAAa,CAAC,cAAc,CAAC,CAAC;AAKhD,MAAa,UAAW,SAAQ,SAAS;IAIvC,YAAY,IAAoB,CAAA;QAC9B,MAAM,IAAI,GAAG,IAAI,cAAc,CAAC,IAAI,CAAC,CAAC;QAEtC,KAAK,CAAC,OAAA,MAAA,CAAA,OAAA,MAAA,CAAA,CAAA,GAAI,IAAI,GAAA;YAAE,IAAI;QAAA,EAAuB,CAAC,CAAC;IAC/C,CAAC;IAED,gBAAA,EAAkB,CAClB,MAAM,CAAU,UAAU,CACtB,GAAiD,EACjD,MAAoC,EAAA;QACtC,OAAO,IAAI,GAAG,CAAC,MAAM,CAAC,CAAC;IACzB,CAAC;;AAdD,gBAAA,EAAkB,CACF,WAAA,SAAS,GAAG,YAAY,CAAC;;AAgB3C,GAAG,CAAC,qSAAa,CAAC,aAAa,CAAC,UAAU,CAAC,CAAC"}},
    {"offset": {"line": 892, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-layers@4.22.0_@tensorflow+tfjs-core@4.22.0/node_modules/@tensorflow/tfjs-layers/dist/layers/core.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-layers/src/layers/core.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * TensorFlow.js Layers: Basic Layers.\n */\n\nimport {any, cast, mul, notEqual, reshape, serialization, Tensor, tidy, transpose, util} from '@tensorflow/tfjs-core';\n\nimport {Activation as ActivationFn, getActivation, serializeActivation} from '../activations';\nimport * as K from '../backend/tfjs_backend';\nimport {Constraint, ConstraintIdentifier, getConstraint, serializeConstraint} from '../constraints';\nimport {DisposeResult, InputSpec, Layer, LayerArgs} from '../engine/topology';\nimport {ValueError} from '../errors';\nimport {getInitializer, Initializer, InitializerIdentifier, serializeInitializer} from '../initializers';\nimport {ActivationIdentifier} from '../keras_format/activation_config';\nimport {DataFormat, Shape} from '../keras_format/common';\nimport {LayerConfig} from '../keras_format/topology_config';\nimport {getRegularizer, Regularizer, RegularizerIdentifier, serializeRegularizer} from '../regularizers';\nimport {Kwargs} from '../types';\nimport {assertPositiveInteger, mapActivationToFusedKernel} from '../utils/generic_utils';\nimport {arrayProd, range} from '../utils/math_utils';\nimport {getExactlyOneShape, getExactlyOneTensor} from '../utils/types_utils';\nimport {LayerVariable} from '../variables';\n\nexport declare interface DropoutLayerArgs extends LayerArgs {\n  /** Float between 0 and 1. Fraction of the input units to drop. */\n  rate: number;\n\n  /**\n   * Integer array representing the shape of the binary dropout mask that will\n   * be multiplied with the input.\n   *\n   * For instance, if your inputs have shape `(batchSize, timesteps, features)`\n   * and you want the dropout mask to be the same for all timesteps, you can use\n   * `noise_shape=(batch_size, 1, features)`.\n   */\n  noiseShape?: number[];\n\n  /** An integer to use as random seed. */\n  seed?: number;\n}\n\nexport class Dropout extends Layer {\n  /** @nocollapse */\n  static className = 'Dropout';\n  private readonly rate: number;\n  private readonly noiseShape: number[];\n  private readonly seed: number;\n\n  constructor(args: DropoutLayerArgs) {\n    super(args);\n    this.rate = Math.max(Math.min(args.rate, 1), 0);\n    // So that the scalar doesn't get tidied up between executions.\n    this.noiseShape = args.noiseShape;\n    this.seed = args.seed;\n    this.supportsMasking = true;\n  }\n\n  protected getNoiseShape(input: Tensor): Shape {\n    if (this.noiseShape == null) {\n      return this.noiseShape;\n    }\n    const inputShape = input.shape;\n    const noiseShape: Shape = [];\n    for (let i = 0; i < this.noiseShape.length; ++i) {\n      noiseShape.push(\n          this.noiseShape[i] == null ? inputShape[i] : this.noiseShape[i]);\n    }\n    return noiseShape;\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      const input = getExactlyOneTensor(inputs);\n      if (0 < this.rate && this.rate < 1) {\n        const training =\n            kwargs['training'] == null ? false : kwargs['training'];\n        const noiseShape = this.getNoiseShape(input);\n        const output = K.inTrainPhase(\n            () => K.dropout(input, this.rate, noiseShape, this.seed),\n            () => input, training);\n        return output;\n      }\n      return inputs;\n    });\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config = {\n      rate: this.rate,\n      noiseShape: this.noiseShape,\n      seed: this.seed,\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n  override dispose(): DisposeResult {\n    return super.dispose();\n  }\n}\nserialization.registerClass(Dropout);\n\nexport declare interface DenseLayerArgs extends LayerArgs {\n  /** Positive integer, dimensionality of the output space. */\n  units: number;\n  /**\n   * Activation function to use.\n   *\n   * If unspecified, no activation is applied.\n   */\n  activation?: ActivationIdentifier;\n  /** Whether to apply a bias. */\n  useBias?: boolean;\n  /**\n   * Initializer for the dense kernel weights matrix.\n   */\n  kernelInitializer?: InitializerIdentifier|Initializer;\n  /**\n   * Initializer for the bias vector.\n   */\n  biasInitializer?: InitializerIdentifier|Initializer;\n  /**\n   * If specified, defines inputShape as `[inputDim]`.\n   */\n  inputDim?: number;\n\n  /**\n   * Constraint for the kernel weights.\n   */\n  kernelConstraint?: ConstraintIdentifier|Constraint;\n\n  /**\n   * Constraint for the bias vector.\n   */\n  biasConstraint?: ConstraintIdentifier|Constraint;\n\n  /**\n   * Regularizer function applied to the dense kernel weights matrix.\n   */\n  kernelRegularizer?: RegularizerIdentifier|Regularizer;\n\n  /**\n   * Regularizer function applied to the bias vector.\n   */\n  biasRegularizer?: RegularizerIdentifier|Regularizer;\n\n  /**\n   * Regularizer function applied to the activation.\n   */\n  activityRegularizer?: RegularizerIdentifier|Regularizer;\n}\n\nexport interface SpatialDropout1DLayerConfig extends LayerConfig {\n  /** Float between 0 and 1. Fraction of the input units to drop. */\n  rate: number;\n\n  /** An integer to use as random seed. */\n  seed?: number;\n}\n\nexport class SpatialDropout1D extends Dropout {\n  /** @nocollapse */\n  static override className = 'SpatialDropout1D';\n\n  constructor(args: SpatialDropout1DLayerConfig) {\n    super(args);\n    this.inputSpec = [{ndim: 3}];\n  }\n\n  protected override getNoiseShape(input: Tensor): Shape {\n    const inputShape = input.shape;\n    return [inputShape[0], 1, inputShape[2]];\n  }\n}\nserialization.registerClass(SpatialDropout1D);\n\nexport class Dense extends Layer {\n  /** @nocollapse */\n  static className = 'Dense';\n  private units: number;\n  // Default activation: Linear (none).\n  private activation: ActivationFn = null;\n  private useBias = true;\n  private kernelInitializer: Initializer;\n  private biasInitializer: Initializer;\n  private kernel: LayerVariable = null;\n  private bias: LayerVariable = null;\n\n  readonly DEFAULT_KERNEL_INITIALIZER: InitializerIdentifier = 'glorotNormal';\n  readonly DEFAULT_BIAS_INITIALIZER: InitializerIdentifier = 'zeros';\n  private readonly kernelConstraint?: Constraint;\n  private readonly biasConstraint?: Constraint;\n  private readonly kernelRegularizer?: Regularizer;\n  private readonly biasRegularizer?: Regularizer;\n\n  constructor(args: DenseLayerArgs) {\n    super(args);\n    if (args.batchInputShape == null && args.inputShape == null &&\n        args.inputDim != null) {\n      // This logic is copied from Layer's constructor, since we can't\n      // do exactly what the Python constructor does for Dense().\n      let batchSize: number = null;\n      if (args.batchSize != null) {\n        batchSize = args.batchSize;\n      }\n      this.batchInputShape = [batchSize, args.inputDim];\n    }\n\n    this.units = args.units;\n    assertPositiveInteger(this.units, 'units');\n    this.activation = getActivation(args.activation);\n    if (args.useBias != null) {\n      this.useBias = args.useBias;\n    }\n    this.kernelInitializer = getInitializer(\n        args.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER);\n    this.biasInitializer =\n        getInitializer(args.biasInitializer || this.DEFAULT_BIAS_INITIALIZER);\n    this.kernelConstraint = getConstraint(args.kernelConstraint);\n    this.biasConstraint = getConstraint(args.biasConstraint);\n    this.kernelRegularizer = getRegularizer(args.kernelRegularizer);\n    this.biasRegularizer = getRegularizer(args.biasRegularizer);\n    this.activityRegularizer = getRegularizer(args.activityRegularizer);\n    this.supportsMasking = true;\n\n    this.inputSpec = [{minNDim: 2}];\n  }\n\n  public override build(inputShape: Shape|Shape[]): void {\n    inputShape = getExactlyOneShape(inputShape);\n    const inputLastDim = inputShape[inputShape.length - 1];\n    if (this.kernel == null) {\n      this.kernel = this.addWeight(\n          'kernel', [inputLastDim, this.units], null, this.kernelInitializer,\n          this.kernelRegularizer, true, this.kernelConstraint);\n      if (this.useBias) {\n        this.bias = this.addWeight(\n            'bias', [this.units], null, this.biasInitializer,\n            this.biasRegularizer, true, this.biasConstraint);\n      }\n    }\n\n    this.inputSpec = [{minNDim: 2, axes: {[-1]: inputLastDim}}];\n    this.built = true;\n  }\n\n  override computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    inputShape = getExactlyOneShape(inputShape);\n    const outputShape = inputShape.slice();\n    outputShape[outputShape.length - 1] = this.units;\n    return outputShape;\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      // Dense layer accepts only a single input.\n      const input = getExactlyOneTensor(inputs);\n      const fusedActivationName =\n          mapActivationToFusedKernel(this.activation.getClassName());\n      let output: Tensor;\n\n      if (fusedActivationName != null) {\n        output = K.dot(\n            input, this.kernel.read(), fusedActivationName,\n            this.bias ? this.bias.read() : null);\n      } else {\n        output = K.dot(input, this.kernel.read());\n        if (this.bias != null) {\n          output = K.biasAdd(output, this.bias.read());\n        }\n        if (this.activation != null) {\n          output = this.activation.apply(output);\n        }\n      }\n\n      return output;\n    });\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config: serialization.ConfigDict = {\n      units: this.units,\n      activation: serializeActivation(this.activation),\n      useBias: this.useBias,\n      kernelInitializer: serializeInitializer(this.kernelInitializer),\n      biasInitializer: serializeInitializer(this.biasInitializer),\n      kernelRegularizer: serializeRegularizer(this.kernelRegularizer),\n      biasRegularizer: serializeRegularizer(this.biasRegularizer),\n      activityRegularizer: serializeRegularizer(this.activityRegularizer),\n      kernelConstraint: serializeConstraint(this.kernelConstraint),\n      biasConstraint: serializeConstraint(this.biasConstraint)\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(Dense);\n\nexport declare interface FlattenLayerArgs extends LayerArgs {\n  /** Image data format: channelsLast (default) or channelsFirst. */\n  dataFormat?: DataFormat;\n}\n\nexport class Flatten extends Layer {\n  private dataFormat: DataFormat;\n\n  /** @nocollapse */\n  static className = 'Flatten';\n  constructor(args?: FlattenLayerArgs) {\n    args = args || {};\n    super(args);\n    this.inputSpec = [{minNDim: 3}];\n    this.dataFormat = args.dataFormat;\n  }\n\n  override computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    inputShape = getExactlyOneShape(inputShape);\n    for (const dim of inputShape.slice(1)) {\n      if (dim == null) {\n        throw new ValueError(\n            `The shape of the input to \"Flatten\" is not fully defined ` +\n            `(got ${inputShape.slice(1)}). Make sure to pass a complete ` +\n            `\"input_shape\" or \"batch_input_shape\" argument to the first ` +\n            `layer in your model.`);\n      }\n    }\n    return [inputShape[0], arrayProd(inputShape, 1)];\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n\n      let input = getExactlyOneTensor(inputs);\n      if (this.dataFormat === 'channelsFirst' && input.rank > 1) {\n        const permutation: number[] = [0];\n        for (let i = 2; i < input.rank; ++i) {\n          permutation.push(i);\n        }\n        permutation.push(1);\n        input = transpose(input, permutation);\n      }\n\n      return K.batchFlatten(input);\n    });\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config: serialization.ConfigDict = {};\n    if (this.dataFormat != null) {\n      config['dataFormat'] = this.dataFormat;\n    }\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(Flatten);\n\nexport declare interface ActivationLayerArgs extends LayerArgs {\n  /**\n   * Name of the activation function to use.\n   */\n  activation: ActivationIdentifier;\n}\n\nexport class Activation extends Layer {\n  /** @nocollapse */\n  static className = 'Activation';\n  activation: ActivationFn;\n\n  constructor(args: ActivationLayerArgs) {\n    super(args);\n    this.supportsMasking = true;\n    this.activation = getActivation(args.activation);\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      const input = getExactlyOneTensor(inputs);\n      return this.activation.apply(input);\n    });\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config = {activation: serializeActivation(this.activation)};\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(Activation);\n\nexport declare interface ReshapeLayerArgs extends LayerArgs {\n  /** The target shape. Does not include the batch axis. */\n  targetShape: Shape;\n}\n\nexport declare interface RepeatVectorLayerArgs extends LayerArgs {\n  /**\n   * The integer number of times to repeat the input.\n   */\n  n: number;\n}\n\nexport class RepeatVector extends Layer {\n  /** @nocollapse */\n  static className = 'RepeatVector';\n  readonly n: number;\n\n  constructor(args: RepeatVectorLayerArgs) {\n    super(args);\n    this.n = args.n;\n    this.inputSpec = [{ndim: 2}];\n  }\n\n  override computeOutputShape(inputShape: Shape): Shape {\n    return [inputShape[0], this.n, inputShape[1]];\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      inputs = getExactlyOneTensor(inputs);\n      return K.repeat(inputs, this.n);\n    });\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config = {\n      n: this.n,\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(RepeatVector);\n\nexport class Reshape extends Layer {\n  /** @nocollapse */\n  static className = 'Reshape';\n  private targetShape: Shape;\n\n  constructor(args: ReshapeLayerArgs) {\n    super(args);\n    this.targetShape = args.targetShape;\n\n    // Make sure that all unknown dimensions are represented as `null`.\n    for (let i = 0; i < this.targetShape.length; ++i) {\n      if (this.isUnknown(this.targetShape[i])) {\n        this.targetShape[i] = null;\n      }\n    }\n  }\n\n  private isUnknown(dim: number): boolean {\n    return dim < 0 || dim == null;\n  }\n\n  /**\n   * Finds and replaces a missing dimension in output shape.\n   *\n   * This is a near direct port of the internal Numpy function\n   * `_fix_unknown_dimension` in `numpy/core/src/multiarray/shape.c`.\n   *\n   * @param inputShape: Original shape of array begin reshape.\n   * @param outputShape: Target shape of the array, with at most a single\n   * `null` or negative number, which indicates an underdetermined dimension\n   * that should be derived from `inputShape` and the known dimensions of\n   *   `outputShape`.\n   * @returns: The output shape with `null` replaced with its computed value.\n   * @throws: ValueError: If `inputShape` and `outputShape` do not match.\n   */\n  private fixUnknownDimension(inputShape: Shape, outputShape: Shape): Shape {\n    const errorMsg = 'Total size of new array must be unchanged.';\n    const finalShape = outputShape.slice();\n    let known = 1;\n    let unknown = null;\n    for (let i = 0; i < finalShape.length; ++i) {\n      const dim = finalShape[i];\n      if (this.isUnknown(dim)) {\n        if (unknown === null) {\n          unknown = i;\n        } else {\n          throw new ValueError('Can only specifiy one unknown dimension.');\n        }\n      } else {\n        known *= dim;\n      }\n    }\n\n    const originalSize = arrayProd(inputShape);\n    if (unknown !== null) {\n      if (known === 0 || originalSize % known !== 0) {\n        throw new ValueError(errorMsg);\n      }\n      finalShape[unknown] = originalSize / known;\n    } else if (originalSize !== known) {\n      throw new ValueError(errorMsg);\n    }\n\n    return finalShape;\n  }\n\n  override computeOutputShape(inputShape: Shape): Shape {\n    let anyUnknownDims = false;\n    for (let i = 0; i < inputShape.length; ++i) {\n      if (this.isUnknown(inputShape[i])) {\n        anyUnknownDims = true;\n        break;\n      }\n    }\n\n    if (anyUnknownDims) {\n      return inputShape.slice(0, 1).concat(this.targetShape);\n    } else {\n      return inputShape.slice(0, 1).concat(\n          this.fixUnknownDimension(inputShape.slice(1), this.targetShape));\n    }\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      const input = getExactlyOneTensor(inputs);\n      const inputShape = input.shape;\n      const outputShape = inputShape.slice(0, 1).concat(\n          this.fixUnknownDimension(inputShape.slice(1), this.targetShape));\n      return reshape(input, outputShape);\n    });\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config = {\n      targetShape: this.targetShape,\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(Reshape);\n\nexport declare interface PermuteLayerArgs extends LayerArgs {\n  /**\n   * Array of integers. Permutation pattern. Does not include the\n   * sample (batch) dimension. Index starts at 1.\n   * For instance, `[2, 1]` permutes the first and second dimensions\n   * of the input.\n   */\n  dims: number[];\n}\n\nexport class Permute extends Layer {\n  /** @nocollapse */\n  static className = 'Permute';\n  readonly dims: number[];\n  private readonly dimsIncludingBatch: number[];\n\n  constructor(args: PermuteLayerArgs) {\n    super(args);\n    if (args.dims == null) {\n      throw new Error(\n          'Required configuration field `dims` is missing during Permute ' +\n          'constructor call.');\n    }\n    if (!Array.isArray(args.dims)) {\n      throw new Error(\n          'Permute constructor requires `dims` to be an Array, but received ' +\n          `${args.dims} instead.`);\n    }\n\n    // Check the validity of the permutation indices.\n    const expectedSortedIndices = range(1, args.dims.length + 1);\n    if (!util.arraysEqual(args.dims.slice().sort(), expectedSortedIndices)) {\n      throw new Error(\n          'Invalid permutation `dims`: ' + JSON.stringify(args.dims) +\n          ' `dims` must contain consecutive integers starting from 1.');\n    }\n\n    this.dims = args.dims;\n    this.dimsIncludingBatch = [0].concat(this.dims);\n    this.inputSpec = [new InputSpec({ndim: this.dims.length + 1})];\n  }\n\n  override computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    inputShape = getExactlyOneShape(inputShape);\n    const outputShape = inputShape.slice();\n    this.dims.forEach((dim: number, i: number) => {\n      outputShape[i + 1] = (inputShape as Shape)[dim];\n    });\n    return outputShape;\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return transpose(getExactlyOneTensor(inputs), this.dimsIncludingBatch);\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config = {\n      dims: this.dims,\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(Permute);\n\nexport declare interface MaskingArgs extends LayerArgs {\n  /**\n   * Masking Value. Defaults to `0.0`.\n   */\n  maskValue?: number;\n}\n\nexport class Masking extends Layer {\n  /** @nocollapse */\n  static className = 'Masking';\n  maskValue: number;\n\n  constructor(args?: MaskingArgs) {\n    super(args == null ? {} : args);\n    this.supportsMasking = true;\n    if (args != null) {\n      this.maskValue = args.maskValue == null ? 0 : args.maskValue;\n    } else {\n      this.maskValue = 0;\n    }\n  }\n\n  override computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    return inputShape;\n  }\n\n  override getConfig() {\n    const baseConfig = super.getConfig();\n    const config = {maskValue: this.maskValue};\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n  override computeMask(inputs: Tensor|Tensor[], mask?: Tensor|Tensor[]):\n      Tensor {\n    const input = getExactlyOneTensor(inputs);\n    const axis = -1;\n    return any(notEqual(input, this.maskValue), axis);\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      const input = getExactlyOneTensor(inputs);\n      const axis = -1;\n      const keepDims = true;\n      const booleanMask = any(notEqual(input, this.maskValue), axis, keepDims);\n      const output = mul(input, cast(booleanMask, input.dtype));\n      return output;\n    });\n  }\n}\nserialization.registerClass(Masking);\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;AAAA;;;;;;;;GAQG,CAEH;;GAEG;;;;;;;;;AAEH,OAAO,EAAC,GAAG,EAAE,IAAI,EAAE,GAAG,EAAE,QAAQ,EAAE,OAAO,EAAE,aAAa,EAAU,IAAI,EAAE,SAAS,EAAE,IAAI,EAAC,MAAM,uBAAuB,CAAC;AAEtH,OAAO,EAA6B,aAAa,EAAE,mBAAmB,EAAC,MAAM,gBAAgB,CAAC;AAC9F,OAAO,KAAK,CAAC,MAAM,yBAAyB,CAAC;AAC7C,OAAO,EAAmC,aAAa,EAAE,mBAAmB,EAAC,MAAM,gBAAgB,CAAC;AACpG,OAAO,EAAgB,SAAS,EAAE,KAAK,EAAY,MAAM,oBAAoB,CAAC;AAC9E,OAAO,EAAC,UAAU,EAAC,MAAM,WAAW,CAAC;AACrC,OAAO,EAAC,cAAc,EAAsC,oBAAoB,EAAC,MAAM,iBAAiB,CAAC;AAIzG,OAAO,EAAC,cAAc,EAAsC,oBAAoB,EAAC,MAAM,iBAAiB,CAAC;AAEzG,OAAO,EAAC,qBAAqB,EAAE,0BAA0B,EAAC,MAAM,wBAAwB,CAAC;AACzF,OAAO,EAAC,SAAS,EAAE,KAAK,EAAC,MAAM,qBAAqB,CAAC;AACrD,OAAO,EAAC,kBAAkB,EAAE,mBAAmB,EAAC,MAAM,sBAAsB,CAAC;;;;;;;;;;;;AAqB7E,MAAa,OAAQ,SAAQ,gTAAK;IAOhC,YAAY,IAAsB,CAAA;QAChC,KAAK,CAAC,IAAI,CAAC,CAAC;QACZ,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC,GAAG,CAAC,IAAI,CAAC,GAAG,CAAC,IAAI,CAAC,IAAI,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;QAChD,+DAA+D;QAC/D,IAAI,CAAC,UAAU,GAAG,IAAI,CAAC,UAAU,CAAC;QAClC,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC,IAAI,CAAC;QACtB,IAAI,CAAC,eAAe,GAAG,IAAI,CAAC;IAC9B,CAAC;IAES,aAAa,CAAC,KAAa,EAAA;QACnC,IAAI,IAAI,CAAC,UAAU,IAAI,IAAI,EAAE;YAC3B,OAAO,IAAI,CAAC,UAAU,CAAC;SACxB;QACD,MAAM,UAAU,GAAG,KAAK,CAAC,KAAK,CAAC;QAC/B,MAAM,UAAU,GAAU,EAAE,CAAC;QAC7B,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,UAAU,CAAC,MAAM,EAAE,EAAE,CAAC,CAAE;YAC/C,UAAU,CAAC,IAAI,CACX,IAAI,CAAC,UAAU,CAAC,CAAC,CAAC,IAAI,IAAI,CAAC,CAAC,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC,CAAC;SACtE;QACD,OAAO,UAAU,CAAC;IACpB,CAAC;IAEQ,IAAI,CAAC,MAAuB,EAAE,MAAc,EAAA;QACnD,WAAO,iPAAI,EAAC,GAAG,EAAE;YACf,IAAI,CAAC,cAAc,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC;YACpC,MAAM,KAAK,OAAG,gUAAmB,EAAC,MAAM,CAAC,CAAC;YAC1C,IAAI,CAAC,GAAG,IAAI,CAAC,IAAI,IAAI,IAAI,CAAC,IAAI,GAAG,CAAC,EAAE;gBAClC,MAAM,QAAQ,GACV,MAAM,CAAC,UAAU,CAAC,IAAI,IAAI,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,MAAM,CAAC,UAAU,CAAC,CAAC;gBAC5D,MAAM,UAAU,GAAG,IAAI,CAAC,aAAa,CAAC,KAAK,CAAC,CAAC;gBAC7C,MAAM,MAAM,GAAG,CAAC,CAAC,0TAAY,CACzB,GAAG,CAAG,CAAD,AAAE,CAAC,qTAAO,CAAC,KAAK,EAAE,IAAI,CAAC,IAAI,EAAE,UAAU,EAAE,IAAI,CAAC,IAAI,CAAC,EACxD,GAAG,CAAG,CAAD,IAAM,EAAE,QAAQ,CAAC,CAAC;gBAC3B,OAAO,MAAM,CAAC;aACf;YACD,OAAO,MAAM,CAAC;QAChB,CAAC,CAAC,CAAC;IACL,CAAC;IAEQ,SAAS,GAAA;QAChB,MAAM,MAAM,GAAG;YACb,IAAI,EAAE,IAAI,CAAC,IAAI;YACf,UAAU,EAAE,IAAI,CAAC,UAAU;YAC3B,IAAI,EAAE,IAAI,CAAC,IAAI;SAChB,CAAC;QACF,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;QACrC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;IAEQ,OAAO,GAAA;QACd,OAAO,KAAK,CAAC,OAAO,EAAE,CAAC;IACzB,CAAC;;AA1DD,gBAAA,EAAkB,CACX,QAAA,SAAS,GAAG,SAAS,CAAC;;AA2D/B,ySAAa,CAAC,aAAa,CAAC,OAAO,CAAC,CAAC;AA4DrC,MAAa,gBAAiB,SAAQ,OAAO;IAI3C,YAAY,IAAiC,CAAA;QAC3C,KAAK,CAAC,IAAI,CAAC,CAAC;QACZ,IAAI,CAAC,SAAS,GAAG;YAAC;gBAAC,IAAI,EAAE,CAAC;YAAA,CAAC;SAAC,CAAC;IAC/B,CAAC;IAEkB,aAAa,CAAC,KAAa,EAAA;QAC5C,MAAM,UAAU,GAAG,KAAK,CAAC,KAAK,CAAC;QAC/B,OAAO;YAAC,UAAU,CAAC,CAAC,CAAC;YAAE,CAAC;YAAE,UAAU,CAAC,CAAC,CAAC;SAAC,CAAC;IAC3C,CAAC;;AAXD,gBAAA,EAAkB,CACF,iBAAA,SAAS,GAAG,kBAAkB,CAAC;;AAYjD,ySAAa,CAAC,aAAa,CAAC,gBAAgB,CAAC,CAAC;AAE9C,MAAa,KAAM,SAAQ,gTAAK;IAmB9B,YAAY,IAAoB,CAAA;QAC9B,KAAK,CAAC,IAAI,CAAC,CAAC;QAhBd,qCAAqC;QAC7B,IAAA,CAAA,UAAU,GAAiB,IAAI,CAAC;QAChC,IAAA,CAAA,OAAO,GAAG,IAAI,CAAC;QAGf,IAAA,CAAA,MAAM,GAAkB,IAAI,CAAC;QAC7B,IAAA,CAAA,IAAI,GAAkB,IAAI,CAAC;QAE1B,IAAA,CAAA,0BAA0B,GAA0B,cAAc,CAAC;QACnE,IAAA,CAAA,wBAAwB,GAA0B,OAAO,CAAC;QAQjE,IAAI,IAAI,CAAC,eAAe,IAAI,IAAI,IAAI,IAAI,CAAC,UAAU,IAAI,IAAI,IACvD,IAAI,CAAC,QAAQ,IAAI,IAAI,EAAE;YACzB,gEAAgE;YAChE,2DAA2D;YAC3D,IAAI,SAAS,GAAW,IAAI,CAAC;YAC7B,IAAI,IAAI,CAAC,SAAS,IAAI,IAAI,EAAE;gBAC1B,SAAS,GAAG,IAAI,CAAC,SAAS,CAAC;aAC5B;YACD,IAAI,CAAC,eAAe,GAAG;gBAAC,SAAS;gBAAE,IAAI,CAAC,QAAQ;aAAC,CAAC;SACnD;QAED,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC,KAAK,CAAC;YACxB,oUAAqB,EAAC,IAAI,CAAC,KAAK,EAAE,OAAO,CAAC,CAAC;QAC3C,IAAI,CAAC,UAAU,OAAG,iTAAa,EAAC,IAAI,CAAC,UAAU,CAAC,CAAC;QACjD,IAAI,IAAI,CAAC,OAAO,IAAI,IAAI,EAAE;YACxB,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC,OAAO,CAAC;SAC7B;QACD,IAAI,CAAC,iBAAiB,OAAG,mTAAc,EACnC,IAAI,CAAC,iBAAiB,IAAI,IAAI,CAAC,0BAA0B,CAAC,CAAC;QAC/D,IAAI,CAAC,eAAe,OAChB,mTAAc,EAAC,IAAI,CAAC,eAAe,IAAI,IAAI,CAAC,wBAAwB,CAAC,CAAC;QAC1E,IAAI,CAAC,gBAAgB,OAAG,iTAAa,EAAC,IAAI,CAAC,gBAAgB,CAAC,CAAC;QAC7D,IAAI,CAAC,cAAc,OAAG,iTAAa,EAAC,IAAI,CAAC,cAAc,CAAC,CAAC;QACzD,IAAI,CAAC,iBAAiB,OAAG,mTAAc,EAAC,IAAI,CAAC,iBAAiB,CAAC,CAAC;QAChE,IAAI,CAAC,eAAe,OAAG,mTAAc,EAAC,IAAI,CAAC,eAAe,CAAC,CAAC;QAC5D,IAAI,CAAC,mBAAmB,OAAG,mTAAc,EAAC,IAAI,CAAC,mBAAmB,CAAC,CAAC;QACpE,IAAI,CAAC,eAAe,GAAG,IAAI,CAAC;QAE5B,IAAI,CAAC,SAAS,GAAG;YAAC;gBAAC,OAAO,EAAE,CAAC;YAAA,CAAC;SAAC,CAAC;IAClC,CAAC;IAEe,KAAK,CAAC,UAAyB,EAAA;QAC7C,UAAU,OAAG,+TAAkB,EAAC,UAAU,CAAC,CAAC;QAC5C,MAAM,YAAY,GAAG,UAAU,CAAC,UAAU,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;QACvD,IAAI,IAAI,CAAC,MAAM,IAAI,IAAI,EAAE;YACvB,IAAI,CAAC,MAAM,GAAG,IAAI,CAAC,SAAS,CACxB,QAAQ,EAAE;gBAAC,YAAY;gBAAE,IAAI,CAAC,KAAK;aAAC,EAAE,IAAI,EAAE,IAAI,CAAC,iBAAiB,EAClE,IAAI,CAAC,iBAAiB,EAAE,IAAI,EAAE,IAAI,CAAC,gBAAgB,CAAC,CAAC;YACzD,IAAI,IAAI,CAAC,OAAO,EAAE;gBAChB,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC,SAAS,CACtB,MAAM,EAAE;oBAAC,IAAI,CAAC,KAAK;iBAAC,EAAE,IAAI,EAAE,IAAI,CAAC,eAAe,EAChD,IAAI,CAAC,eAAe,EAAE,IAAI,EAAE,IAAI,CAAC,cAAc,CAAC,CAAC;aACtD;SACF;QAED,IAAI,CAAC,SAAS,GAAG;YAAC;gBAAC,OAAO,EAAE,CAAC;gBAAE,IAAI,EAAE;oBAAC,CAAC,CAAC,CAAC,CAAC,EAAE,YAAY;gBAAA,CAAC;YAAA,CAAC;SAAC,CAAC;QAC5D,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC;IACpB,CAAC;IAEQ,kBAAkB,CAAC,UAAyB,EAAA;QACnD,UAAU,OAAG,+TAAkB,EAAC,UAAU,CAAC,CAAC;QAC5C,MAAM,WAAW,GAAG,UAAU,CAAC,KAAK,EAAE,CAAC;QACvC,WAAW,CAAC,WAAW,CAAC,MAAM,GAAG,CAAC,CAAC,GAAG,IAAI,CAAC,KAAK,CAAC;QACjD,OAAO,WAAW,CAAC;IACrB,CAAC;IAEQ,IAAI,CAAC,MAAuB,EAAE,MAAc,EAAA;QACnD,WAAO,iPAAI,EAAC,GAAG,EAAE;YACf,IAAI,CAAC,cAAc,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC;YACpC,2CAA2C;YAC3C,MAAM,KAAK,OAAG,gUAAmB,EAAC,MAAM,CAAC,CAAC;YAC1C,MAAM,mBAAmB,OACrB,yUAA0B,EAAC,IAAI,CAAC,UAAU,CAAC,YAAY,EAAE,CAAC,CAAC;YAC/D,IAAI,MAAc,CAAC;YAEnB,IAAI,mBAAmB,IAAI,IAAI,EAAE;gBAC/B,MAAM,GAAG,CAAC,CAAC,iTAAG,CACV,KAAK,EAAE,IAAI,CAAC,MAAM,CAAC,IAAI,EAAE,EAAE,mBAAmB,EAC9C,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;aAC1C,MAAM;gBACL,MAAM,GAAG,CAAC,CAAC,iTAAG,CAAC,KAAK,EAAE,IAAI,CAAC,MAAM,CAAC,IAAI,EAAE,CAAC,CAAC;gBAC1C,IAAI,IAAI,CAAC,IAAI,IAAI,IAAI,EAAE;oBACrB,MAAM,GAAG,CAAC,CAAC,qTAAO,CAAC,MAAM,EAAE,IAAI,CAAC,IAAI,CAAC,IAAI,EAAE,CAAC,CAAC;iBAC9C;gBACD,IAAI,IAAI,CAAC,UAAU,IAAI,IAAI,EAAE;oBAC3B,MAAM,GAAG,IAAI,CAAC,UAAU,CAAC,KAAK,CAAC,MAAM,CAAC,CAAC;iBACxC;aACF;YAED,OAAO,MAAM,CAAC;QAChB,CAAC,CAAC,CAAC;IACL,CAAC;IAEQ,SAAS,GAAA;QAChB,MAAM,MAAM,GAA6B;YACvC,KAAK,EAAE,IAAI,CAAC,KAAK;YACjB,UAAU,MAAE,uTAAmB,EAAC,IAAI,CAAC,UAAU,CAAC;YAChD,OAAO,EAAE,IAAI,CAAC,OAAO;YACrB,iBAAiB,MAAE,yTAAoB,EAAC,IAAI,CAAC,iBAAiB,CAAC;YAC/D,eAAe,MAAE,yTAAoB,EAAC,IAAI,CAAC,eAAe,CAAC;YAC3D,iBAAiB,MAAE,yTAAoB,EAAC,IAAI,CAAC,iBAAiB,CAAC;YAC/D,eAAe,MAAE,yTAAoB,EAAC,IAAI,CAAC,eAAe,CAAC;YAC3D,mBAAmB,MAAE,yTAAoB,EAAC,IAAI,CAAC,mBAAmB,CAAC;YACnE,gBAAgB,MAAE,uTAAmB,EAAC,IAAI,CAAC,gBAAgB,CAAC;YAC5D,cAAc,MAAE,uTAAmB,EAAC,IAAI,CAAC,cAAc,CAAC;SACzD,CAAC;QACF,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;QACrC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;;AAvHD,gBAAA,EAAkB,CACX,MAAA,SAAS,GAAG,OAAO,AAAV,CAAW;;AAwH7B,ySAAa,CAAC,aAAa,CAAC,KAAK,CAAC,CAAC;AAOnC,MAAa,OAAQ,SAAQ,gTAAK;IAKhC,YAAY,IAAuB,CAAA;QACjC,IAAI,GAAG,IAAI,IAAI,CAAA,CAAE,CAAC;QAClB,KAAK,CAAC,IAAI,CAAC,CAAC;QACZ,IAAI,CAAC,SAAS,GAAG;YAAC;gBAAC,OAAO,EAAE,CAAC;YAAA,CAAC;SAAC,CAAC;QAChC,IAAI,CAAC,UAAU,GAAG,IAAI,CAAC,UAAU,CAAC;IACpC,CAAC;IAEQ,kBAAkB,CAAC,UAAyB,EAAA;QACnD,UAAU,OAAG,+TAAkB,EAAC,UAAU,CAAC,CAAC;QAC5C,KAAK,MAAM,GAAG,IAAI,UAAU,CAAC,KAAK,CAAC,CAAC,CAAC,CAAE;YACrC,IAAI,GAAG,IAAI,IAAI,EAAE;gBACf,MAAM,IAAI,ySAAU,CAChB,CAAA,yDAAA,CAA2D,GAC3D,CAAA,KAAA,EAAQ,UAAU,CAAC,KAAK,CAAC,CAAC,CAAC,CAAA,gCAAA,CAAkC,GAC7D,CAAA,2DAAA,CAA6D,GAC7D,CAAA,oBAAA,CAAsB,CAAC,CAAC;aAC7B;SACF;QACD,OAAO;YAAC,UAAU,CAAC,CAAC,CAAC;gBAAE,qTAAS,EAAC,UAAU,EAAE,CAAC,CAAC;SAAC,CAAC;IACnD,CAAC;IAEQ,IAAI,CAAC,MAAuB,EAAE,MAAc,EAAA;QACnD,WAAO,iPAAI,EAAC,GAAG,EAAE;YACf,IAAI,CAAC,cAAc,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC;YAEpC,IAAI,KAAK,OAAG,gUAAmB,EAAC,MAAM,CAAC,CAAC;YACxC,IAAI,IAAI,CAAC,UAAU,KAAK,eAAe,IAAI,KAAK,CAAC,IAAI,GAAG,CAAC,EAAE;gBACzD,MAAM,WAAW,GAAa;oBAAC,CAAC;iBAAC,CAAC;gBAClC,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,KAAK,CAAC,IAAI,EAAE,EAAE,CAAC,CAAE;oBACnC,WAAW,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;iBACrB;gBACD,WAAW,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;gBACpB,KAAK,OAAG,+PAAS,EAAC,KAAK,EAAE,WAAW,CAAC,CAAC;aACvC;YAED,OAAO,CAAC,CAAC,0TAAY,CAAC,KAAK,CAAC,CAAC;QAC/B,CAAC,CAAC,CAAC;IACL,CAAC;IAEQ,SAAS,GAAA;QAChB,MAAM,MAAM,GAA6B,CAAA,CAAE,CAAC;QAC5C,IAAI,IAAI,CAAC,UAAU,IAAI,IAAI,EAAE;YAC3B,MAAM,CAAC,YAAY,CAAC,GAAG,IAAI,CAAC,UAAU,CAAC;SACxC;QACD,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;QACrC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;;AAjDD,gBAAA,EAAkB,CACX,QAAA,SAAS,GAAG,SAAS,CAAC;;AAkD/B,ySAAa,CAAC,aAAa,CAAC,OAAO,CAAC,CAAC;AASrC,MAAa,UAAW,SAAQ,gTAAK;IAKnC,YAAY,IAAyB,CAAA;QACnC,KAAK,CAAC,IAAI,CAAC,CAAC;QACZ,IAAI,CAAC,eAAe,GAAG,IAAI,CAAC;QAC5B,IAAI,CAAC,UAAU,OAAG,iTAAa,EAAC,IAAI,CAAC,UAAU,CAAC,CAAC;IACnD,CAAC;IAEQ,IAAI,CAAC,MAAuB,EAAE,MAAc,EAAA;QACnD,WAAO,iPAAI,EAAC,GAAG,EAAE;YACf,IAAI,CAAC,cAAc,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC;YACpC,MAAM,KAAK,OAAG,gUAAmB,EAAC,MAAM,CAAC,CAAC;YAC1C,OAAO,IAAI,CAAC,UAAU,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC;QACtC,CAAC,CAAC,CAAC;IACL,CAAC;IAEQ,SAAS,GAAA;QAChB,MAAM,MAAM,GAAG;YAAC,UAAU,MAAE,uTAAmB,EAAC,IAAI,CAAC,UAAU,CAAC;QAAA,CAAC,CAAC;QAClE,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;QACrC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;;AAvBD,gBAAA,EAAkB,CACX,WAAA,SAAS,GAAG,YAAY,CAAC;;AAwBlC,ySAAa,CAAC,aAAa,CAAC,UAAU,CAAC,CAAC;AAcxC,MAAa,YAAa,SAAQ,gTAAK;IAKrC,YAAY,IAA2B,CAAA;QACrC,KAAK,CAAC,IAAI,CAAC,CAAC;QACZ,IAAI,CAAC,CAAC,GAAG,IAAI,CAAC,CAAC,CAAC;QAChB,IAAI,CAAC,SAAS,GAAG;YAAC;gBAAC,IAAI,EAAE,CAAC;YAAA,CAAC;SAAC,CAAC;IAC/B,CAAC;IAEQ,kBAAkB,CAAC,UAAiB,EAAA;QAC3C,OAAO;YAAC,UAAU,CAAC,CAAC,CAAC;YAAE,IAAI,CAAC,CAAC;YAAE,UAAU,CAAC,CAAC,CAAC;SAAC,CAAC;IAChD,CAAC;IAEQ,IAAI,CAAC,MAAuB,EAAE,MAAc,EAAA;QACnD,WAAO,iPAAI,EAAC,GAAG,EAAE;YACf,MAAM,OAAG,gUAAmB,EAAC,MAAM,CAAC,CAAC;YACrC,OAAO,CAAC,CAAC,oTAAM,CAAC,MAAM,EAAE,IAAI,CAAC,CAAC,CAAC,CAAC;QAClC,CAAC,CAAC,CAAC;IACL,CAAC;IAEQ,SAAS,GAAA;QAChB,MAAM,MAAM,GAAG;YACb,CAAC,EAAE,IAAI,CAAC,CAAC;SACV,CAAC;QACF,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;QACrC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;;AA5BD,gBAAA,EAAkB,CACX,aAAA,SAAS,GAAG,cAAc,CAAC;;AA6BpC,ySAAa,CAAC,aAAa,CAAC,YAAY,CAAC,CAAC;AAE1C,MAAa,OAAQ,SAAQ,gTAAK;IAKhC,YAAY,IAAsB,CAAA;QAChC,KAAK,CAAC,IAAI,CAAC,CAAC;QACZ,IAAI,CAAC,WAAW,GAAG,IAAI,CAAC,WAAW,CAAC;QAEpC,mEAAmE;QACnE,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,WAAW,CAAC,MAAM,EAAE,EAAE,CAAC,CAAE;YAChD,IAAI,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC,EAAE;gBACvC,IAAI,CAAC,WAAW,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC;aAC5B;SACF;IACH,CAAC;IAEO,SAAS,CAAC,GAAW,EAAA;QAC3B,OAAO,GAAG,GAAG,CAAC,IAAI,GAAG,IAAI,IAAI,CAAC;IAChC,CAAC;IAED;;;;;;;;;;;;;OAaG,CACK,mBAAmB,CAAC,UAAiB,EAAE,WAAkB,EAAA;QAC/D,MAAM,QAAQ,GAAG,4CAA4C,CAAC;QAC9D,MAAM,UAAU,GAAG,WAAW,CAAC,KAAK,EAAE,CAAC;QACvC,IAAI,KAAK,GAAG,CAAC,CAAC;QACd,IAAI,OAAO,GAAG,IAAI,CAAC;QACnB,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,UAAU,CAAC,MAAM,EAAE,EAAE,CAAC,CAAE;YAC1C,MAAM,GAAG,GAAG,UAAU,CAAC,CAAC,CAAC,CAAC;YAC1B,IAAI,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,EAAE;gBACvB,IAAI,OAAO,KAAK,IAAI,EAAE;oBACpB,OAAO,GAAG,CAAC,CAAC;iBACb,MAAM;oBACL,MAAM,IAAI,ySAAU,CAAC,0CAA0C,CAAC,CAAC;iBAClE;aACF,MAAM;gBACL,KAAK,IAAI,GAAG,CAAC;aACd;SACF;QAED,MAAM,YAAY,OAAG,qTAAS,EAAC,UAAU,CAAC,CAAC;QAC3C,IAAI,OAAO,KAAK,IAAI,EAAE;YACpB,IAAI,KAAK,KAAK,CAAC,IAAI,YAAY,GAAG,KAAK,KAAK,CAAC,EAAE;gBAC7C,MAAM,IAAI,ySAAU,CAAC,QAAQ,CAAC,CAAC;aAChC;YACD,UAAU,CAAC,OAAO,CAAC,GAAG,YAAY,GAAG,KAAK,CAAC;SAC5C,MAAM,IAAI,YAAY,KAAK,KAAK,EAAE;YACjC,MAAM,IAAI,ySAAU,CAAC,QAAQ,CAAC,CAAC;SAChC;QAED,OAAO,UAAU,CAAC;IACpB,CAAC;IAEQ,kBAAkB,CAAC,UAAiB,EAAA;QAC3C,IAAI,cAAc,GAAG,KAAK,CAAC;QAC3B,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,UAAU,CAAC,MAAM,EAAE,EAAE,CAAC,CAAE;YAC1C,IAAI,IAAI,CAAC,SAAS,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC,EAAE;gBACjC,cAAc,GAAG,IAAI,CAAC;gBACtB,MAAM;aACP;SACF;QAED,IAAI,cAAc,EAAE;YAClB,OAAO,UAAU,CAAC,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,MAAM,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;SACxD,MAAM;YACL,OAAO,UAAU,CAAC,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,MAAM,CAChC,IAAI,CAAC,mBAAmB,CAAC,UAAU,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,IAAI,CAAC,WAAW,CAAC,CAAC,CAAC;SACtE;IACH,CAAC;IAEQ,IAAI,CAAC,MAAuB,EAAE,MAAc,EAAA;QACnD,WAAO,iPAAI,EAAC,GAAG,EAAE;YACf,IAAI,CAAC,cAAc,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC;YACpC,MAAM,KAAK,OAAG,gUAAmB,EAAC,MAAM,CAAC,CAAC;YAC1C,MAAM,UAAU,GAAG,KAAK,CAAC,KAAK,CAAC;YAC/B,MAAM,WAAW,GAAG,UAAU,CAAC,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,MAAM,CAC7C,IAAI,CAAC,mBAAmB,CAAC,UAAU,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,IAAI,CAAC,WAAW,CAAC,CAAC,CAAC;YACrE,WAAO,2PAAO,EAAC,KAAK,EAAE,WAAW,CAAC,CAAC;QACrC,CAAC,CAAC,CAAC;IACL,CAAC;IAEQ,SAAS,GAAA;QAChB,MAAM,MAAM,GAAG;YACb,WAAW,EAAE,IAAI,CAAC,WAAW;SAC9B,CAAC;QACF,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;QACrC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;;AApGD,gBAAA,EAAkB,CACX,QAAA,SAAS,GAAG,SAAS,CAAC;;AAqG/B,ySAAa,CAAC,aAAa,CAAC,OAAO,CAAC,CAAC;AAYrC,MAAa,OAAQ,SAAQ,gTAAK;IAMhC,YAAY,IAAsB,CAAA;QAChC,KAAK,CAAC,IAAI,CAAC,CAAC;QACZ,IAAI,IAAI,CAAC,IAAI,IAAI,IAAI,EAAE;YACrB,MAAM,IAAI,KAAK,CACX,gEAAgE,GAChE,mBAAmB,CAAC,CAAC;SAC1B;QACD,IAAI,CAAC,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,CAAC,EAAE;YAC7B,MAAM,IAAI,KAAK,CACX,mEAAmE,GACnE,GAAG,IAAI,CAAC,IAAI,CAAA,SAAA,CAAW,CAAC,CAAC;SAC9B;QAED,iDAAiD;QACjD,MAAM,qBAAqB,OAAG,iTAAK,EAAC,CAAC,EAAE,IAAI,CAAC,IAAI,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;QAC7D,IAAI,CAAC,8QAAI,CAAC,WAAW,CAAC,IAAI,CAAC,IAAI,CAAC,KAAK,EAAE,CAAC,IAAI,EAAE,EAAE,qBAAqB,CAAC,EAAE;YACtE,MAAM,IAAI,KAAK,CACX,8BAA8B,GAAG,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,IAAI,CAAC,GAC1D,4DAA4D,CAAC,CAAC;SACnE;QAED,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC,IAAI,CAAC;QACtB,IAAI,CAAC,kBAAkB,GAAG;YAAC,CAAC;SAAC,CAAC,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;QAChD,IAAI,CAAC,SAAS,GAAG;YAAC,IAAI,oTAAS,CAAC;gBAAC,IAAI,EAAE,IAAI,CAAC,IAAI,CAAC,MAAM,GAAG,CAAC;YAAA,CAAC,CAAC;SAAC,CAAC;IACjE,CAAC;IAEQ,kBAAkB,CAAC,UAAyB,EAAA;QACnD,UAAU,OAAG,+TAAkB,EAAC,UAAU,CAAC,CAAC;QAC5C,MAAM,WAAW,GAAG,UAAU,CAAC,KAAK,EAAE,CAAC;QACvC,IAAI,CAAC,IAAI,CAAC,OAAO,CAAC,CAAC,GAAW,EAAE,CAAS,EAAE,EAAE;YAC3C,WAAW,CAAC,CAAC,GAAG,CAAC,CAAC,GAAI,UAAoB,CAAC,GAAG,CAAC,CAAC;QAClD,CAAC,CAAC,CAAC;QACH,OAAO,WAAW,CAAC;IACrB,CAAC;IAEQ,IAAI,CAAC,MAAuB,EAAE,MAAc,EAAA;QACnD,WAAO,+PAAS,MAAC,gUAAmB,EAAC,MAAM,CAAC,EAAE,IAAI,CAAC,kBAAkB,CAAC,CAAC;IACzE,CAAC;IAEQ,SAAS,GAAA;QAChB,MAAM,MAAM,GAAG;YACb,IAAI,EAAE,IAAI,CAAC,IAAI;SAChB,CAAC;QACF,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;QACrC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;;AAnDD,gBAAA,EAAkB,CACX,QAAA,SAAS,GAAG,SAAS,CAAC;;AAoD/B,ySAAa,CAAC,aAAa,CAAC,OAAO,CAAC,CAAC;AASrC,MAAa,OAAQ,SAAQ,gTAAK;IAKhC,YAAY,IAAkB,CAAA;QAC5B,KAAK,CAAC,IAAI,IAAI,IAAI,CAAC,CAAC,CAAC,CAAA,CAAE,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC;QAChC,IAAI,CAAC,eAAe,GAAG,IAAI,CAAC;QAC5B,IAAI,IAAI,IAAI,IAAI,EAAE;YAChB,IAAI,CAAC,SAAS,GAAG,IAAI,CAAC,SAAS,IAAI,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,SAAS,CAAC;SAC9D,MAAM;YACL,IAAI,CAAC,SAAS,GAAG,CAAC,CAAC;SACpB;IACH,CAAC;IAEQ,kBAAkB,CAAC,UAAyB,EAAA;QACnD,OAAO,UAAU,CAAC;IACpB,CAAC;IAEQ,SAAS,GAAA;QAChB,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;QACrC,MAAM,MAAM,GAAG;YAAC,SAAS,EAAE,IAAI,CAAC,SAAS;QAAA,CAAC,CAAC;QAC3C,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;IAEQ,WAAW,CAAC,MAAuB,EAAE,IAAsB,EAAA;QAElE,MAAM,KAAK,OAAG,gUAAmB,EAAC,MAAM,CAAC,CAAC;QAC1C,MAAM,IAAI,GAAG,CAAC,CAAC,CAAC;QAChB,WAAO,mPAAG,MAAC,8PAAQ,EAAC,KAAK,EAAE,IAAI,CAAC,SAAS,CAAC,EAAE,IAAI,CAAC,CAAC;IACpD,CAAC;IAEQ,IAAI,CAAC,MAAuB,EAAE,MAAc,EAAA;QACnD,WAAO,iPAAI,EAAC,GAAG,EAAE;YACf,IAAI,CAAC,cAAc,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC;YACpC,MAAM,KAAK,OAAG,gUAAmB,EAAC,MAAM,CAAC,CAAC;YAC1C,MAAM,IAAI,GAAG,CAAC,CAAC,CAAC;YAChB,MAAM,QAAQ,GAAG,IAAI,CAAC;YACtB,MAAM,WAAW,OAAG,mPAAG,MAAC,8PAAQ,EAAC,KAAK,EAAE,IAAI,CAAC,SAAS,CAAC,EAAE,IAAI,EAAE,QAAQ,CAAC,CAAC;YACzE,MAAM,MAAM,OAAG,mPAAG,EAAC,KAAK,MAAE,qPAAI,EAAC,WAAW,EAAE,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC;YAC1D,OAAO,MAAM,CAAC;QAChB,CAAC,CAAC,CAAC;IACL,CAAC;;AA1CD,gBAAA,EAAkB,CACX,QAAA,SAAS,GAAG,SAAS,CAAC;;AA2C/B,ySAAa,CAAC,aAAa,CAAC,OAAO,CAAC,CAAC"}},
    {"offset": {"line": 1433, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-layers@4.22.0_@tensorflow+tfjs-core@4.22.0/node_modules/@tensorflow/tfjs-layers/dist/layers/embeddings.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-layers/src/layers/embeddings.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * TensorFlow.js Layers: Embedding Layer.\n *\n * Original source: keras/constraints.py\n */\nimport {notEqual, reshape, serialization, Tensor, tidy, zerosLike} from '@tensorflow/tfjs-core';\n\nimport * as K from '../backend/tfjs_backend';\nimport {Constraint, ConstraintIdentifier, getConstraint, serializeConstraint} from '../constraints';\nimport {Layer, LayerArgs} from '../engine/topology';\nimport {ValueError} from '../errors';\nimport {getInitializer, Initializer, InitializerIdentifier, serializeInitializer} from '../initializers';\nimport {Shape} from '../keras_format/common';\nimport {getRegularizer, Regularizer, RegularizerIdentifier, serializeRegularizer} from '../regularizers';\nimport {Kwargs} from '../types';\nimport * as generic_utils from '../utils/generic_utils';\nimport {getExactlyOneShape, getExactlyOneTensor} from '../utils/types_utils';\nimport {LayerVariable} from '../variables';\n\nexport declare interface EmbeddingLayerArgs extends LayerArgs {\n  /**\n   * Integer > 0. Size of the vocabulary, i.e. maximum integer index + 1.\n   */\n  inputDim: number;\n  /**\n   * Integer >= 0. Dimension of the dense embedding.\n   */\n  outputDim: number;\n  /**\n   * Initializer for the `embeddings` matrix.\n   */\n  embeddingsInitializer?: InitializerIdentifier|Initializer;\n  /**\n   * Regularizer function applied to the `embeddings` matrix.\n   */\n  embeddingsRegularizer?: RegularizerIdentifier|Regularizer;\n  /**\n   * Regularizer function applied to the activation.\n   */\n  activityRegularizer?: RegularizerIdentifier|Regularizer;\n  /**\n   * Constraint function applied to the `embeddings` matrix.\n   */\n  embeddingsConstraint?: ConstraintIdentifier|Constraint;\n  /**\n   * Whether the input value 0 is a special \"padding\" value that should be\n   * masked out. This is useful when using recurrent layers which may take\n   * variable length input.\n   *\n   * If this is `True` then all subsequent layers in the model need to support\n   * masking or an exception will be raised. If maskZero is set to `True`, as a\n   * consequence, index 0 cannot be used in the vocabulary (inputDim should\n   * equal size of vocabulary + 1).\n   */\n  maskZero?: boolean;\n  /**\n   * Length of input sequences, when it is constant.\n   *\n   * This argument is required if you are going to connect `flatten` then\n   * `dense` layers upstream (without it, the shape of the dense outputs cannot\n   * be computed).\n   */\n  inputLength?: number|number[];\n}\n\nexport class Embedding extends Layer {\n  /** @nocollapse */\n  static className = 'Embedding';\n  private inputDim: number;\n  private outputDim: number;\n  private embeddingsInitializer: Initializer;\n  private maskZero: boolean;\n  private inputLength: number|number[];\n\n  private embeddings: LayerVariable = null;\n\n  readonly DEFAULT_EMBEDDINGS_INITIALIZER: InitializerIdentifier =\n      'randomUniform';\n  private readonly embeddingsRegularizer?: Regularizer;\n  private readonly embeddingsConstraint?: Constraint;\n\n  constructor(args: EmbeddingLayerArgs) {\n    super(args);\n    if (args.batchInputShape == null && args.inputShape == null) {\n      // Porting Note: This logic is copied from Layer's constructor, since we\n      // can't do exactly what the Python constructor does for Embedding().\n      // Specifically, the super constructor can not be called after the\n      // mutation of the `config` argument.\n      let batchSize: number = null;\n      if (args.batchSize != null) {\n        batchSize = args.batchSize;\n      }\n      if (args.inputLength == null) {\n        // Fix super-constructor to what it would have done if\n        // 'config.inputShape' were (None, )\n        this.batchInputShape = [batchSize, null];\n      } else {\n        // Fix super-constructor to what it would have done if\n        // 'config.inputShape' were (config.inputLength, )\n        this.batchInputShape =\n            [batchSize].concat(generic_utils.toList(args.inputLength));\n      }\n    }\n    this.inputDim = args.inputDim;\n    generic_utils.assertPositiveInteger(this.inputDim, 'inputDim');\n    this.outputDim = args.outputDim;\n    generic_utils.assertPositiveInteger(this.outputDim, 'outputDim');\n    this.embeddingsInitializer = getInitializer(\n        args.embeddingsInitializer || this.DEFAULT_EMBEDDINGS_INITIALIZER);\n    this.embeddingsRegularizer = getRegularizer(args.embeddingsRegularizer);\n    this.activityRegularizer = getRegularizer(args.activityRegularizer);\n    this.embeddingsConstraint = getConstraint(args.embeddingsConstraint);\n    this.maskZero = args.maskZero;\n    this.supportsMasking = args.maskZero;\n    this.inputLength = args.inputLength;\n  }\n\n  public override build(inputShape: Shape|Shape[]): void {\n    this.embeddings = this.addWeight(\n        'embeddings', [this.inputDim, this.outputDim], this.dtype,\n        this.embeddingsInitializer, this.embeddingsRegularizer, true,\n        this.embeddingsConstraint);\n    this.built = true;\n  }\n\n  // Override warnOnIncompatibleInputShape because an embedding layer allows\n  // the input to have varying ranks.\n  protected override warnOnIncompatibleInputShape(inputShape: Shape) {}\n\n  override computeMask(inputs: Tensor|Tensor[], mask?: Tensor|Tensor[]):\n      Tensor {\n    return tidy(() => {\n      if (!this.maskZero) {\n        return null;\n      } else {\n        inputs = getExactlyOneTensor(inputs);\n        return notEqual(inputs, zerosLike(inputs));\n      }\n    });\n  }\n\n  override computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    inputShape = getExactlyOneShape(inputShape);\n    if (this.inputLength == null) {\n      return [...inputShape, this.outputDim];\n    }\n    // inputLength can be an array if input is 3D or higher.\n    const inLens: number[] = generic_utils.toList(this.inputLength);\n    if (inLens.length !== inputShape.length - 1) {\n      throw new ValueError(\n          `\"inputLength\" is ${this.inputLength}, but received ` +\n          `input shape has shape ${inputShape}`);\n    } else {\n      let i = 0;\n      for (let k = 0; k < inLens.length; ++k) {\n        const s1 = inLens[k];\n        const s2 = inputShape[k + 1];\n        if ((s1 != null) && (s2 != null) && (s1 !== s2)) {\n          throw new ValueError(\n              `\"inputLength\" is ${this.inputLength}, but received ` +\n              `input shape has shape ${inputShape}`);\n        } else if (s1 == null) {\n          inLens[i] = s2;\n        }\n        i++;\n      }\n    }\n    return [inputShape[0], ...inLens, this.outputDim];\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      // Embedding layer accepts only a single input.\n      let input = getExactlyOneTensor(inputs);\n      if (input.dtype !== 'int32') {\n        input = K.cast(input, 'int32');\n      }\n      const output =\n          K.gather(this.embeddings.read(), reshape(input, [input.size]));\n      return reshape(\n          output, getExactlyOneShape(this.computeOutputShape(input.shape)));\n    });\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config = {\n      inputDim: this.inputDim,\n      outputDim: this.outputDim,\n      embeddingsInitializer: serializeInitializer(this.embeddingsInitializer),\n      embeddingsRegularizer: serializeRegularizer(this.embeddingsRegularizer),\n      activityRegularizer: serializeRegularizer(this.activityRegularizer),\n      embeddingsConstraint: serializeConstraint(this.embeddingsConstraint),\n      maskZero: this.maskZero,\n      inputLength: this.inputLength\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(Embedding);\n"],"names":[],"mappings":";;;;AAAA;;;;;;;;GAQG,CAEH;;;;GAIG;;;;;AACH,OAAO,EAAC,QAAQ,EAAE,OAAO,EAAE,aAAa,EAAU,IAAI,EAAE,SAAS,EAAC,MAAM,uBAAuB,CAAC;AAEhG,OAAO,KAAK,CAAC,MAAM,yBAAyB,CAAC;AAC7C,OAAO,EAAmC,aAAa,EAAE,mBAAmB,EAAC,MAAM,gBAAgB,CAAC;AACpG,OAAO,EAAC,KAAK,EAAY,MAAM,oBAAoB,CAAC;AACpD,OAAO,EAAC,UAAU,EAAC,MAAM,WAAW,CAAC;AACrC,OAAO,EAAC,cAAc,EAAsC,oBAAoB,EAAC,MAAM,iBAAiB,CAAC;AAEzG,OAAO,EAAC,cAAc,EAAsC,oBAAoB,EAAC,MAAM,iBAAiB,CAAC;AAEzG,OAAO,KAAK,aAAa,MAAM,wBAAwB,CAAC;AACxD,OAAO,EAAC,kBAAkB,EAAE,mBAAmB,EAAC,MAAM,sBAAsB,CAAC;;;;;;;;;;AAiD7E,MAAa,SAAU,SAAQ,gTAAK;IAgBlC,YAAY,IAAwB,CAAA;QAClC,KAAK,CAAC,IAAI,CAAC,CAAC;QARN,IAAA,CAAA,UAAU,GAAkB,IAAI,CAAC;QAEhC,IAAA,CAAA,8BAA8B,GACnC,eAAe,CAAC;QAMlB,IAAI,IAAI,CAAC,eAAe,IAAI,IAAI,IAAI,IAAI,CAAC,UAAU,IAAI,IAAI,EAAE;YAC3D,wEAAwE;YACxE,qEAAqE;YACrE,kEAAkE;YAClE,qCAAqC;YACrC,IAAI,SAAS,GAAW,IAAI,CAAC;YAC7B,IAAI,IAAI,CAAC,SAAS,IAAI,IAAI,EAAE;gBAC1B,SAAS,GAAG,IAAI,CAAC,SAAS,CAAC;aAC5B;YACD,IAAI,IAAI,CAAC,WAAW,IAAI,IAAI,EAAE;gBAC5B,sDAAsD;gBACtD,oCAAoC;gBACpC,IAAI,CAAC,eAAe,GAAG;oBAAC,SAAS;oBAAE,IAAI;iBAAC,CAAC;aAC1C,MAAM;gBACL,sDAAsD;gBACtD,kDAAkD;gBAClD,IAAI,CAAC,eAAe,GAChB;oBAAC,SAAS;iBAAC,CAAC,MAAM,CAAC,aAAa,CAAC,uSAAM,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC,CAAC;aAChE;SACF;QACD,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC,QAAQ,CAAC;QAC9B,aAAa,CAAC,sTAAqB,CAAC,IAAI,CAAC,QAAQ,EAAE,UAAU,CAAC,CAAC;QAC/D,IAAI,CAAC,SAAS,GAAG,IAAI,CAAC,SAAS,CAAC;QAChC,aAAa,CAAC,sTAAqB,CAAC,IAAI,CAAC,SAAS,EAAE,WAAW,CAAC,CAAC;QACjE,IAAI,CAAC,qBAAqB,OAAG,mTAAc,EACvC,IAAI,CAAC,qBAAqB,IAAI,IAAI,CAAC,8BAA8B,CAAC,CAAC;QACvE,IAAI,CAAC,qBAAqB,OAAG,mTAAc,EAAC,IAAI,CAAC,qBAAqB,CAAC,CAAC;QACxE,IAAI,CAAC,mBAAmB,OAAG,mTAAc,EAAC,IAAI,CAAC,mBAAmB,CAAC,CAAC;QACpE,IAAI,CAAC,oBAAoB,OAAG,iTAAa,EAAC,IAAI,CAAC,oBAAoB,CAAC,CAAC;QACrE,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC,QAAQ,CAAC;QAC9B,IAAI,CAAC,eAAe,GAAG,IAAI,CAAC,QAAQ,CAAC;QACrC,IAAI,CAAC,WAAW,GAAG,IAAI,CAAC,WAAW,CAAC;IACtC,CAAC;IAEe,KAAK,CAAC,UAAyB,EAAA;QAC7C,IAAI,CAAC,UAAU,GAAG,IAAI,CAAC,SAAS,CAC5B,YAAY,EAAE;YAAC,IAAI,CAAC,QAAQ;YAAE,IAAI,CAAC,SAAS;SAAC,EAAE,IAAI,CAAC,KAAK,EACzD,IAAI,CAAC,qBAAqB,EAAE,IAAI,CAAC,qBAAqB,EAAE,IAAI,EAC5D,IAAI,CAAC,oBAAoB,CAAC,CAAC;QAC/B,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC;IACpB,CAAC;IAED,0EAA0E;IAC1E,mCAAmC;IAChB,4BAA4B,CAAC,UAAiB,EAAA,CAAG,CAAC;IAE5D,WAAW,CAAC,MAAuB,EAAE,IAAsB,EAAA;QAElE,WAAO,iPAAI,EAAC,GAAG,EAAE;YACf,IAAI,CAAC,IAAI,CAAC,QAAQ,EAAE;gBAClB,OAAO,IAAI,CAAC;aACb,MAAM;gBACL,MAAM,OAAG,gUAAmB,EAAC,MAAM,CAAC,CAAC;gBACrC,WAAO,8PAAQ,EAAC,MAAM,MAAE,gQAAS,EAAC,MAAM,CAAC,CAAC,CAAC;aAC5C;QACH,CAAC,CAAC,CAAC;IACL,CAAC;IAEQ,kBAAkB,CAAC,UAAyB,EAAA;QACnD,UAAU,OAAG,+TAAkB,EAAC,UAAU,CAAC,CAAC;QAC5C,IAAI,IAAI,CAAC,WAAW,IAAI,IAAI,EAAE;YAC5B,OAAO,CAAC;mBAAG,UAAU;gBAAE,IAAI,CAAC,SAAS;aAAC,CAAC;SACxC;QACD,wDAAwD;QACxD,MAAM,MAAM,GAAa,aAAa,CAAC,uSAAM,CAAC,IAAI,CAAC,WAAW,CAAC,CAAC;QAChE,IAAI,MAAM,CAAC,MAAM,KAAK,UAAU,CAAC,MAAM,GAAG,CAAC,EAAE;YAC3C,MAAM,IAAI,ySAAU,CAChB,CAAA,iBAAA,EAAoB,IAAI,CAAC,WAAW,CAAA,eAAA,CAAiB,GACrD,CAAA,sBAAA,EAAyB,UAAU,EAAE,CAAC,CAAC;SAC5C,MAAM;YACL,IAAI,CAAC,GAAG,CAAC,CAAC;YACV,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,EAAE,CAAC,CAAE;gBACtC,MAAM,EAAE,GAAG,MAAM,CAAC,CAAC,CAAC,CAAC;gBACrB,MAAM,EAAE,GAAG,UAAU,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC;gBAC7B,IAAI,AAAC,EAAE,IAAI,IAAI,CAAC,GAAK,CAAD,CAAG,IAAI,IAAI,CAAC,GAAK,CAAD,CAAG,KAAK,EAAE,CAAC,CAAE;oBAC/C,MAAM,IAAI,ySAAU,CAChB,CAAA,iBAAA,EAAoB,IAAI,CAAC,WAAW,CAAA,eAAA,CAAiB,GACrD,CAAA,sBAAA,EAAyB,UAAU,EAAE,CAAC,CAAC;iBAC5C,MAAM,IAAI,EAAE,IAAI,IAAI,EAAE;oBACrB,MAAM,CAAC,CAAC,CAAC,GAAG,EAAE,CAAC;iBAChB;gBACD,CAAC,EAAE,CAAC;aACL;SACF;QACD,OAAO;YAAC,UAAU,CAAC,CAAC,CAAC,EAAE;eAAG,MAAM;YAAE,IAAI,CAAC,SAAS;SAAC,CAAC;IACpD,CAAC;IAEQ,IAAI,CAAC,MAAuB,EAAE,MAAc,EAAA;QACnD,WAAO,iPAAI,EAAC,GAAG,EAAE;YACf,IAAI,CAAC,cAAc,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC;YACpC,+CAA+C;YAC/C,IAAI,KAAK,OAAG,gUAAmB,EAAC,MAAM,CAAC,CAAC;YACxC,IAAI,KAAK,CAAC,KAAK,KAAK,OAAO,EAAE;gBAC3B,KAAK,GAAG,CAAC,CAAC,kTAAI,CAAC,KAAK,EAAE,OAAO,CAAC,CAAC;aAChC;YACD,MAAM,MAAM,GACR,CAAC,CAAC,oTAAM,CAAC,IAAI,CAAC,UAAU,CAAC,IAAI,EAAE,MAAE,2PAAO,EAAC,KAAK,EAAE;gBAAC,KAAK,CAAC,IAAI;aAAC,CAAC,CAAC,CAAC;YACnE,WAAO,2PAAO,EACV,MAAM,MAAE,+TAAkB,EAAC,IAAI,CAAC,kBAAkB,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;QACxE,CAAC,CAAC,CAAC;IACL,CAAC;IAEQ,SAAS,GAAA;QAChB,MAAM,MAAM,GAAG;YACb,QAAQ,EAAE,IAAI,CAAC,QAAQ;YACvB,SAAS,EAAE,IAAI,CAAC,SAAS;YACzB,qBAAqB,MAAE,yTAAoB,EAAC,IAAI,CAAC,qBAAqB,CAAC;YACvE,qBAAqB,MAAE,yTAAoB,EAAC,IAAI,CAAC,qBAAqB,CAAC;YACvE,mBAAmB,MAAE,yTAAoB,EAAC,IAAI,CAAC,mBAAmB,CAAC;YACnE,oBAAoB,MAAE,uTAAmB,EAAC,IAAI,CAAC,oBAAoB,CAAC;YACpE,QAAQ,EAAE,IAAI,CAAC,QAAQ;YACvB,WAAW,EAAE,IAAI,CAAC,WAAW;SAC9B,CAAC;QACF,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;QACrC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;;AArID,gBAAA,EAAkB,CACX,UAAA,SAAS,GAAG,WAAW,AAAd,CAAe;;AAsIjC,ySAAa,CAAC,aAAa,CAAC,SAAS,CAAC,CAAC"}},
    {"offset": {"line": 1601, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-layers@4.22.0_@tensorflow+tfjs-core@4.22.0/node_modules/@tensorflow/tfjs-layers/dist/layers/noise.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-layers/src/layers/noise.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * TensorFlow.js Layers: Noise Layers.\n */\n\nimport {add, greaterEqual, mul, randomUniform, serialization, Tensor, tidy} from '@tensorflow/tfjs-core';\n\nimport * as K from '../backend/tfjs_backend';\nimport {Layer, LayerArgs} from '../engine/topology';\nimport {Shape} from '../keras_format/common';\nimport {Kwargs} from '../types';\nimport {getExactlyOneTensor} from '../utils/types_utils';\n\nexport declare interface GaussianNoiseArgs extends LayerArgs {\n  /** Standard Deviation.  */\n  stddev: number;\n}\n\nexport class GaussianNoise extends Layer {\n  /** @nocollapse */\n  static className = 'GaussianNoise';\n  readonly stddev: number;\n\n  constructor(args: GaussianNoiseArgs) {\n    super(args);\n    this.supportsMasking = true;\n    this.stddev = args.stddev;\n  }\n\n  override computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    return inputShape;\n  }\n\n  override getConfig() {\n    const baseConfig = super.getConfig();\n    const config = {stddev: this.stddev};\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      const input = getExactlyOneTensor(inputs);\n      const noised = () =>\n          add(K.randomNormal(input.shape, 0, this.stddev), input);\n      const output =\n          K.inTrainPhase(noised, () => input, kwargs['training'] || false);\n      return output;\n    });\n  }\n}\nserialization.registerClass(GaussianNoise);\n\nexport declare interface GaussianDropoutArgs extends LayerArgs {\n  /** drop probability.  */\n  rate: number;\n}\n\nexport class GaussianDropout extends Layer {\n  /** @nocollapse */\n  static className = 'GaussianDropout';\n  readonly rate: number;\n\n  constructor(args: GaussianDropoutArgs) {\n    super(args);\n    this.supportsMasking = true;\n    this.rate = args.rate;\n  }\n\n  override computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    return inputShape;\n  }\n\n  override getConfig() {\n    const baseConfig = super.getConfig();\n    const config = {rate: this.rate};\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      const input = getExactlyOneTensor(inputs);\n      if (this.rate > 0 && this.rate < 1) {\n        const noised = () => {\n          const stddev = Math.sqrt(this.rate / (1 - this.rate));\n          return mul(input, K.randomNormal(input.shape, 1, stddev));\n        };\n        return K.inTrainPhase(noised, () => input, kwargs['training'] || false);\n      }\n      return input;\n    });\n  }\n}\nserialization.registerClass(GaussianDropout);\n\nexport declare interface AlphaDropoutArgs extends LayerArgs {\n  /** drop probability.  */\n  rate: number;\n  /**\n   * A 1-D `Tensor` of type `int32`, representing the\n   * shape for randomly generated keep/drop flags.\n   */\n  noiseShape?: Shape;\n}\n\n/**\n * Applies Alpha Dropout to the input.\n *\n * As it is a regularization layer, it is only active at training time.\n *\n * Alpha Dropout is a `Dropout` that keeps mean and variance of inputs\n * to their original values, in order to ensure the self-normalizing property\n * even after this dropout.\n * Alpha Dropout fits well to Scaled Exponential Linear Units\n * by randomly setting activations to the negative saturation value.\n *\n * Arguments:\n *   - `rate`: float, drop probability (as with `Dropout`).\n *     The multiplicative noise will have\n *     standard deviation `sqrt(rate / (1 - rate))`.\n *   - `noise_shape`: A 1-D `Tensor` of type `int32`, representing the\n *     shape for randomly generated keep/drop flags.\n *\n * Input shape:\n *   Arbitrary. Use the keyword argument `inputShape`\n *   (tuple of integers, does not include the samples axis)\n *   when using this layer as the first layer in a model.\n *\n * Output shape:\n *   Same shape as input.\n *\n * References:\n *   - [Self-Normalizing Neural Networks](https://arxiv.org/abs/1706.02515)\n */\nexport class AlphaDropout extends Layer {\n  /** @nocollapse */\n  static className = 'AlphaDropout';\n  readonly rate: number;\n  readonly noiseShape: Shape;\n\n  constructor(args: AlphaDropoutArgs) {\n    super(args);\n    this.supportsMasking = true;\n    this.rate = args.rate;\n    this.noiseShape = args.noiseShape;\n  }\n\n  _getNoiseShape(inputs: Tensor|Tensor[]) {\n    return this.noiseShape || getExactlyOneTensor(inputs).shape;\n  }\n\n  override computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    return inputShape;\n  }\n\n  override getConfig() {\n    const baseConfig = super.getConfig();\n    const config = {rate: this.rate};\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      if (this.rate < 1 && this.rate > 0) {\n        const noiseShape = this._getNoiseShape(inputs);\n\n        const droppedInputs = () => {\n          const input = getExactlyOneTensor(inputs);\n\n          const alpha = 1.6732632423543772848170429916717;\n          const scale = 1.0507009873554804934193349852946;\n\n          const alphaP = -alpha * scale;\n\n          let keptIdx = greaterEqual(randomUniform(noiseShape), this.rate);\n\n          keptIdx = K.cast(keptIdx, 'float32');  // get default dtype.\n\n          // Get affine transformation params.\n          const a = ((1 - this.rate) * (1 + this.rate * alphaP ** 2)) ** -0.5;\n          const b = -a * alphaP * this.rate;\n\n          // Apply mask.\n          const x = add(mul(input, keptIdx), mul(add(keptIdx, -1), alphaP));\n\n          return add(mul(x, a), b);\n        };\n        return K.inTrainPhase(\n            droppedInputs, () => getExactlyOneTensor(inputs),\n            kwargs['training'] || false);\n      }\n      return inputs;\n    });\n  }\n}\nserialization.registerClass(AlphaDropout);\n"],"names":[],"mappings":";;;;;;;;AAAA;;;;;;;;GAQG,CAEH;;GAEG;;;;;;AAEH,OAAO,EAAC,GAAG,EAAE,YAAY,EAAE,GAAG,EAAE,aAAa,EAAE,aAAa,EAAU,IAAI,EAAC,MAAM,uBAAuB,CAAC;AAEzG,OAAO,KAAK,CAAC,MAAM,yBAAyB,CAAC;AAC7C,OAAO,EAAC,KAAK,EAAY,MAAM,oBAAoB,CAAC;AAGpD,OAAO,EAAC,mBAAmB,EAAC,MAAM,sBAAsB,CAAC;;;;;AAOzD,MAAa,aAAc,SAAQ,gTAAK;IAKtC,YAAY,IAAuB,CAAA;QACjC,KAAK,CAAC,IAAI,CAAC,CAAC;QACZ,IAAI,CAAC,eAAe,GAAG,IAAI,CAAC;QAC5B,IAAI,CAAC,MAAM,GAAG,IAAI,CAAC,MAAM,CAAC;IAC5B,CAAC;IAEQ,kBAAkB,CAAC,UAAyB,EAAA;QACnD,OAAO,UAAU,CAAC;IACpB,CAAC;IAEQ,SAAS,GAAA;QAChB,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;QACrC,MAAM,MAAM,GAAG;YAAC,MAAM,EAAE,IAAI,CAAC,MAAM;QAAA,CAAC,CAAC;QACrC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;IAEQ,IAAI,CAAC,MAAuB,EAAE,MAAc,EAAA;QACnD,WAAO,iPAAI,EAAC,GAAG,EAAE;YACf,IAAI,CAAC,cAAc,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC;YACpC,MAAM,KAAK,OAAG,gUAAmB,EAAC,MAAM,CAAC,CAAC;YAC1C,MAAM,MAAM,GAAG,GAAG,EAAE,GAChB,mPAAG,EAAC,CAAC,CAAC,0TAAY,CAAC,KAAK,CAAC,KAAK,EAAE,CAAC,EAAE,IAAI,CAAC,MAAM,CAAC,EAAE,KAAK,CAAC,CAAC;YAC5D,MAAM,MAAM,GACR,CAAC,CAAC,0TAAY,CAAC,MAAM,EAAE,GAAG,CAAG,CAAD,IAAM,EAAE,MAAM,CAAC,UAAU,CAAC,IAAI,KAAK,CAAC,CAAC;YACrE,OAAO,MAAM,CAAC;QAChB,CAAC,CAAC,CAAC;IACL,CAAC;;AA/BD,gBAAA,EAAkB,CACX,cAAA,SAAS,GAAG,eAAe,CAAC;;AAgCrC,ySAAa,CAAC,aAAa,CAAC,aAAa,CAAC,CAAC;AAO3C,MAAa,eAAgB,SAAQ,gTAAK;IAKxC,YAAY,IAAyB,CAAA;QACnC,KAAK,CAAC,IAAI,CAAC,CAAC;QACZ,IAAI,CAAC,eAAe,GAAG,IAAI,CAAC;QAC5B,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC,IAAI,CAAC;IACxB,CAAC;IAEQ,kBAAkB,CAAC,UAAyB,EAAA;QACnD,OAAO,UAAU,CAAC;IACpB,CAAC;IAEQ,SAAS,GAAA;QAChB,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;QACrC,MAAM,MAAM,GAAG;YAAC,IAAI,EAAE,IAAI,CAAC,IAAI;QAAA,CAAC,CAAC;QACjC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;IAEQ,IAAI,CAAC,MAAuB,EAAE,MAAc,EAAA;QACnD,WAAO,iPAAI,EAAC,GAAG,EAAE;YACf,IAAI,CAAC,cAAc,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC;YACpC,MAAM,KAAK,OAAG,gUAAmB,EAAC,MAAM,CAAC,CAAC;YAC1C,IAAI,IAAI,CAAC,IAAI,GAAG,CAAC,IAAI,IAAI,CAAC,IAAI,GAAG,CAAC,EAAE;gBAClC,MAAM,MAAM,GAAG,GAAG,EAAE;oBAClB,MAAM,MAAM,GAAG,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,GAAG,CAAC,CAAC,GAAG,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC;oBACtD,WAAO,mPAAG,EAAC,KAAK,EAAE,CAAC,CAAC,0TAAY,CAAC,KAAK,CAAC,KAAK,EAAE,CAAC,EAAE,MAAM,CAAC,CAAC,CAAC;gBAC5D,CAAC,CAAC;gBACF,OAAO,CAAC,CAAC,0TAAY,CAAC,MAAM,EAAE,GAAG,CAAG,CAAD,IAAM,EAAE,MAAM,CAAC,UAAU,CAAC,IAAI,KAAK,CAAC,CAAC;aACzE;YACD,OAAO,KAAK,CAAC;QACf,CAAC,CAAC,CAAC;IACL,CAAC;;AAlCD,gBAAA,EAAkB,CACX,gBAAA,SAAS,GAAG,iBAAiB,CAAC;;AAmCvC,ySAAa,CAAC,aAAa,CAAC,eAAe,CAAC,CAAC;AAY7C;;;;;;;;;;;;;;;;;;;;;;;;;;;;GA4BG,CACH,MAAa,YAAa,SAAQ,gTAAK;IAMrC,YAAY,IAAsB,CAAA;QAChC,KAAK,CAAC,IAAI,CAAC,CAAC;QACZ,IAAI,CAAC,eAAe,GAAG,IAAI,CAAC;QAC5B,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC,IAAI,CAAC;QACtB,IAAI,CAAC,UAAU,GAAG,IAAI,CAAC,UAAU,CAAC;IACpC,CAAC;IAED,cAAc,CAAC,MAAuB,EAAA;QACpC,OAAO,IAAI,CAAC,UAAU,QAAI,gUAAmB,EAAC,MAAM,CAAC,CAAC,KAAK,CAAC;IAC9D,CAAC;IAEQ,kBAAkB,CAAC,UAAyB,EAAA;QACnD,OAAO,UAAU,CAAC;IACpB,CAAC;IAEQ,SAAS,GAAA;QAChB,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;QACrC,MAAM,MAAM,GAAG;YAAC,IAAI,EAAE,IAAI,CAAC,IAAI;QAAA,CAAC,CAAC;QACjC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;IAEQ,IAAI,CAAC,MAAuB,EAAE,MAAc,EAAA;QACnD,WAAO,iPAAI,EAAC,GAAG,EAAE;YACf,IAAI,IAAI,CAAC,IAAI,GAAG,CAAC,IAAI,IAAI,CAAC,IAAI,GAAG,CAAC,EAAE;gBAClC,MAAM,UAAU,GAAG,IAAI,CAAC,cAAc,CAAC,MAAM,CAAC,CAAC;gBAE/C,MAAM,aAAa,GAAG,GAAG,EAAE;oBACzB,MAAM,KAAK,OAAG,gUAAmB,EAAC,MAAM,CAAC,CAAC;oBAE1C,MAAM,KAAK,GAAG,iCAAiC,CAAC;oBAChD,MAAM,KAAK,GAAG,iCAAiC,CAAC;oBAEhD,MAAM,MAAM,GAAG,CAAC,KAAK,GAAG,KAAK,CAAC;oBAE9B,IAAI,OAAO,OAAG,sQAAY,MAAC,wQAAa,EAAC,UAAU,CAAC,EAAE,IAAI,CAAC,IAAI,CAAC,CAAC;oBAEjE,OAAO,GAAG,CAAC,CAAC,kTAAI,CAAC,OAAO,EAAE,SAAS,CAAC,CAAC,CAAE,qBAAqB;oBAE5D,oCAAoC;oBACpC,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,IAAI,CAAC,GAAG,CAAC,CAAC,GAAG,IAAI,CAAC,IAAI,GAAG,MAAM,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC;oBACpE,MAAM,CAAC,GAAG,CAAC,CAAC,GAAG,MAAM,GAAG,IAAI,CAAC,IAAI,CAAC;oBAElC,cAAc;oBACd,MAAM,CAAC,OAAG,mPAAG,MAAC,mPAAG,EAAC,KAAK,EAAE,OAAO,CAAC,MAAE,mPAAG,MAAC,mPAAG,EAAC,OAAO,EAAE,CAAC,CAAC,CAAC,EAAE,MAAM,CAAC,CAAC,CAAC;oBAElE,WAAO,mPAAG,MAAC,mPAAG,EAAC,CAAC,EAAE,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;gBAC3B,CAAC,CAAC;gBACF,OAAO,CAAC,CAAC,0TAAY,CACjB,aAAa,EAAE,GAAG,EAAE,GAAC,gUAAmB,EAAC,MAAM,CAAC,EAChD,MAAM,CAAC,UAAU,CAAC,IAAI,KAAK,CAAC,CAAC;aAClC;YACD,OAAO,MAAM,CAAC;QAChB,CAAC,CAAC,CAAC;IACL,CAAC;;AA3DD,gBAAA,EAAkB,CACX,aAAA,SAAS,GAAG,cAAc,CAAC;;AA4DpC,ySAAa,CAAC,aAAa,CAAC,YAAY,CAAC,CAAC"}},
    {"offset": {"line": 1778, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-layers@4.22.0_@tensorflow+tfjs-core@4.22.0/node_modules/@tensorflow/tfjs-layers/dist/layers/normalization.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-layers/src/layers/normalization.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * Normalization layers.\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\nimport {moments, reshape, serialization, Tensor, Tensor1D, Tensor2D, Tensor3D, Tensor4D, tidy, util} from '@tensorflow/tfjs-core';\n\nimport {Constraint, ConstraintIdentifier, getConstraint, serializeConstraint} from '../constraints';\nimport {InputSpec, Layer, LayerArgs} from '../engine/topology';\nimport {NotImplementedError, ValueError} from '../errors';\nimport {getInitializer, Initializer, InitializerIdentifier, serializeInitializer} from '../initializers';\nimport {Shape} from '../keras_format/common';\nimport {getRegularizer, Regularizer, RegularizerIdentifier, serializeRegularizer} from '../regularizers';\nimport {Kwargs} from '../types';\nimport * as generic_utils from '../utils/generic_utils';\nimport * as math_utils from '../utils/math_utils';\nimport {getExactlyOneShape, getExactlyOneTensor} from '../utils/types_utils';\nimport {LayerVariable} from '../variables';\n\n/**\n * Applies batch normalization on x given mean, var, beta and gamma.\n *\n * I.e. returns:\n *   `output = (x - mean) / (sqrt(var) + epsilon) * gamma + beta`\n *\n * @param x Input tensor.\n * @param mean Mean of batch.\n * @param variance Variance of batch.\n * @param beta Tensor with which to center the input.\n * @param gamma Tensor by which to scale the input.\n * @param epsilon Fuzz factor.\n * @returns The result of the batch normalization.\n */\nexport function batchNormalization(\n    x: Tensor, mean: Tensor, variance: Tensor, beta?: Tensor, gamma?: Tensor,\n    epsilon = 1e-3): Tensor {\n  let out: Tensor;\n  if (x.rank === 2) {\n    out = tfc.batchNorm2d(\n        x as Tensor2D, mean as Tensor2D | Tensor1D,\n        variance as Tensor2D | Tensor1D, beta as Tensor2D | Tensor1D,\n        gamma as Tensor2D | Tensor1D, epsilon);\n  } else if (x.rank === 3) {\n    // TODO(cais): Check rank; give proper error message.\n    out = tfc.batchNorm3d(\n        x as Tensor3D, mean as Tensor3D | Tensor1D,\n        variance as Tensor3D | Tensor1D, beta as Tensor3D | Tensor1D,\n        gamma as Tensor3D | Tensor1D, epsilon);\n  } else if (x.rank === 4) {\n    out = tfc.batchNorm4d(\n        x as Tensor4D, mean as Tensor4D | Tensor1D,\n        variance as Tensor4D | Tensor1D, beta as Tensor4D | Tensor1D,\n        gamma as Tensor4D | Tensor1D, epsilon);\n  } else {\n    throw new NotImplementedError(\n        `batchNormalization is not implemented for array of rank ${x.rank} ` +\n        `yet`);\n  }\n  return out;\n}\n\n/**\n * Non-broadcasting batch normalization for use in training (not inference).\n *\n * The input is normalized to zero mean and unit variance along the\n * `reductionAxes`, followed by scaling with `gamma` and shifted by `beta`.\n * The result of that is returned as the first element\n * of the returned `Array`. The other two elements are the mean and variance,\n * respectively.\n *\n * @param x Input tensor to be normalized.\n * @param gamma Tensor by which to scale the input.\n * @param beta Tensor by which to center the input.\n * @param reductionAxes Axes over which to normalize.\n * @param epsilon Fuzz factor.\n * @returns An `Array` of three `Tensors`:\n *   [normalized tensor, mean of input, variance of input].\n */\nfunction regularNormalizeBatchInTraining(\n    x: Tensor, gamma: Tensor, beta: Tensor, reductionAxes: number[],\n    epsilon = 1e-3): [Tensor, Tensor, Tensor] {\n  return tidy(() => {\n           const meanAndVariance = tfc.moments(x, reductionAxes);\n           const mean = meanAndVariance.mean;\n           const variance = meanAndVariance.variance;\n           const normed =\n               batchNormalization(x, mean, variance, beta, gamma, epsilon);\n           return [normed, mean, variance];\n         }) as [Tensor, Tensor, Tensor];\n}\n\n/**\n * Broadcasting batch normalization for use in training (not inference).\n *\n * The input is normalized to zero mean and unit variance along the\n * `reductionAxes`, followed by scaling with `gamma` and shifted by `beta`.\n * The result of that is returned as the first element\n * of the returned `Array`. The other two elements are the mean and variance,\n * respectively.\n *\n * @param x Input tensor to be normalized.\n * @param gamma Tensor by which to scale the input.\n * @param beta Tensor by which to center the input.\n * @param reductionAxes Axes over which to normalize.\n * @param epsilon Fuzz factor.\n * @returns An `Array` of three `Tensors`:\n *   [normalized tensor, mean of input, variance of input].\n */\nfunction broadcastNormalizeBatchInTraining(\n    x: Tensor, gamma: Tensor, beta: Tensor, reductionAxes: number[],\n    epsilon = 1e-3): [Tensor, Tensor, Tensor] {\n  return tidy(() => {\n           const meanAndVariance = tfc.moments(x, reductionAxes);\n           const mean = meanAndVariance.mean;\n           const variance = meanAndVariance.variance;\n           const targetShape: number[] = [];\n           for (const axis of math_utils.range(0, x.rank)) {\n             if (reductionAxes.indexOf(axis) !== -1) {\n               targetShape.push(1);\n             } else {\n               targetShape.push(x.shape[axis]);\n             }\n           }\n           const broadcastMean = reshape(mean, targetShape);\n           const broadcastVariance = reshape(variance, targetShape);\n           const broadcastGamma =\n               gamma == null ? null : reshape(gamma, targetShape);\n           const broadcastBeta =\n               beta == null ? null : reshape(beta, targetShape);\n           const normed = batchNormalization(\n               x, broadcastMean, broadcastVariance, broadcastBeta,\n               broadcastGamma, epsilon);\n           return [normed, mean, variance];\n         }) as [Tensor, Tensor, Tensor];\n}\n\n/**\n * Batch normalization for use in training (not inference).\n *\n * @param x Input tensor to be normalized.\n * @param gamma Tensor by which to scale the input.\n * @param beta Tensor by which to center the input.\n * @param reductionAxes Axes over which to normalize.\n * @param epsilon Fuzz factor.\n * @returns An `Array` of three `Tensors`:\n *   [normalized tensor, mean of input, variance of input].\n */\nexport function normalizeBatchInTraining(\n    x: Tensor, gamma: Tensor, beta: Tensor, reductionAxes: number[],\n    epsilon = 1e-3): [Tensor, Tensor, Tensor] {\n  if (util.arraysEqual(\n          reductionAxes.slice().sort(), math_utils.range(0, x.rank - 1))) {\n    return regularNormalizeBatchInTraining(\n        x, gamma, beta, reductionAxes, epsilon);\n  } else {\n    return broadcastNormalizeBatchInTraining(\n        x, gamma, beta, reductionAxes, epsilon);\n  }\n}\n\nexport declare interface BatchNormalizationLayerArgs extends LayerArgs {\n  /**\n   * The integer axis that should be normalized (typically the features axis).\n   * Defaults to -1.\n   *\n   * For instance, after a `Conv2D` layer with `data_format=\"channels_first\"`,\n   * set `axis=1` in `batchNormalization`.\n   */\n  axis?: number;\n\n  /**\n   * Momentum of the moving average. Defaults to 0.99.\n   */\n  momentum?: number;\n\n  /**\n   * Small float added to the variance to avoid dividing by zero. Defaults to\n   * 1e-3.\n   */\n  epsilon?: number;\n\n  /**\n   * If `true`, add offset of `beta` to normalized tensor.\n   * If `false`, `beta` is ignored.\n   * Defaults to `true`.\n   */\n  center?: boolean;\n\n  /**\n   * If `true`, multiply by `gamma`.\n   * If `false`, `gamma` is not used.\n   * When the next layer is linear (also e.g. `nn.relu`),\n   * this can be disabled since the scaling will be done by the next layer.\n   * Defaults to `true`.\n   */\n  scale?: boolean;\n\n  /**\n   * Initializer for the beta weight.\n   *  Defaults to 'zeros'.\n   */\n  betaInitializer?: InitializerIdentifier|Initializer;\n\n  /**\n   * Initializer for the gamma weight.\n   *  Defaults to `ones`.\n   */\n  gammaInitializer?: InitializerIdentifier|Initializer;\n\n  /**\n   * Initializer for the moving mean.\n   * Defaults to `zeros`\n   */\n  movingMeanInitializer?: InitializerIdentifier|Initializer;\n\n  /**\n   * Initializer for the moving variance.\n   *  Defaults to 'Ones'.\n   */\n  movingVarianceInitializer?: InitializerIdentifier|Initializer;\n\n  /**\n   * Constraint for the beta weight.\n   */\n  betaConstraint?: ConstraintIdentifier|Constraint;\n\n  /**\n   * Constraint for gamma weight.\n   */\n  gammaConstraint?: ConstraintIdentifier|Constraint;\n\n  /**\n   * Regularizer for the beta weight.\n   */\n  betaRegularizer?: RegularizerIdentifier|Regularizer;\n\n  /**\n   * Regularizer for the gamma weight.\n   */\n  gammaRegularizer?: RegularizerIdentifier|Regularizer;\n}\n\nexport class BatchNormalization extends Layer {\n  /** @nocollapse */\n  static className = 'BatchNormalization';\n  private readonly axis: number;\n  private readonly momentum: number;\n  private readonly epsilon: number;\n  private readonly center: boolean;\n  private readonly scale: boolean;\n  private readonly betaInitializer: Initializer;\n  private readonly gammaInitializer: Initializer;\n  private readonly movingMeanInitializer: Initializer;\n  private readonly movingVarianceInitializer: Initializer;\n  private readonly betaConstraint: Constraint;\n  private readonly gammaConstraint: Constraint;\n  private readonly betaRegularizer: Regularizer;\n  private readonly gammaRegularizer: Regularizer;\n  private gamma: LayerVariable;\n  private beta: LayerVariable;\n  private movingMean: LayerVariable;\n  private movingVariance: LayerVariable;\n\n  constructor(args?: BatchNormalizationLayerArgs) {\n    if (args == null) {\n      args = {};\n    }\n    super(args);\n\n    this.supportsMasking = true;\n    this.axis = args.axis == null ? -1 : args.axis;\n    this.momentum = args.momentum == null ? 0.99 : args.momentum;\n    this.epsilon = args.epsilon == null ? 1e-3 : args.epsilon;\n    this.center = args.center == null ? true : args.center;\n    this.scale = args.scale == null ? true : args.scale;\n    this.betaInitializer = getInitializer(args.betaInitializer || 'zeros');\n    this.gammaInitializer = getInitializer(args.gammaInitializer || 'ones');\n    this.movingMeanInitializer =\n        getInitializer(args.movingMeanInitializer || 'zeros');\n    this.movingVarianceInitializer =\n        getInitializer(args.movingVarianceInitializer || 'ones');\n    this.betaConstraint = getConstraint(args.betaConstraint);\n    this.gammaConstraint = getConstraint(args.gammaConstraint);\n    this.betaRegularizer = getRegularizer(args.betaRegularizer);\n    this.gammaRegularizer = getRegularizer(args.gammaRegularizer);\n  }\n\n  public override build(inputShape: Shape|Shape[]): void {\n    inputShape = getExactlyOneShape(inputShape);\n    const axis = this.axis >= 0 ? this.axis : (this.axis + inputShape.length);\n    const dim = inputShape[axis];\n    if (dim == null) {\n      throw new ValueError(\n          `Axis ${axis} of input tensor should have a defined dimension but ` +\n          `the layer received an input with shape ` +\n          `${JSON.stringify(inputShape)}.`);\n    }\n    this.inputSpec =\n        [new InputSpec({ndim: inputShape.length, axes: {[axis]: dim}})];\n    const shape = [dim];\n    if (this.scale) {\n      this.gamma = this.addWeight(\n          'gamma', shape, null, this.gammaInitializer, this.gammaRegularizer,\n          true, this.gammaConstraint);\n    }\n    if (this.center) {\n      this.beta = this.addWeight(\n          'beta', shape, null, this.betaInitializer, this.betaRegularizer, true,\n          this.betaConstraint);\n    }\n    this.movingMean = this.addWeight(\n        'moving_mean', shape, null, this.movingMeanInitializer, null, false);\n    this.movingVariance = this.addWeight(\n        'moving_variance', shape, null, this.movingVarianceInitializer, null,\n        false);\n    this.built = true;\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      const training = kwargs['training'] == null ? false : kwargs['training'];\n      const input = getExactlyOneTensor(inputs);\n      const inputShape = input.shape;\n      const ndim = inputShape.length;\n      const reductionAxes = math_utils.range(0, ndim);\n      const axis = this.axis >= 0 ? this.axis : (this.axis + ndim);\n      reductionAxes.splice(axis, 1);\n      const broadcastShape = generic_utils.pyListRepeat(1, ndim);\n      broadcastShape[axis] = inputShape[axis];\n\n      const sortedReductionAxes = reductionAxes.slice();\n      sortedReductionAxes.sort();\n      const needsBroadcasting = !util.arraysEqual(\n          sortedReductionAxes, math_utils.range(0, ndim).slice(0, ndim - 1));\n\n      const normalizeInference: () => Tensor = () => {\n        if (needsBroadcasting) {\n          const broadcastMovingMean =\n              reshape(this.movingMean.read(), broadcastShape);\n          const broadcastMovingVariance =\n              reshape(this.movingVariance.read(), broadcastShape);\n          const broadcastBeta =\n              this.center ? reshape(this.beta.read(), broadcastShape) : null;\n          const broadcastGamma =\n              this.scale ? reshape(this.gamma.read(), broadcastShape) : null;\n          return batchNormalization(\n              input, broadcastMovingMean, broadcastMovingVariance,\n              broadcastBeta, broadcastGamma, this.epsilon);\n        } else {\n          return batchNormalization(\n              input, this.movingMean.read(), this.movingVariance.read(),\n              this.beta == null ? null : this.beta.read(),\n              this.gamma == null ? null : this.gamma.read(), this.epsilon);\n        }\n      };\n\n      if (!training) {\n        return normalizeInference();\n      }\n\n      const [normedTraining, mean, variance] = normalizeBatchInTraining(\n          input, this.gamma.read(), this.beta.read(), reductionAxes,\n          this.epsilon);\n\n      const doMovingAverage =\n          (variable: LayerVariable, value: Tensor, momentum: number): void => {\n            tfc.tidy(() => {\n              const decay = 1 - momentum;\n              const origValue = variable.read();\n              const updateDelta = tfc.mul(tfc.sub(origValue, value), decay);\n              variable.write(tfc.sub(origValue, updateDelta));\n            });\n          };\n\n      // Perform updates to moving mean and moving variance for training.\n      // Porting Note: In PyKeras, these updates to `movingMean` and\n      //   `movingAverage` are done as a deferred Graph, added to the `Layer`'s\n      //   `update`s using the `add_update()` method. Here we do it imperatively\n      //   and encapsulate the updates in a function that is invoked\n      //   immediately.\n      const updateMovingMeanAndVariance = () => {\n        doMovingAverage(this.movingMean, mean, this.momentum);\n        doMovingAverage(this.movingVariance, variance, this.momentum);\n      };\n      updateMovingMeanAndVariance();\n\n      return normedTraining;\n    });\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config: serialization.ConfigDict = {\n      axis: this.axis,\n      momentum: this.momentum,\n      epsilon: this.epsilon,\n      center: this.center,\n      scale: this.scale,\n      betaInitializer: serializeInitializer(this.betaInitializer),\n      gammaInitializer: serializeInitializer(this.gammaInitializer),\n      movingMeanInitializer: serializeInitializer(this.movingMeanInitializer),\n      movingVarianceInitializer:\n          serializeInitializer(this.movingVarianceInitializer),\n      betaRegularizer: serializeRegularizer(this.betaRegularizer),\n      gammaRegularizer: serializeRegularizer(this.gammaRegularizer),\n      betaConstraint: serializeConstraint(this.betaConstraint),\n      gammaConstraint: serializeConstraint(this.gammaConstraint)\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(BatchNormalization);\n\nexport interface LayerNormalizationLayerArgs extends LayerArgs {\n  /**\n   * The axis or axes that should be normalized (typically, the feature axis).\n   * Defaults to -1 (the last axis).\n   */\n  axis?: number|number[];\n\n  /**\n   * A small positive float added to variance to avoid division by zero.\n   * Defaults to 1e-3.\n   */\n  epsilon?: number;\n\n  /**\n   * If `true`, add offset of `beta` to normalized tensor.\n   * If `false`, `beta` is ignored.\n   * Default: `true`.\n   */\n  center?: boolean;\n\n  /**\n   * If `true`, multiply output by `gamma`.\n   * If `false`, `gamma` is not used.\n   * When the next layer is linear, this can be disabled since scaling will\n   * be done by the next layer.\n   * Default: `true`.\n   */\n  scale?: boolean;\n\n  /**\n   * Initializer for the beta weight.\n   * Default: `'zeros'`.\n   */\n  betaInitializer?: InitializerIdentifier|Initializer;\n\n  /**\n   * Initializer for the gamma weight.\n   * Default: `'ones'`.\n   */\n  gammaInitializer?: InitializerIdentifier|Initializer;\n\n  /** Regularizer for the beta weight. */\n  betaRegularizer?: RegularizerIdentifier|Regularizer;\n\n  /** Regularizer for the gamma weight. */\n  gammaRegularizer?: RegularizerIdentifier|Regularizer;\n}\n\nexport class LayerNormalization extends Layer {\n  /** @nocollapse */\n  static className = 'LayerNormalization';\n\n  private axis: number|number[];\n  readonly epsilon: number;\n  readonly center: boolean;\n  readonly scale: boolean;\n  readonly betaInitializer: Initializer;\n  readonly gammaInitializer: Initializer;\n  readonly betaRegularizer: Regularizer;\n  readonly gammaRegularizer: Regularizer;\n\n  private gamma: LayerVariable;\n  private beta: LayerVariable;\n\n  constructor(args?: LayerNormalizationLayerArgs) {\n    if (args == null) {\n      args = {};\n    }\n    super(args);\n\n    this.axis = args.axis == null ? -1 : args.axis;\n    if (typeof this.axis === 'number') {\n      if (!Number.isInteger(this.axis)) {\n        throw new Error(\n            `Expected axis to be an integer, but received ${this.axis}`);\n      }\n    } else if (Array.isArray(this.axis)) {\n      for (const axis of this.axis) {\n        if (!Number.isInteger(axis)) {\n          throw new Error(\n              `Expected axis to be an array of integers, ` +\n              `but received ${JSON.stringify(this.axis)}`);\n        }\n      }\n    } else {\n      throw new Error(\n          `Expected axis to be an integer or an array of integers, ` +\n          `but received ${JSON.stringify(this.axis)}`);\n    }\n\n    this.epsilon = args.epsilon == null ? 1e-3 : args.epsilon;\n    this.center = args.center == null ? true : args.center;\n    this.scale = args.scale == null ? true : args.scale;\n    this.betaInitializer = getInitializer(args.betaInitializer || 'zeros');\n    this.gammaInitializer = getInitializer(args.gammaInitializer || 'ones');\n    this.betaRegularizer = getRegularizer(args.betaRegularizer);\n    this.gammaRegularizer = getRegularizer(args.gammaRegularizer);\n\n    this.supportsMasking = true;\n  }\n\n  public override build(inputShape: Shape|Shape[]): void {\n    inputShape = getExactlyOneShape(inputShape);\n    const nDims = inputShape.length;\n\n    // Convert axis to array and resolve negatives.\n    if (typeof this.axis === 'number') {\n      this.axis = [this.axis];\n    }\n    for (let i = 0; i < this.axis.length; ++i) {\n      if (this.axis[i] < 0) {\n        this.axis[i] += nDims;\n      }\n    }\n\n    // Further validate axes.\n    for (const axis of this.axis) {\n      if (axis < 0 || axis >= nDims) {\n        throw new Error(`Invalid axis: ${axis}`);\n      }\n    }\n    if (this.axis.length !== generic_utils.unique(this.axis).length) {\n      throw new Error(`Found duplicate axes in: ${this.axis}`);\n    }\n\n    const paramShape = this.axis.map(axis => inputShape[axis]) as number[];\n\n    const trainable = true;\n    if (this.scale) {\n      this.gamma = this.addWeight(\n          'gamma', paramShape, 'float32', this.gammaInitializer,\n          this.gammaRegularizer, trainable);\n    } else {\n      this.gamma = null;\n    }\n    if (this.center) {\n      this.beta = this.addWeight(\n          'beta', paramShape, 'float32', this.betaInitializer,\n          this.betaRegularizer, trainable);\n    } else {\n      this.beta = null;\n    }\n\n    this.built = true;\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    const input = getExactlyOneTensor(inputs);\n    const inputShape = input.shape;\n    const nDims = inputShape.length;\n\n    return tidy(() => {\n      const keepDims = true;\n      let {mean, variance} = moments(input, this.axis, keepDims);\n      const broadcastShape = generic_utils.pyListRepeat(1, nDims);\n      for (const dim of this.axis as number[]) {\n        broadcastShape[dim] = inputShape[dim];\n      }\n\n      const broadcast = (v: Tensor) => {\n        if (v != null && v.shape.length !== nDims) {\n          return tfc.reshape(v, broadcastShape);\n        } else {\n          return v;\n        }\n      };\n\n      let scale = this.scale ? broadcast(this.gamma.read()) : null;\n      let offset = this.center ? broadcast(this.beta.read()) : null;\n\n      // TODO(https://github.com/tensorflow/tfjs/issues/2120): The tiling below\n      // is a workaround for the limitation of core's batchNormalization?d don't\n      // support broadcasting in their gradients. In addition, the tiling is\n      // necessary to ensure correctness on the browser CPU backend regardless\n      // of forward or backward computation. Remove this workaround once the\n      // limitation is addressed. See .\n      const momentsTiling: number[] = [];\n      const scaleOffsetTiling: number[] = [];\n      for (let i = 0; i < nDims; ++i) {\n        if ((this.axis as number[]).indexOf(i) !== -1) {\n          momentsTiling.push(inputShape[i]);\n          scaleOffsetTiling.push(1);\n        } else {\n          momentsTiling.push(1);\n          scaleOffsetTiling.push(inputShape[i]);\n        }\n      }\n      mean = tfc.tile(mean, momentsTiling);\n      variance = tfc.tile(variance, momentsTiling);\n      if (scale != null) {\n        scale = tfc.tile(scale, scaleOffsetTiling);\n      }\n      if (offset != null) {\n        offset = tfc.tile(offset, scaleOffsetTiling);\n      }\n\n      return batchNormalization(\n          input, mean, variance, offset, scale, this.epsilon);\n    });\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config: serialization.ConfigDict = {\n      axis: this.axis,\n      epsilon: this.epsilon,\n      center: this.center,\n      scale: this.scale,\n      betaInitializer: serializeInitializer(this.betaInitializer),\n      gammaInitializer: serializeInitializer(this.gammaInitializer),\n      betaRegularizer: serializeRegularizer(this.betaRegularizer),\n      gammaRegularizer: serializeRegularizer(this.gammaRegularizer)\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(LayerNormalization);\n"],"names":[],"mappings":";;;;;;;;;;AAAA;;;;;;;;GAQG,CAEH;;GAEG;;;;;;;;;AAEH,OAAO,KAAK,GAAG,MAAM,uBAAuB,CAAC;;AAC7C,OAAO,EAAC,OAAO,EAAE,OAAO,EAAE,aAAa,EAAkD,IAAI,EAAE,IAAI,EAAC,MAAM,uBAAuB,CAAC;AAElI,OAAO,EAAmC,aAAa,EAAE,mBAAmB,EAAC,MAAM,gBAAgB,CAAC;AACpG,OAAO,EAAC,SAAS,EAAE,KAAK,EAAY,MAAM,oBAAoB,CAAC;AAC/D,OAAO,EAAC,mBAAmB,EAAE,UAAU,EAAC,MAAM,WAAW,CAAC;AAC1D,OAAO,EAAC,cAAc,EAAsC,oBAAoB,EAAC,MAAM,iBAAiB,CAAC;AAEzG,OAAO,EAAC,cAAc,EAAsC,oBAAoB,EAAC,MAAM,iBAAiB,CAAC;AAEzG,OAAO,KAAK,aAAa,MAAM,wBAAwB,CAAC;AACxD,OAAO,KAAK,UAAU,MAAM,qBAAqB,CAAC;AAClD,OAAO,EAAC,kBAAkB,EAAE,mBAAmB,EAAC,MAAM,sBAAsB,CAAC;;;;;;;;;;;AAiBvE,SAAU,kBAAkB,CAC9B,CAAS,EAAE,IAAY,EAAE,QAAgB,EAAE,IAAa,EAAE,KAAc,EACxE,OAAO,GAAG,IAAI;IAChB,IAAI,GAAW,CAAC;IAChB,IAAI,CAAC,CAAC,IAAI,KAAK,CAAC,EAAE;QAChB,GAAG,GAAG,GAAG,CAAC,+PAAW,CACjB,CAAa,EAAE,IAA2B,EAC1C,QAA+B,EAAE,IAA2B,EAC5D,KAA4B,EAAE,OAAO,CAAC,CAAC;KAC5C,MAAM,IAAI,CAAC,CAAC,IAAI,KAAK,CAAC,EAAE;QACvB,qDAAqD;QACrD,GAAG,GAAG,GAAG,CAAC,+PAAW,CACjB,CAAa,EAAE,IAA2B,EAC1C,QAA+B,EAAE,IAA2B,EAC5D,KAA4B,EAAE,OAAO,CAAC,CAAC;KAC5C,MAAM,IAAI,CAAC,CAAC,IAAI,KAAK,CAAC,EAAE;QACvB,GAAG,GAAG,GAAG,CAAC,+PAAW,CACjB,CAAa,EAAE,IAA2B,EAC1C,QAA+B,EAAE,IAA2B,EAC5D,KAA4B,EAAE,OAAO,CAAC,CAAC;KAC5C,MAAM;QACL,MAAM,IAAI,kTAAmB,CACzB,CAAA,wDAAA,EAA2D,CAAC,CAAC,IAAI,CAAA,CAAA,CAAG,GACpE,CAAA,GAAA,CAAK,CAAC,CAAC;KACZ;IACD,OAAO,GAAG,CAAC;AACb,CAAC;AAED;;;;;;;;;;;;;;;;GAgBG,CACH,SAAS,+BAA+B,CACpC,CAAS,EAAE,KAAa,EAAE,IAAY,EAAE,aAAuB,EAC/D,OAAO,GAAG,IAAI;IAChB,WAAO,iPAAI,EAAC,GAAG,EAAE;QACR,MAAM,eAAe,GAAG,GAAG,CAAC,uPAAO,CAAC,CAAC,EAAE,aAAa,CAAC,CAAC;QACtD,MAAM,IAAI,GAAG,eAAe,CAAC,IAAI,CAAC;QAClC,MAAM,QAAQ,GAAG,eAAe,CAAC,QAAQ,CAAC;QAC1C,MAAM,MAAM,GACR,kBAAkB,CAAC,CAAC,EAAE,IAAI,EAAE,QAAQ,EAAE,IAAI,EAAE,KAAK,EAAE,OAAO,CAAC,CAAC;QAChE,OAAO;YAAC,MAAM;YAAE,IAAI;YAAE,QAAQ;SAAC,CAAC;IAClC,CAAC,CAA6B,CAAC;AACxC,CAAC;AAED;;;;;;;;;;;;;;;;GAgBG,CACH,SAAS,iCAAiC,CACtC,CAAS,EAAE,KAAa,EAAE,IAAY,EAAE,aAAuB,EAC/D,OAAO,GAAG,IAAI;IAChB,WAAO,iPAAI,EAAC,GAAG,EAAE;QACR,MAAM,eAAe,GAAG,GAAG,CAAC,uPAAO,CAAC,CAAC,EAAE,aAAa,CAAC,CAAC;QACtD,MAAM,IAAI,GAAG,eAAe,CAAC,IAAI,CAAC;QAClC,MAAM,QAAQ,GAAG,eAAe,CAAC,QAAQ,CAAC;QAC1C,MAAM,WAAW,GAAa,EAAE,CAAC;QACjC,KAAK,MAAM,IAAI,IAAI,UAAU,CAAC,sSAAK,CAAC,CAAC,EAAE,CAAC,CAAC,IAAI,CAAC,CAAE;YAC9C,IAAI,aAAa,CAAC,OAAO,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC,EAAE;gBACtC,WAAW,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;aACrB,MAAM;gBACL,WAAW,CAAC,IAAI,CAAC,CAAC,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC,CAAC;aACjC;SACF;QACD,MAAM,aAAa,OAAG,2PAAO,EAAC,IAAI,EAAE,WAAW,CAAC,CAAC;QACjD,MAAM,iBAAiB,OAAG,2PAAO,EAAC,QAAQ,EAAE,WAAW,CAAC,CAAC;QACzD,MAAM,cAAc,GAChB,KAAK,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,KAAC,2PAAO,EAAC,KAAK,EAAE,WAAW,CAAC,CAAC;QACvD,MAAM,aAAa,GACf,IAAI,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,KAAC,2PAAO,EAAC,IAAI,EAAE,WAAW,CAAC,CAAC;QACrD,MAAM,MAAM,GAAG,kBAAkB,CAC7B,CAAC,EAAE,aAAa,EAAE,iBAAiB,EAAE,aAAa,EAClD,cAAc,EAAE,OAAO,CAAC,CAAC;QAC7B,OAAO;YAAC,MAAM;YAAE,IAAI;YAAE,QAAQ;SAAC,CAAC;IAClC,CAAC,CAA6B,CAAC;AACxC,CAAC;AAaK,SAAU,wBAAwB,CACpC,CAAS,EAAE,KAAa,EAAE,IAAY,EAAE,aAAuB,EAC/D,OAAO,GAAG,IAAI;IAChB,IAAI,8QAAI,CAAC,WAAW,CACZ,aAAa,CAAC,KAAK,EAAE,CAAC,IAAI,EAAE,EAAE,UAAU,CAAC,sSAAK,CAAC,CAAC,EAAE,CAAC,CAAC,IAAI,GAAG,CAAC,CAAC,CAAC,EAAE;QACtE,OAAO,+BAA+B,CAClC,CAAC,EAAE,KAAK,EAAE,IAAI,EAAE,aAAa,EAAE,OAAO,CAAC,CAAC;KAC7C,MAAM;QACL,OAAO,iCAAiC,CACpC,CAAC,EAAE,KAAK,EAAE,IAAI,EAAE,aAAa,EAAE,OAAO,CAAC,CAAC;KAC7C;AACH,CAAC;AAoFD,MAAa,kBAAmB,SAAQ,gTAAK;IAqB3C,YAAY,IAAkC,CAAA;QAC5C,IAAI,IAAI,IAAI,IAAI,EAAE;YAChB,IAAI,GAAG,CAAA,CAAE,CAAC;SACX;QACD,KAAK,CAAC,IAAI,CAAC,CAAC;QAEZ,IAAI,CAAC,eAAe,GAAG,IAAI,CAAC;QAC5B,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC,IAAI,IAAI,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC;QAC/C,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC,QAAQ,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,QAAQ,CAAC;QAC7D,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC,OAAO,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,OAAO,CAAC;QAC1D,IAAI,CAAC,MAAM,GAAG,IAAI,CAAC,MAAM,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,MAAM,CAAC;QACvD,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC,KAAK,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC;QACpD,IAAI,CAAC,eAAe,OAAG,mTAAc,EAAC,IAAI,CAAC,eAAe,IAAI,OAAO,CAAC,CAAC;QACvE,IAAI,CAAC,gBAAgB,OAAG,mTAAc,EAAC,IAAI,CAAC,gBAAgB,IAAI,MAAM,CAAC,CAAC;QACxE,IAAI,CAAC,qBAAqB,OACtB,mTAAc,EAAC,IAAI,CAAC,qBAAqB,IAAI,OAAO,CAAC,CAAC;QAC1D,IAAI,CAAC,yBAAyB,OAC1B,mTAAc,EAAC,IAAI,CAAC,yBAAyB,IAAI,MAAM,CAAC,CAAC;QAC7D,IAAI,CAAC,cAAc,OAAG,iTAAa,EAAC,IAAI,CAAC,cAAc,CAAC,CAAC;QACzD,IAAI,CAAC,eAAe,OAAG,iTAAa,EAAC,IAAI,CAAC,eAAe,CAAC,CAAC;QAC3D,IAAI,CAAC,eAAe,OAAG,mTAAc,EAAC,IAAI,CAAC,eAAe,CAAC,CAAC;QAC5D,IAAI,CAAC,gBAAgB,OAAG,mTAAc,EAAC,IAAI,CAAC,gBAAgB,CAAC,CAAC;IAChE,CAAC;IAEe,KAAK,CAAC,UAAyB,EAAA;QAC7C,UAAU,OAAG,+TAAkB,EAAC,UAAU,CAAC,CAAC;QAC5C,MAAM,IAAI,GAAG,IAAI,CAAC,IAAI,IAAI,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,AAAC,IAAI,CAAC,IAAI,GAAG,UAAU,CAAC,MAAM,CAAC,CAAC;QAC1E,MAAM,GAAG,GAAG,UAAU,CAAC,IAAI,CAAC,CAAC;QAC7B,IAAI,GAAG,IAAI,IAAI,EAAE;YACf,MAAM,IAAI,ySAAU,CAChB,CAAA,KAAA,EAAQ,IAAI,CAAA,qDAAA,CAAuD,GACnE,CAAA,uCAAA,CAAyC,GACzC,GAAG,IAAI,CAAC,SAAS,CAAC,UAAU,CAAC,CAAA,CAAA,CAAG,CAAC,CAAC;SACvC;QACD,IAAI,CAAC,SAAS,GACV;YAAC,IAAI,oTAAS,CAAC;gBAAC,IAAI,EAAE,UAAU,CAAC,MAAM;gBAAE,IAAI,EAAE;oBAAC,CAAC,IAAI,CAAC,EAAE,GAAG;gBAAA,CAAC;YAAA,CAAC,CAAC;SAAC,CAAC;QACpE,MAAM,KAAK,GAAG;YAAC,GAAG;SAAC,CAAC;QACpB,IAAI,IAAI,CAAC,KAAK,EAAE;YACd,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC,SAAS,CACvB,OAAO,EAAE,KAAK,EAAE,IAAI,EAAE,IAAI,CAAC,gBAAgB,EAAE,IAAI,CAAC,gBAAgB,EAClE,IAAI,EAAE,IAAI,CAAC,eAAe,CAAC,CAAC;SACjC;QACD,IAAI,IAAI,CAAC,MAAM,EAAE;YACf,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC,SAAS,CACtB,MAAM,EAAE,KAAK,EAAE,IAAI,EAAE,IAAI,CAAC,eAAe,EAAE,IAAI,CAAC,eAAe,EAAE,IAAI,EACrE,IAAI,CAAC,cAAc,CAAC,CAAC;SAC1B;QACD,IAAI,CAAC,UAAU,GAAG,IAAI,CAAC,SAAS,CAC5B,aAAa,EAAE,KAAK,EAAE,IAAI,EAAE,IAAI,CAAC,qBAAqB,EAAE,IAAI,EAAE,KAAK,CAAC,CAAC;QACzE,IAAI,CAAC,cAAc,GAAG,IAAI,CAAC,SAAS,CAChC,iBAAiB,EAAE,KAAK,EAAE,IAAI,EAAE,IAAI,CAAC,yBAAyB,EAAE,IAAI,EACpE,KAAK,CAAC,CAAC;QACX,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC;IACpB,CAAC;IAEQ,IAAI,CAAC,MAAuB,EAAE,MAAc,EAAA;QACnD,WAAO,iPAAI,EAAC,GAAG,EAAE;YACf,MAAM,QAAQ,GAAG,MAAM,CAAC,UAAU,CAAC,IAAI,IAAI,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,MAAM,CAAC,UAAU,CAAC,CAAC;YACzE,MAAM,KAAK,OAAG,gUAAmB,EAAC,MAAM,CAAC,CAAC;YAC1C,MAAM,UAAU,GAAG,KAAK,CAAC,KAAK,CAAC;YAC/B,MAAM,IAAI,GAAG,UAAU,CAAC,MAAM,CAAC;YAC/B,MAAM,aAAa,GAAG,UAAU,CAAC,sSAAK,CAAC,CAAC,EAAE,IAAI,CAAC,CAAC;YAChD,MAAM,IAAI,GAAG,IAAI,CAAC,IAAI,IAAI,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,AAAC,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC,CAAC;YAC7D,aAAa,CAAC,MAAM,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC;YAC9B,MAAM,cAAc,GAAG,aAAa,CAAC,6SAAY,CAAC,CAAC,EAAE,IAAI,CAAC,CAAC;YAC3D,cAAc,CAAC,IAAI,CAAC,GAAG,UAAU,CAAC,IAAI,CAAC,CAAC;YAExC,MAAM,mBAAmB,GAAG,aAAa,CAAC,KAAK,EAAE,CAAC;YAClD,mBAAmB,CAAC,IAAI,EAAE,CAAC;YAC3B,MAAM,iBAAiB,GAAG,CAAC,8QAAI,CAAC,WAAW,CACvC,mBAAmB,EAAE,UAAU,CAAC,sSAAK,CAAC,CAAC,EAAE,IAAI,CAAC,CAAC,KAAK,CAAC,CAAC,EAAE,IAAI,GAAG,CAAC,CAAC,CAAC,CAAC;YAEvE,MAAM,kBAAkB,GAAiB,GAAG,EAAE;gBAC5C,IAAI,iBAAiB,EAAE;oBACrB,MAAM,mBAAmB,OACrB,2PAAO,EAAC,IAAI,CAAC,UAAU,CAAC,IAAI,EAAE,EAAE,cAAc,CAAC,CAAC;oBACpD,MAAM,uBAAuB,OACzB,2PAAO,EAAC,IAAI,CAAC,cAAc,CAAC,IAAI,EAAE,EAAE,cAAc,CAAC,CAAC;oBACxD,MAAM,aAAa,GACf,IAAI,CAAC,MAAM,CAAC,CAAC,KAAC,2PAAO,EAAC,IAAI,CAAC,IAAI,CAAC,IAAI,EAAE,EAAE,cAAc,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC;oBACnE,MAAM,cAAc,GAChB,IAAI,CAAC,KAAK,CAAC,CAAC,KAAC,2PAAO,EAAC,IAAI,CAAC,KAAK,CAAC,IAAI,EAAE,EAAE,cAAc,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC;oBACnE,OAAO,kBAAkB,CACrB,KAAK,EAAE,mBAAmB,EAAE,uBAAuB,EACnD,aAAa,EAAE,cAAc,EAAE,IAAI,CAAC,OAAO,CAAC,CAAC;iBAClD,MAAM;oBACL,OAAO,kBAAkB,CACrB,KAAK,EAAE,IAAI,CAAC,UAAU,CAAC,IAAI,EAAE,EAAE,IAAI,CAAC,cAAc,CAAC,IAAI,EAAE,EACzD,IAAI,CAAC,IAAI,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,EAAE,EAC3C,IAAI,CAAC,KAAK,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC,IAAI,EAAE,EAAE,IAAI,CAAC,OAAO,CAAC,CAAC;iBAClE;YACH,CAAC,CAAC;YAEF,IAAI,CAAC,QAAQ,EAAE;gBACb,OAAO,kBAAkB,EAAE,CAAC;aAC7B;YAED,MAAM,CAAC,cAAc,EAAE,IAAI,EAAE,QAAQ,CAAC,GAAG,wBAAwB,CAC7D,KAAK,EAAE,IAAI,CAAC,KAAK,CAAC,IAAI,EAAE,EAAE,IAAI,CAAC,IAAI,CAAC,IAAI,EAAE,EAAE,aAAa,EACzD,IAAI,CAAC,OAAO,CAAC,CAAC;YAElB,MAAM,eAAe,GACjB,CAAC,QAAuB,EAAE,KAAa,EAAE,QAAgB,EAAQ,EAAE;gBACjE,GAAG,CAAC,6OAAI,CAAC,GAAG,EAAE;oBACZ,MAAM,KAAK,GAAG,CAAC,GAAG,QAAQ,CAAC;oBAC3B,MAAM,SAAS,GAAG,QAAQ,CAAC,IAAI,EAAE,CAAC;oBAClC,MAAM,WAAW,GAAG,GAAG,CAAC,+OAAG,CAAC,GAAG,CAAC,+OAAG,CAAC,SAAS,EAAE,KAAK,CAAC,EAAE,KAAK,CAAC,CAAC;oBAC9D,QAAQ,CAAC,KAAK,CAAC,GAAG,CAAC,+OAAG,CAAC,SAAS,EAAE,WAAW,CAAC,CAAC,CAAC;gBAClD,CAAC,CAAC,CAAC;YACL,CAAC,CAAC;YAEN,mEAAmE;YACnE,8DAA8D;YAC9D,yEAAyE;YACzE,0EAA0E;YAC1E,8DAA8D;YAC9D,iBAAiB;YACjB,MAAM,2BAA2B,GAAG,GAAG,EAAE;gBACvC,eAAe,CAAC,IAAI,CAAC,UAAU,EAAE,IAAI,EAAE,IAAI,CAAC,QAAQ,CAAC,CAAC;gBACtD,eAAe,CAAC,IAAI,CAAC,cAAc,EAAE,QAAQ,EAAE,IAAI,CAAC,QAAQ,CAAC,CAAC;YAChE,CAAC,CAAC;YACF,2BAA2B,EAAE,CAAC;YAE9B,OAAO,cAAc,CAAC;QACxB,CAAC,CAAC,CAAC;IACL,CAAC;IAEQ,SAAS,GAAA;QAChB,MAAM,MAAM,GAA6B;YACvC,IAAI,EAAE,IAAI,CAAC,IAAI;YACf,QAAQ,EAAE,IAAI,CAAC,QAAQ;YACvB,OAAO,EAAE,IAAI,CAAC,OAAO;YACrB,MAAM,EAAE,IAAI,CAAC,MAAM;YACnB,KAAK,EAAE,IAAI,CAAC,KAAK;YACjB,eAAe,MAAE,yTAAoB,EAAC,IAAI,CAAC,eAAe,CAAC;YAC3D,gBAAgB,MAAE,yTAAoB,EAAC,IAAI,CAAC,gBAAgB,CAAC;YAC7D,qBAAqB,MAAE,yTAAoB,EAAC,IAAI,CAAC,qBAAqB,CAAC;YACvE,yBAAyB,MACrB,yTAAoB,EAAC,IAAI,CAAC,yBAAyB,CAAC;YACxD,eAAe,MAAE,yTAAoB,EAAC,IAAI,CAAC,eAAe,CAAC;YAC3D,gBAAgB,MAAE,yTAAoB,EAAC,IAAI,CAAC,gBAAgB,CAAC;YAC7D,cAAc,MAAE,uTAAmB,EAAC,IAAI,CAAC,cAAc,CAAC;YACxD,eAAe,MAAE,uTAAmB,EAAC,IAAI,CAAC,eAAe,CAAC;SAC3D,CAAC;QACF,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;QACrC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;;AAvKD,gBAAA,EAAkB,CACX,mBAAA,SAAS,GAAG,oBAAoB,CAAC;;AAwK1C,ySAAa,CAAC,aAAa,CAAC,kBAAkB,CAAC,CAAC;AAkDhD,MAAa,kBAAmB,SAAQ,gTAAK;IAgB3C,YAAY,IAAkC,CAAA;QAC5C,IAAI,IAAI,IAAI,IAAI,EAAE;YAChB,IAAI,GAAG,CAAA,CAAE,CAAC;SACX;QACD,KAAK,CAAC,IAAI,CAAC,CAAC;QAEZ,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC,IAAI,IAAI,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC;QAC/C,IAAI,OAAO,IAAI,CAAC,IAAI,KAAK,QAAQ,EAAE;YACjC,IAAI,CAAC,MAAM,CAAC,SAAS,CAAC,IAAI,CAAC,IAAI,CAAC,EAAE;gBAChC,MAAM,IAAI,KAAK,CACX,CAAA,6CAAA,EAAgD,IAAI,CAAC,IAAI,EAAE,CAAC,CAAC;aAClE;SACF,MAAM,IAAI,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,CAAC,EAAE;YACnC,KAAK,MAAM,IAAI,IAAI,IAAI,CAAC,IAAI,CAAE;gBAC5B,IAAI,CAAC,MAAM,CAAC,SAAS,CAAC,IAAI,CAAC,EAAE;oBAC3B,MAAM,IAAI,KAAK,CACX,CAAA,0CAAA,CAA4C,GAC5C,CAAA,aAAA,EAAgB,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC;iBAClD;aACF;SACF,MAAM;YACL,MAAM,IAAI,KAAK,CACX,CAAA,wDAAA,CAA0D,GAC1D,CAAA,aAAA,EAAgB,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,IAAI,CAAC,EAAE,CAAC,CAAC;SAClD;QAED,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC,OAAO,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,OAAO,CAAC;QAC1D,IAAI,CAAC,MAAM,GAAG,IAAI,CAAC,MAAM,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,MAAM,CAAC;QACvD,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC,KAAK,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,KAAK,CAAC;QACpD,IAAI,CAAC,eAAe,OAAG,mTAAc,EAAC,IAAI,CAAC,eAAe,IAAI,OAAO,CAAC,CAAC;QACvE,IAAI,CAAC,gBAAgB,OAAG,mTAAc,EAAC,IAAI,CAAC,gBAAgB,IAAI,MAAM,CAAC,CAAC;QACxE,IAAI,CAAC,eAAe,OAAG,mTAAc,EAAC,IAAI,CAAC,eAAe,CAAC,CAAC;QAC5D,IAAI,CAAC,gBAAgB,OAAG,mTAAc,EAAC,IAAI,CAAC,gBAAgB,CAAC,CAAC;QAE9D,IAAI,CAAC,eAAe,GAAG,IAAI,CAAC;IAC9B,CAAC;IAEe,KAAK,CAAC,UAAyB,EAAA;QAC7C,UAAU,OAAG,+TAAkB,EAAC,UAAU,CAAC,CAAC;QAC5C,MAAM,KAAK,GAAG,UAAU,CAAC,MAAM,CAAC;QAEhC,+CAA+C;QAC/C,IAAI,OAAO,IAAI,CAAC,IAAI,KAAK,QAAQ,EAAE;YACjC,IAAI,CAAC,IAAI,GAAG;gBAAC,IAAI,CAAC,IAAI;aAAC,CAAC;SACzB;QACD,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,IAAI,CAAC,IAAI,CAAC,MAAM,EAAE,EAAE,CAAC,CAAE;YACzC,IAAI,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,GAAG,CAAC,EAAE;gBACpB,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,IAAI,KAAK,CAAC;aACvB;SACF;QAED,yBAAyB;QACzB,KAAK,MAAM,IAAI,IAAI,IAAI,CAAC,IAAI,CAAE;YAC5B,IAAI,IAAI,GAAG,CAAC,IAAI,IAAI,IAAI,KAAK,EAAE;gBAC7B,MAAM,IAAI,KAAK,CAAC,CAAA,cAAA,EAAiB,IAAI,EAAE,CAAC,CAAC;aAC1C;SACF;QACD,IAAI,IAAI,CAAC,IAAI,CAAC,MAAM,KAAK,aAAa,CAAC,uSAAM,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC,MAAM,EAAE;YAC/D,MAAM,IAAI,KAAK,CAAC,CAAA,yBAAA,EAA4B,IAAI,CAAC,IAAI,EAAE,CAAC,CAAC;SAC1D;QAED,MAAM,UAAU,GAAG,IAAI,CAAC,IAAI,CAAC,GAAG,EAAC,IAAI,CAAC,EAAE,AAAC,UAAU,CAAC,IAAI,CAAC,CAAa,CAAC;QAEvE,MAAM,SAAS,GAAG,IAAI,CAAC;QACvB,IAAI,IAAI,CAAC,KAAK,EAAE;YACd,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC,SAAS,CACvB,OAAO,EAAE,UAAU,EAAE,SAAS,EAAE,IAAI,CAAC,gBAAgB,EACrD,IAAI,CAAC,gBAAgB,EAAE,SAAS,CAAC,CAAC;SACvC,MAAM;YACL,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC;SACnB;QACD,IAAI,IAAI,CAAC,MAAM,EAAE;YACf,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC,SAAS,CACtB,MAAM,EAAE,UAAU,EAAE,SAAS,EAAE,IAAI,CAAC,eAAe,EACnD,IAAI,CAAC,eAAe,EAAE,SAAS,CAAC,CAAC;SACtC,MAAM;YACL,IAAI,CAAC,IAAI,GAAG,IAAI,CAAC;SAClB;QAED,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC;IACpB,CAAC;IAEQ,IAAI,CAAC,MAAuB,EAAE,MAAc,EAAA;QACnD,MAAM,KAAK,OAAG,gUAAmB,EAAC,MAAM,CAAC,CAAC;QAC1C,MAAM,UAAU,GAAG,KAAK,CAAC,KAAK,CAAC;QAC/B,MAAM,KAAK,GAAG,UAAU,CAAC,MAAM,CAAC;QAEhC,WAAO,iPAAI,EAAC,GAAG,EAAE;YACf,MAAM,QAAQ,GAAG,IAAI,CAAC;YACtB,IAAI,EAAC,IAAI,EAAE,QAAQ,EAAC,OAAG,2PAAO,EAAC,KAAK,EAAE,IAAI,CAAC,IAAI,EAAE,QAAQ,CAAC,CAAC;YAC3D,MAAM,cAAc,GAAG,aAAa,CAAC,6SAAY,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC;YAC5D,KAAK,MAAM,GAAG,IAAI,IAAI,CAAC,IAAgB,CAAE;gBACvC,cAAc,CAAC,GAAG,CAAC,GAAG,UAAU,CAAC,GAAG,CAAC,CAAC;aACvC;YAED,MAAM,SAAS,GAAG,CAAC,CAAS,EAAE,EAAE;gBAC9B,IAAI,CAAC,IAAI,IAAI,IAAI,CAAC,CAAC,KAAK,CAAC,MAAM,KAAK,KAAK,EAAE;oBACzC,OAAO,GAAG,CAAC,uPAAO,CAAC,CAAC,EAAE,cAAc,CAAC,CAAC;iBACvC,MAAM;oBACL,OAAO,CAAC,CAAC;iBACV;YACH,CAAC,CAAC;YAEF,IAAI,KAAK,GAAG,IAAI,CAAC,KAAK,CAAC,CAAC,CAAC,SAAS,CAAC,IAAI,CAAC,KAAK,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC;YAC7D,IAAI,MAAM,GAAG,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC,SAAS,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,EAAE,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC;YAE9D,yEAAyE;YACzE,0EAA0E;YAC1E,sEAAsE;YACtE,wEAAwE;YACxE,sEAAsE;YACtE,iCAAiC;YACjC,MAAM,aAAa,GAAa,EAAE,CAAC;YACnC,MAAM,iBAAiB,GAAa,EAAE,CAAC;YACvC,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,KAAK,EAAE,EAAE,CAAC,CAAE;gBAC9B,IAAK,IAAI,CAAC,IAAiB,CAAC,OAAO,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,EAAE;oBAC7C,aAAa,CAAC,IAAI,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC,CAAC;oBAClC,iBAAiB,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;iBAC3B,MAAM;oBACL,aAAa,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;oBACtB,iBAAiB,CAAC,IAAI,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC,CAAC;iBACvC;aACF;YACD,IAAI,GAAG,GAAG,CAAC,iPAAI,CAAC,IAAI,EAAE,aAAa,CAAC,CAAC;YACrC,QAAQ,GAAG,GAAG,CAAC,iPAAI,CAAC,QAAQ,EAAE,aAAa,CAAC,CAAC;YAC7C,IAAI,KAAK,IAAI,IAAI,EAAE;gBACjB,KAAK,GAAG,GAAG,CAAC,iPAAI,CAAC,KAAK,EAAE,iBAAiB,CAAC,CAAC;aAC5C;YACD,IAAI,MAAM,IAAI,IAAI,EAAE;gBAClB,MAAM,GAAG,GAAG,CAAC,iPAAI,CAAC,MAAM,EAAE,iBAAiB,CAAC,CAAC;aAC9C;YAED,OAAO,kBAAkB,CACrB,KAAK,EAAE,IAAI,EAAE,QAAQ,EAAE,MAAM,EAAE,KAAK,EAAE,IAAI,CAAC,OAAO,CAAC,CAAC;QAC1D,CAAC,CAAC,CAAC;IACL,CAAC;IAEQ,SAAS,GAAA;QAChB,MAAM,MAAM,GAA6B;YACvC,IAAI,EAAE,IAAI,CAAC,IAAI;YACf,OAAO,EAAE,IAAI,CAAC,OAAO;YACrB,MAAM,EAAE,IAAI,CAAC,MAAM;YACnB,KAAK,EAAE,IAAI,CAAC,KAAK;YACjB,eAAe,MAAE,yTAAoB,EAAC,IAAI,CAAC,eAAe,CAAC;YAC3D,gBAAgB,MAAE,yTAAoB,EAAC,IAAI,CAAC,gBAAgB,CAAC;YAC7D,eAAe,MAAE,yTAAoB,EAAC,IAAI,CAAC,eAAe,CAAC;YAC3D,gBAAgB,MAAE,yTAAoB,EAAC,IAAI,CAAC,gBAAgB,CAAC;SAC9D,CAAC;QACF,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;QACrC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;;AAtKD,gBAAA,EAAkB,CACX,mBAAA,SAAS,GAAG,oBAAoB,CAAC;;AAuK1C,ySAAa,CAAC,aAAa,CAAC,kBAAkB,CAAC,CAAC"}},
    {"offset": {"line": 2180, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-layers@4.22.0_@tensorflow+tfjs-core@4.22.0/node_modules/@tensorflow/tfjs-layers/dist/layers/padding.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-layers/src/layers/padding.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * Padding Layers.\n */\n\n// Porting Note: In Python Keras, the padding layers are in convolutional.py,\n//   but we decided to put them in a separate file (padding.ts) for clarity.\n\nimport * as tfc from '@tensorflow/tfjs-core';\nimport {serialization, Tensor, tidy} from '@tensorflow/tfjs-core';\n\nimport {imageDataFormat} from '../backend/common';\nimport {InputSpec, Layer, LayerArgs} from '../engine/topology';\nimport {ValueError} from '../errors';\nimport {DataFormat, Shape} from '../keras_format/common';\nimport {Kwargs} from '../types';\nimport {getExactlyOneShape, getExactlyOneTensor} from '../utils/types_utils';\n\n/**\n * Pads the middle dimension of a 3D tensor.\n *\n * @param x Input `tf.Tensor` to be padded.\n * @param padding `Array` of 2 integers, how many zeros to add at the start and\n *   end of the middle dimension (i.e., dimension 1).\n * @return A padded 3D `tf.Tensor`.\n */\nexport function temporalPadding(x: Tensor, padding?: [number, number]): Tensor {\n  return tidy(() => {\n    if (x.rank !== 3) {\n      throw new ValueError(\n          `temporalPadding expects input tensor to be 3-D, but received a ` +\n          `${x.rank}-D tensor.`);\n    }\n\n    if (padding == null) {\n      padding = [1, 1];\n    }\n    if (padding.length !== 2) {\n      throw new ValueError(\n          `temporalPadding expects input padding pattern to be a length-2 ` +\n          `array, but received a length-${padding.length} array.`);\n    }\n\n    const pattern: Array<[number, number]> = [[0, 0], padding, [0, 0]];\n    return tfc.pad(x, pattern);\n  });\n}\n\n/**\n * Pads the 2nd and 3rd dimensions of a 4D tensor.\n *\n * @param x Input `tf.Tensor` to be padded.\n * @param padding `Array` of two `Array`s, each of which is an `Array` of two\n *   integers. The amount of padding at the beginning and end of the 2nd and 3rd\n *   dimensions, respectively.\n * @param dataFormat 'channelsLast' (default) or 'channelsFirst'.\n * @return Padded 4D `tf.Tensor`.\n */\nexport function spatial2dPadding(\n    x: Tensor, padding?: [[number, number], [number, number]],\n    dataFormat?: DataFormat): Tensor {\n  return tidy(() => {\n    if (x.rank !== 4) {\n      throw new ValueError(\n          `temporalPadding expects input tensor to be 4-D, but received a ` +\n          `${x.rank}-D tensor.`);\n    }\n\n    if (padding == null) {\n      padding = [[1, 1], [1, 1]];\n    }\n    if (padding.length !== 2 || padding[0].length !== 2 ||\n        padding[1].length !== 2) {\n      throw new ValueError(\n          'spatial2dPadding expects `padding` to be an Array of two Arrays, ' +\n          'each of which is an Array of two integers.');\n    }\n\n    if (dataFormat == null) {\n      dataFormat = imageDataFormat();\n    }\n    if (dataFormat !== 'channelsLast' && dataFormat !== 'channelsFirst') {\n      throw new ValueError(\n          `Unknown data format: ${dataFormat}. ` +\n          `Supported data formats are 'channelsLast' and 'channelsFirst.`);\n    }\n\n    let pattern: Array<[number, number]>;\n    if (dataFormat === 'channelsFirst') {\n      pattern = [[0, 0], [0, 0], padding[0], padding[1]];\n    } else {\n      pattern = [[0, 0], padding[0], padding[1], [0, 0]];\n    }\n\n    return tfc.pad(x, pattern);\n  });\n}\n\nexport declare interface ZeroPadding2DLayerArgs extends LayerArgs {\n  /**\n   * Integer, or `Array` of 2 integers, or `Array` of 2 `Array`s, each of\n   * which is an `Array` of 2 integers.\n   * - If integer, the same symmetric padding is applied to width and height.\n   * - If `Array` of 2 integers, interpreted as two different symmetric values\n   *   for height and width:\n   *   `[symmetricHeightPad, symmetricWidthPad]`.\n   * - If `Array` of 2 `Array`s, interpreted as:\n   *   `[[topPad, bottomPad], [leftPad, rightPad]]`.\n   */\n  padding?: number|[number, number]|[[number, number], [number, number]];\n\n  /**\n   * One of `'channelsLast'` (default) and `'channelsFirst'`.\n   *\n   * The ordering of the dimensions in the inputs.\n   * `channelsLast` corresponds to inputs with shape\n   * `[batch, height, width, channels]` while `channelsFirst`\n   * corresponds to inputs with shape\n   * `[batch, channels, height, width]`.\n   */\n  dataFormat?: DataFormat;\n}\n\nexport class ZeroPadding2D extends Layer {\n  /** @nocollapse */\n  static className = 'ZeroPadding2D';\n  readonly dataFormat: DataFormat;\n  readonly padding: [[number, number], [number, number]];\n\n  constructor(args?: ZeroPadding2DLayerArgs) {\n    if (args == null) {\n      args = {};\n    }\n    super(args);\n\n    this.dataFormat =\n        args.dataFormat == null ? imageDataFormat() : args.dataFormat;\n    // TODO(cais): Maybe refactor the following logic surrounding `padding`\n    //   into a helper method.\n    if (args.padding == null) {\n      this.padding = [[1, 1], [1, 1]];\n    } else if (typeof args.padding === 'number') {\n      this.padding =\n          [[args.padding, args.padding], [args.padding, args.padding]];\n    } else {\n      args.padding = args.padding;\n      if (args.padding.length !== 2) {\n        throw new ValueError(\n            `ZeroPadding2D expects padding to be a length-2 array, but ` +\n            `received a length-${args.padding.length} array.`);\n      }\n\n      let heightPadding: [number, number];\n      let widthPadding: [number, number];\n      if (typeof args.padding[0] === 'number') {\n        heightPadding = [args.padding[0], args.padding[0]];\n        widthPadding = [args.padding[1] as number, args.padding[1] as number];\n      } else {\n        args.padding = args.padding as [[number, number], [number, number]];\n\n        if (args.padding[0].length !== 2) {\n          throw new ValueError(\n              `ZeroPadding2D expects height padding to be a length-2 array, ` +\n              `but received a length-${args.padding[0].length} array.`);\n        }\n        heightPadding = args.padding[0] as [number, number];\n\n        if (args.padding[1].length !== 2) {\n          throw new ValueError(\n              `ZeroPadding2D expects width padding to be a length-2 array, ` +\n              `but received a length-${args.padding[1].length} array.`);\n        }\n        widthPadding = args.padding[1] as [number, number];\n      }\n      this.padding = [heightPadding, widthPadding];\n    }\n    this.inputSpec = [new InputSpec({ndim: 4})];\n  }\n\n  override computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    inputShape = getExactlyOneShape(inputShape);\n\n    let rows: number;\n    let cols: number;\n    if (this.dataFormat === 'channelsFirst') {\n      if (inputShape[2] != null && inputShape[2] >= 0) {\n        rows = inputShape[2] + this.padding[0][0] + this.padding[0][1];\n      } else {\n        rows = null;\n      }\n      if (inputShape[3] != null && inputShape[3] >= 0) {\n        cols = inputShape[3] + this.padding[1][0] + this.padding[1][1];\n      } else {\n        cols = null;\n      }\n      return [inputShape[0], inputShape[1], rows, cols];\n    } else {\n      if (inputShape[1] != null && inputShape[1] >= 0) {\n        rows = inputShape[1] + this.padding[0][0] + this.padding[0][1];\n      } else {\n        rows = null;\n      }\n      if (inputShape[2] != null && inputShape[2] >= 0) {\n        cols = inputShape[2] + this.padding[1][0] + this.padding[1][1];\n      } else {\n        cols = null;\n      }\n      return [inputShape[0], rows, cols, inputShape[3]];\n    }\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(\n        () => spatial2dPadding(\n            getExactlyOneTensor(inputs), this.padding, this.dataFormat));\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config: serialization.ConfigDict = {\n      padding: this.padding,\n      dataFormat: this.dataFormat,\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\nserialization.registerClass(ZeroPadding2D);\n"],"names":[],"mappings":";;;;;;;;AAAA;;;;;;;;GAQG,CAEH;;GAEG,CAEH,6EAA6E;AAC7E,4EAA4E;;AAE5E,OAAO,KAAK,GAAG,MAAM,uBAAuB,CAAC;;AAC7C,OAAO,EAAC,aAAa,EAAU,IAAI,EAAC,MAAM,uBAAuB,CAAC;AAElE,OAAO,EAAC,eAAe,EAAC,MAAM,mBAAmB,CAAC;AAClD,OAAO,EAAC,SAAS,EAAE,KAAK,EAAY,MAAM,oBAAoB,CAAC;AAC/D,OAAO,EAAC,UAAU,EAAC,MAAM,WAAW,CAAC;AAGrC,OAAO,EAAC,kBAAkB,EAAE,mBAAmB,EAAC,MAAM,sBAAsB,CAAC;;;;;;;AAUvE,SAAU,eAAe,CAAC,CAAS,EAAE,OAA0B;IACnE,WAAO,iPAAI,EAAC,GAAG,EAAE;QACf,IAAI,CAAC,CAAC,IAAI,KAAK,CAAC,EAAE;YAChB,MAAM,IAAI,ySAAU,CAChB,CAAA,+DAAA,CAAiE,GACjE,GAAG,CAAC,CAAC,IAAI,CAAA,UAAA,CAAY,CAAC,CAAC;SAC5B;QAED,IAAI,OAAO,IAAI,IAAI,EAAE;YACnB,OAAO,GAAG;gBAAC,CAAC;gBAAE,CAAC;aAAC,CAAC;SAClB;QACD,IAAI,OAAO,CAAC,MAAM,KAAK,CAAC,EAAE;YACxB,MAAM,IAAI,ySAAU,CAChB,CAAA,+DAAA,CAAiE,GACjE,CAAA,6BAAA,EAAgC,OAAO,CAAC,MAAM,CAAA,OAAA,CAAS,CAAC,CAAC;SAC9D;QAED,MAAM,OAAO,GAA4B;YAAC;gBAAC,CAAC;gBAAE,CAAC;aAAC;YAAE,OAAO;YAAE;gBAAC,CAAC;gBAAE,CAAC;aAAC;SAAC,CAAC;QACnE,OAAO,GAAG,CAAC,+OAAG,CAAC,CAAC,EAAE,OAAO,CAAC,CAAC;IAC7B,CAAC,CAAC,CAAC;AACL,CAAC;AAYK,SAAU,gBAAgB,CAC5B,CAAS,EAAE,OAA8C,EACzD,UAAuB;IACzB,WAAO,iPAAI,EAAC,GAAG,EAAE;QACf,IAAI,CAAC,CAAC,IAAI,KAAK,CAAC,EAAE;YAChB,MAAM,IAAI,ySAAU,CAChB,CAAA,+DAAA,CAAiE,GACjE,GAAG,CAAC,CAAC,IAAI,CAAA,UAAA,CAAY,CAAC,CAAC;SAC5B;QAED,IAAI,OAAO,IAAI,IAAI,EAAE;YACnB,OAAO,GAAG;gBAAC;oBAAC,CAAC;oBAAE,CAAC;iBAAC;gBAAE;oBAAC,CAAC;oBAAE,CAAC;iBAAC;aAAC,CAAC;SAC5B;QACD,IAAI,OAAO,CAAC,MAAM,KAAK,CAAC,IAAI,OAAO,CAAC,CAAC,CAAC,CAAC,MAAM,KAAK,CAAC,IAC/C,OAAO,CAAC,CAAC,CAAC,CAAC,MAAM,KAAK,CAAC,EAAE;YAC3B,MAAM,IAAI,ySAAU,CAChB,mEAAmE,GACnE,4CAA4C,CAAC,CAAC;SACnD;QAED,IAAI,UAAU,IAAI,IAAI,EAAE;YACtB,UAAU,OAAG,yTAAe,EAAE,CAAC;SAChC;QACD,IAAI,UAAU,KAAK,cAAc,IAAI,UAAU,KAAK,eAAe,EAAE;YACnE,MAAM,IAAI,ySAAU,CAChB,CAAA,qBAAA,EAAwB,UAAU,CAAA,EAAA,CAAI,GACtC,CAAA,6DAAA,CAA+D,CAAC,CAAC;SACtE;QAED,IAAI,OAAgC,CAAC;QACrC,IAAI,UAAU,KAAK,eAAe,EAAE;YAClC,OAAO,GAAG;gBAAC;oBAAC,CAAC;oBAAE,CAAC;iBAAC;gBAAE;oBAAC,CAAC;oBAAE,CAAC;iBAAC;gBAAE,OAAO,CAAC,CAAC,CAAC;gBAAE,OAAO,CAAC,CAAC,CAAC;aAAC,CAAC;SACpD,MAAM;YACL,OAAO,GAAG;gBAAC;oBAAC,CAAC;oBAAE,CAAC;iBAAC;gBAAE,OAAO,CAAC,CAAC,CAAC;gBAAE,OAAO,CAAC,CAAC,CAAC;gBAAE;oBAAC,CAAC;oBAAE,CAAC;iBAAC;aAAC,CAAC;SACpD;QAED,OAAO,GAAG,CAAC,+OAAG,CAAC,CAAC,EAAE,OAAO,CAAC,CAAC;IAC7B,CAAC,CAAC,CAAC;AACL,CAAC;AA2BD,MAAa,aAAc,SAAQ,gTAAK;IAMtC,YAAY,IAA6B,CAAA;QACvC,IAAI,IAAI,IAAI,IAAI,EAAE;YAChB,IAAI,GAAG,CAAA,CAAE,CAAC;SACX;QACD,KAAK,CAAC,IAAI,CAAC,CAAC;QAEZ,IAAI,CAAC,UAAU,GACX,IAAI,CAAC,UAAU,IAAI,IAAI,CAAC,CAAC,KAAC,yTAAe,EAAE,CAAC,CAAC,EAAC,IAAI,CAAC,UAAU,CAAC;QAClE,uEAAuE;QACvE,0BAA0B;QAC1B,IAAI,IAAI,CAAC,OAAO,IAAI,IAAI,EAAE;YACxB,IAAI,CAAC,OAAO,GAAG;gBAAC;oBAAC,CAAC;oBAAE,CAAC;iBAAC;gBAAE;oBAAC,CAAC;oBAAE,CAAC;iBAAC;aAAC,CAAC;SACjC,MAAM,IAAI,OAAO,IAAI,CAAC,OAAO,KAAK,QAAQ,EAAE;YAC3C,IAAI,CAAC,OAAO,GACR;gBAAC;oBAAC,IAAI,CAAC,OAAO;oBAAE,IAAI,CAAC,OAAO;iBAAC;gBAAE;oBAAC,IAAI,CAAC,OAAO;oBAAE,IAAI,CAAC,OAAO;iBAAC;aAAC,CAAC;SAClE,MAAM;YACL,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC,OAAO,CAAC;YAC5B,IAAI,IAAI,CAAC,OAAO,CAAC,MAAM,KAAK,CAAC,EAAE;gBAC7B,MAAM,IAAI,ySAAU,CAChB,CAAA,0DAAA,CAA4D,GAC5D,CAAA,kBAAA,EAAqB,IAAI,CAAC,OAAO,CAAC,MAAM,CAAA,OAAA,CAAS,CAAC,CAAC;aACxD;YAED,IAAI,aAA+B,CAAC;YACpC,IAAI,YAA8B,CAAC;YACnC,IAAI,OAAO,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,KAAK,QAAQ,EAAE;gBACvC,aAAa,GAAG;oBAAC,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC;oBAAE,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC;iBAAC,CAAC;gBACnD,YAAY,GAAG;oBAAC,IAAI,CAAC,OAAO,CAAC,CAAC,CAAW;oBAAE,IAAI,CAAC,OAAO,CAAC,CAAC,CAAW;iBAAC,CAAC;aACvE,MAAM;gBACL,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC,OAA+C,CAAC;gBAEpE,IAAI,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,MAAM,KAAK,CAAC,EAAE;oBAChC,MAAM,IAAI,ySAAU,CAChB,CAAA,6DAAA,CAA+D,GAC/D,CAAA,sBAAA,EAAyB,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,MAAM,CAAA,OAAA,CAAS,CAAC,CAAC;iBAC/D;gBACD,aAAa,GAAG,IAAI,CAAC,OAAO,CAAC,CAAC,CAAqB,CAAC;gBAEpD,IAAI,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,MAAM,KAAK,CAAC,EAAE;oBAChC,MAAM,IAAI,ySAAU,CAChB,CAAA,4DAAA,CAA8D,GAC9D,CAAA,sBAAA,EAAyB,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,MAAM,CAAA,OAAA,CAAS,CAAC,CAAC;iBAC/D;gBACD,YAAY,GAAG,IAAI,CAAC,OAAO,CAAC,CAAC,CAAqB,CAAC;aACpD;YACD,IAAI,CAAC,OAAO,GAAG;gBAAC,aAAa;gBAAE,YAAY;aAAC,CAAC;SAC9C;QACD,IAAI,CAAC,SAAS,GAAG;YAAC,IAAI,oTAAS,CAAC;gBAAC,IAAI,EAAE,CAAC;YAAA,CAAC,CAAC;SAAC,CAAC;IAC9C,CAAC;IAEQ,kBAAkB,CAAC,UAAyB,EAAA;QACnD,UAAU,OAAG,+TAAkB,EAAC,UAAU,CAAC,CAAC;QAE5C,IAAI,IAAY,CAAC;QACjB,IAAI,IAAY,CAAC;QACjB,IAAI,IAAI,CAAC,UAAU,KAAK,eAAe,EAAE;YACvC,IAAI,UAAU,CAAC,CAAC,CAAC,IAAI,IAAI,IAAI,UAAU,CAAC,CAAC,CAAC,IAAI,CAAC,EAAE;gBAC/C,IAAI,GAAG,UAAU,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;aAChE,MAAM;gBACL,IAAI,GAAG,IAAI,CAAC;aACb;YACD,IAAI,UAAU,CAAC,CAAC,CAAC,IAAI,IAAI,IAAI,UAAU,CAAC,CAAC,CAAC,IAAI,CAAC,EAAE;gBAC/C,IAAI,GAAG,UAAU,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;aAChE,MAAM;gBACL,IAAI,GAAG,IAAI,CAAC;aACb;YACD,OAAO;gBAAC,UAAU,CAAC,CAAC,CAAC;gBAAE,UAAU,CAAC,CAAC,CAAC;gBAAE,IAAI;gBAAE,IAAI;aAAC,CAAC;SACnD,MAAM;YACL,IAAI,UAAU,CAAC,CAAC,CAAC,IAAI,IAAI,IAAI,UAAU,CAAC,CAAC,CAAC,IAAI,CAAC,EAAE;gBAC/C,IAAI,GAAG,UAAU,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;aAChE,MAAM;gBACL,IAAI,GAAG,IAAI,CAAC;aACb;YACD,IAAI,UAAU,CAAC,CAAC,CAAC,IAAI,IAAI,IAAI,UAAU,CAAC,CAAC,CAAC,IAAI,CAAC,EAAE;gBAC/C,IAAI,GAAG,UAAU,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,GAAG,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;aAChE,MAAM;gBACL,IAAI,GAAG,IAAI,CAAC;aACb;YACD,OAAO;gBAAC,UAAU,CAAC,CAAC,CAAC;gBAAE,IAAI;gBAAE,IAAI;gBAAE,UAAU,CAAC,CAAC,CAAC;aAAC,CAAC;SACnD;IACH,CAAC;IAEQ,IAAI,CAAC,MAAuB,EAAE,MAAc,EAAA;QACnD,WAAO,iPAAI,EACP,GAAG,CAAG,CAAD,eAAiB,KAClB,gUAAmB,EAAC,MAAM,CAAC,EAAE,IAAI,CAAC,OAAO,EAAE,IAAI,CAAC,UAAU,CAAC,CAAC,CAAC;IACvE,CAAC;IAEQ,SAAS,GAAA;QAChB,MAAM,MAAM,GAA6B;YACvC,OAAO,EAAE,IAAI,CAAC,OAAO;YACrB,UAAU,EAAE,IAAI,CAAC,UAAU;SAC5B,CAAC;QACF,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;QACrC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;;AArGD,gBAAA,EAAkB,CACX,cAAA,SAAS,GAAG,eAAe,CAAC;;AAsGrC,ySAAa,CAAC,aAAa,CAAC,aAAa,CAAC,CAAC"}},
    {"offset": {"line": 2428, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-layers@4.22.0_@tensorflow+tfjs-core@4.22.0/node_modules/@tensorflow/tfjs-layers/dist/layers/pooling.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-layers/src/layers/pooling.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * TensorFlow.js Layers: Pooling Layers.\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\nimport {serialization, Tensor, Tensor3D, Tensor4D, Tensor5D, tidy} from '@tensorflow/tfjs-core';\n\nimport {imageDataFormat} from '../backend/common';\nimport * as K from '../backend/tfjs_backend';\nimport {checkDataFormat, checkPaddingMode, checkPoolMode} from '../common';\nimport {InputSpec} from '../engine/topology';\nimport {Layer, LayerArgs} from '../engine/topology';\nimport {NotImplementedError, ValueError} from '../errors';\nimport {DataFormat, PaddingMode, PoolMode, Shape} from '../keras_format/common';\nimport {Kwargs} from '../types';\nimport {convOutputLength} from '../utils/conv_utils';\nimport {assertPositiveInteger} from '../utils/generic_utils';\nimport {getExactlyOneShape, getExactlyOneTensor} from '../utils/types_utils';\n\nimport {preprocessConv2DInput, preprocessConv3DInput} from './convolutional';\n\n/**\n * 2D pooling.\n * @param x\n * @param poolSize\n * @param strides strides. Defaults to [1, 1].\n * @param padding padding. Defaults to 'valid'.\n * @param dataFormat data format. Defaults to 'channelsLast'.\n * @param poolMode Mode of pooling. Defaults to 'max'.\n * @returns Result of the 2D pooling.\n */\nexport function pool2d(\n    x: Tensor, poolSize: [number, number], strides?: [number, number],\n    padding?: PaddingMode, dataFormat?: DataFormat,\n    poolMode?: PoolMode): Tensor {\n  return tidy(() => {\n    checkDataFormat(dataFormat);\n    checkPoolMode(poolMode);\n    checkPaddingMode(padding);\n    if (strides == null) {\n      strides = [1, 1];\n    }\n    if (padding == null) {\n      padding = 'valid';\n    }\n    if (dataFormat == null) {\n      dataFormat = imageDataFormat();\n    }\n    if (poolMode == null) {\n      poolMode = 'max';\n    }\n\n    // TODO(cais): Remove the preprocessing step once deeplearn.js supports\n    // dataFormat as an input argument.\n    x = preprocessConv2DInput(x, dataFormat);  // x is NHWC after preprocessing.\n    let y: Tensor;\n    const paddingString = (padding === 'same') ? 'same' : 'valid';\n    if (poolMode === 'max') {\n      // TODO(cais): Rank check?\n      y = tfc.maxPool(x as Tensor4D, poolSize, strides, paddingString);\n    } else {  // 'avg'\n      // TODO(cais): Check the dtype and rank of x and give clear error message\n      //   if those are incorrect.\n      y = tfc.avgPool(\n          // TODO(cais): Rank check?\n          x as Tensor3D | Tensor4D, poolSize, strides, paddingString);\n    }\n    if (dataFormat === 'channelsFirst') {\n      y = tfc.transpose(y, [0, 3, 1, 2]);  // NHWC -> NCHW.\n    }\n    return y;\n  });\n}\n\n/**\n * 3D pooling.\n * @param x\n * @param poolSize. Default to [1, 1, 1].\n * @param strides strides. Defaults to [1, 1, 1].\n * @param padding padding. Defaults to 'valid'.\n * @param dataFormat data format. Defaults to 'channelsLast'.\n * @param poolMode Mode of pooling. Defaults to 'max'.\n * @returns Result of the 3D pooling.\n */\nexport function pool3d(\n    x: Tensor5D, poolSize: [number, number, number],\n    strides?: [number, number, number], padding?: PaddingMode,\n    dataFormat?: DataFormat, poolMode?: PoolMode): Tensor {\n  return tidy(() => {\n    checkDataFormat(dataFormat);\n    checkPoolMode(poolMode);\n    checkPaddingMode(padding);\n    if (strides == null) {\n      strides = [1, 1, 1];\n    }\n    if (padding == null) {\n      padding = 'valid';\n    }\n    if (dataFormat == null) {\n      dataFormat = imageDataFormat();\n    }\n    if (poolMode == null) {\n      poolMode = 'max';\n    }\n\n    // x is NDHWC after preprocessing.\n    x = preprocessConv3DInput(x as Tensor, dataFormat) as Tensor5D;\n    let y: Tensor;\n    const paddingString = (padding === 'same') ? 'same' : 'valid';\n    if (poolMode === 'max') {\n      y = tfc.maxPool3d(x, poolSize, strides, paddingString);\n    } else {  // 'avg'\n      y = tfc.avgPool3d(x, poolSize, strides, paddingString);\n    }\n    if (dataFormat === 'channelsFirst') {\n      y = tfc.transpose(y, [0, 4, 1, 2, 3]);  // NDHWC -> NCDHW.\n    }\n    return y;\n  });\n}\n\nexport declare interface Pooling1DLayerArgs extends LayerArgs {\n  /**\n   * Size of the window to pool over, should be an integer.\n   */\n  poolSize?: number|[number];\n  /**\n   * Period at which to sample the pooled values.\n   *\n   * If `null`, defaults to `poolSize`.\n   */\n  strides?: number|[number];\n  /** How to fill in data that's not an integer multiple of poolSize. */\n  padding?: PaddingMode;\n}\n\n/**\n * Abstract class for different pooling 1D layers.\n */\nexport abstract class Pooling1D extends Layer {\n  protected readonly poolSize: [number];\n  protected readonly strides: [number];\n  protected readonly padding: PaddingMode;\n\n  /**\n   *\n   * @param args Parameters for the Pooling layer.\n   *\n   * config.poolSize defaults to 2.\n   */\n  constructor(args: Pooling1DLayerArgs) {\n    if (args.poolSize == null) {\n      args.poolSize = 2;\n    }\n    super(args);\n    if (typeof args.poolSize === 'number') {\n      this.poolSize = [args.poolSize];\n    } else if (\n        Array.isArray(args.poolSize) &&\n        (args.poolSize as number[]).length === 1 &&\n        typeof (args.poolSize as number[])[0] === 'number') {\n      this.poolSize = args.poolSize;\n    } else {\n      throw new ValueError(\n          `poolSize for 1D convolutional layer must be a number or an ` +\n          `Array of a single number, but received ` +\n          `${JSON.stringify(args.poolSize)}`);\n    }\n    assertPositiveInteger(this.poolSize, 'poolSize');\n    if (args.strides == null) {\n      this.strides = this.poolSize;\n    } else {\n      if (typeof args.strides === 'number') {\n        this.strides = [args.strides];\n      } else if (\n          Array.isArray(args.strides) &&\n          (args.strides as number[]).length === 1 &&\n          typeof (args.strides as number[])[0] === 'number') {\n        this.strides = args.strides;\n      } else {\n        throw new ValueError(\n            `strides for 1D convolutional layer must be a number or an ` +\n            `Array of a single number, but received ` +\n            `${JSON.stringify(args.strides)}`);\n      }\n    }\n    assertPositiveInteger(this.strides, 'strides');\n\n    this.padding = args.padding == null ? 'valid' : args.padding;\n    checkPaddingMode(this.padding);\n    this.inputSpec = [new InputSpec({ndim: 3})];\n  }\n\n  override computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    inputShape = getExactlyOneShape(inputShape);\n    const length = convOutputLength(\n        inputShape[1], this.poolSize[0], this.padding, this.strides[0]);\n    return [inputShape[0], length, inputShape[2]];\n  }\n\n  protected abstract poolingFunction(\n      inputs: Tensor, poolSize: [number, number], strides: [number, number],\n      padding: PaddingMode, dataFormat: DataFormat): Tensor;\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      // Add dummy last dimension.\n      inputs = K.expandDims(getExactlyOneTensor(inputs), 2);\n      const output = this.poolingFunction(\n          getExactlyOneTensor(inputs), [this.poolSize[0], 1],\n          [this.strides[0], 1], this.padding, 'channelsLast');\n      // Remove dummy last dimension.\n      return tfc.squeeze(output, [2]);\n    });\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config = {\n      poolSize: this.poolSize,\n      padding: this.padding,\n      strides: this.strides,\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\n\nexport class MaxPooling1D extends Pooling1D {\n  /** @nocollapse */\n  static className = 'MaxPooling1D';\n  constructor(args: Pooling1DLayerArgs) {\n    super(args);\n  }\n\n  protected poolingFunction(\n      inputs: Tensor, poolSize: [number, number], strides: [number, number],\n      padding: PaddingMode, dataFormat: DataFormat): Tensor {\n    checkDataFormat(dataFormat);\n    checkPaddingMode(padding);\n    return pool2d(inputs, poolSize, strides, padding, dataFormat, 'max');\n  }\n}\nserialization.registerClass(MaxPooling1D);\n\nexport class AveragePooling1D extends Pooling1D {\n  /** @nocollapse */\n  static className = 'AveragePooling1D';\n  constructor(args: Pooling1DLayerArgs) {\n    super(args);\n  }\n\n  protected poolingFunction(\n      inputs: Tensor, poolSize: [number, number], strides: [number, number],\n      padding: PaddingMode, dataFormat: DataFormat): Tensor {\n    checkDataFormat(dataFormat);\n    checkPaddingMode(padding);\n    return pool2d(inputs, poolSize, strides, padding, dataFormat, 'avg');\n  }\n}\nserialization.registerClass(AveragePooling1D);\n\nexport declare interface Pooling2DLayerArgs extends LayerArgs {\n  /**\n   * Factors by which to downscale in each dimension [vertical, horizontal].\n   * Expects an integer or an array of 2 integers.\n   *\n   * For example, `[2, 2]` will halve the input in both spatial dimensions.\n   * If only one integer is specified, the same window length\n   * will be used for both dimensions.\n   */\n  poolSize?: number|[number, number];\n\n  /**\n   * The size of the stride in each dimension of the pooling window. Expects\n   * an integer or an array of 2 integers. Integer, tuple of 2 integers, or\n   * None.\n   *\n   * If `null`, defaults to `poolSize`.\n   */\n  strides?: number|[number, number];\n\n  /** The padding type to use for the pooling layer. */\n  padding?: PaddingMode;\n  /** The data format to use for the pooling layer. */\n  dataFormat?: DataFormat;\n}\n\n/**\n * Abstract class for different pooling 2D layers.\n */\nexport abstract class Pooling2D extends Layer {\n  protected readonly poolSize: [number, number];\n  protected readonly strides: [number, number];\n  protected readonly padding: PaddingMode;\n  protected readonly dataFormat: DataFormat;\n\n  constructor(args: Pooling2DLayerArgs) {\n    if (args.poolSize == null) {\n      args.poolSize = [2, 2];\n    }\n    super(args);\n    this.poolSize = Array.isArray(args.poolSize) ?\n        args.poolSize :\n        [args.poolSize, args.poolSize];\n    if (args.strides == null) {\n      this.strides = this.poolSize;\n    } else if (Array.isArray(args.strides)) {\n      if (args.strides.length !== 2) {\n        throw new ValueError(\n            `If the strides property of a 2D pooling layer is an Array, ` +\n            `it is expected to have a length of 2, but received length ` +\n            `${args.strides.length}.`);\n      }\n      this.strides = args.strides;\n    } else {\n      // `config.strides` is a number.\n      this.strides = [args.strides, args.strides];\n    }\n    assertPositiveInteger(this.poolSize, 'poolSize');\n    assertPositiveInteger(this.strides, 'strides');\n    this.padding = args.padding == null ? 'valid' : args.padding;\n    this.dataFormat =\n        args.dataFormat == null ? 'channelsLast' : args.dataFormat;\n    checkDataFormat(this.dataFormat);\n    checkPaddingMode(this.padding);\n\n    this.inputSpec = [new InputSpec({ndim: 4})];\n  }\n\n  override computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    inputShape = getExactlyOneShape(inputShape);\n    let rows =\n        this.dataFormat === 'channelsFirst' ? inputShape[2] : inputShape[1];\n    let cols =\n        this.dataFormat === 'channelsFirst' ? inputShape[3] : inputShape[2];\n    rows =\n        convOutputLength(rows, this.poolSize[0], this.padding, this.strides[0]);\n    cols =\n        convOutputLength(cols, this.poolSize[1], this.padding, this.strides[1]);\n    if (this.dataFormat === 'channelsFirst') {\n      return [inputShape[0], inputShape[1], rows, cols];\n    } else {\n      return [inputShape[0], rows, cols, inputShape[3]];\n    }\n  }\n\n  protected abstract poolingFunction(\n      inputs: Tensor, poolSize: [number, number], strides: [number, number],\n      padding: PaddingMode, dataFormat: DataFormat): Tensor;\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      return this.poolingFunction(\n          getExactlyOneTensor(inputs), this.poolSize, this.strides,\n          this.padding, this.dataFormat);\n    });\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config = {\n      poolSize: this.poolSize,\n      padding: this.padding,\n      strides: this.strides,\n      dataFormat: this.dataFormat\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\n\nexport class MaxPooling2D extends Pooling2D {\n  /** @nocollapse */\n  static className = 'MaxPooling2D';\n  constructor(args: Pooling2DLayerArgs) {\n    super(args);\n  }\n\n  protected poolingFunction(\n      inputs: Tensor, poolSize: [number, number], strides: [number, number],\n      padding: PaddingMode, dataFormat: DataFormat): Tensor {\n    checkDataFormat(dataFormat);\n    checkPaddingMode(padding);\n    return pool2d(inputs, poolSize, strides, padding, dataFormat, 'max');\n  }\n}\nserialization.registerClass(MaxPooling2D);\n\nexport class AveragePooling2D extends Pooling2D {\n  /** @nocollapse */\n  static className = 'AveragePooling2D';\n  constructor(args: Pooling2DLayerArgs) {\n    super(args);\n  }\n\n  protected poolingFunction(\n      inputs: Tensor, poolSize: [number, number], strides: [number, number],\n      padding: PaddingMode, dataFormat: DataFormat): Tensor {\n    checkDataFormat(dataFormat);\n    checkPaddingMode(padding);\n    return pool2d(inputs, poolSize, strides, padding, dataFormat, 'avg');\n  }\n}\nserialization.registerClass(AveragePooling2D);\n\nexport declare interface Pooling3DLayerArgs extends LayerArgs {\n  /**\n   * Factors by which to downscale in each dimension [depth, height, width].\n   * Expects an integer or an array of 3 integers.\n   *\n   * For example, `[2, 2, 2]` will halve the input in three dimensions.\n   * If only one integer is specified, the same window length\n   * will be used for all dimensions.\n   */\n  poolSize?: number|[number, number, number];\n\n  /**\n   * The size of the stride in each dimension of the pooling window. Expects\n   * an integer or an array of 3 integers. Integer, tuple of 3 integers, or\n   * None.\n   *\n   * If `null`, defaults to `poolSize`.\n   */\n  strides?: number|[number, number, number];\n\n  /** The padding type to use for the pooling layer. */\n  padding?: PaddingMode;\n  /** The data format to use for the pooling layer. */\n  dataFormat?: DataFormat;\n}\n\n/**\n * Abstract class for different pooling 3D layers.\n */\nexport abstract class Pooling3D extends Layer {\n  protected readonly poolSize: [number, number, number];\n  protected readonly strides: [number, number, number];\n  protected readonly padding: PaddingMode;\n  protected readonly dataFormat: DataFormat;\n\n  constructor(args: Pooling3DLayerArgs) {\n    if (args.poolSize == null) {\n      args.poolSize = [2, 2, 2];\n    }\n    super(args);\n    this.poolSize = Array.isArray(args.poolSize) ?\n        args.poolSize :\n        [args.poolSize, args.poolSize, args.poolSize];\n    if (args.strides == null) {\n      this.strides = this.poolSize;\n    } else if (Array.isArray(args.strides)) {\n      if (args.strides.length !== 3) {\n        throw new ValueError(\n            `If the strides property of a 3D pooling layer is an Array, ` +\n            `it is expected to have a length of 3, but received length ` +\n            `${args.strides.length}.`);\n      }\n      this.strides = args.strides;\n    } else {\n      // `config.strides` is a number.\n      this.strides = [args.strides, args.strides, args.strides];\n    }\n    assertPositiveInteger(this.poolSize, 'poolSize');\n    assertPositiveInteger(this.strides, 'strides');\n    this.padding = args.padding == null ? 'valid' : args.padding;\n    this.dataFormat =\n        args.dataFormat == null ? 'channelsLast' : args.dataFormat;\n    checkDataFormat(this.dataFormat);\n    checkPaddingMode(this.padding);\n\n    this.inputSpec = [new InputSpec({ndim: 5})];\n  }\n\n  override computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    inputShape = getExactlyOneShape(inputShape);\n    let depths =\n        this.dataFormat === 'channelsFirst' ? inputShape[2] : inputShape[1];\n    let rows =\n        this.dataFormat === 'channelsFirst' ? inputShape[3] : inputShape[2];\n    let cols =\n        this.dataFormat === 'channelsFirst' ? inputShape[4] : inputShape[3];\n    depths = convOutputLength(\n        depths, this.poolSize[0], this.padding, this.strides[0]);\n    rows =\n        convOutputLength(rows, this.poolSize[1], this.padding, this.strides[1]);\n    cols =\n        convOutputLength(cols, this.poolSize[2], this.padding, this.strides[2]);\n    if (this.dataFormat === 'channelsFirst') {\n      return [inputShape[0], inputShape[1], depths, rows, cols];\n    } else {\n      return [inputShape[0], depths, rows, cols, inputShape[4]];\n    }\n  }\n\n  protected abstract poolingFunction(\n      inputs: Tensor, poolSize: [number, number, number],\n      strides: [number, number, number], padding: PaddingMode,\n      dataFormat: DataFormat): Tensor;\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      return this.poolingFunction(\n          getExactlyOneTensor(inputs), this.poolSize, this.strides,\n          this.padding, this.dataFormat);\n    });\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config = {\n      poolSize: this.poolSize,\n      padding: this.padding,\n      strides: this.strides,\n      dataFormat: this.dataFormat\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\n\nexport class MaxPooling3D extends Pooling3D {\n  /** @nocollapse */\n  static className = 'MaxPooling3D';\n  constructor(args: Pooling3DLayerArgs) {\n    super(args);\n  }\n\n  protected poolingFunction(\n      inputs: Tensor, poolSize: [number, number, number],\n      strides: [number, number, number], padding: PaddingMode,\n      dataFormat: DataFormat): Tensor {\n    checkDataFormat(dataFormat);\n    checkPaddingMode(padding);\n    return pool3d(\n        inputs as Tensor5D, poolSize, strides, padding, dataFormat, 'max');\n  }\n}\nserialization.registerClass(MaxPooling3D);\n\nexport class AveragePooling3D extends Pooling3D {\n  /** @nocollapse */\n  static className = 'AveragePooling3D';\n  constructor(args: Pooling3DLayerArgs) {\n    super(args);\n  }\n\n  protected poolingFunction(\n      inputs: Tensor, poolSize: [number, number, number],\n      strides: [number, number, number], padding: PaddingMode,\n      dataFormat: DataFormat): Tensor {\n    checkDataFormat(dataFormat);\n    checkPaddingMode(padding);\n    return pool3d(\n        inputs as Tensor5D, poolSize, strides, padding, dataFormat, 'avg');\n  }\n}\nserialization.registerClass(AveragePooling3D);\n\n/**\n * Abstract class for different global pooling 1D layers.\n */\nexport abstract class GlobalPooling1D extends Layer {\n  constructor(args: LayerArgs) {\n    super(args);\n    this.inputSpec = [new InputSpec({ndim: 3})];\n  }\n\n  override computeOutputShape(inputShape: Shape): Shape {\n    return [inputShape[0], inputShape[2]];\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    throw new NotImplementedError();\n  }\n}\n\nexport class GlobalAveragePooling1D extends GlobalPooling1D {\n  /** @nocollapse */\n  static className = 'GlobalAveragePooling1D';\n  constructor(args?: LayerArgs) {\n    super(args || {});\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      const input = getExactlyOneTensor(inputs);\n      return tfc.mean(input, 1);\n    });\n  }\n}\nserialization.registerClass(GlobalAveragePooling1D);\n\nexport class GlobalMaxPooling1D extends GlobalPooling1D {\n  /** @nocollapse */\n  static className = 'GlobalMaxPooling1D';\n  constructor(args: LayerArgs) {\n    super(args || {});\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      const input = getExactlyOneTensor(inputs);\n      return tfc.max(input, 1);\n    });\n  }\n}\nserialization.registerClass(GlobalMaxPooling1D);\n\nexport declare interface GlobalPooling2DLayerArgs extends LayerArgs {\n  /**\n   * One of `CHANNEL_LAST` (default) or `CHANNEL_FIRST`.\n   *\n   * The ordering of the dimensions in the inputs. `CHANNEL_LAST` corresponds\n   * to inputs with shape `[batch, height, width, channels]` while\n   * `CHANNEL_FIRST` corresponds to inputs with shape\n   * `[batch, channels, height, width]`.\n   */\n  dataFormat?: DataFormat;\n}\n\n/**\n * Abstract class for different global pooling 2D layers.\n */\nexport abstract class GlobalPooling2D extends Layer {\n  protected dataFormat: DataFormat;\n  constructor(args: GlobalPooling2DLayerArgs) {\n    super(args);\n    this.dataFormat =\n        args.dataFormat == null ? 'channelsLast' : args.dataFormat;\n    checkDataFormat(this.dataFormat);\n    this.inputSpec = [new InputSpec({ndim: 4})];\n  }\n\n  override computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    inputShape = inputShape as Shape;\n    if (this.dataFormat === 'channelsLast') {\n      return [inputShape[0], inputShape[3]];\n    } else {\n      return [inputShape[0], inputShape[1]];\n    }\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    throw new NotImplementedError();\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config = {dataFormat: this.dataFormat};\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n}\n\nexport class GlobalAveragePooling2D extends GlobalPooling2D {\n  /** @nocollapse */\n  static className = 'GlobalAveragePooling2D';\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      const input = getExactlyOneTensor(inputs);\n      if (this.dataFormat === 'channelsLast') {\n        return tfc.mean(input, [1, 2]);\n      } else {\n        return tfc.mean(input, [2, 3]);\n      }\n    });\n  }\n}\nserialization.registerClass(GlobalAveragePooling2D);\n\nexport class GlobalMaxPooling2D extends GlobalPooling2D {\n  /** @nocollapse */\n  static className = 'GlobalMaxPooling2D';\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      const input = getExactlyOneTensor(inputs);\n      if (this.dataFormat === 'channelsLast') {\n        return tfc.max(input, [1, 2]);\n      } else {\n        return tfc.max(input, [2, 3]);\n      }\n    });\n  }\n}\nserialization.registerClass(GlobalMaxPooling2D);\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;;;;;;;;GAQG,CAEH;;GAEG;;;;;;;;AAEH,OAAO,KAAK,GAAG,MAAM,uBAAuB,CAAC;;AAC7C,OAAO,EAAC,aAAa,EAAwC,IAAI,EAAC,MAAM,uBAAuB,CAAC;AAEhG,OAAO,EAAC,eAAe,EAAC,MAAM,mBAAmB,CAAC;AAClD,OAAO,KAAK,CAAC,MAAM,yBAAyB,CAAC;AAC7C,OAAO,EAAC,eAAe,EAAE,gBAAgB,EAAE,aAAa,EAAC,MAAM,WAAW,CAAC;AAC3E,OAAO,EAAC,SAAS,EAAC,MAAM,oBAAoB,CAAC;AAE7C,OAAO,EAAC,mBAAmB,EAAE,UAAU,EAAC,MAAM,WAAW,CAAC;AAG1D,OAAO,EAAC,gBAAgB,EAAC,MAAM,qBAAqB,CAAC;AACrD,OAAO,EAAC,qBAAqB,EAAC,MAAM,wBAAwB,CAAC;AAC7D,OAAO,EAAC,kBAAkB,EAAE,mBAAmB,EAAC,MAAM,sBAAsB,CAAC;AAE7E,OAAO,EAAC,qBAAqB,EAAE,qBAAqB,EAAC,MAAM,iBAAiB,CAAC;;;;;;;;;;;;;AAYvE,SAAU,MAAM,CAClB,CAAS,EAAE,QAA0B,EAAE,OAA0B,EACjE,OAAqB,EAAE,UAAuB,EAC9C,QAAmB;IACrB,WAAO,iPAAI,EAAC,GAAG,EAAE;YACf,8SAAe,EAAC,UAAU,CAAC,CAAC;YAC5B,4SAAa,EAAC,QAAQ,CAAC,CAAC;YACxB,+SAAgB,EAAC,OAAO,CAAC,CAAC;QAC1B,IAAI,OAAO,IAAI,IAAI,EAAE;YACnB,OAAO,GAAG;gBAAC,CAAC;gBAAE,CAAC;aAAC,CAAC;SAClB;QACD,IAAI,OAAO,IAAI,IAAI,EAAE;YACnB,OAAO,GAAG,OAAO,CAAC;SACnB;QACD,IAAI,UAAU,IAAI,IAAI,EAAE;YACtB,UAAU,OAAG,yTAAe,EAAE,CAAC;SAChC;QACD,IAAI,QAAQ,IAAI,IAAI,EAAE;YACpB,QAAQ,GAAG,KAAK,CAAC;SAClB;QAED,uEAAuE;QACvE,mCAAmC;QACnC,CAAC,OAAG,qUAAqB,EAAC,CAAC,EAAE,UAAU,CAAC,CAAC,CAAE,iCAAiC;QAC5E,IAAI,CAAS,CAAC;QACd,MAAM,aAAa,GAAG,AAAC,OAAO,KAAK,MAAM,CAAC,CAAC,CAAC,AAAC,MAAM,CAAC,CAAC,CAAC,OAAO,CAAC;QAC9D,IAAI,QAAQ,KAAK,KAAK,EAAE;YACtB,0BAA0B;YAC1B,CAAC,GAAG,GAAG,CAAC,wPAAO,CAAC,CAAa,EAAE,QAAQ,EAAE,OAAO,EAAE,aAAa,CAAC,CAAC;SAClE,MAAM,EAAG,QAAQ;YAChB,yEAAyE;YACzE,4BAA4B;YAC5B,CAAC,GAAG,GAAG,CAAC,wPAAO,CACX,0BAA0B;YAC1B,CAAwB,EAAE,QAAQ,EAAE,OAAO,EAAE,aAAa,CAAC,CAAC;SACjE;QACD,IAAI,UAAU,KAAK,eAAe,EAAE;YAClC,CAAC,GAAG,GAAG,CAAC,2PAAS,CAAC,CAAC,EAAE;gBAAC,CAAC;gBAAE,CAAC;gBAAE,CAAC;gBAAE,CAAC;aAAC,CAAC,CAAC,CAAE,gBAAgB;SACtD;QACD,OAAO,CAAC,CAAC;IACX,CAAC,CAAC,CAAC;AACL,CAAC;AAYK,SAAU,MAAM,CAClB,CAAW,EAAE,QAAkC,EAC/C,OAAkC,EAAE,OAAqB,EACzD,UAAuB,EAAE,QAAmB;IAC9C,WAAO,iPAAI,EAAC,GAAG,EAAE;YACf,8SAAe,EAAC,UAAU,CAAC,CAAC;YAC5B,4SAAa,EAAC,QAAQ,CAAC,CAAC;YACxB,+SAAgB,EAAC,OAAO,CAAC,CAAC;QAC1B,IAAI,OAAO,IAAI,IAAI,EAAE;YACnB,OAAO,GAAG;gBAAC,CAAC;gBAAE,CAAC;gBAAE,CAAC;aAAC,CAAC;SACrB;QACD,IAAI,OAAO,IAAI,IAAI,EAAE;YACnB,OAAO,GAAG,OAAO,CAAC;SACnB;QACD,IAAI,UAAU,IAAI,IAAI,EAAE;YACtB,UAAU,OAAG,yTAAe,EAAE,CAAC;SAChC;QACD,IAAI,QAAQ,IAAI,IAAI,EAAE;YACpB,QAAQ,GAAG,KAAK,CAAC;SAClB;QAED,kCAAkC;QAClC,CAAC,OAAG,qUAAqB,EAAC,CAAW,EAAE,UAAU,CAAa,CAAC;QAC/D,IAAI,CAAS,CAAC;QACd,MAAM,aAAa,GAAG,AAAC,OAAO,KAAK,MAAM,CAAC,CAAC,CAAC,AAAC,MAAM,CAAC,CAAC,CAAC,OAAO,CAAC;QAC9D,IAAI,QAAQ,KAAK,KAAK,EAAE;YACtB,CAAC,GAAG,GAAG,CAAC,6PAAS,CAAC,CAAC,EAAE,QAAQ,EAAE,OAAO,EAAE,aAAa,CAAC,CAAC;SACxD,MAAM,EAAG,QAAQ;YAChB,CAAC,GAAG,GAAG,CAAC,6PAAS,CAAC,CAAC,EAAE,QAAQ,EAAE,OAAO,EAAE,aAAa,CAAC,CAAC;SACxD;QACD,IAAI,UAAU,KAAK,eAAe,EAAE;YAClC,CAAC,GAAG,GAAG,CAAC,2PAAS,CAAC,CAAC,EAAE;gBAAC,CAAC;gBAAE,CAAC;gBAAE,CAAC;gBAAE,CAAC;gBAAE,CAAC;aAAC,CAAC,CAAC,CAAE,kBAAkB;SAC3D;QACD,OAAO,CAAC,CAAC;IACX,CAAC,CAAC,CAAC;AACL,CAAC;AAoBK,MAAgB,SAAU,SAAQ,gTAAK;IAK3C;;;;;OAKG,CACH,YAAY,IAAwB,CAAA;QAClC,IAAI,IAAI,CAAC,QAAQ,IAAI,IAAI,EAAE;YACzB,IAAI,CAAC,QAAQ,GAAG,CAAC,CAAC;SACnB;QACD,KAAK,CAAC,IAAI,CAAC,CAAC;QACZ,IAAI,OAAO,IAAI,CAAC,QAAQ,KAAK,QAAQ,EAAE;YACrC,IAAI,CAAC,QAAQ,GAAG;gBAAC,IAAI,CAAC,QAAQ;aAAC,CAAC;SACjC,MAAM,IACH,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,QAAQ,CAAC,IAC3B,IAAI,CAAC,QAAqB,CAAC,MAAM,KAAK,CAAC,IACxC,OAAQ,IAAI,CAAC,QAAqB,CAAC,CAAC,CAAC,KAAK,QAAQ,EAAE;YACtD,IAAI,CAAC,QAAQ,GAAG,IAAI,CAAC,QAAQ,CAAC;SAC/B,MAAM;YACL,MAAM,IAAI,ySAAU,CAChB,CAAA,2DAAA,CAA6D,GAC7D,CAAA,uCAAA,CAAyC,GACzC,GAAG,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,QAAQ,CAAC,EAAE,CAAC,CAAC;SACzC;YACD,oUAAqB,EAAC,IAAI,CAAC,QAAQ,EAAE,UAAU,CAAC,CAAC;QACjD,IAAI,IAAI,CAAC,OAAO,IAAI,IAAI,EAAE;YACxB,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC,QAAQ,CAAC;SAC9B,MAAM;YACL,IAAI,OAAO,IAAI,CAAC,OAAO,KAAK,QAAQ,EAAE;gBACpC,IAAI,CAAC,OAAO,GAAG;oBAAC,IAAI,CAAC,OAAO;iBAAC,CAAC;aAC/B,MAAM,IACH,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,OAAO,CAAC,IAC1B,IAAI,CAAC,OAAoB,CAAC,MAAM,KAAK,CAAC,IACvC,OAAQ,IAAI,CAAC,OAAoB,CAAC,CAAC,CAAC,KAAK,QAAQ,EAAE;gBACrD,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC,OAAO,CAAC;aAC7B,MAAM;gBACL,MAAM,IAAI,ySAAU,CAChB,CAAA,0DAAA,CAA4D,GAC5D,CAAA,uCAAA,CAAyC,GACzC,GAAG,IAAI,CAAC,SAAS,CAAC,IAAI,CAAC,OAAO,CAAC,EAAE,CAAC,CAAC;aACxC;SACF;YACD,oUAAqB,EAAC,IAAI,CAAC,OAAO,EAAE,SAAS,CAAC,CAAC;QAE/C,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC,OAAO,IAAI,IAAI,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,IAAI,CAAC,OAAO,CAAC;YAC7D,+SAAgB,EAAC,IAAI,CAAC,OAAO,CAAC,CAAC;QAC/B,IAAI,CAAC,SAAS,GAAG;YAAC,IAAI,oTAAS,CAAC;gBAAC,IAAI,EAAE,CAAC;YAAA,CAAC,CAAC;SAAC,CAAC;IAC9C,CAAC;IAEQ,kBAAkB,CAAC,UAAyB,EAAA;QACnD,UAAU,OAAG,+TAAkB,EAAC,UAAU,CAAC,CAAC;QAC5C,MAAM,MAAM,OAAG,4TAAgB,EAC3B,UAAU,CAAC,CAAC,CAAC,EAAE,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,IAAI,CAAC,OAAO,EAAE,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC;QACpE,OAAO;YAAC,UAAU,CAAC,CAAC,CAAC;YAAE,MAAM;YAAE,UAAU,CAAC,CAAC,CAAC;SAAC,CAAC;IAChD,CAAC;IAMQ,IAAI,CAAC,MAAuB,EAAE,MAAc,EAAA;QACnD,WAAO,iPAAI,EAAC,GAAG,EAAE;YACf,IAAI,CAAC,cAAc,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC;YACpC,4BAA4B;YAC5B,MAAM,GAAG,CAAC,CAAC,wTAAU,KAAC,gUAAmB,EAAC,MAAM,CAAC,EAAE,CAAC,CAAC,CAAC;YACtD,MAAM,MAAM,GAAG,IAAI,CAAC,eAAe,KAC/B,gUAAmB,EAAC,MAAM,CAAC,EAAE;gBAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC;gBAAE,CAAC;aAAC,EAClD;gBAAC,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC;gBAAE,CAAC;aAAC,EAAE,IAAI,CAAC,OAAO,EAAE,cAAc,CAAC,CAAC;YACxD,+BAA+B;YAC/B,OAAO,GAAG,CAAC,uPAAO,CAAC,MAAM,EAAE;gBAAC,CAAC;aAAC,CAAC,CAAC;QAClC,CAAC,CAAC,CAAC;IACL,CAAC;IAEQ,SAAS,GAAA;QAChB,MAAM,MAAM,GAAG;YACb,QAAQ,EAAE,IAAI,CAAC,QAAQ;YACvB,OAAO,EAAE,IAAI,CAAC,OAAO;YACrB,OAAO,EAAE,IAAI,CAAC,OAAO;SACtB,CAAC;QACF,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;QACrC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;CACF;AAED,MAAa,YAAa,SAAQ,SAAS;IAGzC,YAAY,IAAwB,CAAA;QAClC,KAAK,CAAC,IAAI,CAAC,CAAC;IACd,CAAC;IAES,eAAe,CACrB,MAAc,EAAE,QAA0B,EAAE,OAAyB,EACrE,OAAoB,EAAE,UAAsB,EAAA;YAC9C,8SAAe,EAAC,UAAU,CAAC,CAAC;YAC5B,+SAAgB,EAAC,OAAO,CAAC,CAAC;QAC1B,OAAO,MAAM,CAAC,MAAM,EAAE,QAAQ,EAAE,OAAO,EAAE,OAAO,EAAE,UAAU,EAAE,KAAK,CAAC,CAAC;IACvE,CAAC;;AAZD,gBAAA,EAAkB,CACX,aAAA,SAAS,GAAG,cAAc,CAAC;;AAapC,ySAAa,CAAC,aAAa,CAAC,YAAY,CAAC,CAAC;AAE1C,MAAa,gBAAiB,SAAQ,SAAS;IAG7C,YAAY,IAAwB,CAAA;QAClC,KAAK,CAAC,IAAI,CAAC,CAAC;IACd,CAAC;IAES,eAAe,CACrB,MAAc,EAAE,QAA0B,EAAE,OAAyB,EACrE,OAAoB,EAAE,UAAsB,EAAA;YAC9C,8SAAe,EAAC,UAAU,CAAC,CAAC;YAC5B,+SAAgB,EAAC,OAAO,CAAC,CAAC;QAC1B,OAAO,MAAM,CAAC,MAAM,EAAE,QAAQ,EAAE,OAAO,EAAE,OAAO,EAAE,UAAU,EAAE,KAAK,CAAC,CAAC;IACvE,CAAC;;AAZD,gBAAA,EAAkB,CACX,iBAAA,SAAS,GAAG,kBAAkB,CAAC;;AAaxC,ySAAa,CAAC,aAAa,CAAC,gBAAgB,CAAC,CAAC;AA+BxC,MAAgB,SAAU,SAAQ,gTAAK;IAM3C,YAAY,IAAwB,CAAA;QAClC,IAAI,IAAI,CAAC,QAAQ,IAAI,IAAI,EAAE;YACzB,IAAI,CAAC,QAAQ,GAAG;gBAAC,CAAC;gBAAE,CAAC;aAAC,CAAC;SACxB;QACD,KAAK,CAAC,IAAI,CAAC,CAAC;QACZ,IAAI,CAAC,QAAQ,GAAG,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,CAC1C,IAAI,CAAC,QAAQ,CAAC,CAAC,CACf;YAAC,IAAI,CAAC,QAAQ;YAAE,IAAI,CAAC,QAAQ;SAAC,CAAC;QACnC,IAAI,IAAI,CAAC,OAAO,IAAI,IAAI,EAAE;YACxB,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC,QAAQ,CAAC;SAC9B,MAAM,IAAI,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,OAAO,CAAC,EAAE;YACtC,IAAI,IAAI,CAAC,OAAO,CAAC,MAAM,KAAK,CAAC,EAAE;gBAC7B,MAAM,IAAI,ySAAU,CAChB,CAAA,2DAAA,CAA6D,GAC7D,CAAA,0DAAA,CAA4D,GAC5D,GAAG,IAAI,CAAC,OAAO,CAAC,MAAM,CAAA,CAAA,CAAG,CAAC,CAAC;aAChC;YACD,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC,OAAO,CAAC;SAC7B,MAAM;YACL,gCAAgC;YAChC,IAAI,CAAC,OAAO,GAAG;gBAAC,IAAI,CAAC,OAAO;gBAAE,IAAI,CAAC,OAAO;aAAC,CAAC;SAC7C;YACD,oUAAqB,EAAC,IAAI,CAAC,QAAQ,EAAE,UAAU,CAAC,CAAC;YACjD,oUAAqB,EAAC,IAAI,CAAC,OAAO,EAAE,SAAS,CAAC,CAAC;QAC/C,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC,OAAO,IAAI,IAAI,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,IAAI,CAAC,OAAO,CAAC;QAC7D,IAAI,CAAC,UAAU,GACX,IAAI,CAAC,UAAU,IAAI,IAAI,CAAC,CAAC,CAAC,cAAc,CAAC,CAAC,CAAC,IAAI,CAAC,UAAU,CAAC;YAC/D,8SAAe,EAAC,IAAI,CAAC,UAAU,CAAC,CAAC;YACjC,+SAAgB,EAAC,IAAI,CAAC,OAAO,CAAC,CAAC;QAE/B,IAAI,CAAC,SAAS,GAAG;YAAC,IAAI,oTAAS,CAAC;gBAAC,IAAI,EAAE,CAAC;YAAA,CAAC,CAAC;SAAC,CAAC;IAC9C,CAAC;IAEQ,kBAAkB,CAAC,UAAyB,EAAA;QACnD,UAAU,OAAG,+TAAkB,EAAC,UAAU,CAAC,CAAC;QAC5C,IAAI,IAAI,GACJ,IAAI,CAAC,UAAU,KAAK,eAAe,CAAC,CAAC,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC;QACxE,IAAI,IAAI,GACJ,IAAI,CAAC,UAAU,KAAK,eAAe,CAAC,CAAC,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC;QACxE,IAAI,OACA,4TAAgB,EAAC,IAAI,EAAE,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,IAAI,CAAC,OAAO,EAAE,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC;QAC5E,IAAI,OACA,4TAAgB,EAAC,IAAI,EAAE,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,IAAI,CAAC,OAAO,EAAE,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC;QAC5E,IAAI,IAAI,CAAC,UAAU,KAAK,eAAe,EAAE;YACvC,OAAO;gBAAC,UAAU,CAAC,CAAC,CAAC;gBAAE,UAAU,CAAC,CAAC,CAAC;gBAAE,IAAI;gBAAE,IAAI;aAAC,CAAC;SACnD,MAAM;YACL,OAAO;gBAAC,UAAU,CAAC,CAAC,CAAC;gBAAE,IAAI;gBAAE,IAAI;gBAAE,UAAU,CAAC,CAAC,CAAC;aAAC,CAAC;SACnD;IACH,CAAC;IAMQ,IAAI,CAAC,MAAuB,EAAE,MAAc,EAAA;QACnD,WAAO,iPAAI,EAAC,GAAG,EAAE;YACf,IAAI,CAAC,cAAc,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC;YACpC,OAAO,IAAI,CAAC,eAAe,KACvB,gUAAmB,EAAC,MAAM,CAAC,EAAE,IAAI,CAAC,QAAQ,EAAE,IAAI,CAAC,OAAO,EACxD,IAAI,CAAC,OAAO,EAAE,IAAI,CAAC,UAAU,CAAC,CAAC;QACrC,CAAC,CAAC,CAAC;IACL,CAAC;IAEQ,SAAS,GAAA;QAChB,MAAM,MAAM,GAAG;YACb,QAAQ,EAAE,IAAI,CAAC,QAAQ;YACvB,OAAO,EAAE,IAAI,CAAC,OAAO;YACrB,OAAO,EAAE,IAAI,CAAC,OAAO;YACrB,UAAU,EAAE,IAAI,CAAC,UAAU;SAC5B,CAAC;QACF,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;QACrC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;CACF;AAED,MAAa,YAAa,SAAQ,SAAS;IAGzC,YAAY,IAAwB,CAAA;QAClC,KAAK,CAAC,IAAI,CAAC,CAAC;IACd,CAAC;IAES,eAAe,CACrB,MAAc,EAAE,QAA0B,EAAE,OAAyB,EACrE,OAAoB,EAAE,UAAsB,EAAA;YAC9C,8SAAe,EAAC,UAAU,CAAC,CAAC;YAC5B,+SAAgB,EAAC,OAAO,CAAC,CAAC;QAC1B,OAAO,MAAM,CAAC,MAAM,EAAE,QAAQ,EAAE,OAAO,EAAE,OAAO,EAAE,UAAU,EAAE,KAAK,CAAC,CAAC;IACvE,CAAC;;AAZD,gBAAA,EAAkB,CACX,aAAA,SAAS,GAAG,cAAc,CAAC;;AAapC,ySAAa,CAAC,aAAa,CAAC,YAAY,CAAC,CAAC;AAE1C,MAAa,gBAAiB,SAAQ,SAAS;IAG7C,YAAY,IAAwB,CAAA;QAClC,KAAK,CAAC,IAAI,CAAC,CAAC;IACd,CAAC;IAES,eAAe,CACrB,MAAc,EAAE,QAA0B,EAAE,OAAyB,EACrE,OAAoB,EAAE,UAAsB,EAAA;YAC9C,8SAAe,EAAC,UAAU,CAAC,CAAC;YAC5B,+SAAgB,EAAC,OAAO,CAAC,CAAC;QAC1B,OAAO,MAAM,CAAC,MAAM,EAAE,QAAQ,EAAE,OAAO,EAAE,OAAO,EAAE,UAAU,EAAE,KAAK,CAAC,CAAC;IACvE,CAAC;;AAZD,gBAAA,EAAkB,CACX,iBAAA,SAAS,GAAG,kBAAkB,CAAC;;AAaxC,ySAAa,CAAC,aAAa,CAAC,gBAAgB,CAAC,CAAC;AA+BxC,MAAgB,SAAU,SAAQ,gTAAK;IAM3C,YAAY,IAAwB,CAAA;QAClC,IAAI,IAAI,CAAC,QAAQ,IAAI,IAAI,EAAE;YACzB,IAAI,CAAC,QAAQ,GAAG;gBAAC,CAAC;gBAAE,CAAC;gBAAE,CAAC;aAAC,CAAC;SAC3B;QACD,KAAK,CAAC,IAAI,CAAC,CAAC;QACZ,IAAI,CAAC,QAAQ,GAAG,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,CAC1C,IAAI,CAAC,QAAQ,CAAC,CAAC,CACf;YAAC,IAAI,CAAC,QAAQ;YAAE,IAAI,CAAC,QAAQ;YAAE,IAAI,CAAC,QAAQ;SAAC,CAAC;QAClD,IAAI,IAAI,CAAC,OAAO,IAAI,IAAI,EAAE;YACxB,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC,QAAQ,CAAC;SAC9B,MAAM,IAAI,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,OAAO,CAAC,EAAE;YACtC,IAAI,IAAI,CAAC,OAAO,CAAC,MAAM,KAAK,CAAC,EAAE;gBAC7B,MAAM,IAAI,ySAAU,CAChB,CAAA,2DAAA,CAA6D,GAC7D,CAAA,0DAAA,CAA4D,GAC5D,GAAG,IAAI,CAAC,OAAO,CAAC,MAAM,CAAA,CAAA,CAAG,CAAC,CAAC;aAChC;YACD,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC,OAAO,CAAC;SAC7B,MAAM;YACL,gCAAgC;YAChC,IAAI,CAAC,OAAO,GAAG;gBAAC,IAAI,CAAC,OAAO;gBAAE,IAAI,CAAC,OAAO;gBAAE,IAAI,CAAC,OAAO;aAAC,CAAC;SAC3D;YACD,oUAAqB,EAAC,IAAI,CAAC,QAAQ,EAAE,UAAU,CAAC,CAAC;YACjD,oUAAqB,EAAC,IAAI,CAAC,OAAO,EAAE,SAAS,CAAC,CAAC;QAC/C,IAAI,CAAC,OAAO,GAAG,IAAI,CAAC,OAAO,IAAI,IAAI,CAAC,CAAC,CAAC,OAAO,CAAC,CAAC,CAAC,IAAI,CAAC,OAAO,CAAC;QAC7D,IAAI,CAAC,UAAU,GACX,IAAI,CAAC,UAAU,IAAI,IAAI,CAAC,CAAC,CAAC,cAAc,CAAC,CAAC,CAAC,IAAI,CAAC,UAAU,CAAC;YAC/D,8SAAe,EAAC,IAAI,CAAC,UAAU,CAAC,CAAC;YACjC,+SAAgB,EAAC,IAAI,CAAC,OAAO,CAAC,CAAC;QAE/B,IAAI,CAAC,SAAS,GAAG;YAAC,IAAI,oTAAS,CAAC;gBAAC,IAAI,EAAE,CAAC;YAAA,CAAC,CAAC;SAAC,CAAC;IAC9C,CAAC;IAEQ,kBAAkB,CAAC,UAAyB,EAAA;QACnD,UAAU,OAAG,+TAAkB,EAAC,UAAU,CAAC,CAAC;QAC5C,IAAI,MAAM,GACN,IAAI,CAAC,UAAU,KAAK,eAAe,CAAC,CAAC,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC;QACxE,IAAI,IAAI,GACJ,IAAI,CAAC,UAAU,KAAK,eAAe,CAAC,CAAC,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC;QACxE,IAAI,IAAI,GACJ,IAAI,CAAC,UAAU,KAAK,eAAe,CAAC,CAAC,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC,UAAU,CAAC,CAAC,CAAC,CAAC;QACxE,MAAM,OAAG,4TAAgB,EACrB,MAAM,EAAE,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,IAAI,CAAC,OAAO,EAAE,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC;QAC7D,IAAI,OACA,4TAAgB,EAAC,IAAI,EAAE,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,IAAI,CAAC,OAAO,EAAE,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC;QAC5E,IAAI,OACA,4TAAgB,EAAC,IAAI,EAAE,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,EAAE,IAAI,CAAC,OAAO,EAAE,IAAI,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,CAAC;QAC5E,IAAI,IAAI,CAAC,UAAU,KAAK,eAAe,EAAE;YACvC,OAAO;gBAAC,UAAU,CAAC,CAAC,CAAC;gBAAE,UAAU,CAAC,CAAC,CAAC;gBAAE,MAAM;gBAAE,IAAI;gBAAE,IAAI;aAAC,CAAC;SAC3D,MAAM;YACL,OAAO;gBAAC,UAAU,CAAC,CAAC,CAAC;gBAAE,MAAM;gBAAE,IAAI;gBAAE,IAAI;gBAAE,UAAU,CAAC,CAAC,CAAC;aAAC,CAAC;SAC3D;IACH,CAAC;IAOQ,IAAI,CAAC,MAAuB,EAAE,MAAc,EAAA;QACnD,WAAO,iPAAI,EAAC,GAAG,EAAE;YACf,IAAI,CAAC,cAAc,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC;YACpC,OAAO,IAAI,CAAC,eAAe,KACvB,gUAAmB,EAAC,MAAM,CAAC,EAAE,IAAI,CAAC,QAAQ,EAAE,IAAI,CAAC,OAAO,EACxD,IAAI,CAAC,OAAO,EAAE,IAAI,CAAC,UAAU,CAAC,CAAC;QACrC,CAAC,CAAC,CAAC;IACL,CAAC;IAEQ,SAAS,GAAA;QAChB,MAAM,MAAM,GAAG;YACb,QAAQ,EAAE,IAAI,CAAC,QAAQ;YACvB,OAAO,EAAE,IAAI,CAAC,OAAO;YACrB,OAAO,EAAE,IAAI,CAAC,OAAO;YACrB,UAAU,EAAE,IAAI,CAAC,UAAU;SAC5B,CAAC;QACF,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;QACrC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;CACF;AAED,MAAa,YAAa,SAAQ,SAAS;IAGzC,YAAY,IAAwB,CAAA;QAClC,KAAK,CAAC,IAAI,CAAC,CAAC;IACd,CAAC;IAES,eAAe,CACrB,MAAc,EAAE,QAAkC,EAClD,OAAiC,EAAE,OAAoB,EACvD,UAAsB,EAAA;YACxB,8SAAe,EAAC,UAAU,CAAC,CAAC;YAC5B,+SAAgB,EAAC,OAAO,CAAC,CAAC;QAC1B,OAAO,MAAM,CACT,MAAkB,EAAE,QAAQ,EAAE,OAAO,EAAE,OAAO,EAAE,UAAU,EAAE,KAAK,CAAC,CAAC;IACzE,CAAC;;AAdD,gBAAA,EAAkB,CACX,aAAA,SAAS,GAAG,cAAc,CAAC;;AAepC,ySAAa,CAAC,aAAa,CAAC,YAAY,CAAC,CAAC;AAE1C,MAAa,gBAAiB,SAAQ,SAAS;IAG7C,YAAY,IAAwB,CAAA;QAClC,KAAK,CAAC,IAAI,CAAC,CAAC;IACd,CAAC;IAES,eAAe,CACrB,MAAc,EAAE,QAAkC,EAClD,OAAiC,EAAE,OAAoB,EACvD,UAAsB,EAAA;YACxB,8SAAe,EAAC,UAAU,CAAC,CAAC;YAC5B,+SAAgB,EAAC,OAAO,CAAC,CAAC;QAC1B,OAAO,MAAM,CACT,MAAkB,EAAE,QAAQ,EAAE,OAAO,EAAE,OAAO,EAAE,UAAU,EAAE,KAAK,CAAC,CAAC;IACzE,CAAC;;AAdD,gBAAA,EAAkB,CACX,iBAAA,SAAS,GAAG,kBAAkB,CAAC;;AAexC,ySAAa,CAAC,aAAa,CAAC,gBAAgB,CAAC,CAAC;AAKxC,MAAgB,eAAgB,SAAQ,gTAAK;IACjD,YAAY,IAAe,CAAA;QACzB,KAAK,CAAC,IAAI,CAAC,CAAC;QACZ,IAAI,CAAC,SAAS,GAAG;YAAC,IAAI,oTAAS,CAAC;gBAAC,IAAI,EAAE,CAAC;YAAA,CAAC,CAAC;SAAC,CAAC;IAC9C,CAAC;IAEQ,kBAAkB,CAAC,UAAiB,EAAA;QAC3C,OAAO;YAAC,UAAU,CAAC,CAAC,CAAC;YAAE,UAAU,CAAC,CAAC,CAAC;SAAC,CAAC;IACxC,CAAC;IAEQ,IAAI,CAAC,MAAuB,EAAE,MAAc,EAAA;QACnD,MAAM,IAAI,kTAAmB,EAAE,CAAC;IAClC,CAAC;CACF;AAED,MAAa,sBAAuB,SAAQ,eAAe;IAGzD,YAAY,IAAgB,CAAA;QAC1B,KAAK,CAAC,IAAI,IAAI,CAAA,CAAE,CAAC,CAAC;IACpB,CAAC;IAEQ,IAAI,CAAC,MAAuB,EAAE,MAAc,EAAA;QACnD,WAAO,iPAAI,EAAC,GAAG,EAAE;YACf,MAAM,KAAK,OAAG,gUAAmB,EAAC,MAAM,CAAC,CAAC;YAC1C,OAAO,GAAG,CAAC,iPAAI,CAAC,KAAK,EAAE,CAAC,CAAC,CAAC;QAC5B,CAAC,CAAC,CAAC;IACL,CAAC;;AAXD,gBAAA,EAAkB,CACX,uBAAA,SAAS,GAAG,wBAAwB,CAAC;;AAY9C,ySAAa,CAAC,aAAa,CAAC,sBAAsB,CAAC,CAAC;AAEpD,MAAa,kBAAmB,SAAQ,eAAe;IAGrD,YAAY,IAAe,CAAA;QACzB,KAAK,CAAC,IAAI,IAAI,CAAA,CAAE,CAAC,CAAC;IACpB,CAAC;IAEQ,IAAI,CAAC,MAAuB,EAAE,MAAc,EAAA;QACnD,WAAO,iPAAI,EAAC,GAAG,EAAE;YACf,MAAM,KAAK,OAAG,gUAAmB,EAAC,MAAM,CAAC,CAAC;YAC1C,OAAO,GAAG,CAAC,+OAAG,CAAC,KAAK,EAAE,CAAC,CAAC,CAAC;QAC3B,CAAC,CAAC,CAAC;IACL,CAAC;;AAXD,gBAAA,EAAkB,CACX,mBAAA,SAAS,GAAG,oBAAoB,CAAC;;AAY1C,ySAAa,CAAC,aAAa,CAAC,kBAAkB,CAAC,CAAC;AAiB1C,MAAgB,eAAgB,SAAQ,gTAAK;IAEjD,YAAY,IAA8B,CAAA;QACxC,KAAK,CAAC,IAAI,CAAC,CAAC;QACZ,IAAI,CAAC,UAAU,GACX,IAAI,CAAC,UAAU,IAAI,IAAI,CAAC,CAAC,CAAC,cAAc,CAAC,CAAC,CAAC,IAAI,CAAC,UAAU,CAAC;YAC/D,8SAAe,EAAC,IAAI,CAAC,UAAU,CAAC,CAAC;QACjC,IAAI,CAAC,SAAS,GAAG;YAAC,IAAI,oTAAS,CAAC;gBAAC,IAAI,EAAE,CAAC;YAAA,CAAC,CAAC;SAAC,CAAC;IAC9C,CAAC;IAEQ,kBAAkB,CAAC,UAAyB,EAAA;QACnD,UAAU,GAAG,UAAmB,CAAC;QACjC,IAAI,IAAI,CAAC,UAAU,KAAK,cAAc,EAAE;YACtC,OAAO;gBAAC,UAAU,CAAC,CAAC,CAAC;gBAAE,UAAU,CAAC,CAAC,CAAC;aAAC,CAAC;SACvC,MAAM;YACL,OAAO;gBAAC,UAAU,CAAC,CAAC,CAAC;gBAAE,UAAU,CAAC,CAAC,CAAC;aAAC,CAAC;SACvC;IACH,CAAC;IAEQ,IAAI,CAAC,MAAuB,EAAE,MAAc,EAAA;QACnD,MAAM,IAAI,kTAAmB,EAAE,CAAC;IAClC,CAAC;IAEQ,SAAS,GAAA;QAChB,MAAM,MAAM,GAAG;YAAC,UAAU,EAAE,IAAI,CAAC,UAAU;QAAA,CAAC,CAAC;QAC7C,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;QACrC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;CACF;AAED,MAAa,sBAAuB,SAAQ,eAAe;IAIhD,IAAI,CAAC,MAAuB,EAAE,MAAc,EAAA;QACnD,WAAO,iPAAI,EAAC,GAAG,EAAE;YACf,MAAM,KAAK,OAAG,gUAAmB,EAAC,MAAM,CAAC,CAAC;YAC1C,IAAI,IAAI,CAAC,UAAU,KAAK,cAAc,EAAE;gBACtC,OAAO,GAAG,CAAC,iPAAI,CAAC,KAAK,EAAE;oBAAC,CAAC;oBAAE,CAAC;iBAAC,CAAC,CAAC;aAChC,MAAM;gBACL,OAAO,GAAG,CAAC,iPAAI,CAAC,KAAK,EAAE;oBAAC,CAAC;oBAAE,CAAC;iBAAC,CAAC,CAAC;aAChC;QACH,CAAC,CAAC,CAAC;IACL,CAAC;;AAZD,gBAAA,EAAkB,CACX,uBAAA,SAAS,GAAG,wBAAwB,CAAC;;AAa9C,ySAAa,CAAC,aAAa,CAAC,sBAAsB,CAAC,CAAC;AAEpD,MAAa,kBAAmB,SAAQ,eAAe;IAI5C,IAAI,CAAC,MAAuB,EAAE,MAAc,EAAA;QACnD,WAAO,iPAAI,EAAC,GAAG,EAAE;YACf,MAAM,KAAK,OAAG,gUAAmB,EAAC,MAAM,CAAC,CAAC;YAC1C,IAAI,IAAI,CAAC,UAAU,KAAK,cAAc,EAAE;gBACtC,OAAO,GAAG,CAAC,+OAAG,CAAC,KAAK,EAAE;oBAAC,CAAC;oBAAE,CAAC;iBAAC,CAAC,CAAC;aAC/B,MAAM;gBACL,OAAO,GAAG,CAAC,+OAAG,CAAC,KAAK,EAAE;oBAAC,CAAC;oBAAE,CAAC;iBAAC,CAAC,CAAC;aAC/B;QACH,CAAC,CAAC,CAAC;IACL,CAAC;;AAZD,gBAAA,EAAkB,CACX,mBAAA,SAAS,GAAG,oBAAoB,CAAC;;AAa1C,ySAAa,CAAC,aAAa,CAAC,kBAAkB,CAAC,CAAC"}},
    {"offset": {"line": 3047, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-layers@4.22.0_@tensorflow+tfjs-core@4.22.0/node_modules/@tensorflow/tfjs-layers/dist/layers/wrappers.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-layers/src/layers/wrappers.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * Layers that augment the functionality of a base layer.\n */\n\nimport * as tfc from '@tensorflow/tfjs-core';\nimport {serialization, Tensor, tidy} from '@tensorflow/tfjs-core';\nimport * as K from '../backend/tfjs_backend';\nimport {nameScope} from '../common';\nimport {InputSpec, Layer, LayerArgs, SymbolicTensor} from '../engine/topology';\nimport {NotImplementedError, ValueError} from '../errors';\nimport {BidirectionalMergeMode, Shape, VALID_BIDIRECTIONAL_MERGE_MODES} from '../keras_format/common';\nimport {Kwargs} from '../types';\nimport {RegularizerFn, RnnStepFunction} from '../types';\nimport * as generic_utils from '../utils/generic_utils';\nimport {getExactlyOneShape, getExactlyOneTensor} from '../utils/types_utils';\nimport {LayerVariable} from '../variables';\n\nimport {rnn, RNN, standardizeArgs} from './recurrent';\nimport {deserialize} from './serialization';\n\nexport declare interface WrapperLayerArgs extends LayerArgs {\n  /**\n   * The layer to be wrapped.\n   */\n  layer: Layer;\n}\n\n/**\n * Abstract wrapper base class.\n *\n * Wrappers take another layer and augment it in various ways.\n * Do not use this class as a layer, it is only an abstract base class.\n * Two usable wrappers are the `TimeDistributed` and `Bidirectional` wrappers.\n */\nexport abstract class Wrapper extends Layer {\n  readonly layer: Layer;\n\n  constructor(args: WrapperLayerArgs) {\n    // Porting Note: In PyKeras, `self.layer` is set prior to the calling\n    //   `super()`. But we can't do that here due to TypeScript's restriction.\n    //   See: https://github.com/Microsoft/TypeScript/issues/8277\n    //   As a result, we have to add checks in `get trainable()` and\n    //   `set trainable()` below in order to prevent using `this.layer` when\n    //   its value is `undefined`. The super constructor does use the getter\n    //   and the setter of `this.layer`.\n    super(args);\n    this.layer = args.layer;\n  }\n\n  override build(inputShape: Shape|Shape[]): void {\n    this.built = true;\n  }\n\n  // TODO(cais): Implement activityRegularizer getter.\n\n  override get trainable(): boolean {\n    // Porting Note: the check of `this.layer` here is necessary due to the\n    //   way the `constructor` of this class is written (see Porting Note\n    //   above).\n    if (this.layer != null) {\n      return this.layer.trainable;\n    } else {\n      return false;\n    }\n  }\n\n  override set trainable(value: boolean) {\n    // Porting Note: the check of `this.layer` here is necessary due to the\n    //   way the `constructor` of this class is written (see Porting Note\n    //   above).\n    if (this.layer != null) {\n      this.layer.trainable = value;\n    }\n  }\n\n  override get trainableWeights(): LayerVariable[] {\n    return this.layer.trainableWeights;\n  }\n  // TODO(cais): Implement setter for trainableWeights.\n\n  override get nonTrainableWeights(): LayerVariable[] {\n    return this.layer.nonTrainableWeights;\n  }\n  // TODO(cais): Implement setter for nonTrainableWeights.\n\n  override get updates(): Tensor[] {\n    // tslint:disable-next-line:no-any\n    return (this.layer as any)._updates;\n  }\n\n  // TODO(cais): Implement getUpdatesFor().\n\n  override get losses(): RegularizerFn[] {\n    return this.layer.losses;\n  }\n\n  // TODO(cais): Implement getLossesFor().\n\n  override getWeights(): Tensor[] {\n    return this.layer.getWeights();\n  }\n\n  override setWeights(weights: Tensor[]): void {\n    this.layer.setWeights(weights);\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config: serialization.ConfigDict = {\n      'layer': {\n        'className': this.layer.getClassName(),\n        'config': this.layer.getConfig(),\n      }\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n  override setFastWeightInitDuringBuild(value: boolean) {\n    super.setFastWeightInitDuringBuild(value);\n    if (this.layer != null) {\n      this.layer.setFastWeightInitDuringBuild(value);\n    }\n  }\n\n  /** @nocollapse */\n  static override fromConfig<T extends serialization.Serializable>(\n      cls: serialization.SerializableConstructor<T>,\n      config: serialization.ConfigDict,\n      customObjects = {} as serialization.ConfigDict): T {\n    const layerConfig = config['layer'] as serialization.ConfigDict;\n    const layer = deserialize(layerConfig, customObjects) as Layer;\n    delete config['layer'];\n    const newConfig = {layer};\n    Object.assign(newConfig, config);\n    return new cls(newConfig);\n  }\n}\n\nexport class TimeDistributed extends Wrapper {\n  /** @nocollapse */\n  static className = 'TimeDistributed';\n  constructor(args: WrapperLayerArgs) {\n    super(args);\n    this.supportsMasking = true;\n  }\n\n  override build(inputShape: Shape|Shape[]): void {\n    inputShape = getExactlyOneShape(inputShape);\n    if (inputShape.length < 3) {\n      throw new ValueError(\n          `TimeDistributed layer expects an input shape >= 3D, but received ` +\n          `input shape ${JSON.stringify(inputShape)}`);\n    }\n    this.inputSpec = [{shape: inputShape}];\n    const childInputShape = [inputShape[0]].concat(inputShape.slice(2));\n    if (!this.layer.built) {\n      this.layer.build(childInputShape);\n      this.layer.built = true;\n    }\n    super.build(inputShape);\n  }\n\n  override computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    inputShape = getExactlyOneShape(inputShape);\n    const childInputShape = [inputShape[0]].concat(inputShape.slice(2));\n    const childOutputShape =\n        this.layer.computeOutputShape(childInputShape) as Shape;\n    const timesteps = inputShape[1];\n    return [childOutputShape[0], timesteps].concat(childOutputShape.slice(1));\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      // TODO(cais): Add 'training' and 'useLearningPhase' to kwargs.\n      inputs = getExactlyOneTensor(inputs);\n      // Porting Note: In tfjs-layers, `inputs` are always concrete tensor\n      // values. Hence the inputs can't have an undetermined first (batch)\n      // dimension, which is why we always use the K.rnn approach here.\n      const step: RnnStepFunction = (inputs: Tensor, states: Tensor[]) => {\n        // TODO(cais): Add useLearningPhase.\n        // NOTE(cais): `layer.call` may return a length-1 array of Tensor in\n        //   some cases (e.g., `layer` is a `Sequential` instance), which is\n        //   why `getExactlyOneTensor` is used below.\n        const output = getExactlyOneTensor(this.layer.call(inputs, kwargs));\n        return [output, []];\n      };\n      const rnnOutputs =\n          rnn(step, inputs, [], false /* goBackwards */, null /* mask */,\n              null /* constants */, false /* unroll */,\n              true /* needPerStepOutputs */);\n      const y = rnnOutputs[1];\n      // TODO(cais): Add activity regularization.\n      // TODO(cais): Add useLearningPhase.\n      return y;\n    });\n  }\n\n  // TODO(cais): Implement detailed computeMask() logic.\n}\nserialization.registerClass(TimeDistributed);\n\nexport function checkBidirectionalMergeMode(value?: string): void {\n  generic_utils.checkStringTypeUnionValue(\n      VALID_BIDIRECTIONAL_MERGE_MODES, 'BidirectionalMergeMode', value);\n}\n\nexport declare interface BidirectionalLayerArgs extends WrapperLayerArgs {\n  /**\n   * The instance of an `RNN` layer to be wrapped.\n   */\n  layer: RNN;\n\n  /**\n   * Mode by which outputs of the forward and backward RNNs are\n   * combined. If `null` or `undefined`, the output will not be\n   * combined, they will be returned as an `Array`.\n   *\n   * If `undefined` (i.e., not provided), defaults to `'concat'`.\n   */\n  mergeMode?: BidirectionalMergeMode;\n}\n\nconst DEFAULT_BIDIRECTIONAL_MERGE_MODE: BidirectionalMergeMode = 'concat';\n\nexport class Bidirectional extends Wrapper {\n  /** @nocollapse */\n  static className = 'Bidirectional';\n  mergeMode: BidirectionalMergeMode;\n  private forwardLayer: RNN;\n  private backwardLayer: RNN;\n  private returnSequences: boolean;\n  private returnState: boolean;\n  private numConstants?: number;\n  private _trainable: boolean;\n\n  constructor(args: BidirectionalLayerArgs) {\n    super(args);\n\n    // Note: When creating `this.forwardLayer`, the original Layer object\n    //   (`config.layer`) ought to be cloned. This is why we call\n    //   `getConfig()` followed by `deserialize()`. Without this cloning,\n    //   the layer names saved during serialization will incorrectly contain\n    //   the 'forward_' prefix. In Python Keras, this is done using\n    //   `copy.copy` (shallow copy), which does not have a simple equivalent\n    //   in JavaScript. JavaScript's `Object.assign()` does not copy\n    //   methods.\n    const layerConfig = args.layer.getConfig();\n    const forwDict: serialization.ConfigDict = {};\n    forwDict['className'] = args.layer.getClassName();\n    forwDict['config'] = layerConfig;\n    this.forwardLayer = deserialize(forwDict) as RNN;\n    layerConfig['goBackwards'] =\n        layerConfig['goBackwards'] === true ? false : true;\n    const backDict: serialization.ConfigDict = {};\n    backDict['className'] = args.layer.getClassName();\n    backDict['config'] = layerConfig;\n    this.backwardLayer = deserialize(backDict) as RNN;\n    this.forwardLayer.name = 'forward_' + this.forwardLayer.name;\n    this.backwardLayer.name = 'backward_' + this.backwardLayer.name;\n\n    this.mergeMode = args.mergeMode === undefined ?\n        DEFAULT_BIDIRECTIONAL_MERGE_MODE :\n        args.mergeMode;\n    checkBidirectionalMergeMode(this.mergeMode);\n    if (args.weights) {\n      throw new NotImplementedError(\n          'weights support is not implemented for Bidirectional layer yet.');\n    }\n    this._stateful = args.layer.stateful;\n    this.returnSequences = args.layer.returnSequences;\n    this.returnState = args.layer.returnState;\n    this.supportsMasking = true;\n    this._trainable = true;\n    this.inputSpec = args.layer.inputSpec;\n    this.numConstants = null;\n  }\n\n  override get trainable(): boolean {\n    return this._trainable;\n  }\n\n  override set trainable(value: boolean) {\n    // Porting Note: the check of `this.layer` here is necessary due to the\n    //   way the `constructor` of this class is written (see Porting Note\n    //   above).\n    this._trainable = value;\n    if (this.forwardLayer != null) {\n      this.forwardLayer.trainable = value;\n    }\n    if (this.backwardLayer != null) {\n      this.backwardLayer.trainable = value;\n    }\n  }\n\n  override getWeights(): Tensor[] {\n    return this.forwardLayer.getWeights().concat(\n        this.backwardLayer.getWeights());\n  }\n\n  override setWeights(weights: Tensor[]): void {\n    const numWeights = weights.length;\n    const numeightsOver2 = Math.floor(numWeights / 2);\n    this.forwardLayer.setWeights(weights.slice(0, numeightsOver2));\n    this.backwardLayer.setWeights(weights.slice(numeightsOver2));\n  }\n\n  override computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    let layerShapes: Shape|Shape[] =\n        this.forwardLayer.computeOutputShape(inputShape);\n    if (!(Array.isArray(layerShapes) && Array.isArray(layerShapes[0]))) {\n      layerShapes = [layerShapes as Shape];\n    }\n    layerShapes = layerShapes as Shape[];\n\n    let outputShape: Shape;\n    let outputShapes: Shape[];\n    let stateShape: Shape[];\n    if (this.returnState) {\n      stateShape = layerShapes.slice(1);\n      outputShape = layerShapes[0];\n    } else {\n      outputShape = layerShapes[0];\n    }\n    outputShape = outputShape;\n    if (this.mergeMode === 'concat') {\n      outputShape[outputShape.length - 1] *= 2;\n      outputShapes = [outputShape];\n    } else if (this.mergeMode == null) {\n      outputShapes = [outputShape, outputShape.slice()];\n    } else {\n      outputShapes = [outputShape];\n    }\n\n    if (this.returnState) {\n      if (this.mergeMode == null) {\n        return outputShapes.concat(stateShape).concat(stateShape.slice());\n      }\n      return [outputShape].concat(stateShape).concat(stateShape.slice());\n    }\n    return generic_utils.singletonOrArray(outputShapes);\n  }\n\n  override apply(\n      inputs: Tensor|Tensor[]|SymbolicTensor|SymbolicTensor[],\n      kwargs?: Kwargs): Tensor|Tensor[]|SymbolicTensor|SymbolicTensor[] {\n    let initialState: Tensor[]|SymbolicTensor[] =\n        kwargs == null ? null : kwargs['initialState'];\n    let constants: Tensor[]|SymbolicTensor[] =\n        kwargs == null ? null : kwargs['constants'];\n    if (kwargs == null) {\n      kwargs = {};\n    }\n    const standardized =\n        standardizeArgs(inputs, initialState, constants, this.numConstants);\n    inputs = standardized.inputs;\n    initialState = standardized.initialState;\n    constants = standardized.constants;\n\n    if (Array.isArray(inputs)) {\n      initialState = (inputs as Tensor[] | SymbolicTensor[]).slice(1);\n      inputs = (inputs as Tensor[] | SymbolicTensor[])[0];\n    }\n\n    if ((initialState == null || initialState.length === 0) &&\n        constants == null) {\n      return super.apply(inputs, kwargs);\n    }\n    const additionalInputs: Array<Tensor|SymbolicTensor> = [];\n    const additionalSpecs: InputSpec[] = [];\n    if (initialState != null) {\n      const numStates = initialState.length;\n      if (numStates % 2 > 0) {\n        throw new ValueError(\n            'When passing `initialState` to a Bidrectional RNN, ' +\n            'the state should be an Array containing the states of ' +\n            'the underlying RNNs.');\n      }\n      kwargs['initialState'] = initialState;\n      additionalInputs.push(...initialState);\n      const stateSpecs = (initialState as Array<Tensor|SymbolicTensor>)\n                             .map(state => new InputSpec({shape: state.shape}));\n      this.forwardLayer.stateSpec = stateSpecs.slice(0, numStates / 2);\n      this.backwardLayer.stateSpec = stateSpecs.slice(numStates / 2);\n      additionalSpecs.push(...stateSpecs);\n    }\n    if (constants != null) {\n      throw new NotImplementedError(\n          'Support for constants in Bidirectional layers is not ' +\n          'implemented yet.');\n    }\n\n    const isSymbolicTensor = additionalInputs[0] instanceof SymbolicTensor;\n    for (const tensor of additionalInputs) {\n      if (tensor instanceof SymbolicTensor !== isSymbolicTensor) {\n        throw new ValueError(\n            'The initial state of a Bidirectional layer cannot be ' +\n            'specified as a mix of symbolic and non-symbolic tensors');\n      }\n    }\n\n    if (isSymbolicTensor) {\n      // Compute the full input and specs, including the states.\n      const fullInput = [inputs].concat(additionalInputs);\n      const fullInputSpec = this.inputSpec.concat(additionalSpecs);\n      // Perform the call temporarily and replace inputSpec.\n      // Note: with initial states symbolic calls and non-symbolic calls to\n      // this method differ in how the initial states are passed. For\n      // symbolic calls, the initial states are passed in the first arg, as\n      // an Array of SymbolicTensors; for non-symbolic calls, they are\n      // passed in the second arg as a part of the kwargs. Hence the need to\n      // temporarily modify inputSpec here.\n      // TODO(cais): Make refactoring so that this hacky code below is no\n      // longer needed.\n      const originalInputSpec = this.inputSpec;\n      this.inputSpec = fullInputSpec;\n      const output =\n          super.apply(fullInput as Tensor[] | SymbolicTensor[], kwargs);\n      this.inputSpec = originalInputSpec;\n      return output;\n    } else {\n      return super.apply(inputs, kwargs);\n    }\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor|Tensor[] {\n    return tidy(() => {\n      const initialState = kwargs['initialState'];\n\n      let y: Tensor|Tensor[];\n      let yRev: Tensor|Tensor[];\n      if (initialState == null) {\n        y = this.forwardLayer.call(inputs, kwargs);\n        yRev = this.backwardLayer.call(inputs, kwargs);\n      } else {\n        const forwardState = initialState.slice(0, initialState.length / 2);\n        const backwardState = initialState.slice(initialState.length / 2);\n        y = this.forwardLayer.call(\n            inputs, Object.assign(kwargs, {initialState: forwardState}));\n        yRev = this.backwardLayer.call(\n            inputs, Object.assign(kwargs, {initialState: backwardState}));\n      }\n\n      let states: Tensor[];\n      if (this.returnState) {\n        if (Array.isArray(y)) {\n          states = y.slice(1).concat((yRev as Tensor[]).slice(1));\n        } else {\n        }\n        y = (y as Tensor[])[0];\n        yRev = (yRev as Tensor[])[0];\n      }\n\n      if (this.returnSequences) {\n        yRev = tfc.reverse(yRev as Tensor, 1);\n      }\n\n      let output: Tensor|Tensor[];\n      if (this.mergeMode === 'concat') {\n        output = K.concatenate([y as Tensor, yRev as Tensor]);\n      } else if (this.mergeMode === 'sum') {\n        output = tfc.add(y as Tensor, yRev as Tensor);\n      } else if (this.mergeMode === 'ave') {\n        output = tfc.mul(.5, tfc.add(y as Tensor, yRev as Tensor));\n      } else if (this.mergeMode === 'mul') {\n        output = tfc.mul(y as Tensor, yRev as Tensor);\n      } else if (this.mergeMode == null) {\n        output = [y as Tensor, yRev as Tensor];\n      }\n\n      // TODO(cais): Properly set learning phase.\n      if (this.returnState) {\n        if (this.mergeMode == null) {\n          return (output as Tensor[]).concat(states);\n        }\n        return [output as Tensor].concat(states);\n      }\n      return output;\n    });\n  }\n\n  override resetStates(states?: Tensor|Tensor[]): void {\n    this.forwardLayer.resetStates();\n    this.backwardLayer.resetStates();\n  }\n\n  override build(inputShape: Shape|Shape[]): void {\n    nameScope(this.forwardLayer.name, () => {\n      this.forwardLayer.build(inputShape);\n    });\n    nameScope(this.backwardLayer.name, () => {\n      this.backwardLayer.build(inputShape);\n    });\n    this.built = true;\n  }\n\n  override computeMask(inputs: Tensor|Tensor[], mask?: Tensor|Tensor[]): Tensor\n      |Tensor[] {\n    if (Array.isArray(mask)) {\n      mask = mask[0];\n    }\n    let outputMask: Tensor|Tensor[];\n    if (this.returnSequences) {\n      if (this.mergeMode == null) {\n        outputMask = [mask, mask];\n      } else {\n        outputMask = mask;\n      }\n    } else {\n      if (this.mergeMode == null) {\n        outputMask = [null, null];\n      } else {\n        outputMask = null;\n      }\n    }\n    if (this.returnState) {\n      const states = this.forwardLayer.states;\n      const stateMask: Tensor[] = states.map(state => null);\n      if (Array.isArray(outputMask)) {\n        return outputMask.concat(stateMask).concat(stateMask);\n      } else {\n        return [outputMask].concat(stateMask).concat(stateMask);\n      }\n    } else {\n      return outputMask;\n    }\n  }\n\n  override get trainableWeights(): LayerVariable[] {\n    return this.forwardLayer.trainableWeights.concat(\n        this.backwardLayer.trainableWeights);\n  }\n\n  override get nonTrainableWeights(): LayerVariable[] {\n    return this.forwardLayer.nonTrainableWeights.concat(\n        this.backwardLayer.nonTrainableWeights);\n  }\n\n  // TODO(cais): Implement constraints().\n\n  override setFastWeightInitDuringBuild(value: boolean) {\n    super.setFastWeightInitDuringBuild(value);\n    if (this.forwardLayer != null) {\n      this.forwardLayer.setFastWeightInitDuringBuild(value);\n    }\n    if (this.backwardLayer != null) {\n      this.backwardLayer.setFastWeightInitDuringBuild(value);\n    }\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config: serialization.ConfigDict = {\n      'mergeMode': this.mergeMode,\n    };\n    // TODO(cais): Add logic for `numConstants` once the property is added.\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n  /** @nocollapse */\n  static override fromConfig<T extends serialization.Serializable>(\n      cls: serialization.SerializableConstructor<T>,\n      config: serialization.ConfigDict): T {\n    const rnnLayer =\n        deserialize(config['layer'] as serialization.ConfigDict) as RNN;\n    delete config['layer'];\n    // TODO(cais): Add logic for `numConstants` once the property is added.\n    if (config['numConstants'] != null) {\n      throw new NotImplementedError(\n          `Deserialization of a Bidirectional layer with numConstants ` +\n          `present is not supported yet.`);\n    }\n    // tslint:disable-next-line:no-any\n    const newConfig: {[key: string]: any} = config;\n    newConfig['layer'] = rnnLayer;\n    return new cls(newConfig);\n  }\n}\nserialization.registerClass(Bidirectional);\n"],"names":[],"mappings":";;;;;;;;;;AAAA;;;;;;;;GAQG,CAEH;;GAEG;;;AAEH,OAAO,KAAK,GAAG,MAAM,uBAAuB,CAAC;;AAC7C,OAAO,EAAC,aAAa,EAAU,IAAI,EAAC,MAAM,uBAAuB,CAAC;AAClE,OAAO,KAAK,CAAC,MAAM,yBAAyB,CAAC;AAC7C,OAAO,EAAC,SAAS,EAAC,MAAM,WAAW,CAAC;AACpC,OAAO,EAAC,SAAS,EAAE,KAAK,EAAa,cAAc,EAAC,MAAM,oBAAoB,CAAC;AAC/E,OAAO,EAAC,mBAAmB,EAAE,UAAU,EAAC,MAAM,WAAW,CAAC;AAC1D,OAAO,EAAgC,+BAA+B,EAAC,MAAM,wBAAwB,CAAC;AAGtG,OAAO,KAAK,aAAa,MAAM,wBAAwB,CAAC;AACxD,OAAO,EAAC,kBAAkB,EAAE,mBAAmB,EAAC,MAAM,sBAAsB,CAAC;AAG7E,OAAO,EAAC,GAAG,EAAO,eAAe,EAAC,MAAM,aAAa,CAAC;AACtD,OAAO,EAAC,WAAW,EAAC,MAAM,iBAAiB,CAAC;;;;;;;;;;;;AAgBtC,MAAgB,OAAQ,SAAQ,gTAAK;IAGzC,YAAY,IAAsB,CAAA;QAChC,qEAAqE;QACrE,0EAA0E;QAC1E,6DAA6D;QAC7D,gEAAgE;QAChE,wEAAwE;QACxE,wEAAwE;QACxE,oCAAoC;QACpC,KAAK,CAAC,IAAI,CAAC,CAAC;QACZ,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC,KAAK,CAAC;IAC1B,CAAC;IAEQ,KAAK,CAAC,UAAyB,EAAA;QACtC,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC;IACpB,CAAC;IAED,oDAAoD;IAEpD,IAAa,SAAS,GAAA;QACpB,uEAAuE;QACvE,qEAAqE;QACrE,YAAY;QACZ,IAAI,IAAI,CAAC,KAAK,IAAI,IAAI,EAAE;YACtB,OAAO,IAAI,CAAC,KAAK,CAAC,SAAS,CAAC;SAC7B,MAAM;YACL,OAAO,KAAK,CAAC;SACd;IACH,CAAC;IAED,IAAa,SAAS,CAAC,KAAc,EAAA;QACnC,uEAAuE;QACvE,qEAAqE;QACrE,YAAY;QACZ,IAAI,IAAI,CAAC,KAAK,IAAI,IAAI,EAAE;YACtB,IAAI,CAAC,KAAK,CAAC,SAAS,GAAG,KAAK,CAAC;SAC9B;IACH,CAAC;IAED,IAAa,gBAAgB,GAAA;QAC3B,OAAO,IAAI,CAAC,KAAK,CAAC,gBAAgB,CAAC;IACrC,CAAC;IACD,qDAAqD;IAErD,IAAa,mBAAmB,GAAA;QAC9B,OAAO,IAAI,CAAC,KAAK,CAAC,mBAAmB,CAAC;IACxC,CAAC;IACD,wDAAwD;IAExD,IAAa,OAAO,GAAA;QAClB,kCAAkC;QAClC,OAAQ,IAAI,CAAC,KAAa,CAAC,QAAQ,CAAC;IACtC,CAAC;IAED,yCAAyC;IAEzC,IAAa,MAAM,GAAA;QACjB,OAAO,IAAI,CAAC,KAAK,CAAC,MAAM,CAAC;IAC3B,CAAC;IAED,wCAAwC;IAE/B,UAAU,GAAA;QACjB,OAAO,IAAI,CAAC,KAAK,CAAC,UAAU,EAAE,CAAC;IACjC,CAAC;IAEQ,UAAU,CAAC,OAAiB,EAAA;QACnC,IAAI,CAAC,KAAK,CAAC,UAAU,CAAC,OAAO,CAAC,CAAC;IACjC,CAAC;IAEQ,SAAS,GAAA;QAChB,MAAM,MAAM,GAA6B;YACvC,OAAO,EAAE;gBACP,WAAW,EAAE,IAAI,CAAC,KAAK,CAAC,YAAY,EAAE;gBACtC,QAAQ,EAAE,IAAI,CAAC,KAAK,CAAC,SAAS,EAAE;aACjC;SACF,CAAC;QACF,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;QACrC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;IAEQ,4BAA4B,CAAC,KAAc,EAAA;QAClD,KAAK,CAAC,4BAA4B,CAAC,KAAK,CAAC,CAAC;QAC1C,IAAI,IAAI,CAAC,KAAK,IAAI,IAAI,EAAE;YACtB,IAAI,CAAC,KAAK,CAAC,4BAA4B,CAAC,KAAK,CAAC,CAAC;SAChD;IACH,CAAC;IAED,gBAAA,EAAkB,CAClB,MAAM,CAAU,UAAU,CACtB,GAA6C,EAC7C,MAAgC,EAChC,gBAAgB,CAAA,CAA8B,EAAA;QAChD,MAAM,WAAW,GAAG,MAAM,CAAC,OAAO,CAA6B,CAAC;QAChE,MAAM,KAAK,OAAG,2TAAW,EAAC,WAAW,EAAE,aAAa,CAAU,CAAC;QAC/D,OAAO,MAAM,CAAC,OAAO,CAAC,CAAC;QACvB,MAAM,SAAS,GAAG;YAAC,KAAK;QAAA,CAAC,CAAC;QAC1B,MAAM,CAAC,MAAM,CAAC,SAAS,EAAE,MAAM,CAAC,CAAC;QACjC,OAAO,IAAI,GAAG,CAAC,SAAS,CAAC,CAAC;IAC5B,CAAC;CACF;AAED,MAAa,eAAgB,SAAQ,OAAO;IAG1C,YAAY,IAAsB,CAAA;QAChC,KAAK,CAAC,IAAI,CAAC,CAAC;QACZ,IAAI,CAAC,eAAe,GAAG,IAAI,CAAC;IAC9B,CAAC;IAEQ,KAAK,CAAC,UAAyB,EAAA;QACtC,UAAU,OAAG,+TAAkB,EAAC,UAAU,CAAC,CAAC;QAC5C,IAAI,UAAU,CAAC,MAAM,GAAG,CAAC,EAAE;YACzB,MAAM,IAAI,ySAAU,CAChB,CAAA,iEAAA,CAAmE,GACnE,CAAA,YAAA,EAAe,IAAI,CAAC,SAAS,CAAC,UAAU,CAAC,EAAE,CAAC,CAAC;SAClD;QACD,IAAI,CAAC,SAAS,GAAG;YAAC;gBAAC,KAAK,EAAE,UAAU;YAAA,CAAC;SAAC,CAAC;QACvC,MAAM,eAAe,GAAG;YAAC,UAAU,CAAC,CAAC,CAAC;SAAC,CAAC,MAAM,CAAC,UAAU,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;QACpE,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC,KAAK,EAAE;YACrB,IAAI,CAAC,KAAK,CAAC,KAAK,CAAC,eAAe,CAAC,CAAC;YAClC,IAAI,CAAC,KAAK,CAAC,KAAK,GAAG,IAAI,CAAC;SACzB;QACD,KAAK,CAAC,KAAK,CAAC,UAAU,CAAC,CAAC;IAC1B,CAAC;IAEQ,kBAAkB,CAAC,UAAyB,EAAA;QACnD,UAAU,OAAG,+TAAkB,EAAC,UAAU,CAAC,CAAC;QAC5C,MAAM,eAAe,GAAG;YAAC,UAAU,CAAC,CAAC,CAAC;SAAC,CAAC,MAAM,CAAC,UAAU,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;QACpE,MAAM,gBAAgB,GAClB,IAAI,CAAC,KAAK,CAAC,kBAAkB,CAAC,eAAe,CAAU,CAAC;QAC5D,MAAM,SAAS,GAAG,UAAU,CAAC,CAAC,CAAC,CAAC;QAChC,OAAO;YAAC,gBAAgB,CAAC,CAAC,CAAC;YAAE,SAAS;SAAC,CAAC,MAAM,CAAC,gBAAgB,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;IAC5E,CAAC;IAEQ,IAAI,CAAC,MAAuB,EAAE,MAAc,EAAA;QACnD,WAAO,iPAAI,EAAC,GAAG,EAAE;YACf,+DAA+D;YAC/D,MAAM,OAAG,gUAAmB,EAAC,MAAM,CAAC,CAAC;YACrC,oEAAoE;YACpE,oEAAoE;YACpE,iEAAiE;YACjE,MAAM,IAAI,GAAoB,CAAC,MAAc,EAAE,MAAgB,EAAE,EAAE;gBACjE,oCAAoC;gBACpC,oEAAoE;gBACpE,oEAAoE;gBACpE,6CAA6C;gBAC7C,MAAM,MAAM,OAAG,gUAAmB,EAAC,IAAI,CAAC,KAAK,CAAC,IAAI,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC,CAAC;gBACpE,OAAO;oBAAC,MAAM;oBAAE,EAAE;iBAAC,CAAC;YACtB,CAAC,CAAC;YACF,MAAM,UAAU,OACZ,+SAAG,EAAC,IAAI,EAAE,MAAM,EAAE,EAAE,EAAE,KAAK,CAAC,CAAmB,IAAI,CAAC,CAChD,IAAI,CAAC,CAAiB,GADoC,CAAjB,CACd,CAAC,CAC5B,IAAI,CAAC,EADe,IAAoB,kBACX,CAAC,CAAC;YACvC,MAAM,CAAC,GAAG,UAAU,CAAC,CAAC,CAAC,CAAC;YACxB,2CAA2C;YAC3C,oCAAoC;YACpC,OAAO,CAAC,CAAC;QACX,CAAC,CAAC,CAAC;IACL,CAAC;;AAxDD,gBAAA,EAAkB,CACX,gBAAA,SAAS,GAAG,iBAAiB,CAAC;;AA2DvC,ySAAa,CAAC,aAAa,CAAC,eAAe,CAAC,CAAC;AAEvC,SAAU,2BAA2B,CAAC,KAAc;IACxD,aAAa,CAAC,0TAAyB,CACnC,8UAA+B,EAAE,wBAAwB,EAAE,KAAK,CAAC,CAAC;AACxE,CAAC;AAkBD,MAAM,gCAAgC,GAA2B,QAAQ,CAAC;AAE1E,MAAa,aAAc,SAAQ,OAAO;IAWxC,YAAY,IAA4B,CAAA;QACtC,KAAK,CAAC,IAAI,CAAC,CAAC;QAEZ,qEAAqE;QACrE,6DAA6D;QAC7D,qEAAqE;QACrE,wEAAwE;QACxE,+DAA+D;QAC/D,wEAAwE;QACxE,gEAAgE;QAChE,aAAa;QACb,MAAM,WAAW,GAAG,IAAI,CAAC,KAAK,CAAC,SAAS,EAAE,CAAC;QAC3C,MAAM,QAAQ,GAA6B,CAAA,CAAE,CAAC;QAC9C,QAAQ,CAAC,WAAW,CAAC,GAAG,IAAI,CAAC,KAAK,CAAC,YAAY,EAAE,CAAC;QAClD,QAAQ,CAAC,QAAQ,CAAC,GAAG,WAAW,CAAC;QACjC,IAAI,CAAC,YAAY,OAAG,2TAAW,EAAC,QAAQ,CAAQ,CAAC;QACjD,WAAW,CAAC,aAAa,CAAC,GACtB,WAAW,CAAC,aAAa,CAAC,KAAK,IAAI,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,IAAI,CAAC;QACvD,MAAM,QAAQ,GAA6B,CAAA,CAAE,CAAC;QAC9C,QAAQ,CAAC,WAAW,CAAC,GAAG,IAAI,CAAC,KAAK,CAAC,YAAY,EAAE,CAAC;QAClD,QAAQ,CAAC,QAAQ,CAAC,GAAG,WAAW,CAAC;QACjC,IAAI,CAAC,aAAa,OAAG,2TAAW,EAAC,QAAQ,CAAQ,CAAC;QAClD,IAAI,CAAC,YAAY,CAAC,IAAI,GAAG,UAAU,GAAG,IAAI,CAAC,YAAY,CAAC,IAAI,CAAC;QAC7D,IAAI,CAAC,aAAa,CAAC,IAAI,GAAG,WAAW,GAAG,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC;QAEhE,IAAI,CAAC,SAAS,GAAG,IAAI,CAAC,SAAS,KAAK,SAAS,CAAC,CAAC,CAC3C,gCAAgC,CAAC,CAAC,CAClC,IAAI,CAAC,SAAS,CAAC;QACnB,2BAA2B,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC;QAC5C,IAAI,IAAI,CAAC,OAAO,EAAE;YAChB,MAAM,IAAI,kTAAmB,CACzB,iEAAiE,CAAC,CAAC;SACxE;QACD,IAAI,CAAC,SAAS,GAAG,IAAI,CAAC,KAAK,CAAC,QAAQ,CAAC;QACrC,IAAI,CAAC,eAAe,GAAG,IAAI,CAAC,KAAK,CAAC,eAAe,CAAC;QAClD,IAAI,CAAC,WAAW,GAAG,IAAI,CAAC,KAAK,CAAC,WAAW,CAAC;QAC1C,IAAI,CAAC,eAAe,GAAG,IAAI,CAAC;QAC5B,IAAI,CAAC,UAAU,GAAG,IAAI,CAAC;QACvB,IAAI,CAAC,SAAS,GAAG,IAAI,CAAC,KAAK,CAAC,SAAS,CAAC;QACtC,IAAI,CAAC,YAAY,GAAG,IAAI,CAAC;IAC3B,CAAC;IAED,IAAa,SAAS,GAAA;QACpB,OAAO,IAAI,CAAC,UAAU,CAAC;IACzB,CAAC;IAED,IAAa,SAAS,CAAC,KAAc,EAAA;QACnC,uEAAuE;QACvE,qEAAqE;QACrE,YAAY;QACZ,IAAI,CAAC,UAAU,GAAG,KAAK,CAAC;QACxB,IAAI,IAAI,CAAC,YAAY,IAAI,IAAI,EAAE;YAC7B,IAAI,CAAC,YAAY,CAAC,SAAS,GAAG,KAAK,CAAC;SACrC;QACD,IAAI,IAAI,CAAC,aAAa,IAAI,IAAI,EAAE;YAC9B,IAAI,CAAC,aAAa,CAAC,SAAS,GAAG,KAAK,CAAC;SACtC;IACH,CAAC;IAEQ,UAAU,GAAA;QACjB,OAAO,IAAI,CAAC,YAAY,CAAC,UAAU,EAAE,CAAC,MAAM,CACxC,IAAI,CAAC,aAAa,CAAC,UAAU,EAAE,CAAC,CAAC;IACvC,CAAC;IAEQ,UAAU,CAAC,OAAiB,EAAA;QACnC,MAAM,UAAU,GAAG,OAAO,CAAC,MAAM,CAAC;QAClC,MAAM,cAAc,GAAG,IAAI,CAAC,KAAK,CAAC,UAAU,GAAG,CAAC,CAAC,CAAC;QAClD,IAAI,CAAC,YAAY,CAAC,UAAU,CAAC,OAAO,CAAC,KAAK,CAAC,CAAC,EAAE,cAAc,CAAC,CAAC,CAAC;QAC/D,IAAI,CAAC,aAAa,CAAC,UAAU,CAAC,OAAO,CAAC,KAAK,CAAC,cAAc,CAAC,CAAC,CAAC;IAC/D,CAAC;IAEQ,kBAAkB,CAAC,UAAyB,EAAA;QACnD,IAAI,WAAW,GACX,IAAI,CAAC,YAAY,CAAC,kBAAkB,CAAC,UAAU,CAAC,CAAC;QACrD,IAAI,CAAC,CAAC,KAAK,CAAC,OAAO,CAAC,WAAW,CAAC,IAAI,KAAK,CAAC,OAAO,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC,CAAC,EAAE;YAClE,WAAW,GAAG;gBAAC,WAAoB;aAAC,CAAC;SACtC;QACD,WAAW,GAAG,WAAsB,CAAC;QAErC,IAAI,WAAkB,CAAC;QACvB,IAAI,YAAqB,CAAC;QAC1B,IAAI,UAAmB,CAAC;QACxB,IAAI,IAAI,CAAC,WAAW,EAAE;YACpB,UAAU,GAAG,WAAW,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;YAClC,WAAW,GAAG,WAAW,CAAC,CAAC,CAAC,CAAC;SAC9B,MAAM;YACL,WAAW,GAAG,WAAW,CAAC,CAAC,CAAC,CAAC;SAC9B;QACD,WAAW,GAAG,WAAW,CAAC;QAC1B,IAAI,IAAI,CAAC,SAAS,KAAK,QAAQ,EAAE;YAC/B,WAAW,CAAC,WAAW,CAAC,MAAM,GAAG,CAAC,CAAC,IAAI,CAAC,CAAC;YACzC,YAAY,GAAG;gBAAC,WAAW;aAAC,CAAC;SAC9B,MAAM,IAAI,IAAI,CAAC,SAAS,IAAI,IAAI,EAAE;YACjC,YAAY,GAAG;gBAAC,WAAW;gBAAE,WAAW,CAAC,KAAK,EAAE;aAAC,CAAC;SACnD,MAAM;YACL,YAAY,GAAG;gBAAC,WAAW;aAAC,CAAC;SAC9B;QAED,IAAI,IAAI,CAAC,WAAW,EAAE;YACpB,IAAI,IAAI,CAAC,SAAS,IAAI,IAAI,EAAE;gBAC1B,OAAO,YAAY,CAAC,MAAM,CAAC,UAAU,CAAC,CAAC,MAAM,CAAC,UAAU,CAAC,KAAK,EAAE,CAAC,CAAC;aACnE;YACD,OAAO;gBAAC,WAAW;aAAC,CAAC,MAAM,CAAC,UAAU,CAAC,CAAC,MAAM,CAAC,UAAU,CAAC,KAAK,EAAE,CAAC,CAAC;SACpE;QACD,OAAO,aAAa,CAAC,iTAAgB,CAAC,YAAY,CAAC,CAAC;IACtD,CAAC;IAEQ,KAAK,CACV,MAAuD,EACvD,MAAe,EAAA;QACjB,IAAI,YAAY,GACZ,MAAM,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,MAAM,CAAC,cAAc,CAAC,CAAC;QACnD,IAAI,SAAS,GACT,MAAM,IAAI,IAAI,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,CAAC,MAAM,CAAC,WAAW,CAAC,CAAC;QAChD,IAAI,MAAM,IAAI,IAAI,EAAE;YAClB,MAAM,GAAG,CAAA,CAAE,CAAC;SACb;QACD,MAAM,YAAY,OACd,2TAAe,EAAC,MAAM,EAAE,YAAY,EAAE,SAAS,EAAE,IAAI,CAAC,YAAY,CAAC,CAAC;QACxE,MAAM,GAAG,YAAY,CAAC,MAAM,CAAC;QAC7B,YAAY,GAAG,YAAY,CAAC,YAAY,CAAC;QACzC,SAAS,GAAG,YAAY,CAAC,SAAS,CAAC;QAEnC,IAAI,KAAK,CAAC,OAAO,CAAC,MAAM,CAAC,EAAE;YACzB,YAAY,GAAI,MAAsC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;YAChE,MAAM,GAAI,MAAsC,CAAC,CAAC,CAAC,CAAC;SACrD;QAED,IAAI,CAAC,YAAY,IAAI,IAAI,IAAI,YAAY,CAAC,MAAM,KAAK,CAAC,CAAC,IACnD,SAAS,IAAI,IAAI,EAAE;YACrB,OAAO,KAAK,CAAC,KAAK,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC;SACpC;QACD,MAAM,gBAAgB,GAAiC,EAAE,CAAC;QAC1D,MAAM,eAAe,GAAgB,EAAE,CAAC;QACxC,IAAI,YAAY,IAAI,IAAI,EAAE;YACxB,MAAM,SAAS,GAAG,YAAY,CAAC,MAAM,CAAC;YACtC,IAAI,SAAS,GAAG,CAAC,GAAG,CAAC,EAAE;gBACrB,MAAM,IAAI,ySAAU,CAChB,qDAAqD,GACrD,wDAAwD,GACxD,sBAAsB,CAAC,CAAC;aAC7B;YACD,MAAM,CAAC,cAAc,CAAC,GAAG,YAAY,CAAC;YACtC,gBAAgB,CAAC,IAAI,CAAC,GAAG,YAAY,CAAC,CAAC;YACvC,MAAM,UAAU,GAAI,YAA6C,CACzC,GAAG,EAAC,KAAK,CAAC,EAAG,AAAD,IAAK,oTAAS,CAAC;oBAAC,KAAK,EAAE,KAAK,CAAC,KAAK;gBAAA,CAAC,CAAC,CAAC,CAAC;YAC1E,IAAI,CAAC,YAAY,CAAC,SAAS,GAAG,UAAU,CAAC,KAAK,CAAC,CAAC,EAAE,SAAS,GAAG,CAAC,CAAC,CAAC;YACjE,IAAI,CAAC,aAAa,CAAC,SAAS,GAAG,UAAU,CAAC,KAAK,CAAC,SAAS,GAAG,CAAC,CAAC,CAAC;YAC/D,eAAe,CAAC,IAAI,CAAC,GAAG,UAAU,CAAC,CAAC;SACrC;QACD,IAAI,SAAS,IAAI,IAAI,EAAE;YACrB,MAAM,IAAI,kTAAmB,CACzB,uDAAuD,GACvD,kBAAkB,CAAC,CAAC;SACzB;QAED,MAAM,gBAAgB,GAAG,gBAAgB,CAAC,CAAC,CAAC,YAAY,yTAAc,CAAC;QACvE,KAAK,MAAM,MAAM,IAAI,gBAAgB,CAAE;YACrC,IAAI,MAAM,YAAY,yTAAc,KAAK,gBAAgB,EAAE;gBACzD,MAAM,IAAI,ySAAU,CAChB,uDAAuD,GACvD,yDAAyD,CAAC,CAAC;aAChE;SACF;QAED,IAAI,gBAAgB,EAAE;YACpB,0DAA0D;YAC1D,MAAM,SAAS,GAAG;gBAAC,MAAM;aAAC,CAAC,MAAM,CAAC,gBAAgB,CAAC,CAAC;YACpD,MAAM,aAAa,GAAG,IAAI,CAAC,SAAS,CAAC,MAAM,CAAC,eAAe,CAAC,CAAC;YAC7D,sDAAsD;YACtD,qEAAqE;YACrE,+DAA+D;YAC/D,qEAAqE;YACrE,gEAAgE;YAChE,sEAAsE;YACtE,qCAAqC;YACrC,mEAAmE;YACnE,iBAAiB;YACjB,MAAM,iBAAiB,GAAG,IAAI,CAAC,SAAS,CAAC;YACzC,IAAI,CAAC,SAAS,GAAG,aAAa,CAAC;YAC/B,MAAM,MAAM,GACR,KAAK,CAAC,KAAK,CAAC,SAAwC,EAAE,MAAM,CAAC,CAAC;YAClE,IAAI,CAAC,SAAS,GAAG,iBAAiB,CAAC;YACnC,OAAO,MAAM,CAAC;SACf,MAAM;YACL,OAAO,KAAK,CAAC,KAAK,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC;SACpC;IACH,CAAC;IAEQ,IAAI,CAAC,MAAuB,EAAE,MAAc,EAAA;QACnD,WAAO,iPAAI,EAAC,GAAG,EAAE;YACf,MAAM,YAAY,GAAG,MAAM,CAAC,cAAc,CAAC,CAAC;YAE5C,IAAI,CAAkB,CAAC;YACvB,IAAI,IAAqB,CAAC;YAC1B,IAAI,YAAY,IAAI,IAAI,EAAE;gBACxB,CAAC,GAAG,IAAI,CAAC,YAAY,CAAC,IAAI,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC;gBAC3C,IAAI,GAAG,IAAI,CAAC,aAAa,CAAC,IAAI,CAAC,MAAM,EAAE,MAAM,CAAC,CAAC;aAChD,MAAM;gBACL,MAAM,YAAY,GAAG,YAAY,CAAC,KAAK,CAAC,CAAC,EAAE,YAAY,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;gBACpE,MAAM,aAAa,GAAG,YAAY,CAAC,KAAK,CAAC,YAAY,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;gBAClE,CAAC,GAAG,IAAI,CAAC,YAAY,CAAC,IAAI,CACtB,MAAM,EAAE,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE;oBAAC,YAAY,EAAE,YAAY;gBAAA,CAAC,CAAC,CAAC,CAAC;gBACjE,IAAI,GAAG,IAAI,CAAC,aAAa,CAAC,IAAI,CAC1B,MAAM,EAAE,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE;oBAAC,YAAY,EAAE,aAAa;gBAAA,CAAC,CAAC,CAAC,CAAC;aACnE;YAED,IAAI,MAAgB,CAAC;YACrB,IAAI,IAAI,CAAC,WAAW,EAAE;gBACpB,IAAI,KAAK,CAAC,OAAO,CAAC,CAAC,CAAC,EAAE;oBACpB,MAAM,GAAG,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,MAAM,CAAE,IAAiB,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;iBACzD,MAAM,EACN;gBACD,CAAC,GAAI,CAAc,CAAC,CAAC,CAAC,CAAC;gBACvB,IAAI,GAAI,IAAiB,CAAC,CAAC,CAAC,CAAC;aAC9B;YAED,IAAI,IAAI,CAAC,eAAe,EAAE;gBACxB,IAAI,GAAG,GAAG,CAAC,uPAAO,CAAC,IAAc,EAAE,CAAC,CAAC,CAAC;aACvC;YAED,IAAI,MAAuB,CAAC;YAC5B,IAAI,IAAI,CAAC,SAAS,KAAK,QAAQ,EAAE;gBAC/B,MAAM,GAAG,CAAC,CAAC,yTAAW,CAAC;oBAAC,CAAW;oBAAE,IAAc;iBAAC,CAAC,CAAC;aACvD,MAAM,IAAI,IAAI,CAAC,SAAS,KAAK,KAAK,EAAE;gBACnC,MAAM,GAAG,GAAG,CAAC,+OAAG,CAAC,CAAW,EAAE,IAAc,CAAC,CAAC;aAC/C,MAAM,IAAI,IAAI,CAAC,SAAS,KAAK,KAAK,EAAE;gBACnC,MAAM,GAAG,GAAG,CAAC,+OAAG,CAAC,EAAE,EAAE,GAAG,CAAC,+OAAG,CAAC,CAAW,EAAE,IAAc,CAAC,CAAC,CAAC;aAC5D,MAAM,IAAI,IAAI,CAAC,SAAS,KAAK,KAAK,EAAE;gBACnC,MAAM,GAAG,GAAG,CAAC,+OAAG,CAAC,CAAW,EAAE,IAAc,CAAC,CAAC;aAC/C,MAAM,IAAI,IAAI,CAAC,SAAS,IAAI,IAAI,EAAE;gBACjC,MAAM,GAAG;oBAAC,CAAW;oBAAE,IAAc;iBAAC,CAAC;aACxC;YAED,2CAA2C;YAC3C,IAAI,IAAI,CAAC,WAAW,EAAE;gBACpB,IAAI,IAAI,CAAC,SAAS,IAAI,IAAI,EAAE;oBAC1B,OAAQ,MAAmB,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;iBAC5C;gBACD,OAAO;oBAAC,MAAgB;iBAAC,CAAC,MAAM,CAAC,MAAM,CAAC,CAAC;aAC1C;YACD,OAAO,MAAM,CAAC;QAChB,CAAC,CAAC,CAAC;IACL,CAAC;IAEQ,WAAW,CAAC,MAAwB,EAAA;QAC3C,IAAI,CAAC,YAAY,CAAC,WAAW,EAAE,CAAC;QAChC,IAAI,CAAC,aAAa,CAAC,WAAW,EAAE,CAAC;IACnC,CAAC;IAEQ,KAAK,CAAC,UAAyB,EAAA;YACtC,wSAAS,EAAC,IAAI,CAAC,YAAY,CAAC,IAAI,EAAE,GAAG,EAAE;YACrC,IAAI,CAAC,YAAY,CAAC,KAAK,CAAC,UAAU,CAAC,CAAC;QACtC,CAAC,CAAC,CAAC;YACH,wSAAS,EAAC,IAAI,CAAC,aAAa,CAAC,IAAI,EAAE,GAAG,EAAE;YACtC,IAAI,CAAC,aAAa,CAAC,KAAK,CAAC,UAAU,CAAC,CAAC;QACvC,CAAC,CAAC,CAAC;QACH,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC;IACpB,CAAC;IAEQ,WAAW,CAAC,MAAuB,EAAE,IAAsB,EAAA;QAElE,IAAI,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,EAAE;YACvB,IAAI,GAAG,IAAI,CAAC,CAAC,CAAC,CAAC;SAChB;QACD,IAAI,UAA2B,CAAC;QAChC,IAAI,IAAI,CAAC,eAAe,EAAE;YACxB,IAAI,IAAI,CAAC,SAAS,IAAI,IAAI,EAAE;gBAC1B,UAAU,GAAG;oBAAC,IAAI;oBAAE,IAAI;iBAAC,CAAC;aAC3B,MAAM;gBACL,UAAU,GAAG,IAAI,CAAC;aACnB;SACF,MAAM;YACL,IAAI,IAAI,CAAC,SAAS,IAAI,IAAI,EAAE;gBAC1B,UAAU,GAAG;oBAAC,IAAI;oBAAE,IAAI;iBAAC,CAAC;aAC3B,MAAM;gBACL,UAAU,GAAG,IAAI,CAAC;aACnB;SACF;QACD,IAAI,IAAI,CAAC,WAAW,EAAE;YACpB,MAAM,MAAM,GAAG,IAAI,CAAC,YAAY,CAAC,MAAM,CAAC;YACxC,MAAM,SAAS,GAAa,MAAM,CAAC,GAAG,EAAC,KAAK,CAAC,EAAE,AAAC,IAAI,CAAC,CAAC;YACtD,IAAI,KAAK,CAAC,OAAO,CAAC,UAAU,CAAC,EAAE;gBAC7B,OAAO,UAAU,CAAC,MAAM,CAAC,SAAS,CAAC,CAAC,MAAM,CAAC,SAAS,CAAC,CAAC;aACvD,MAAM;gBACL,OAAO;oBAAC,UAAU;iBAAC,CAAC,MAAM,CAAC,SAAS,CAAC,CAAC,MAAM,CAAC,SAAS,CAAC,CAAC;aACzD;SACF,MAAM;YACL,OAAO,UAAU,CAAC;SACnB;IACH,CAAC;IAED,IAAa,gBAAgB,GAAA;QAC3B,OAAO,IAAI,CAAC,YAAY,CAAC,gBAAgB,CAAC,MAAM,CAC5C,IAAI,CAAC,aAAa,CAAC,gBAAgB,CAAC,CAAC;IAC3C,CAAC;IAED,IAAa,mBAAmB,GAAA;QAC9B,OAAO,IAAI,CAAC,YAAY,CAAC,mBAAmB,CAAC,MAAM,CAC/C,IAAI,CAAC,aAAa,CAAC,mBAAmB,CAAC,CAAC;IAC9C,CAAC;IAED,uCAAuC;IAE9B,4BAA4B,CAAC,KAAc,EAAA;QAClD,KAAK,CAAC,4BAA4B,CAAC,KAAK,CAAC,CAAC;QAC1C,IAAI,IAAI,CAAC,YAAY,IAAI,IAAI,EAAE;YAC7B,IAAI,CAAC,YAAY,CAAC,4BAA4B,CAAC,KAAK,CAAC,CAAC;SACvD;QACD,IAAI,IAAI,CAAC,aAAa,IAAI,IAAI,EAAE;YAC9B,IAAI,CAAC,aAAa,CAAC,4BAA4B,CAAC,KAAK,CAAC,CAAC;SACxD;IACH,CAAC;IAEQ,SAAS,GAAA;QAChB,MAAM,MAAM,GAA6B;YACvC,WAAW,EAAE,IAAI,CAAC,SAAS;SAC5B,CAAC;QACF,uEAAuE;QACvE,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;QACrC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;IAED,gBAAA,EAAkB,CAClB,MAAM,CAAU,UAAU,CACtB,GAA6C,EAC7C,MAAgC,EAAA;QAClC,MAAM,QAAQ,OACV,2TAAW,EAAC,MAAM,CAAC,OAAO,CAA6B,CAAQ,CAAC;QACpE,OAAO,MAAM,CAAC,OAAO,CAAC,CAAC;QACvB,uEAAuE;QACvE,IAAI,MAAM,CAAC,cAAc,CAAC,IAAI,IAAI,EAAE;YAClC,MAAM,IAAI,kTAAmB,CACzB,CAAA,2DAAA,CAA6D,GAC7D,CAAA,6BAAA,CAA+B,CAAC,CAAC;SACtC;QACD,kCAAkC;QAClC,MAAM,SAAS,GAAyB,MAAM,CAAC;QAC/C,SAAS,CAAC,OAAO,CAAC,GAAG,QAAQ,CAAC;QAC9B,OAAO,IAAI,GAAG,CAAC,SAAS,CAAC,CAAC;IAC5B,CAAC;;AA/VD,gBAAA,EAAkB,CACX,cAAA,SAAS,GAAG,eAAe,CAAC;;AAgWrC,ySAAa,CAAC,aAAa,CAAC,aAAa,CAAC,CAAC"}},
    {"offset": {"line": 3571, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-layers@4.22.0_@tensorflow+tfjs-core@4.22.0/node_modules/@tensorflow/tfjs-layers/dist/layers/preprocessing/image_preprocessing.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-layers/src/layers/preprocessing/image_preprocessing.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2022 CodeSmith LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\nimport {LayerArgs, Layer} from '../../engine/topology';\nimport { serialization, Tensor, mul, add, tidy } from '@tensorflow/tfjs-core';\nimport { getExactlyOneTensor } from '../../utils/types_utils';\nimport * as K from '../../backend/tfjs_backend';\nimport { Kwargs } from '../../types';\n\nexport declare interface RescalingArgs extends LayerArgs {\n  scale: number;\n  offset?: number;\n}\n\n/**\n * Preprocessing Rescaling Layer\n *\n * This rescales images by a scaling and offset factor\n */\nexport class Rescaling extends Layer {\n  /** @nocollapse */\n  static className = 'Rescaling';\n  private readonly scale: number;\n  private readonly offset: number;\n  constructor(args: RescalingArgs) {\n    super(args);\n\n    this.scale = args.scale;\n\n    if(args.offset) {\n    this.offset = args.offset;\n    } else {\n      this.offset = 0;\n    }\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config: serialization.ConfigDict = {\n      'scale': this.scale,\n      'offset': this.offset\n    };\n\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor[]|Tensor {\n    return tidy(() => {\n      inputs = getExactlyOneTensor(inputs);\n      if(inputs.dtype !== 'float32') {\n          inputs = K.cast(inputs, 'float32');\n      }\n      return add(mul(inputs, this.scale), this.offset);\n    });\n  }\n}\n\nserialization.registerClass(Rescaling);\n"],"names":[],"mappings":";;;;AAAA;;;;;;;;GAQG,CAEH,OAAO,EAAY,KAAK,EAAC,MAAM,uBAAuB,CAAC;;;;;AACvD,OAAO,EAAE,aAAa,EAAU,GAAG,EAAE,GAAG,EAAE,IAAI,EAAE,MAAM,uBAAuB,CAAC;AAC9E,OAAO,EAAE,mBAAmB,EAAE,MAAM,yBAAyB,CAAC;AAC9D,OAAO,KAAK,CAAC,MAAM,4BAA4B,CAAC;;;;;AAQhD;;;;GAIG,CACH,MAAa,SAAU,SAAQ,gTAAK;IAKlC,YAAY,IAAmB,CAAA;QAC7B,KAAK,CAAC,IAAI,CAAC,CAAC;QAEZ,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC,KAAK,CAAC;QAExB,IAAG,IAAI,CAAC,MAAM,EAAE;YAChB,IAAI,CAAC,MAAM,GAAG,IAAI,CAAC,MAAM,CAAC;SACzB,MAAM;YACL,IAAI,CAAC,MAAM,GAAG,CAAC,CAAC;SACjB;IACH,CAAC;IAEQ,SAAS,GAAA;QAChB,MAAM,MAAM,GAA6B;YACvC,OAAO,EAAE,IAAI,CAAC,KAAK;YACnB,QAAQ,EAAE,IAAI,CAAC,MAAM;SACtB,CAAC;QAEF,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;QACrC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;IAEQ,IAAI,CAAC,MAAuB,EAAE,MAAc,EAAA;QACnD,WAAO,iPAAI,EAAC,GAAG,EAAE;YACf,MAAM,OAAG,gUAAmB,EAAC,MAAM,CAAC,CAAC;YACrC,IAAG,MAAM,CAAC,KAAK,KAAK,SAAS,EAAE;gBAC3B,MAAM,GAAG,CAAC,CAAC,kTAAI,CAAC,MAAM,EAAE,SAAS,CAAC,CAAC;aACtC;YACD,WAAO,mPAAG,MAAC,mPAAG,EAAC,MAAM,EAAE,IAAI,CAAC,KAAK,CAAC,EAAE,IAAI,CAAC,MAAM,CAAC,CAAC;QACnD,CAAC,CAAC,CAAC;IACL,CAAC;;AAnCD,gBAAA,EAAkB,CACX,UAAA,SAAS,GAAG,WAAW,CAAC;;AAqCjC,ySAAa,CAAC,aAAa,CAAC,SAAS,CAAC,CAAC"}},
    {"offset": {"line": 3635, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-layers@4.22.0_@tensorflow+tfjs-core@4.22.0/node_modules/@tensorflow/tfjs-layers/dist/layers/preprocessing/center_crop.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-layers/src/layers/preprocessing/center_crop.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2022 CodeSmith LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\nimport {serialization,DataType,unstack,stack,tensor,Tensor,Tensor1D,Tensor2D, Tensor3D, Tensor4D, tidy, range, image} from '@tensorflow/tfjs-core';\nimport {getExactlyOneShape, getExactlyOneTensor} from '../../utils/types_utils';\nimport {LayerArgs, Layer} from '../../engine/topology';\nimport {Kwargs} from '../../types';\nimport {Shape} from '../../keras_format/common';\nimport * as K from '../../backend/tfjs_backend';\n\nconst {resizeBilinear, cropAndResize} = image;\n\nexport declare interface CenterCropArgs extends LayerArgs{\n  height: number;\n  width: number;\n}\n\nexport class CenterCrop extends Layer {\n  /** @nocollapse */\n  static className = 'CenterCrop';\n  private readonly height: number;\n  private readonly width: number;\n  constructor(args: CenterCropArgs) {\n    super(args);\n    this.height = args.height;\n    this.width = args.width;\n  }\n\n  centerCrop(inputs: Tensor3D | Tensor4D, hBuffer: number, wBuffer: number,\n            height: number, width: number, inputHeight: number,\n            inputWidth: number, dtype: DataType): Tensor | Tensor[] {\n\n    return tidy(() => {\n      let input: Tensor4D;\n      let isRank3      = false;\n      const top      = hBuffer / inputHeight;\n      const left     = wBuffer / inputWidth;\n      const bottom   = ((height) + hBuffer) / inputHeight;\n      const right    = ((width) + wBuffer) / inputWidth;\n      const bound    = [top, left, bottom, right];\n      const boxesArr = [];\n\n      if(inputs.rank === 3) {\n        isRank3  = true;\n        input  = stack([inputs]) as Tensor4D;\n      } else {\n        input = inputs as Tensor4D;\n      }\n\n      for (let i = 0; i < input.shape[0]; i++) {\n        boxesArr.push(bound);\n      }\n\n      const boxes: Tensor2D  = tensor(boxesArr, [boxesArr.length, 4]);\n      const boxInd: Tensor1D = range(0, boxesArr.length, 1, 'int32');\n\n      const cropSize: [number, number] = [height, width];\n      const cropped = cropAndResize(input, boxes, boxInd, cropSize, 'nearest');\n\n      if(isRank3) {\n        return K.cast(getExactlyOneTensor(unstack(cropped)), dtype);\n      }\n      return K.cast(cropped, dtype);\n   });\n\n  }\n\n  upsize(inputs : Tensor3D | Tensor4D, height: number,\n         width: number, dtype: DataType): Tensor | Tensor[] {\n\n    return tidy(() => {\n      const outputs = resizeBilinear(inputs, [height, width]);\n      return K.cast(outputs, dtype);\n  });\n\n}\n\n  override call(inputs: Tensor3D | Tensor4D , kwargs: Kwargs):\n      Tensor[] | Tensor {\n    return tidy(() => {\n      const rankedInputs = getExactlyOneTensor(inputs) as Tensor3D | Tensor4D;\n      const dtype       = rankedInputs.dtype;\n      const inputShape  = rankedInputs.shape;\n      const inputHeight = inputShape[inputShape.length - 3];\n      const inputWidth  =  inputShape[inputShape.length - 2];\n\n      let hBuffer = 0;\n      if (inputHeight !== this.height) {\n        hBuffer =  Math.floor((inputHeight - this.height) / 2);\n      }\n\n      let wBuffer = 0;\n      if (inputWidth !== this.width) {\n        wBuffer = Math.floor((inputWidth - this.width) / 2);\n\n        if (wBuffer === 0) {\n          wBuffer = 1;\n        }\n      }\n\n      if(hBuffer >= 0 && wBuffer >= 0) {\n        return this.centerCrop(rankedInputs, hBuffer, wBuffer,\n                              this.height, this.width, inputHeight,\n                              inputWidth, dtype);\n      } else {\n        return this.upsize(inputs, this.height, this.width, dtype);\n      }\n   });\n\n  }\n\n  override getConfig(): serialization.ConfigDict{\n\n    const config: serialization.ConfigDict = {\n      'height' : this.height,\n      'width' : this.width\n    };\n\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n  override computeOutputShape(inputShape: Shape | Shape[]): Shape | Shape[] {\n    inputShape = getExactlyOneShape(inputShape);\n    const hAxis = inputShape.length - 3;\n    const wAxis = inputShape.length - 2;\n    inputShape[hAxis] = this.height;\n    inputShape[wAxis] = this.width;\n    return inputShape;\n  }\n}\n\nserialization.registerClass(CenterCrop);\n"],"names":[],"mappings":";;;;AAAA;;;;;;;;GAQG;;;;;;;AAEH,OAAO,EAAC,aAAa,EAAU,OAAO,EAAC,KAAK,EAAC,MAAM,EAA+C,IAAI,EAAE,KAAK,EAAE,KAAK,EAAC,MAAM,uBAAuB,CAAC;AACnJ,OAAO,EAAC,kBAAkB,EAAE,mBAAmB,EAAC,MAAM,yBAAyB,CAAC;AAChF,OAAO,EAAY,KAAK,EAAC,MAAM,uBAAuB,CAAC;AAGvD,OAAO,KAAK,CAAC,MAAM,4BAA4B,CAAC;;;;;AAEhD,MAAM,EAAC,cAAc,EAAE,aAAa,EAAC,GAAG,qQAAK,CAAC;AAO9C,MAAa,UAAW,SAAQ,gTAAK;IAKnC,YAAY,IAAoB,CAAA;QAC9B,KAAK,CAAC,IAAI,CAAC,CAAC;QACZ,IAAI,CAAC,MAAM,GAAG,IAAI,CAAC,MAAM,CAAC;QAC1B,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC,KAAK,CAAC;IAC1B,CAAC;IAED,UAAU,CAAC,MAA2B,EAAE,OAAe,EAAE,OAAe,EAC9D,MAAc,EAAE,KAAa,EAAE,WAAmB,EAClD,UAAkB,EAAE,KAAe,EAAA;QAE3C,WAAO,iPAAI,EAAC,GAAG,EAAE;YACf,IAAI,KAAe,CAAC;YACpB,IAAI,OAAO,GAAQ,KAAK,CAAC;YACzB,MAAM,GAAG,GAAQ,OAAO,GAAG,WAAW,CAAC;YACvC,MAAM,IAAI,GAAO,OAAO,GAAG,UAAU,CAAC;YACtC,MAAM,MAAM,GAAK,CAAC,AAAC,MAAM,CAAC,EAAG,OAAO,CAAC,GAAG,WAAW,CAAC;YACpD,MAAM,KAAK,GAAM,CAAC,AAAC,KAAK,CAAC,EAAG,OAAO,CAAC,GAAG,UAAU,CAAC;YAClD,MAAM,KAAK,GAAM;gBAAC,GAAG;gBAAE,IAAI;gBAAE,MAAM;gBAAE,KAAK;aAAC,CAAC;YAC5C,MAAM,QAAQ,GAAG,EAAE,CAAC;YAEpB,IAAG,MAAM,CAAC,IAAI,KAAK,CAAC,EAAE;gBACpB,OAAO,GAAI,IAAI,CAAC;gBAChB,KAAK,OAAI,uPAAK,EAAC;oBAAC,MAAM;iBAAC,CAAa,CAAC;aACtC,MAAM;gBACL,KAAK,GAAG,MAAkB,CAAC;aAC5B;YAED,IAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,EAAE,CAAE;gBACvC,QAAQ,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;aACtB;YAED,MAAM,KAAK,OAAc,yPAAM,EAAC,QAAQ,EAAE;gBAAC,QAAQ,CAAC,MAAM;gBAAE,CAAC;aAAC,CAAC,CAAC;YAChE,MAAM,MAAM,OAAa,uPAAK,EAAC,CAAC,EAAE,QAAQ,CAAC,MAAM,EAAE,CAAC,EAAE,OAAO,CAAC,CAAC;YAE/D,MAAM,QAAQ,GAAqB;gBAAC,MAAM;gBAAE,KAAK;aAAC,CAAC;YACnD,MAAM,OAAO,GAAG,aAAa,CAAC,KAAK,EAAE,KAAK,EAAE,MAAM,EAAE,QAAQ,EAAE,SAAS,CAAC,CAAC;YAEzE,IAAG,OAAO,EAAE;gBACV,OAAO,CAAC,CAAC,kTAAI,KAAC,gUAAmB,MAAC,2PAAO,EAAC,OAAO,CAAC,CAAC,EAAE,KAAK,CAAC,CAAC;aAC7D;YACD,OAAO,CAAC,CAAC,kTAAI,CAAC,OAAO,EAAE,KAAK,CAAC,CAAC;QACjC,CAAC,CAAC,CAAC;IAEJ,CAAC;IAED,MAAM,CAAC,MAA4B,EAAE,MAAc,EAC5C,KAAa,EAAE,KAAe,EAAA;QAEnC,WAAO,iPAAI,EAAC,GAAG,EAAE;YACf,MAAM,OAAO,GAAG,cAAc,CAAC,MAAM,EAAE;gBAAC,MAAM;gBAAE,KAAK;aAAC,CAAC,CAAC;YACxD,OAAO,CAAC,CAAC,kTAAI,CAAC,OAAO,EAAE,KAAK,CAAC,CAAC;QAClC,CAAC,CAAC,CAAC;IAEL,CAAC;IAEU,IAAI,CAAC,MAA2B,EAAG,MAAc,EAAA;QAExD,WAAO,iPAAI,EAAC,GAAG,EAAE;YACf,MAAM,YAAY,OAAG,gUAAmB,EAAC,MAAM,CAAwB,CAAC;YACxE,MAAM,KAAK,GAAS,YAAY,CAAC,KAAK,CAAC;YACvC,MAAM,UAAU,GAAI,YAAY,CAAC,KAAK,CAAC;YACvC,MAAM,WAAW,GAAG,UAAU,CAAC,UAAU,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;YACtD,MAAM,UAAU,GAAK,UAAU,CAAC,UAAU,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;YAEvD,IAAI,OAAO,GAAG,CAAC,CAAC;YAChB,IAAI,WAAW,KAAK,IAAI,CAAC,MAAM,EAAE;gBAC/B,OAAO,GAAI,IAAI,CAAC,KAAK,CAAC,CAAC,WAAW,GAAG,IAAI,CAAC,MAAM,CAAC,GAAG,CAAC,CAAC,CAAC;aACxD;YAED,IAAI,OAAO,GAAG,CAAC,CAAC;YAChB,IAAI,UAAU,KAAK,IAAI,CAAC,KAAK,EAAE;gBAC7B,OAAO,GAAG,IAAI,CAAC,KAAK,CAAC,CAAC,UAAU,GAAG,IAAI,CAAC,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC;gBAEpD,IAAI,OAAO,KAAK,CAAC,EAAE;oBACjB,OAAO,GAAG,CAAC,CAAC;iBACb;aACF;YAED,IAAG,OAAO,IAAI,CAAC,IAAI,OAAO,IAAI,CAAC,EAAE;gBAC/B,OAAO,IAAI,CAAC,UAAU,CAAC,YAAY,EAAE,OAAO,EAAE,OAAO,EAC/B,IAAI,CAAC,MAAM,EAAE,IAAI,CAAC,KAAK,EAAE,WAAW,EACpC,UAAU,EAAE,KAAK,CAAC,CAAC;aAC1C,MAAM;gBACL,OAAO,IAAI,CAAC,MAAM,CAAC,MAAM,EAAE,IAAI,CAAC,MAAM,EAAE,IAAI,CAAC,KAAK,EAAE,KAAK,CAAC,CAAC;aAC5D;QACJ,CAAC,CAAC,CAAC;IAEJ,CAAC;IAEQ,SAAS,GAAA;QAEhB,MAAM,MAAM,GAA6B;YACvC,QAAQ,EAAG,IAAI,CAAC,MAAM;YACtB,OAAO,EAAG,IAAI,CAAC,KAAK;SACrB,CAAC;QAEF,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;QACrC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;IAEQ,kBAAkB,CAAC,UAA2B,EAAA;QACrD,UAAU,OAAG,+TAAkB,EAAC,UAAU,CAAC,CAAC;QAC5C,MAAM,KAAK,GAAG,UAAU,CAAC,MAAM,GAAG,CAAC,CAAC;QACpC,MAAM,KAAK,GAAG,UAAU,CAAC,MAAM,GAAG,CAAC,CAAC;QACpC,UAAU,CAAC,KAAK,CAAC,GAAG,IAAI,CAAC,MAAM,CAAC;QAChC,UAAU,CAAC,KAAK,CAAC,GAAG,IAAI,CAAC,KAAK,CAAC;QAC/B,OAAO,UAAU,CAAC;IACpB,CAAC;;AAhHD,gBAAA,EAAkB,CACX,WAAA,SAAS,GAAG,YAAY,CAAC;;AAkHlC,ySAAa,CAAC,aAAa,CAAC,UAAU,CAAC,CAAC"}},
    {"offset": {"line": 3770, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-layers@4.22.0_@tensorflow+tfjs-core@4.22.0/node_modules/@tensorflow/tfjs-layers/dist/layers/preprocessing/preprocessing_utils.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-layers/src/layers/preprocessing/preprocessing_utils.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2022 CodeSmith LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\nimport { Tensor, denseBincount, Tensor1D, Tensor2D, TensorLike, mul} from '@tensorflow/tfjs-core';\nimport { getExactlyOneTensor } from '../../utils/types_utils';\nimport { expandDims} from '@tensorflow/tfjs-core';\nimport { ValueError } from '../../errors';\nimport * as K from '../../backend/tfjs_backend';\n\nexport type OutputMode = 'int' | 'oneHot' | 'multiHot' | 'count' | 'tfIdf';\n\nexport function encodeCategoricalInputs(inputs: Tensor|Tensor[],\n                                        outputMode: OutputMode,\n                                        depth: number,\n                                        weights?: Tensor1D|Tensor2D|TensorLike):\n                                        Tensor|Tensor[] {\n\n  let input = getExactlyOneTensor(inputs);\n\n  if(input.dtype !== 'int32') {\n    input = K.cast(input, 'int32');\n    }\n\n  if(outputMode === 'int') {\n    return input;\n  }\n\n  const originalShape = input.shape;\n\n  if(input.rank === 0) {\n    input = expandDims(input, -1);\n  }\n\n  if(outputMode === 'oneHot') {\n    if(input.shape[input.shape.length - 1] !== 1) {\n      input = expandDims(input, -1);\n    }\n  }\n\n  if(input.rank > 2) {\n    throw new ValueError(`When outputMode is not int, maximum output rank is 2`\n    + ` Received outputMode ${outputMode} and input shape ${originalShape}`\n    + ` which would result in output rank ${input.rank}.`);\n  }\n\n  const binaryOutput = ['multiHot', 'oneHot'].includes(outputMode);\n\n  const denseBincountInput = input as Tensor1D | Tensor2D;\n\n  let binCounts: Tensor1D | Tensor2D;\n\n  if ((typeof weights) !== 'undefined' && outputMode === 'count') {\n    binCounts = denseBincount(denseBincountInput, weights, depth, binaryOutput);\n   } else {\n    binCounts = denseBincount(denseBincountInput, [], depth, binaryOutput);\n   }\n\n  if(outputMode !== 'tfIdf') {\n    return binCounts;\n  }\n\n  if (weights) {\n    return mul(binCounts, weights);\n  } else {\n      throw new ValueError(\n        `When outputMode is 'tfIdf', weights must be provided.`\n      );\n  }\n}\n"],"names":[],"mappings":";;;;AAAA;;;;;;;;GAQG;;AAEH,OAAO,EAAU,aAAa,EAAkC,GAAG,EAAC,MAAM,uBAAuB,CAAC;AAClG,OAAO,EAAE,mBAAmB,EAAE,MAAM,yBAAyB,CAAC;AAC9D,OAAO,EAAE,UAAU,EAAC,MAAM,uBAAuB,CAAC;AAClD,OAAO,EAAE,UAAU,EAAE,MAAM,cAAc,CAAC;AAC1C,OAAO,KAAK,CAAC,MAAM,4BAA4B,CAAC;;;;;;AAI1C,SAAU,uBAAuB,CAAC,MAAuB,EACvB,UAAsB,EACtB,KAAa,EACb,OAAsC;IAG5E,IAAI,KAAK,OAAG,gUAAmB,EAAC,MAAM,CAAC,CAAC;IAExC,IAAG,KAAK,CAAC,KAAK,KAAK,OAAO,EAAE;QAC1B,KAAK,GAAG,CAAC,CAAC,kTAAI,CAAC,KAAK,EAAE,OAAO,CAAC,CAAC;KAC9B;IAEH,IAAG,UAAU,KAAK,KAAK,EAAE;QACvB,OAAO,KAAK,CAAC;KACd;IAED,MAAM,aAAa,GAAG,KAAK,CAAC,KAAK,CAAC;IAElC,IAAG,KAAK,CAAC,IAAI,KAAK,CAAC,EAAE;QACnB,KAAK,OAAG,kQAAU,EAAC,KAAK,EAAE,CAAC,CAAC,CAAC,CAAC;KAC/B;IAED,IAAG,UAAU,KAAK,QAAQ,EAAE;QAC1B,IAAG,KAAK,CAAC,KAAK,CAAC,KAAK,CAAC,KAAK,CAAC,MAAM,GAAG,CAAC,CAAC,KAAK,CAAC,EAAE;YAC5C,KAAK,OAAG,kQAAU,EAAC,KAAK,EAAE,CAAC,CAAC,CAAC,CAAC;SAC/B;KACF;IAED,IAAG,KAAK,CAAC,IAAI,GAAG,CAAC,EAAE;QACjB,MAAM,IAAI,ySAAU,CAAC,CAAA,oDAAA,CAAsD,GACzE,CAAA,qBAAA,EAAwB,UAAU,CAAA,iBAAA,EAAoB,aAAa,EAAE,GACrE,CAAA,mCAAA,EAAsC,KAAK,CAAC,IAAI,CAAA,CAAA,CAAG,CAAC,CAAC;KACxD;IAED,MAAM,YAAY,GAAG;QAAC,UAAU;QAAE,QAAQ;KAAC,CAAC,QAAQ,CAAC,UAAU,CAAC,CAAC;IAEjE,MAAM,kBAAkB,GAAG,KAA4B,CAAC;IAExD,IAAI,SAA8B,CAAC;IAEnC,IAAI,AAAC,OAAO,OAAO,CAAC,IAAK,WAAW,IAAI,UAAU,KAAK,OAAO,EAAE;QAC9D,SAAS,OAAG,wQAAa,EAAC,kBAAkB,EAAE,OAAO,EAAE,KAAK,EAAE,YAAY,CAAC,CAAC;KAC5E,MAAM;QACN,SAAS,OAAG,wQAAa,EAAC,kBAAkB,EAAE,EAAE,EAAE,KAAK,EAAE,YAAY,CAAC,CAAC;KACvE;IAEF,IAAG,UAAU,KAAK,OAAO,EAAE;QACzB,OAAO,SAAS,CAAC;KAClB;IAED,IAAI,OAAO,EAAE;QACX,WAAO,mPAAG,EAAC,SAAS,EAAE,OAAO,CAAC,CAAC;KAChC,MAAM;QACH,MAAM,IAAI,ySAAU,CAClB,CAAA,qDAAA,CAAuD,CACxD,CAAC;KACL;AACH,CAAC"}},
    {"offset": {"line": 3838, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-layers@4.22.0_@tensorflow+tfjs-core@4.22.0/node_modules/@tensorflow/tfjs-layers/dist/layers/preprocessing/category_encoding.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-layers/src/layers/preprocessing/category_encoding.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2022 CodeSmith LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\nimport { LayerArgs, Layer } from '../../engine/topology';\nimport { serialization, Tensor, tidy, Tensor1D, Tensor2D} from '@tensorflow/tfjs-core';\nimport { greater, greaterEqual, max, min} from '@tensorflow/tfjs-core';\nimport { Shape } from '../../keras_format/common';\nimport { getExactlyOneShape, getExactlyOneTensor } from '../../utils/types_utils';\nimport { Kwargs } from '../../types';\nimport { ValueError } from '../../errors';\nimport * as K from '../../backend/tfjs_backend';\nimport * as utils from './preprocessing_utils';\nimport { OutputMode } from './preprocessing_utils';\n\nexport declare interface CategoryEncodingArgs extends LayerArgs {\n  numTokens: number;\n  outputMode?: OutputMode;\n }\n\nexport class CategoryEncoding extends Layer {\n  /** @nocollapse */\n  static className = 'CategoryEncoding';\n  private readonly numTokens: number;\n  private readonly outputMode: OutputMode;\n\n  constructor(args: CategoryEncodingArgs) {\n    super(args);\n    this.numTokens = args.numTokens;\n\n    if(args.outputMode) {\n    this.outputMode = args.outputMode;\n    } else {\n      this.outputMode = 'multiHot';\n    }\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config: serialization.ConfigDict = {\n      'numTokens': this.numTokens,\n      'outputMode': this.outputMode,\n    };\n\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n  override computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    inputShape = getExactlyOneShape(inputShape);\n\n    if(inputShape == null) {\n      return [this.numTokens];\n    }\n\n    if(this.outputMode === 'oneHot' && inputShape[inputShape.length - 1] !== 1){\n      inputShape.push(this.numTokens);\n      return inputShape;\n    }\n\n    inputShape[inputShape.length - 1] = this.numTokens;\n    return inputShape;\n  }\n\n  override call(inputs: Tensor|Tensor[], kwargs: Kwargs): Tensor[]|Tensor {\n    return tidy(() => {\n\n        inputs = getExactlyOneTensor(inputs);\n        if(inputs.dtype !== 'int32') {\n          inputs = K.cast(inputs, 'int32');\n      }\n\n        let countWeights: Tensor1D | Tensor2D;\n\n        if((typeof kwargs['countWeights']) !== 'undefined') {\n\n          if(this.outputMode !== 'count') {\n            throw new ValueError(\n              `countWeights is not used when outputMode !== count.\n              Received countWeights=${kwargs['countWeights']}`);\n          }\n\n          countWeights\n            =  getExactlyOneTensor(kwargs['countWeights']) as Tensor1D|Tensor2D;\n        }\n\n        const maxValue = max(inputs);\n        const minValue = min(inputs);\n        const greaterEqualMax = greater(this.numTokens, maxValue)\n                                                    .bufferSync().get(0);\n\n        const greaterMin = greaterEqual(minValue, 0).bufferSync().get(0);\n\n        if(!(greaterEqualMax && greaterMin)) {\n\n          throw new ValueError('Input values must be between 0 < values <='\n            + ` numTokens with numTokens=${this.numTokens}`);\n        }\n\n        return utils.encodeCategoricalInputs(inputs,\n          this.outputMode, this.numTokens, countWeights);\n    });\n  }\n}\n\nserialization.registerClass(CategoryEncoding);\n"],"names":[],"mappings":";;;;AAAA;;;;;;;;GAQG,CAEH,OAAO,EAAa,KAAK,EAAE,MAAM,uBAAuB,CAAC;;;AACzD,OAAO,EAAE,aAAa,EAAU,IAAI,EAAqB,MAAM,uBAAuB,CAAC;;;;AACvF,OAAO,EAAE,OAAO,EAAE,YAAY,EAAE,GAAG,EAAE,GAAG,EAAC,MAAM,uBAAuB,CAAC;AAEvE,OAAO,EAAE,kBAAkB,EAAE,mBAAmB,EAAE,MAAM,yBAAyB,CAAC;AAElF,OAAO,EAAE,UAAU,EAAE,MAAM,cAAc,CAAC;AAC1C,OAAO,KAAK,CAAC,MAAM,4BAA4B,CAAC;AAChD,OAAO,KAAK,KAAK,MAAM,uBAAuB,CAAC;;;;;;;;AAQ/C,MAAa,gBAAiB,SAAQ,gTAAK;IAMzC,YAAY,IAA0B,CAAA;QACpC,KAAK,CAAC,IAAI,CAAC,CAAC;QACZ,IAAI,CAAC,SAAS,GAAG,IAAI,CAAC,SAAS,CAAC;QAEhC,IAAG,IAAI,CAAC,UAAU,EAAE;YACpB,IAAI,CAAC,UAAU,GAAG,IAAI,CAAC,UAAU,CAAC;SACjC,MAAM;YACL,IAAI,CAAC,UAAU,GAAG,UAAU,CAAC;SAC9B;IACH,CAAC;IAEQ,SAAS,GAAA;QAChB,MAAM,MAAM,GAA6B;YACvC,WAAW,EAAE,IAAI,CAAC,SAAS;YAC3B,YAAY,EAAE,IAAI,CAAC,UAAU;SAC9B,CAAC;QAEF,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;QACrC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;IAEQ,kBAAkB,CAAC,UAAyB,EAAA;QACnD,UAAU,OAAG,+TAAkB,EAAC,UAAU,CAAC,CAAC;QAE5C,IAAG,UAAU,IAAI,IAAI,EAAE;YACrB,OAAO;gBAAC,IAAI,CAAC,SAAS;aAAC,CAAC;SACzB;QAED,IAAG,IAAI,CAAC,UAAU,KAAK,QAAQ,IAAI,UAAU,CAAC,UAAU,CAAC,MAAM,GAAG,CAAC,CAAC,KAAK,CAAC,EAAC;YACzE,UAAU,CAAC,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,CAAC;YAChC,OAAO,UAAU,CAAC;SACnB;QAED,UAAU,CAAC,UAAU,CAAC,MAAM,GAAG,CAAC,CAAC,GAAG,IAAI,CAAC,SAAS,CAAC;QACnD,OAAO,UAAU,CAAC;IACpB,CAAC;IAEQ,IAAI,CAAC,MAAuB,EAAE,MAAc,EAAA;QACnD,WAAO,iPAAI,EAAC,GAAG,EAAE;YAEb,MAAM,OAAG,gUAAmB,EAAC,MAAM,CAAC,CAAC;YACrC,IAAG,MAAM,CAAC,KAAK,KAAK,OAAO,EAAE;gBAC3B,MAAM,GAAG,CAAC,CAAC,kTAAI,CAAC,MAAM,EAAE,OAAO,CAAC,CAAC;aACpC;YAEC,IAAI,YAAiC,CAAC;YAEtC,IAAG,AAAC,OAAO,MAAM,CAAC,cAAc,CAAC,CAAC,IAAK,WAAW,EAAE;gBAElD,IAAG,IAAI,CAAC,UAAU,KAAK,OAAO,EAAE;oBAC9B,MAAM,IAAI,ySAAU,CAClB,CAAA;sCACwB,MAAM,CAAC,cAAc,CAAC,EAAE,CAAC,CAAC;iBACrD;gBAED,YAAY,OACP,gUAAmB,EAAC,MAAM,CAAC,cAAc,CAAC,CAAsB,CAAC;aACvE;YAED,MAAM,QAAQ,OAAG,mPAAG,EAAC,MAAM,CAAC,CAAC;YAC7B,MAAM,QAAQ,OAAG,mPAAG,EAAC,MAAM,CAAC,CAAC;YAC7B,MAAM,eAAe,OAAG,2PAAO,EAAC,IAAI,CAAC,SAAS,EAAE,QAAQ,CAAC,CACZ,UAAU,EAAE,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;YAEjE,MAAM,UAAU,OAAG,sQAAY,EAAC,QAAQ,EAAE,CAAC,CAAC,CAAC,UAAU,EAAE,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;YAEjE,IAAG,CAAC,CAAC,eAAe,IAAI,UAAU,CAAC,EAAE;gBAEnC,MAAM,IAAI,ySAAU,CAAC,4CAA4C,GAC7D,CAAA,0BAAA,EAA6B,IAAI,CAAC,SAAS,EAAE,CAAC,CAAC;aACpD;YAED,OAAO,KAAK,CAAC,wVAAuB,CAAC,MAAM,EACzC,IAAI,CAAC,UAAU,EAAE,IAAI,CAAC,SAAS,EAAE,YAAY,CAAC,CAAC;QACrD,CAAC,CAAC,CAAC;IACL,CAAC;;AAjFD,gBAAA,EAAkB,CACX,iBAAA,SAAS,GAAG,kBAAkB,CAAC;;AAmFxC,ySAAa,CAAC,aAAa,CAAC,gBAAgB,CAAC,CAAC"}},
    {"offset": {"line": 3934, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-layers@4.22.0_@tensorflow+tfjs-core@4.22.0/node_modules/@tensorflow/tfjs-layers/dist/layers/preprocessing/image_resizing.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-layers/src/layers/preprocessing/image_resizing.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2022 CodeSmith LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\nimport {image, Rank, serialization, Tensor, tidy} from '@tensorflow/tfjs-core';  // mul, add\n\nimport {Layer, LayerArgs} from '../../engine/topology';\nimport {ValueError} from '../../errors';\nimport {Shape} from '../../keras_format/common';\nimport {Kwargs} from '../../types';\nimport {getExactlyOneShape} from '../../utils/types_utils';  //, getExactlyOneTensor\n\n// tf methods unimplemented in tfjs: 'bicubic', 'area', 'lanczos3', 'lanczos5',\n//                                   'gaussian', 'mitchellcubic'\nconst INTERPOLATION_KEYS = ['bilinear', 'nearest'] as const;\nconst INTERPOLATION_METHODS = new Set(INTERPOLATION_KEYS);\ntype InterpolationType = typeof INTERPOLATION_KEYS[number];\n\nexport declare interface ResizingArgs extends LayerArgs {\n  height: number;\n  width: number;\n  interpolation?: InterpolationType; // default = 'bilinear';\n  cropToAspectRatio?: boolean;       // default = false;\n}\n\n/**\n * Preprocessing Resizing Layer\n *\n * This resizes images by a scaling and offset factor\n */\n\nexport class Resizing extends Layer {\n  /** @nocollapse */\n  static className = 'Resizing';\n  private readonly height: number;\n  private readonly width: number;\n  // method of interpolation to be used; default = \"bilinear\";\n  private readonly interpolation: InterpolationType;\n  // toggle whether the aspect ratio should be preserved; default = false;\n  private readonly cropToAspectRatio: boolean;\n\n  constructor(args: ResizingArgs) {\n    super(args);\n\n    this.height = args.height;\n    this.width = args.width;\n\n    if (args.interpolation) {\n      if (INTERPOLATION_METHODS.has(args.interpolation)) {\n        this.interpolation = args.interpolation;\n      } else {\n        throw new ValueError(`Invalid interpolation parameter: ${\n            args.interpolation} is not implemented`);\n      }\n    } else {\n      this.interpolation = 'bilinear';\n    }\n    this.cropToAspectRatio = Boolean(args.cropToAspectRatio);\n  }\n\n  override computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    inputShape = getExactlyOneShape(inputShape);\n    const numChannels = inputShape[2];\n    return [this.height, this.width, numChannels];\n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config: serialization.ConfigDict = {\n      'height': this.height,\n      'width': this.width,\n      'interpolation': this.interpolation,\n      'cropToAspectRatio': this.cropToAspectRatio\n    };\n\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n  override call(inputs: Tensor<Rank.R3>|Tensor<Rank.R4>, kwargs: Kwargs):\n      Tensor[]|Tensor {\n    return tidy(() => {\n      const size: [number, number] = [this.height, this.width];\n      if (this.interpolation === 'bilinear') {\n        return image.resizeBilinear(inputs, size, !this.cropToAspectRatio);\n      } else if (this.interpolation === 'nearest') {\n        return image.resizeNearestNeighbor(\n            inputs, size, !this.cropToAspectRatio);\n      } else {\n        throw new Error(`Interpolation is ${this.interpolation} but only ${[...INTERPOLATION_METHODS]} are supported`);\n      }\n    });\n  }\n}\n\nserialization.registerClass(Resizing);\n"],"names":[],"mappings":";;;;AAAA;;;;;;;;GAQG,CAEH,OAAO,EAAC,KAAK,EAAQ,aAAa,EAAU,IAAI,EAAC,MAAM,uBAAuB,CAAC,kWAAE,WAAW;;;;AAE5F,OAAO,EAAC,KAAK,EAAY,MAAM,uBAAuB,CAAC;AACvD,OAAO,EAAC,UAAU,EAAC,MAAM,cAAc,CAAC;AAGxC,OAAO,EAAC,kBAAkB,EAAC,MAAM,yBAAyB,CAAC,8bAAE,uBAAuB;;;;;AAEpF,+EAA+E;AAC/E,gEAAgE;AAChE,MAAM,kBAAkB,GAAG;IAAC,UAAU;IAAE,SAAS;CAAU,CAAC;AAC5D,MAAM,qBAAqB,GAAG,IAAI,GAAG,CAAC,kBAAkB,CAAC,CAAC;AAU1D;;;;GAIG,CAEH,MAAa,QAAS,SAAQ,gTAAK;IAUjC,YAAY,IAAkB,CAAA;QAC5B,KAAK,CAAC,IAAI,CAAC,CAAC;QAEZ,IAAI,CAAC,MAAM,GAAG,IAAI,CAAC,MAAM,CAAC;QAC1B,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC,KAAK,CAAC;QAExB,IAAI,IAAI,CAAC,aAAa,EAAE;YACtB,IAAI,qBAAqB,CAAC,GAAG,CAAC,IAAI,CAAC,aAAa,CAAC,EAAE;gBACjD,IAAI,CAAC,aAAa,GAAG,IAAI,CAAC,aAAa,CAAC;aACzC,MAAM;gBACL,MAAM,IAAI,ySAAU,CAAC,CAAA,iCAAA,EACjB,IAAI,CAAC,aAAa,CAAA,mBAAA,CAAqB,CAAC,CAAC;aAC9C;SACF,MAAM;YACL,IAAI,CAAC,aAAa,GAAG,UAAU,CAAC;SACjC;QACD,IAAI,CAAC,iBAAiB,GAAG,OAAO,CAAC,IAAI,CAAC,iBAAiB,CAAC,CAAC;IAC3D,CAAC;IAEQ,kBAAkB,CAAC,UAAyB,EAAA;QACnD,UAAU,OAAG,+TAAkB,EAAC,UAAU,CAAC,CAAC;QAC5C,MAAM,WAAW,GAAG,UAAU,CAAC,CAAC,CAAC,CAAC;QAClC,OAAO;YAAC,IAAI,CAAC,MAAM;YAAE,IAAI,CAAC,KAAK;YAAE,WAAW;SAAC,CAAC;IAChD,CAAC;IAEQ,SAAS,GAAA;QAChB,MAAM,MAAM,GAA6B;YACvC,QAAQ,EAAE,IAAI,CAAC,MAAM;YACrB,OAAO,EAAE,IAAI,CAAC,KAAK;YACnB,eAAe,EAAE,IAAI,CAAC,aAAa;YACnC,mBAAmB,EAAE,IAAI,CAAC,iBAAiB;SAC5C,CAAC;QAEF,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;QACrC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;IAEQ,IAAI,CAAC,MAAuC,EAAE,MAAc,EAAA;QAEnE,WAAO,iPAAI,EAAC,GAAG,EAAE;YACf,MAAM,IAAI,GAAqB;gBAAC,IAAI,CAAC,MAAM;gBAAE,IAAI,CAAC,KAAK;aAAC,CAAC;YACzD,IAAI,IAAI,CAAC,aAAa,KAAK,UAAU,EAAE;gBACrC,OAAO,qQAAK,CAAC,cAAc,CAAC,MAAM,EAAE,IAAI,EAAE,CAAC,IAAI,CAAC,iBAAiB,CAAC,CAAC;aACpE,MAAM,IAAI,IAAI,CAAC,aAAa,KAAK,SAAS,EAAE;gBAC3C,OAAO,qQAAK,CAAC,qBAAqB,CAC9B,MAAM,EAAE,IAAI,EAAE,CAAC,IAAI,CAAC,iBAAiB,CAAC,CAAC;aAC5C,MAAM;gBACL,MAAM,IAAI,KAAK,CAAC,CAAA,iBAAA,EAAoB,IAAI,CAAC,aAAa,CAAA,UAAA,EAAa,CAAC;uBAAG,qBAAqB;iBAAC,CAAA,cAAA,CAAgB,CAAC,CAAC;aAChH;QACH,CAAC,CAAC,CAAC;IACL,CAAC;;AA5DD,gBAAA,EAAkB,CACX,SAAA,SAAS,GAAG,UAAU,CAAC;;AA8DhC,ySAAa,CAAC,aAAa,CAAC,QAAQ,CAAC,CAAC"}},
    {"offset": {"line": 4029, "column": 0}, "map": {"version":3,"file":"turbopack:///[project]/node_modules/.pnpm/@tensorflow+tfjs-layers@4.22.0_@tensorflow+tfjs-core@4.22.0/node_modules/@tensorflow/tfjs-layers/dist/layers/preprocessing/random_width.js","sources":["file:///Users/nishant/Documents/software/blog/node_modules/.pnpm/tfjs-layers/src/layers/preprocessing/random_width.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2023 CodeSmith LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\nimport { image, Rank, serialization, Tensor, tidy } from '@tensorflow/tfjs-core';\nimport { getExactlyOneTensor, getExactlyOneShape } from '../../utils/types_utils';\nimport { Shape } from '../../keras_format/common';\nimport { Kwargs } from '../../types';\nimport { ValueError } from '../../errors';\nimport { BaseRandomLayerArgs, BaseRandomLayer } from '../../engine/base_random_layer';\nimport { randomUniform } from '@tensorflow/tfjs-core';\n\nexport declare interface RandomWidthArgs extends BaseRandomLayerArgs {\n   factor: number | [number, number];\n   interpolation?: InterpolationType; // default = 'bilinear';\n   seed?: number; // default = null;\n   autoVectorize?: boolean;\n}\n\nconst INTERPOLATION_KEYS = ['bilinear', 'nearest'] as const;\nexport const INTERPOLATION_METHODS = new Set(INTERPOLATION_KEYS);\ntype InterpolationType = typeof INTERPOLATION_KEYS[number];\n\n/**\n * Preprocessing Layer with randomly varies image during training\n *\n * This layer randomly adjusts the width of a batch of images of a\n * batch of images by a random factor.\n *\n * The input should be a 3D (unbatched) or\n * 4D (batched) tensor in the `\"channels_last\"` image data format. Input pixel\n * values can be of any range (e.g. `[0., 1.)` or `[0, 255]`) and of integer\n * or floating point dtype. By default, the layer will output floats.\n *\n * tf methods implemented in tfjs: 'bilinear', 'nearest',\n * tf methods unimplemented in tfjs: 'bicubic', 'area', 'lanczos3', 'lanczos5',\n *                                   'gaussian', 'mitchellcubic'\n *\n */\n\nexport class RandomWidth extends BaseRandomLayer {\n  /** @nocollapse */\n  static override className = 'RandomWidth';\n  private readonly factor: number | [number, number];\n  private readonly interpolation?: InterpolationType;  // default = 'bilinear\n  private widthLower: number;\n  private widthUpper: number;\n  private imgHeight: number;\n  private widthFactor: Tensor<Rank.R1>;\n\n  constructor(args: RandomWidthArgs) {\n    super(args);\n    const {factor, interpolation = 'bilinear'} = args;\n\n    this.factor = factor;\n\n    if (Array.isArray(this.factor) && this.factor.length === 2) {\n      this.widthLower = this.factor[0];\n      this.widthUpper = this.factor[1];\n    } else if (!Array.isArray(this.factor) && this.factor > 0){\n      this.widthLower = -this.factor;\n      this.widthUpper = this.factor;\n    } else {\n      throw new ValueError(\n        `Invalid factor: ${this.factor}. Must be positive number or tuple of 2 numbers`\n      );\n    }\n    if (this.widthLower < -1.0 || this.widthUpper < -1.0) {\n      throw new ValueError(\n        `factor must have values larger than -1. Got: ${this.factor}`\n      );\n    }\n\n    if (this.widthUpper < this.widthLower) {\n      throw new ValueError(\n        `factor cannot have upper bound less than lower bound.\n        Got upper bound: ${this.widthUpper}.\n        Got lower bound: ${this.widthLower}\n      `);\n    }\n\n    if (interpolation) {\n      if (INTERPOLATION_METHODS.has(interpolation)) {\n        this.interpolation = interpolation;\n      } else {\n        throw new ValueError(`Invalid interpolation parameter: ${\n            interpolation} is not implemented`);\n      }\n    } \n  }\n\n  override getConfig(): serialization.ConfigDict {\n    const config: serialization.ConfigDict = {\n      'factor': this.factor,\n      'interpolation': this.interpolation,\n    };\n\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n  override computeOutputShape(inputShape: Shape|Shape[]): Shape|Shape[] {\n    inputShape = getExactlyOneShape(inputShape);\n    const numChannels = inputShape[2];\n    return [this.imgHeight, -1, numChannels];\n  }\n\n  override call(inputs: Tensor<Rank.R3>|Tensor<Rank.R4>,\n    kwargs: Kwargs): Tensor[]|Tensor {\n\n    return tidy(() => {\n      const input = getExactlyOneTensor(inputs);\n      this.imgHeight = input.shape[input.shape.length - 3];\n      const imgWidth = input.shape[input.shape.length - 2];\n\n      this.widthFactor = randomUniform([1],\n        (1.0 + this.widthLower), (1.0 + this.widthUpper),\n        'float32', this.randomGenerator.next()\n      );\n\n      let adjustedWidth = this.widthFactor.dataSync()[0] * imgWidth;\n      adjustedWidth = Math.round(adjustedWidth);\n\n      const size:[number, number] = [this.imgHeight, adjustedWidth];\n\n      switch (this.interpolation) {\n        case 'bilinear':\n          return image.resizeBilinear(inputs, size);\n        case 'nearest':\n          return image.resizeNearestNeighbor(inputs, size);\n        default:\n          throw new Error(`Interpolation is ${this.interpolation}\n          but only ${[...INTERPOLATION_METHODS]} are supported`);\n      }\n    });\n  }\n}\n\nserialization.registerClass(RandomWidth);\n"],"names":[],"mappings":";;;;;;AAAA;;;;;;;;GAQG;;;AAEH,OAAO,EAAE,KAAK,EAAQ,aAAa,EAAU,IAAI,EAAE,MAAM,uBAAuB,CAAC;AACjF,OAAO,EAAE,mBAAmB,EAAE,kBAAkB,EAAE,MAAM,yBAAyB,CAAC;AAGlF,OAAO,EAAE,UAAU,EAAE,MAAM,cAAc,CAAC;AAC1C,OAAO,EAAuB,eAAe,EAAE,MAAM,gCAAgC,CAAC;AACtF,OAAO,EAAE,aAAa,EAAE,MAAM,uBAAuB,CAAC;;;;;;AAStD,MAAM,kBAAkB,GAAG;IAAC,UAAU;IAAE,SAAS;CAAU,CAAC;AACrD,MAAM,qBAAqB,GAAG,IAAI,GAAG,CAAC,kBAAkB,CAAC,CAAC;AAGjE;;;;;;;;;;;;;;;GAeG,CAEH,MAAa,WAAY,SAAQ,mUAAe;IAU9C,YAAY,IAAqB,CAAA;QAC/B,KAAK,CAAC,IAAI,CAAC,CAAC;QACZ,MAAM,EAAC,MAAM,EAAE,aAAa,GAAG,UAAU,EAAC,GAAG,IAAI,CAAC;QAElD,IAAI,CAAC,MAAM,GAAG,MAAM,CAAC;QAErB,IAAI,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,IAAI,IAAI,CAAC,MAAM,CAAC,MAAM,KAAK,CAAC,EAAE;YAC1D,IAAI,CAAC,UAAU,GAAG,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC;YACjC,IAAI,CAAC,UAAU,GAAG,IAAI,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC;SAClC,MAAM,IAAI,CAAC,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,MAAM,CAAC,IAAI,IAAI,CAAC,MAAM,GAAG,CAAC,EAAC;YACxD,IAAI,CAAC,UAAU,GAAG,CAAC,IAAI,CAAC,MAAM,CAAC;YAC/B,IAAI,CAAC,UAAU,GAAG,IAAI,CAAC,MAAM,CAAC;SAC/B,MAAM;YACL,MAAM,IAAI,ySAAU,CAClB,CAAA,gBAAA,EAAmB,IAAI,CAAC,MAAM,CAAA,+CAAA,CAAiD,CAChF,CAAC;SACH;QACD,IAAI,IAAI,CAAC,UAAU,GAAG,CAAC,GAAG,IAAI,IAAI,CAAC,UAAU,GAAG,CAAC,GAAG,EAAE;YACpD,MAAM,IAAI,ySAAU,CAClB,CAAA,6CAAA,EAAgD,IAAI,CAAC,MAAM,EAAE,CAC9D,CAAC;SACH;QAED,IAAI,IAAI,CAAC,UAAU,GAAG,IAAI,CAAC,UAAU,EAAE;YACrC,MAAM,IAAI,ySAAU,CAClB,CAAA;2BACmB,IAAI,CAAC,UAAU,CAAA;2BACf,IAAI,CAAC,UAAU,CAAA;OACnC,CAAC,CAAC;SACJ;QAED,IAAI,aAAa,EAAE;YACjB,IAAI,qBAAqB,CAAC,GAAG,CAAC,aAAa,CAAC,EAAE;gBAC5C,IAAI,CAAC,aAAa,GAAG,aAAa,CAAC;aACpC,MAAM;gBACL,MAAM,IAAI,ySAAU,CAAC,CAAA,iCAAA,EACjB,aAAa,CAAA,mBAAA,CAAqB,CAAC,CAAC;aACzC;SACF;IACH,CAAC;IAEQ,SAAS,GAAA;QAChB,MAAM,MAAM,GAA6B;YACvC,QAAQ,EAAE,IAAI,CAAC,MAAM;YACrB,eAAe,EAAE,IAAI,CAAC,aAAa;SACpC,CAAC;QAEF,MAAM,UAAU,GAAG,KAAK,CAAC,SAAS,EAAE,CAAC;QACrC,MAAM,CAAC,MAAM,CAAC,MAAM,EAAE,UAAU,CAAC,CAAC;QAClC,OAAO,MAAM,CAAC;IAChB,CAAC;IAEQ,kBAAkB,CAAC,UAAyB,EAAA;QACnD,UAAU,OAAG,+TAAkB,EAAC,UAAU,CAAC,CAAC;QAC5C,MAAM,WAAW,GAAG,UAAU,CAAC,CAAC,CAAC,CAAC;QAClC,OAAO;YAAC,IAAI,CAAC,SAAS;YAAE,CAAC,CAAC;YAAE,WAAW;SAAC,CAAC;IAC3C,CAAC;IAEQ,IAAI,CAAC,MAAuC,EACnD,MAAc,EAAA;QAEd,WAAO,iPAAI,EAAC,GAAG,EAAE;YACf,MAAM,KAAK,OAAG,gUAAmB,EAAC,MAAM,CAAC,CAAC;YAC1C,IAAI,CAAC,SAAS,GAAG,KAAK,CAAC,KAAK,CAAC,KAAK,CAAC,KAAK,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;YACrD,MAAM,QAAQ,GAAG,KAAK,CAAC,KAAK,CAAC,KAAK,CAAC,KAAK,CAAC,MAAM,GAAG,CAAC,CAAC,CAAC;YAErD,IAAI,CAAC,WAAW,OAAG,wQAAa,EAAC;gBAAC,CAAC;aAAC,EAClC,AAAC,GAAG,GAAG,IAAI,CAAC,UAAU,CAAC,CAAG,CAAD,EAAI,GAAG,IAAI,CAAC,UAAU,CAAC,CAChD,SAAS,EAAE,IAAI,CAAC,eAAe,CAAC,IAAI,EAAE,CACvC,CAAC;YAEF,IAAI,aAAa,GAAG,IAAI,CAAC,WAAW,CAAC,QAAQ,EAAE,CAAC,CAAC,CAAC,GAAG,QAAQ,CAAC;YAC9D,aAAa,GAAG,IAAI,CAAC,KAAK,CAAC,aAAa,CAAC,CAAC;YAE1C,MAAM,IAAI,GAAoB;gBAAC,IAAI,CAAC,SAAS;gBAAE,aAAa;aAAC,CAAC;YAE9D,OAAQ,IAAI,CAAC,aAAa,EAAE;gBAC1B,KAAK,UAAU;oBACb,OAAO,qQAAK,CAAC,cAAc,CAAC,MAAM,EAAE,IAAI,CAAC,CAAC;gBAC5C,KAAK,SAAS;oBACZ,OAAO,qQAAK,CAAC,qBAAqB,CAAC,MAAM,EAAE,IAAI,CAAC,CAAC;gBACnD;oBACE,MAAM,IAAI,KAAK,CAAC,CAAA,iBAAA,EAAoB,IAAI,CAAC,aAAa,CAAA;qBAC3C,CAAC;2BAAG,qBAAqB;qBAAC,CAAA,cAAA,CAAgB,CAAC,CAAC;aAC1D;QACH,CAAC,CAAC,CAAC;IACL,CAAC;;AA/FD,gBAAA,EAAkB,CACF,YAAA,SAAS,GAAG,aAAa,CAAC;;AAiG5C,ySAAa,CAAC,aAAa,CAAC,WAAW,CAAC,CAAC"}}]
}